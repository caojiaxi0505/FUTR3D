2025-06-10 07:15:06,997 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090 D
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0+cu116
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0+cu116
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+91e369b
spconv2.0: True
------------------------------------------------------------

2025-06-10 07:15:08,555 - mmdet - INFO - 分布式训练: True
2025-06-10 07:15:10,094 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['points', 'img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points', 'img'])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
checkpoint_config = dict(interval=1, max_keep_ckpts=10)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2/fuse_model'
load_from = 'pretrained/fuse_forced.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[57.375, 57.12, 58.395], to_rgb=False)
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_grid_mask=True,
    freeze_backbone=True,
    img_backbone=dict(
        type='VoVNet',
        spec_name='V-99-eSE',
        norm_eval=True,
        frozen_stages=-1,
        input_ch=3,
        out_features=['stage2', 'stage3', 'stage4', 'stage5']),
    img_neck=dict(
        type='FPN',
        in_channels=[256, 512, 768, 1024],
        out_channels=256,
        start_level=0,
        add_extra_convs='on_output',
        num_outs=4,
        relu_before_extra_convs=True),
    pts_voxel_layer=dict(
        max_num_points=-1,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(-1, -1),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(
        type='DynamicVFE',
        in_channels=5,
        feat_channels=[64, 128],
        with_distance=False,
        with_cluster_center=True,
        with_voxel_center=True,
        voxel_size=[0.075, 0.075, 0.2],
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_middle_encoder=dict(
        type='HEDNet',
        in_channels=128,
        sparse_shape=[41, 1440, 1440],
        model_cfg=dict(
            FEATURE_DIM=128,
            NUM_LAYERS=2,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDE=[1, 2, 2],
            DOWN_KERNEL_SIZE=[3, 3, 3])),
    pts_backbone=dict(
        type='CascadeDEDBackbone',
        in_channels=256,
        model_cfg=dict(
            USE_SECONDMAMBA=False,
            FEATURE_DIM=256,
            NUM_LAYERS=4,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDES=[1, 2, 2])),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        dss_date_version='0511',
        dss_drop_prob=0.3,
        dss_mamba_version='DSSMamba_Huge_EP2',
        dss_num_layers=2,
        dss_use_morton=True,
        dss_use_conv=True,
        dss_use_xy=True,
        dss_use_rope=True,
        dss_stack=True,
        dss_strong_cls=True,
        anchor_size=3,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='FUTR3DAttention',
                            use_lidar=True,
                            use_camera=True,
                            use_radar=False,
                            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
db_sampler = dict(
    data_root='data/nuscenes/',
    info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
    rate=1.0,
    prepare=dict(
        filter_by_difficulty=[-1],
        filter_by_min_points=dict(
            car=5,
            truck=5,
            bus=5,
            trailer=5,
            construction_vehicle=5,
            traffic_cone=5,
            barrier=5,
            motorcycle=5,
            bicycle=5,
            pedestrian=5)),
    classes=[
        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
    ],
    sample_groups=dict(
        car=2,
        truck=3,
        construction_vehicle=7,
        bus=4,
        trailer=6,
        barrier=2,
        motorcycle=6,
        bicycle=6,
        pedestrian=2,
        traffic_cone=2),
    points_loader=dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk')))
find_unused_parameters = True
runner = dict(type='EpochBasedRunner', max_epochs=6)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    paramwise_cfg=dict(
        custom_keys=dict(
            img_backbone=dict(lr_mult=0.1),
            img_neck=dict(lr_mult=0.1),
            pts_middle_encoder=dict(lr_mult=0.1),
            pts_backbone=dict(lr_mult=0.1),
            pts_neck=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
gpu_ids = range(0, 2)

2025-06-10 07:15:10,096 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-06-10 07:15:12,344 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-06-10 07:15:12,998 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_voxel_encoder.vfe_layers.0.0.weight - torch.Size([64, 11]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.0.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.0.weight - torch.Size([16, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.0.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.0.weight - torch.Size([32, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.3.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.0.weight - torch.Size([64, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.0.weight - torch.Size([128, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.3.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/conv.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/conv.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/conv.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.ese.fc.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.ese.fc.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/conv.weight - torch.Size([160, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/conv.weight - torch.Size([512, 1056, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/conv.weight - torch.Size([160, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/conv.weight - torch.Size([512, 1312, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/conv.weight - torch.Size([160, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/conv.weight - torch.Size([512, 1312, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/conv.weight - torch.Size([192, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/conv.weight - torch.Size([768, 1472, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/conv.weight - torch.Size([224, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/conv.weight - torch.Size([1024, 1888, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/conv.weight - torch.Size([224, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/conv.weight - torch.Size([1024, 2144, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/conv.weight - torch.Size([224, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/conv.weight - torch.Size([1024, 2144, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.2.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.3.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-06-10 07:15:13,048 - mmdet - INFO - Model:
FUTR3D(
  (grid_mask): GridMask()
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=-1, max_voxels=(-1, -1), deterministic=True)
  (pts_voxel_encoder): DynamicVFE(
    (scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
    (vfe_layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=11, out_features=64, bias=False)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (vfe_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=False)
    (cluster_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
  )
  (pts_middle_encoder): HEDNet(
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SubMConv3d(128, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (3): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv2): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv3): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[1, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (layers): ModuleList(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (4): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU()
    )
  )
  (pts_backbone): CascadeDEDBackbone(
    (layers): ModuleList(
      (0): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (2): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (3): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (1): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (2): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (3): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (4): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (5): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
  )
  (img_backbone): VoVNet(
    (stem): Sequential(
      (stem_1/conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (stem_1/norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_1/relu): ReLU(inplace=True)
      (stem_2/conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (stem_2/norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_2/relu): ReLU(inplace=True)
      (stem_3/conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (stem_3/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_3/relu): ReLU(inplace=True)
    )
    (stage2): _OSA_stage(
      (OSA2_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA2_1_0/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_0/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA2_1_1/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_1/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA2_1_2/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_2/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA2_1_3/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_3/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA2_1_4/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_4/norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA2_1_concat/conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA2_1_concat/norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA2_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage3): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA3_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_1_0/conv): Conv2d(256, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_0/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_1_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_1/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_1_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_2/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_1_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_3/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_1_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_4/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_1_concat/conv): Conv2d(1056, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_1_concat/norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA3_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_2_0/conv): Conv2d(512, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_0/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_2_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_1/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_2_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_2/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_2_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_3/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_2_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_4/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_2_concat/conv): Conv2d(1312, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_2_concat/norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA3_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_3_0/conv): Conv2d(512, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_0/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_3_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_1/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_3_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_2/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_3_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_3/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_3_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_4/norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_3_concat/conv): Conv2d(1312, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_3_concat/norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage4): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA4_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_1_0/conv): Conv2d(512, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_1_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_1_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_1_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_1_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_1_concat/conv): Conv2d(1472, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_1_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_2_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_2_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_2_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_2_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_2_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_2_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_2_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_3_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_3_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_3_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_3_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_3_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_3_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_3_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_4): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_4_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_4_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_4_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_4_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_4_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_4_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_4_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_4_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_5): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_5_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_5_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_5_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_5_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_5_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_5_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_5_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_5_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_6): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_6_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_6_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_6_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_6_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_6_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_6_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_6_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_6_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_7): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_7_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_7_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_7_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_7_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_7_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_7_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_7_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_7_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_8): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_8_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_8_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_8_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_8_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_8_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_8_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_8_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_8_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_9): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_9_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_0/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_9_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_1/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_9_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_2/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_9_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_3/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_9_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_4/norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_9_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_9_concat/norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_9_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage5): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA5_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_1_0/conv): Conv2d(768, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_0/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_1_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_1/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_1_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_2/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_1_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_3/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_1_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_4/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_1_concat/conv): Conv2d(1888, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_1_concat/norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA5_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_2_0/conv): Conv2d(1024, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_0/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_2_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_1/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_2_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_2/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_2_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_3/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_2_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_4/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_2_concat/conv): Conv2d(2144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_2_concat/norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA5_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_3_0/conv): Conv2d(1024, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_0/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_3_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_1/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_3_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_2/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_3_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_3/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_3_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_4/norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_3_concat/conv): Conv2d(2144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_3_concat/norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
  )
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
)
2025-06-10 07:15:51,547 - mmdet - INFO - load checkpoint from local path: pretrained/fuse_forced.pth
2025-06-10 07:16:19,869 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.code_weights, pts_bbox_head.query_embedding.weight, pts_bbox_head.aux_head.shared_conv.conv.weight, pts_bbox_head.aux_head.shared_conv.bn.weight, pts_bbox_head.aux_head.shared_conv.bn.bias, pts_bbox_head.aux_head.shared_conv.bn.running_mean, pts_bbox_head.aux_head.shared_conv.bn.running_var, pts_bbox_head.aux_head.shared_conv.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.1.weight, pts_bbox_head.aux_head.task_heads.0.reg.1.bias, pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.height.1.weight, pts_bbox_head.aux_head.task_heads.0.height.1.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.dim.1.weight, pts_bbox_head.aux_head.task_heads.0.dim.1.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.rot.1.weight, pts_bbox_head.aux_head.task_heads.0.rot.1.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.vel.1.weight, pts_bbox_head.aux_head.task_heads.0.vel.1.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.reg.1.weight, pts_bbox_head.aux_head.task_heads.1.reg.1.bias, pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.height.1.weight, pts_bbox_head.aux_head.task_heads.1.height.1.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.dim.1.weight, pts_bbox_head.aux_head.task_heads.1.dim.1.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.rot.1.weight, pts_bbox_head.aux_head.task_heads.1.rot.1.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.vel.1.weight, pts_bbox_head.aux_head.task_heads.1.vel.1.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.reg.1.weight, pts_bbox_head.aux_head.task_heads.2.reg.1.bias, pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.height.1.weight, pts_bbox_head.aux_head.task_heads.2.height.1.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.dim.1.weight, pts_bbox_head.aux_head.task_heads.2.dim.1.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.rot.1.weight, pts_bbox_head.aux_head.task_heads.2.rot.1.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.vel.1.weight, pts_bbox_head.aux_head.task_heads.2.vel.1.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.reg.1.weight, pts_bbox_head.aux_head.task_heads.3.reg.1.bias, pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.height.1.weight, pts_bbox_head.aux_head.task_heads.3.height.1.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.dim.1.weight, pts_bbox_head.aux_head.task_heads.3.dim.1.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.rot.1.weight, pts_bbox_head.aux_head.task_heads.3.rot.1.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.vel.1.weight, pts_bbox_head.aux_head.task_heads.3.vel.1.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.reg.1.weight, pts_bbox_head.aux_head.task_heads.4.reg.1.bias, pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.height.1.weight, pts_bbox_head.aux_head.task_heads.4.height.1.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.dim.1.weight, pts_bbox_head.aux_head.task_heads.4.dim.1.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.rot.1.weight, pts_bbox_head.aux_head.task_heads.4.rot.1.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.vel.1.weight, pts_bbox_head.aux_head.task_heads.4.vel.1.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.reg.1.weight, pts_bbox_head.aux_head.task_heads.5.reg.1.bias, pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.height.1.weight, pts_bbox_head.aux_head.task_heads.5.height.1.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.dim.1.weight, pts_bbox_head.aux_head.task_heads.5.dim.1.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.rot.1.weight, pts_bbox_head.aux_head.task_heads.5.rot.1.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.vel.1.weight, pts_bbox_head.aux_head.task_heads.5.vel.1.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.sin_cached, pts_bbox_head.cls_branches.0.0.weight, pts_bbox_head.cls_branches.0.0.bias, pts_bbox_head.cls_branches.0.1.weight, pts_bbox_head.cls_branches.0.1.bias, pts_bbox_head.cls_branches.0.3.weight, pts_bbox_head.cls_branches.0.3.bias, pts_bbox_head.cls_branches.0.4.weight, pts_bbox_head.cls_branches.0.4.bias, pts_bbox_head.cls_branches.0.6.weight, pts_bbox_head.cls_branches.0.6.bias, pts_bbox_head.cls_branches.1.0.weight, pts_bbox_head.cls_branches.1.0.bias, pts_bbox_head.cls_branches.1.1.weight, pts_bbox_head.cls_branches.1.1.bias, pts_bbox_head.cls_branches.1.3.weight, pts_bbox_head.cls_branches.1.3.bias, pts_bbox_head.cls_branches.1.4.weight, pts_bbox_head.cls_branches.1.4.bias, pts_bbox_head.cls_branches.1.6.weight, pts_bbox_head.cls_branches.1.6.bias, pts_bbox_head.cls_branches.2.0.weight, pts_bbox_head.cls_branches.2.0.bias, pts_bbox_head.cls_branches.2.1.weight, pts_bbox_head.cls_branches.2.1.bias, pts_bbox_head.cls_branches.2.3.weight, pts_bbox_head.cls_branches.2.3.bias, pts_bbox_head.cls_branches.2.4.weight, pts_bbox_head.cls_branches.2.4.bias, pts_bbox_head.cls_branches.2.6.weight, pts_bbox_head.cls_branches.2.6.bias, pts_bbox_head.cls_branches.3.0.weight, pts_bbox_head.cls_branches.3.0.bias, pts_bbox_head.cls_branches.3.1.weight, pts_bbox_head.cls_branches.3.1.bias, pts_bbox_head.cls_branches.3.3.weight, pts_bbox_head.cls_branches.3.3.bias, pts_bbox_head.cls_branches.3.4.weight, pts_bbox_head.cls_branches.3.4.bias, pts_bbox_head.cls_branches.3.6.weight, pts_bbox_head.cls_branches.3.6.bias, pts_bbox_head.cls_branches.4.0.weight, pts_bbox_head.cls_branches.4.0.bias, pts_bbox_head.cls_branches.4.1.weight, pts_bbox_head.cls_branches.4.1.bias, pts_bbox_head.cls_branches.4.3.weight, pts_bbox_head.cls_branches.4.3.bias, pts_bbox_head.cls_branches.4.4.weight, pts_bbox_head.cls_branches.4.4.bias, pts_bbox_head.cls_branches.4.6.weight, pts_bbox_head.cls_branches.4.6.bias, pts_bbox_head.cls_branches.5.0.weight, pts_bbox_head.cls_branches.5.0.bias, pts_bbox_head.cls_branches.5.1.weight, pts_bbox_head.cls_branches.5.1.bias, pts_bbox_head.cls_branches.5.3.weight, pts_bbox_head.cls_branches.5.3.bias, pts_bbox_head.cls_branches.5.4.weight, pts_bbox_head.cls_branches.5.4.bias, pts_bbox_head.cls_branches.5.6.weight, pts_bbox_head.cls_branches.5.6.bias

missing keys in source state_dict: pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias

2025-06-10 07:16:19,898 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2/fuse_model
2025-06-10 07:16:19,901 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-06-10 07:16:19,904 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-06-10 07:16:19,907 - mmdet - INFO - Checkpoints will be saved to /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2/fuse_model by HardDiskBackend.
2025-06-10 07:18:11,713 - mmdet - INFO - Epoch [1][50/7033]	lr: 3.987e-05, eta: 1 day, 2:00:46, time: 2.222, data_time: 0.238, memory: 17915, loss_cls: 1.0427, loss_bbox: 1.5721, d0.loss_cls: 1.1127, d0.loss_bbox: 1.6457, d1.loss_cls: 1.1267, d1.loss_bbox: 1.5911, d2.loss_cls: 1.0662, d2.loss_bbox: 1.5715, d3.loss_cls: 1.0550, d3.loss_bbox: 1.5648, d4.loss_cls: 1.0385, d4.loss_bbox: 1.5370, loss: 15.9240, grad_norm: 19.6339
2025-06-10 07:19:38,185 - mmdet - INFO - Epoch [1][100/7033]	lr: 4.653e-05, eta: 23:06:10, time: 1.729, data_time: 0.051, memory: 18055, loss_cls: 0.8234, loss_bbox: 1.2493, d0.loss_cls: 0.9496, d0.loss_bbox: 1.4329, d1.loss_cls: 0.8953, d1.loss_bbox: 1.3286, d2.loss_cls: 0.8338, d2.loss_bbox: 1.2971, d3.loss_cls: 0.8440, d3.loss_bbox: 1.2635, d4.loss_cls: 0.8141, d4.loss_bbox: 1.2492, loss: 12.9809, grad_norm: 16.2341
2025-06-10 07:21:03,902 - mmdet - INFO - Epoch [1][150/7033]	lr: 5.320e-05, eta: 22:03:18, time: 1.714, data_time: 0.052, memory: 18055, loss_cls: 0.7095, loss_bbox: 1.1535, d0.loss_cls: 0.8601, d0.loss_bbox: 1.3661, d1.loss_cls: 0.7722, d1.loss_bbox: 1.2448, d2.loss_cls: 0.7161, d2.loss_bbox: 1.2002, d3.loss_cls: 0.7215, d3.loss_bbox: 1.1673, d4.loss_cls: 0.6960, d4.loss_bbox: 1.1461, loss: 11.7533, grad_norm: 15.0712
2025-06-10 07:22:27,710 - mmdet - INFO - Epoch [1][200/7033]	lr: 5.987e-05, eta: 21:24:42, time: 1.677, data_time: 0.072, memory: 18055, loss_cls: 0.6503, loss_bbox: 1.1144, d0.loss_cls: 0.8094, d0.loss_bbox: 1.3272, d1.loss_cls: 0.6996, d1.loss_bbox: 1.1912, d2.loss_cls: 0.6524, d2.loss_bbox: 1.1501, d3.loss_cls: 0.6569, d3.loss_bbox: 1.1303, d4.loss_cls: 0.6339, d4.loss_bbox: 1.1045, loss: 11.1201, grad_norm: 11.6929
2025-06-10 07:23:50,356 - mmdet - INFO - Epoch [1][250/7033]	lr: 6.653e-05, eta: 20:57:39, time: 1.653, data_time: 0.049, memory: 18055, loss_cls: 0.6027, loss_bbox: 1.0492, d0.loss_cls: 0.7786, d0.loss_bbox: 1.2701, d1.loss_cls: 0.6364, d1.loss_bbox: 1.1203, d2.loss_cls: 0.6067, d2.loss_bbox: 1.0802, d3.loss_cls: 0.6170, d3.loss_bbox: 1.0660, d4.loss_cls: 0.5895, d4.loss_bbox: 1.0455, loss: 10.4624, grad_norm: 12.0906
2025-06-10 07:25:17,693 - mmdet - INFO - Epoch [1][300/7033]	lr: 7.320e-05, eta: 20:50:05, time: 1.747, data_time: 0.071, memory: 18055, loss_cls: 0.5142, loss_bbox: 0.9998, d0.loss_cls: 0.7358, d0.loss_bbox: 1.2205, d1.loss_cls: 0.5333, d1.loss_bbox: 1.0495, d2.loss_cls: 0.5039, d2.loss_bbox: 1.0211, d3.loss_cls: 0.5188, d3.loss_bbox: 1.0044, d4.loss_cls: 0.4983, d4.loss_bbox: 0.9873, loss: 9.5868, grad_norm: 13.7673
2025-06-10 07:26:40,075 - mmdet - INFO - Epoch [1][350/7033]	lr: 7.987e-05, eta: 20:34:23, time: 1.648, data_time: 0.050, memory: 18055, loss_cls: 0.4047, loss_bbox: 0.9646, d0.loss_cls: 0.6702, d0.loss_bbox: 1.2000, d1.loss_cls: 0.4412, d1.loss_bbox: 1.0089, d2.loss_cls: 0.3992, d2.loss_bbox: 0.9760, d3.loss_cls: 0.4050, d3.loss_bbox: 0.9718, d4.loss_cls: 0.3984, d4.loss_bbox: 0.9518, loss: 8.7920, grad_norm: 15.4554
2025-06-10 07:28:21,769 - mmdet - INFO - Epoch [1][400/7033]	lr: 8.653e-05, eta: 20:55:54, time: 2.034, data_time: 0.109, memory: 18090, loss_cls: 0.3186, loss_bbox: 0.8896, d0.loss_cls: 0.5747, d0.loss_bbox: 1.1469, d1.loss_cls: 0.3618, d1.loss_bbox: 0.9241, d2.loss_cls: 0.3326, d2.loss_bbox: 0.8833, d3.loss_cls: 0.3235, d3.loss_bbox: 0.8802, d4.loss_cls: 0.3162, d4.loss_bbox: 0.8745, loss: 7.8261, grad_norm: 19.5497
2025-06-10 07:29:49,909 - mmdet - INFO - Epoch [1][450/7033]	lr: 9.320e-05, eta: 20:51:17, time: 1.763, data_time: 0.053, memory: 18090, loss_cls: 0.2866, loss_bbox: 0.7707, d0.loss_cls: 0.4730, d0.loss_bbox: 1.0648, d1.loss_cls: 0.3150, d1.loss_bbox: 0.7803, d2.loss_cls: 0.2887, d2.loss_bbox: 0.7612, d3.loss_cls: 0.2811, d3.loss_bbox: 0.7675, d4.loss_cls: 0.2765, d4.loss_bbox: 0.7631, loss: 6.8283, grad_norm: 20.2029
2025-06-10 07:31:17,731 - mmdet - INFO - Epoch [1][500/7033]	lr: 9.987e-05, eta: 20:46:52, time: 1.756, data_time: 0.059, memory: 18090, loss_cls: 0.2342, loss_bbox: 0.6383, d0.loss_cls: 0.3992, d0.loss_bbox: 0.9794, d1.loss_cls: 0.2746, d1.loss_bbox: 0.6537, d2.loss_cls: 0.2466, d2.loss_bbox: 0.6354, d3.loss_cls: 0.2333, d3.loss_bbox: 0.6420, d4.loss_cls: 0.2306, d4.loss_bbox: 0.6282, loss: 5.7954, grad_norm: 19.9105
2025-06-10 07:32:45,779 - mmdet - INFO - Epoch [1][550/7033]	lr: 1.000e-04, eta: 20:43:07, time: 1.759, data_time: 0.083, memory: 18143, loss_cls: 0.2036, loss_bbox: 0.5250, d0.loss_cls: 0.3194, d0.loss_bbox: 0.8446, d1.loss_cls: 0.2304, d1.loss_bbox: 0.5308, d2.loss_cls: 0.2087, d2.loss_bbox: 0.5154, d3.loss_cls: 0.2007, d3.loss_bbox: 0.5235, d4.loss_cls: 0.1985, d4.loss_bbox: 0.5093, loss: 4.8098, grad_norm: 30.1833
2025-06-10 07:34:13,338 - mmdet - INFO - Epoch [1][600/7033]	lr: 1.000e-04, eta: 20:39:28, time: 1.753, data_time: 0.075, memory: 18338, loss_cls: 0.1876, loss_bbox: 0.4570, d0.loss_cls: 0.2747, d0.loss_bbox: 0.7926, d1.loss_cls: 0.2143, d1.loss_bbox: 0.4645, d2.loss_cls: 0.1871, d2.loss_bbox: 0.4611, d3.loss_cls: 0.1826, d3.loss_bbox: 0.4635, d4.loss_cls: 0.1855, d4.loss_bbox: 0.4541, loss: 4.3244, grad_norm: 21.6193
2025-06-10 07:35:42,348 - mmdet - INFO - Epoch [1][650/7033]	lr: 1.000e-04, eta: 20:37:35, time: 1.780, data_time: 0.052, memory: 18338, loss_cls: 0.1814, loss_bbox: 0.4362, d0.loss_cls: 0.2542, d0.loss_bbox: 0.7400, d1.loss_cls: 0.2033, d1.loss_bbox: 0.4220, d2.loss_cls: 0.1769, d2.loss_bbox: 0.4271, d3.loss_cls: 0.1697, d3.loss_bbox: 0.4252, d4.loss_cls: 0.1762, d4.loss_bbox: 0.4278, loss: 4.0400, grad_norm: 35.5890
2025-06-10 07:37:09,406 - mmdet - INFO - Epoch [1][700/7033]	lr: 1.000e-04, eta: 20:33:49, time: 1.741, data_time: 0.058, memory: 18338, loss_cls: 0.1732, loss_bbox: 0.4151, d0.loss_cls: 0.2427, d0.loss_bbox: 0.6614, d1.loss_cls: 0.1985, d1.loss_bbox: 0.3890, d2.loss_cls: 0.1695, d2.loss_bbox: 0.3859, d3.loss_cls: 0.1631, d3.loss_bbox: 0.3960, d4.loss_cls: 0.1687, d4.loss_bbox: 0.4076, loss: 3.7706, grad_norm: 36.2589
2025-06-10 07:38:36,751 - mmdet - INFO - Epoch [1][750/7033]	lr: 1.000e-04, eta: 20:30:35, time: 1.746, data_time: 0.054, memory: 18338, loss_cls: 0.1656, loss_bbox: 0.4077, d0.loss_cls: 0.2354, d0.loss_bbox: 0.6209, d1.loss_cls: 0.1890, d1.loss_bbox: 0.3875, d2.loss_cls: 0.1615, d2.loss_bbox: 0.3771, d3.loss_cls: 0.1583, d3.loss_bbox: 0.3825, d4.loss_cls: 0.1628, d4.loss_bbox: 0.3952, loss: 3.6435, grad_norm: 34.1010
2025-06-10 07:40:04,568 - mmdet - INFO - Epoch [1][800/7033]	lr: 1.000e-04, eta: 20:28:03, time: 1.757, data_time: 0.055, memory: 18338, loss_cls: 0.1676, loss_bbox: 0.3903, d0.loss_cls: 0.2337, d0.loss_bbox: 0.5620, d1.loss_cls: 0.1865, d1.loss_bbox: 0.3633, d2.loss_cls: 0.1587, d2.loss_bbox: 0.3546, d3.loss_cls: 0.1532, d3.loss_bbox: 0.3645, d4.loss_cls: 0.1613, d4.loss_bbox: 0.3795, loss: 3.4752, grad_norm: 34.6940
2025-06-10 07:41:34,816 - mmdet - INFO - Epoch [1][850/7033]	lr: 1.000e-04, eta: 20:27:35, time: 1.805, data_time: 0.060, memory: 18338, loss_cls: 0.1482, loss_bbox: 0.3851, d0.loss_cls: 0.2219, d0.loss_bbox: 0.5392, d1.loss_cls: 0.1773, d1.loss_bbox: 0.3586, d2.loss_cls: 0.1470, d2.loss_bbox: 0.3440, d3.loss_cls: 0.1396, d3.loss_bbox: 0.3522, d4.loss_cls: 0.1412, d4.loss_bbox: 0.3721, loss: 3.3265, grad_norm: 46.4938
2025-06-10 07:43:04,418 - mmdet - INFO - Epoch [1][900/7033]	lr: 1.000e-04, eta: 20:26:27, time: 1.791, data_time: 0.076, memory: 18338, loss_cls: 0.1537, loss_bbox: 0.3741, d0.loss_cls: 0.2192, d0.loss_bbox: 0.5211, d1.loss_cls: 0.1737, d1.loss_bbox: 0.3529, d2.loss_cls: 0.1469, d2.loss_bbox: 0.3384, d3.loss_cls: 0.1427, d3.loss_bbox: 0.3452, d4.loss_cls: 0.1489, d4.loss_bbox: 0.3595, loss: 3.2761, grad_norm: 29.4605
2025-06-10 07:44:29,127 - mmdet - INFO - Epoch [1][950/7033]	lr: 1.000e-04, eta: 20:21:50, time: 1.696, data_time: 0.057, memory: 18338, loss_cls: 0.1322, loss_bbox: 0.3616, d0.loss_cls: 0.2076, d0.loss_bbox: 0.5011, d1.loss_cls: 0.1577, d1.loss_bbox: 0.3464, d2.loss_cls: 0.1314, d2.loss_bbox: 0.3252, d3.loss_cls: 0.1258, d3.loss_bbox: 0.3296, d4.loss_cls: 0.1265, d4.loss_bbox: 0.3475, loss: 3.0925, grad_norm: 36.3375
2025-06-10 07:45:55,511 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 07:45:55,512 - mmdet - INFO - Epoch [1][1000/7033]	lr: 1.000e-04, eta: 20:18:39, time: 1.728, data_time: 0.075, memory: 18338, loss_cls: 0.1231, loss_bbox: 0.3312, d0.loss_cls: 0.1986, d0.loss_bbox: 0.4682, d1.loss_cls: 0.1515, d1.loss_bbox: 0.3221, d2.loss_cls: 0.1259, d2.loss_bbox: 0.3000, d3.loss_cls: 0.1188, d3.loss_bbox: 0.3057, d4.loss_cls: 0.1212, d4.loss_bbox: 0.3199, loss: 2.8861, grad_norm: 37.0142
2025-06-10 07:47:23,718 - mmdet - INFO - Epoch [1][1050/7033]	lr: 1.000e-04, eta: 20:16:49, time: 1.764, data_time: 0.074, memory: 18338, loss_cls: 0.1303, loss_bbox: 0.3415, d0.loss_cls: 0.2083, d0.loss_bbox: 0.4811, d1.loss_cls: 0.1606, d1.loss_bbox: 0.3344, d2.loss_cls: 0.1328, d2.loss_bbox: 0.3127, d3.loss_cls: 0.1252, d3.loss_bbox: 0.3170, d4.loss_cls: 0.1282, d4.loss_bbox: 0.3297, loss: 3.0019, grad_norm: 31.0462
2025-06-10 07:48:50,548 - mmdet - INFO - Epoch [1][1100/7033]	lr: 1.000e-04, eta: 20:14:10, time: 1.737, data_time: 0.058, memory: 18338, loss_cls: 0.1301, loss_bbox: 0.3247, d0.loss_cls: 0.2056, d0.loss_bbox: 0.4520, d1.loss_cls: 0.1518, d1.loss_bbox: 0.3256, d2.loss_cls: 0.1281, d2.loss_bbox: 0.3025, d3.loss_cls: 0.1202, d3.loss_bbox: 0.3059, d4.loss_cls: 0.1261, d4.loss_bbox: 0.3159, loss: 2.8886, grad_norm: 29.2800
2025-06-10 07:50:16,929 - mmdet - INFO - Epoch [1][1150/7033]	lr: 1.000e-04, eta: 20:11:21, time: 1.728, data_time: 0.052, memory: 18338, loss_cls: 0.1332, loss_bbox: 0.3334, d0.loss_cls: 0.2082, d0.loss_bbox: 0.4522, d1.loss_cls: 0.1632, d1.loss_bbox: 0.3204, d2.loss_cls: 0.1368, d2.loss_bbox: 0.2996, d3.loss_cls: 0.1272, d3.loss_bbox: 0.3076, d4.loss_cls: 0.1292, d4.loss_bbox: 0.3199, loss: 2.9309, grad_norm: 66.6765
2025-06-10 07:51:43,325 - mmdet - INFO - Epoch [1][1200/7033]	lr: 1.000e-04, eta: 20:08:38, time: 1.727, data_time: 0.054, memory: 18338, loss_cls: 0.1295, loss_bbox: 0.3543, d0.loss_cls: 0.2057, d0.loss_bbox: 0.4604, d1.loss_cls: 0.1524, d1.loss_bbox: 0.3416, d2.loss_cls: 0.1329, d2.loss_bbox: 0.3135, d3.loss_cls: 0.1276, d3.loss_bbox: 0.3221, d4.loss_cls: 0.1264, d4.loss_bbox: 0.3392, loss: 3.0056, grad_norm: 33.3604
2025-06-10 07:53:11,296 - mmdet - INFO - Epoch [1][1250/7033]	lr: 1.000e-04, eta: 20:06:55, time: 1.760, data_time: 0.053, memory: 18338, loss_cls: 0.1317, loss_bbox: 0.3348, d0.loss_cls: 0.2080, d0.loss_bbox: 0.4411, d1.loss_cls: 0.1527, d1.loss_bbox: 0.3334, d2.loss_cls: 0.1350, d2.loss_bbox: 0.3115, d3.loss_cls: 0.1311, d3.loss_bbox: 0.3120, d4.loss_cls: 0.1288, d4.loss_bbox: 0.3230, loss: 2.9432, grad_norm: 160.3592
2025-06-10 07:54:38,723 - mmdet - INFO - Epoch [1][1300/7033]	lr: 1.000e-04, eta: 20:04:55, time: 1.748, data_time: 0.053, memory: 18338, loss_cls: 0.1208, loss_bbox: 0.3229, d0.loss_cls: 0.1919, d0.loss_bbox: 0.4284, d1.loss_cls: 0.1470, d1.loss_bbox: 0.3216, d2.loss_cls: 0.1283, d2.loss_bbox: 0.2961, d3.loss_cls: 0.1183, d3.loss_bbox: 0.3001, d4.loss_cls: 0.1168, d4.loss_bbox: 0.3121, loss: 2.8043, grad_norm: 27.2350
2025-06-10 07:56:06,545 - mmdet - INFO - Epoch [1][1350/7033]	lr: 1.000e-04, eta: 20:03:10, time: 1.757, data_time: 0.056, memory: 18338, loss_cls: 0.1201, loss_bbox: 0.3176, d0.loss_cls: 0.1884, d0.loss_bbox: 0.4274, d1.loss_cls: 0.1406, d1.loss_bbox: 0.3219, d2.loss_cls: 0.1200, d2.loss_bbox: 0.2969, d3.loss_cls: 0.1132, d3.loss_bbox: 0.2979, d4.loss_cls: 0.1148, d4.loss_bbox: 0.3062, loss: 2.7652, grad_norm: 37.4004
2025-06-10 07:57:34,108 - mmdet - INFO - Epoch [1][1400/7033]	lr: 1.000e-04, eta: 20:01:19, time: 1.752, data_time: 0.053, memory: 18338, loss_cls: 0.1210, loss_bbox: 0.3071, d0.loss_cls: 0.1978, d0.loss_bbox: 0.4135, d1.loss_cls: 0.1482, d1.loss_bbox: 0.3082, d2.loss_cls: 0.1238, d2.loss_bbox: 0.2845, d3.loss_cls: 0.1170, d3.loss_bbox: 0.2877, d4.loss_cls: 0.1158, d4.loss_bbox: 0.2984, loss: 2.7230, grad_norm: 72.6810
2025-06-10 07:59:01,433 - mmdet - INFO - Epoch [1][1450/7033]	lr: 1.000e-04, eta: 19:59:22, time: 1.746, data_time: 0.069, memory: 18338, loss_cls: 0.1188, loss_bbox: 0.3096, d0.loss_cls: 0.1892, d0.loss_bbox: 0.4147, d1.loss_cls: 0.1459, d1.loss_bbox: 0.3092, d2.loss_cls: 0.1245, d2.loss_bbox: 0.2868, d3.loss_cls: 0.1159, d3.loss_bbox: 0.2882, d4.loss_cls: 0.1156, d4.loss_bbox: 0.2988, loss: 2.7171, grad_norm: 23.8559
2025-06-10 08:00:25,917 - mmdet - INFO - Epoch [1][1500/7033]	lr: 1.000e-04, eta: 19:56:10, time: 1.690, data_time: 0.060, memory: 18338, loss_cls: 0.1180, loss_bbox: 0.2975, d0.loss_cls: 0.1898, d0.loss_bbox: 0.4160, d1.loss_cls: 0.1400, d1.loss_bbox: 0.3088, d2.loss_cls: 0.1205, d2.loss_bbox: 0.2825, d3.loss_cls: 0.1127, d3.loss_bbox: 0.2821, d4.loss_cls: 0.1134, d4.loss_bbox: 0.2886, loss: 2.6700, grad_norm: 35.3833
2025-06-10 08:01:51,039 - mmdet - INFO - Epoch [1][1550/7033]	lr: 1.000e-04, eta: 19:53:21, time: 1.702, data_time: 0.060, memory: 18338, loss_cls: 0.1135, loss_bbox: 0.2999, d0.loss_cls: 0.1936, d0.loss_bbox: 0.4049, d1.loss_cls: 0.1377, d1.loss_bbox: 0.3060, d2.loss_cls: 0.1171, d2.loss_bbox: 0.2812, d3.loss_cls: 0.1119, d3.loss_bbox: 0.2832, d4.loss_cls: 0.1111, d4.loss_bbox: 0.2921, loss: 2.6523, grad_norm: 21.9722
2025-06-10 08:03:18,345 - mmdet - INFO - Epoch [1][1600/7033]	lr: 1.000e-04, eta: 19:51:34, time: 1.746, data_time: 0.053, memory: 18338, loss_cls: 0.1276, loss_bbox: 0.3082, d0.loss_cls: 0.1932, d0.loss_bbox: 0.4212, d1.loss_cls: 0.1438, d1.loss_bbox: 0.3206, d2.loss_cls: 0.1304, d2.loss_bbox: 0.2927, d3.loss_cls: 0.1216, d3.loss_bbox: 0.2917, d4.loss_cls: 0.1242, d4.loss_bbox: 0.2978, loss: 2.7731, grad_norm: 31.8682
2025-06-10 08:04:43,244 - mmdet - INFO - Epoch [1][1650/7033]	lr: 1.000e-04, eta: 19:48:48, time: 1.698, data_time: 0.061, memory: 18338, loss_cls: 0.1139, loss_bbox: 0.2873, d0.loss_cls: 0.1914, d0.loss_bbox: 0.4007, d1.loss_cls: 0.1384, d1.loss_bbox: 0.3041, d2.loss_cls: 0.1245, d2.loss_bbox: 0.2736, d3.loss_cls: 0.1124, d3.loss_bbox: 0.2738, d4.loss_cls: 0.1120, d4.loss_bbox: 0.2795, loss: 2.6115, grad_norm: 42.8386
2025-06-10 08:06:06,982 - mmdet - INFO - Epoch [1][1700/7033]	lr: 1.000e-04, eta: 19:45:40, time: 1.675, data_time: 0.058, memory: 18338, loss_cls: 0.1163, loss_bbox: 0.3057, d0.loss_cls: 0.1911, d0.loss_bbox: 0.4213, d1.loss_cls: 0.1408, d1.loss_bbox: 0.3202, d2.loss_cls: 0.1225, d2.loss_bbox: 0.2892, d3.loss_cls: 0.1135, d3.loss_bbox: 0.2892, d4.loss_cls: 0.1117, d4.loss_bbox: 0.2956, loss: 2.7172, grad_norm: 31.3459
2025-06-10 08:07:33,106 - mmdet - INFO - Epoch [1][1750/7033]	lr: 1.000e-04, eta: 19:43:32, time: 1.722, data_time: 0.053, memory: 18370, loss_cls: 0.1190, loss_bbox: 0.2998, d0.loss_cls: 0.1923, d0.loss_bbox: 0.4063, d1.loss_cls: 0.1414, d1.loss_bbox: 0.3056, d2.loss_cls: 0.1250, d2.loss_bbox: 0.2800, d3.loss_cls: 0.1159, d3.loss_bbox: 0.2795, d4.loss_cls: 0.1145, d4.loss_bbox: 0.2894, loss: 2.6687, grad_norm: 38.2717
2025-06-10 08:09:04,641 - mmdet - INFO - Epoch [1][1800/7033]	lr: 1.000e-04, eta: 19:43:29, time: 1.831, data_time: 0.058, memory: 18370, loss_cls: 0.1123, loss_bbox: 0.3044, d0.loss_cls: 0.1822, d0.loss_bbox: 0.4073, d1.loss_cls: 0.1366, d1.loss_bbox: 0.3131, d2.loss_cls: 0.1187, d2.loss_bbox: 0.2872, d3.loss_cls: 0.1112, d3.loss_bbox: 0.2890, d4.loss_cls: 0.1101, d4.loss_bbox: 0.2965, loss: 2.6687, grad_norm: 29.9513
2025-06-10 08:10:32,456 - mmdet - INFO - Epoch [1][1850/7033]	lr: 1.000e-04, eta: 19:41:59, time: 1.756, data_time: 0.054, memory: 18370, loss_cls: 0.1168, loss_bbox: 0.3000, d0.loss_cls: 0.1851, d0.loss_bbox: 0.4044, d1.loss_cls: 0.1411, d1.loss_bbox: 0.3106, d2.loss_cls: 0.1267, d2.loss_bbox: 0.2837, d3.loss_cls: 0.1171, d3.loss_bbox: 0.2836, d4.loss_cls: 0.1154, d4.loss_bbox: 0.2901, loss: 2.6747, grad_norm: 82.0144
2025-06-10 08:12:00,031 - mmdet - INFO - Epoch [1][1900/7033]	lr: 1.000e-04, eta: 19:40:25, time: 1.752, data_time: 0.055, memory: 18370, loss_cls: 0.1181, loss_bbox: 0.2995, d0.loss_cls: 0.1835, d0.loss_bbox: 0.3972, d1.loss_cls: 0.1376, d1.loss_bbox: 0.3073, d2.loss_cls: 0.1216, d2.loss_bbox: 0.2813, d3.loss_cls: 0.1137, d3.loss_bbox: 0.2832, d4.loss_cls: 0.1149, d4.loss_bbox: 0.2904, loss: 2.6484, grad_norm: 41.4570
2025-06-10 08:13:27,078 - mmdet - INFO - Epoch [1][1950/7033]	lr: 1.000e-04, eta: 19:38:40, time: 1.741, data_time: 0.058, memory: 18370, loss_cls: 0.1153, loss_bbox: 0.2958, d0.loss_cls: 0.1905, d0.loss_bbox: 0.4041, d1.loss_cls: 0.1424, d1.loss_bbox: 0.3050, d2.loss_cls: 0.1224, d2.loss_bbox: 0.2771, d3.loss_cls: 0.1136, d3.loss_bbox: 0.2761, d4.loss_cls: 0.1128, d4.loss_bbox: 0.2856, loss: 2.6407, grad_norm: 27.2379
2025-06-10 08:14:53,584 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 08:14:53,585 - mmdet - INFO - Epoch [1][2000/7033]	lr: 1.000e-04, eta: 19:36:45, time: 1.730, data_time: 0.059, memory: 18370, loss_cls: 0.1285, loss_bbox: 0.3070, d0.loss_cls: 0.2041, d0.loss_bbox: 0.4226, d1.loss_cls: 0.1541, d1.loss_bbox: 0.3243, d2.loss_cls: 0.1382, d2.loss_bbox: 0.2907, d3.loss_cls: 0.1253, d3.loss_bbox: 0.2917, d4.loss_cls: 0.1260, d4.loss_bbox: 0.2968, loss: 2.8094, grad_norm: 54.7069
2025-06-10 08:16:21,722 - mmdet - INFO - Epoch [1][2050/7033]	lr: 1.000e-04, eta: 19:35:23, time: 1.763, data_time: 0.061, memory: 18370, loss_cls: 0.1162, loss_bbox: 0.2980, d0.loss_cls: 0.1872, d0.loss_bbox: 0.3957, d1.loss_cls: 0.1387, d1.loss_bbox: 0.3052, d2.loss_cls: 0.1245, d2.loss_bbox: 0.2764, d3.loss_cls: 0.1143, d3.loss_bbox: 0.2809, d4.loss_cls: 0.1149, d4.loss_bbox: 0.2851, loss: 2.6370, grad_norm: 34.2378
2025-06-10 08:17:49,397 - mmdet - INFO - Epoch [1][2100/7033]	lr: 1.000e-04, eta: 19:33:51, time: 1.752, data_time: 0.056, memory: 18370, loss_cls: 0.1139, loss_bbox: 0.2920, d0.loss_cls: 0.1915, d0.loss_bbox: 0.3954, d1.loss_cls: 0.1363, d1.loss_bbox: 0.2997, d2.loss_cls: 0.1187, d2.loss_bbox: 0.2719, d3.loss_cls: 0.1099, d3.loss_bbox: 0.2730, d4.loss_cls: 0.1100, d4.loss_bbox: 0.2812, loss: 2.5934, grad_norm: 29.2919
2025-06-10 08:19:16,945 - mmdet - INFO - Epoch [1][2150/7033]	lr: 1.000e-04, eta: 19:32:20, time: 1.753, data_time: 0.059, memory: 18370, loss_cls: 0.1104, loss_bbox: 0.2813, d0.loss_cls: 0.1943, d0.loss_bbox: 0.3916, d1.loss_cls: 0.1349, d1.loss_bbox: 0.2934, d2.loss_cls: 0.1141, d2.loss_bbox: 0.2654, d3.loss_cls: 0.1082, d3.loss_bbox: 0.2660, d4.loss_cls: 0.1080, d4.loss_bbox: 0.2707, loss: 2.5382, grad_norm: 28.1445
2025-06-10 08:20:44,120 - mmdet - INFO - Epoch [1][2200/7033]	lr: 1.000e-04, eta: 19:30:40, time: 1.744, data_time: 0.059, memory: 18370, loss_cls: 0.1098, loss_bbox: 0.2824, d0.loss_cls: 0.1864, d0.loss_bbox: 0.3940, d1.loss_cls: 0.1365, d1.loss_bbox: 0.2961, d2.loss_cls: 0.1175, d2.loss_bbox: 0.2681, d3.loss_cls: 0.1075, d3.loss_bbox: 0.2677, d4.loss_cls: 0.1066, d4.loss_bbox: 0.2727, loss: 2.5453, grad_norm: 34.0808
2025-06-10 08:22:16,867 - mmdet - INFO - Epoch [1][2250/7033]	lr: 1.000e-04, eta: 19:30:40, time: 1.855, data_time: 0.063, memory: 18370, loss_cls: 0.1103, loss_bbox: 0.2860, d0.loss_cls: 0.1906, d0.loss_bbox: 0.3930, d1.loss_cls: 0.1403, d1.loss_bbox: 0.2986, d2.loss_cls: 0.1201, d2.loss_bbox: 0.2698, d3.loss_cls: 0.1111, d3.loss_bbox: 0.2676, d4.loss_cls: 0.1085, d4.loss_bbox: 0.2761, loss: 2.5720, grad_norm: 42.0135
2025-06-10 08:23:42,686 - mmdet - INFO - Epoch [1][2300/7033]	lr: 1.000e-04, eta: 19:28:36, time: 1.716, data_time: 0.061, memory: 18370, loss_cls: 0.1106, loss_bbox: 0.2813, d0.loss_cls: 0.1987, d0.loss_bbox: 0.3835, d1.loss_cls: 0.1413, d1.loss_bbox: 0.2940, d2.loss_cls: 0.1186, d2.loss_bbox: 0.2644, d3.loss_cls: 0.1136, d3.loss_bbox: 0.2651, d4.loss_cls: 0.1115, d4.loss_bbox: 0.2686, loss: 2.5512, grad_norm: 36.3849
2025-06-10 08:25:12,536 - mmdet - INFO - Epoch [1][2350/7033]	lr: 1.000e-04, eta: 19:27:41, time: 1.797, data_time: 0.057, memory: 18425, loss_cls: 0.1099, loss_bbox: 0.2943, d0.loss_cls: 0.1923, d0.loss_bbox: 0.4007, d1.loss_cls: 0.1408, d1.loss_bbox: 0.3017, d2.loss_cls: 0.1221, d2.loss_bbox: 0.2719, d3.loss_cls: 0.1115, d3.loss_bbox: 0.2728, d4.loss_cls: 0.1074, d4.loss_bbox: 0.2807, loss: 2.6061, grad_norm: 28.0512
2025-06-10 08:26:41,577 - mmdet - INFO - Epoch [1][2400/7033]	lr: 1.000e-04, eta: 19:26:32, time: 1.781, data_time: 0.055, memory: 18425, loss_cls: 0.1109, loss_bbox: 0.2848, d0.loss_cls: 0.1845, d0.loss_bbox: 0.3942, d1.loss_cls: 0.1355, d1.loss_bbox: 0.3018, d2.loss_cls: 0.1183, d2.loss_bbox: 0.2715, d3.loss_cls: 0.1132, d3.loss_bbox: 0.2678, d4.loss_cls: 0.1116, d4.loss_bbox: 0.2739, loss: 2.5679, grad_norm: 36.7254
2025-06-10 08:28:10,014 - mmdet - INFO - Epoch [1][2450/7033]	lr: 1.000e-04, eta: 19:25:12, time: 1.768, data_time: 0.055, memory: 18425, loss_cls: 0.1155, loss_bbox: 0.2841, d0.loss_cls: 0.1881, d0.loss_bbox: 0.3898, d1.loss_cls: 0.1369, d1.loss_bbox: 0.2990, d2.loss_cls: 0.1224, d2.loss_bbox: 0.2688, d3.loss_cls: 0.1140, d3.loss_bbox: 0.2690, d4.loss_cls: 0.1129, d4.loss_bbox: 0.2755, loss: 2.5761, grad_norm: 27.6461
2025-06-10 08:29:35,838 - mmdet - INFO - Epoch [1][2500/7033]	lr: 1.000e-04, eta: 19:23:11, time: 1.717, data_time: 0.061, memory: 18425, loss_cls: 0.1086, loss_bbox: 0.2812, d0.loss_cls: 0.1892, d0.loss_bbox: 0.3943, d1.loss_cls: 0.1369, d1.loss_bbox: 0.2998, d2.loss_cls: 0.1184, d2.loss_bbox: 0.2677, d3.loss_cls: 0.1053, d3.loss_bbox: 0.2690, d4.loss_cls: 0.1060, d4.loss_bbox: 0.2728, loss: 2.5493, grad_norm: 22.0361
2025-06-10 08:31:03,907 - mmdet - INFO - Epoch [1][2550/7033]	lr: 1.000e-04, eta: 19:21:45, time: 1.761, data_time: 0.066, memory: 18425, loss_cls: 0.1069, loss_bbox: 0.2748, d0.loss_cls: 0.1809, d0.loss_bbox: 0.3770, d1.loss_cls: 0.1253, d1.loss_bbox: 0.2880, d2.loss_cls: 0.1127, d2.loss_bbox: 0.2567, d3.loss_cls: 0.1034, d3.loss_bbox: 0.2593, d4.loss_cls: 0.1062, d4.loss_bbox: 0.2642, loss: 2.4554, grad_norm: 54.1926
2025-06-10 08:32:30,492 - mmdet - INFO - Epoch [1][2600/7033]	lr: 1.000e-04, eta: 19:19:57, time: 1.732, data_time: 0.062, memory: 18425, loss_cls: 0.1108, loss_bbox: 0.2849, d0.loss_cls: 0.1834, d0.loss_bbox: 0.3914, d1.loss_cls: 0.1330, d1.loss_bbox: 0.2991, d2.loss_cls: 0.1178, d2.loss_bbox: 0.2713, d3.loss_cls: 0.1085, d3.loss_bbox: 0.2706, d4.loss_cls: 0.1101, d4.loss_bbox: 0.2735, loss: 2.5544, grad_norm: 38.3453
2025-06-10 08:33:54,237 - mmdet - INFO - Epoch [1][2650/7033]	lr: 1.000e-04, eta: 19:17:27, time: 1.674, data_time: 0.055, memory: 18425, loss_cls: 0.1128, loss_bbox: 0.2915, d0.loss_cls: 0.1865, d0.loss_bbox: 0.3953, d1.loss_cls: 0.1331, d1.loss_bbox: 0.3046, d2.loss_cls: 0.1193, d2.loss_bbox: 0.2786, d3.loss_cls: 0.1129, d3.loss_bbox: 0.2774, d4.loss_cls: 0.1121, d4.loss_bbox: 0.2797, loss: 2.6040, grad_norm: 39.9996
2025-06-10 08:35:21,545 - mmdet - INFO - Epoch [1][2700/7033]	lr: 1.000e-04, eta: 19:15:53, time: 1.747, data_time: 0.063, memory: 18425, loss_cls: 0.1084, loss_bbox: 0.2710, d0.loss_cls: 0.1855, d0.loss_bbox: 0.3807, d1.loss_cls: 0.1307, d1.loss_bbox: 0.2894, d2.loss_cls: 0.1158, d2.loss_bbox: 0.2600, d3.loss_cls: 0.1065, d3.loss_bbox: 0.2588, d4.loss_cls: 0.1080, d4.loss_bbox: 0.2614, loss: 2.4762, grad_norm: 28.8191
2025-06-10 08:36:49,004 - mmdet - INFO - Epoch [1][2750/7033]	lr: 1.000e-04, eta: 19:14:19, time: 1.748, data_time: 0.064, memory: 18425, loss_cls: 0.1084, loss_bbox: 0.2958, d0.loss_cls: 0.1890, d0.loss_bbox: 0.4017, d1.loss_cls: 0.1369, d1.loss_bbox: 0.3074, d2.loss_cls: 0.1185, d2.loss_bbox: 0.2785, d3.loss_cls: 0.1122, d3.loss_bbox: 0.2789, d4.loss_cls: 0.1099, d4.loss_bbox: 0.2836, loss: 2.6209, grad_norm: 38.0591
2025-06-10 08:38:15,225 - mmdet - INFO - Epoch [1][2800/7033]	lr: 1.000e-04, eta: 19:12:30, time: 1.726, data_time: 0.062, memory: 18425, loss_cls: 0.1031, loss_bbox: 0.2700, d0.loss_cls: 0.1851, d0.loss_bbox: 0.3779, d1.loss_cls: 0.1293, d1.loss_bbox: 0.2868, d2.loss_cls: 0.1098, d2.loss_bbox: 0.2599, d3.loss_cls: 0.1032, d3.loss_bbox: 0.2589, d4.loss_cls: 0.1020, d4.loss_bbox: 0.2620, loss: 2.4479, grad_norm: 25.7532
2025-06-10 08:39:41,189 - mmdet - INFO - Epoch [1][2850/7033]	lr: 1.000e-04, eta: 19:10:38, time: 1.719, data_time: 0.056, memory: 18425, loss_cls: 0.1028, loss_bbox: 0.2764, d0.loss_cls: 0.1803, d0.loss_bbox: 0.3834, d1.loss_cls: 0.1277, d1.loss_bbox: 0.2948, d2.loss_cls: 0.1188, d2.loss_bbox: 0.2626, d3.loss_cls: 0.1051, d3.loss_bbox: 0.2645, d4.loss_cls: 0.1032, d4.loss_bbox: 0.2670, loss: 2.4867, grad_norm: 32.9616
2025-06-10 08:41:06,364 - mmdet - INFO - Epoch [1][2900/7033]	lr: 1.000e-04, eta: 19:08:35, time: 1.704, data_time: 0.061, memory: 18425, loss_cls: 0.1001, loss_bbox: 0.2716, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3687, d1.loss_cls: 0.1222, d1.loss_bbox: 0.2840, d2.loss_cls: 0.1079, d2.loss_bbox: 0.2578, d3.loss_cls: 0.1003, d3.loss_bbox: 0.2591, d4.loss_cls: 0.0987, d4.loss_bbox: 0.2615, loss: 2.4030, grad_norm: 26.3957
2025-06-10 08:42:32,847 - mmdet - INFO - Epoch [1][2950/7033]	lr: 1.000e-04, eta: 19:06:52, time: 1.730, data_time: 0.059, memory: 18425, loss_cls: 0.1133, loss_bbox: 0.2887, d0.loss_cls: 0.1928, d0.loss_bbox: 0.3866, d1.loss_cls: 0.1385, d1.loss_bbox: 0.3030, d2.loss_cls: 0.1234, d2.loss_bbox: 0.2753, d3.loss_cls: 0.1126, d3.loss_bbox: 0.2775, d4.loss_cls: 0.1117, d4.loss_bbox: 0.2795, loss: 2.6028, grad_norm: 39.1253
2025-06-10 08:44:01,528 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 08:44:01,529 - mmdet - INFO - Epoch [1][3000/7033]	lr: 1.000e-04, eta: 19:05:37, time: 1.774, data_time: 0.051, memory: 18425, loss_cls: 0.1095, loss_bbox: 0.2804, d0.loss_cls: 0.1952, d0.loss_bbox: 0.3909, d1.loss_cls: 0.1401, d1.loss_bbox: 0.2940, d2.loss_cls: 0.1191, d2.loss_bbox: 0.2661, d3.loss_cls: 0.1095, d3.loss_bbox: 0.2663, d4.loss_cls: 0.1102, d4.loss_bbox: 0.2712, loss: 2.5524, grad_norm: 31.8881
2025-06-10 08:45:28,689 - mmdet - INFO - Epoch [1][3050/7033]	lr: 1.000e-04, eta: 19:04:03, time: 1.743, data_time: 0.060, memory: 18425, loss_cls: 0.1019, loss_bbox: 0.2825, d0.loss_cls: 0.1831, d0.loss_bbox: 0.3889, d1.loss_cls: 0.1288, d1.loss_bbox: 0.3001, d2.loss_cls: 0.1129, d2.loss_bbox: 0.2699, d3.loss_cls: 0.1011, d3.loss_bbox: 0.2696, d4.loss_cls: 0.1026, d4.loss_bbox: 0.2710, loss: 2.5123, grad_norm: 37.8125
2025-06-10 08:46:54,644 - mmdet - INFO - Epoch [1][3100/7033]	lr: 1.000e-04, eta: 19:02:14, time: 1.719, data_time: 0.060, memory: 18425, loss_cls: 0.0968, loss_bbox: 0.2684, d0.loss_cls: 0.1757, d0.loss_bbox: 0.3755, d1.loss_cls: 0.1222, d1.loss_bbox: 0.2897, d2.loss_cls: 0.1044, d2.loss_bbox: 0.2630, d3.loss_cls: 0.0965, d3.loss_bbox: 0.2609, d4.loss_cls: 0.0953, d4.loss_bbox: 0.2612, loss: 2.4095, grad_norm: 37.9460
2025-06-10 08:48:20,650 - mmdet - INFO - Epoch [1][3150/7033]	lr: 1.000e-04, eta: 19:00:26, time: 1.720, data_time: 0.058, memory: 18425, loss_cls: 0.1065, loss_bbox: 0.2908, d0.loss_cls: 0.1892, d0.loss_bbox: 0.4015, d1.loss_cls: 0.1347, d1.loss_bbox: 0.3069, d2.loss_cls: 0.1158, d2.loss_bbox: 0.2784, d3.loss_cls: 0.1082, d3.loss_bbox: 0.2778, d4.loss_cls: 0.1067, d4.loss_bbox: 0.2811, loss: 2.5974, grad_norm: 80.2682
2025-06-10 08:49:49,155 - mmdet - INFO - Epoch [1][3200/7033]	lr: 1.000e-04, eta: 18:59:08, time: 1.769, data_time: 0.066, memory: 18425, loss_cls: 0.1102, loss_bbox: 0.2783, d0.loss_cls: 0.1914, d0.loss_bbox: 0.3847, d1.loss_cls: 0.1361, d1.loss_bbox: 0.2931, d2.loss_cls: 0.1179, d2.loss_bbox: 0.2675, d3.loss_cls: 0.1113, d3.loss_bbox: 0.2647, d4.loss_cls: 0.1094, d4.loss_bbox: 0.2687, loss: 2.5333, grad_norm: 30.3823
2025-06-10 08:51:14,812 - mmdet - INFO - Epoch [1][3250/7033]	lr: 1.000e-04, eta: 18:57:18, time: 1.714, data_time: 0.056, memory: 18425, loss_cls: 0.1003, loss_bbox: 0.2679, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3788, d1.loss_cls: 0.1232, d1.loss_bbox: 0.2856, d2.loss_cls: 0.1085, d2.loss_bbox: 0.2625, d3.loss_cls: 0.1020, d3.loss_bbox: 0.2595, d4.loss_cls: 0.0997, d4.loss_bbox: 0.2607, loss: 2.4218, grad_norm: 23.7913
2025-06-10 08:52:41,910 - mmdet - INFO - Epoch [1][3300/7033]	lr: 1.000e-04, eta: 18:55:44, time: 1.742, data_time: 0.061, memory: 18425, loss_cls: 0.1045, loss_bbox: 0.2724, d0.loss_cls: 0.1824, d0.loss_bbox: 0.3858, d1.loss_cls: 0.1278, d1.loss_bbox: 0.2948, d2.loss_cls: 0.1120, d2.loss_bbox: 0.2669, d3.loss_cls: 0.1039, d3.loss_bbox: 0.2645, d4.loss_cls: 0.1036, d4.loss_bbox: 0.2658, loss: 2.4843, grad_norm: 30.9102
2025-06-10 08:54:04,974 - mmdet - INFO - Epoch [1][3350/7033]	lr: 1.000e-04, eta: 18:53:24, time: 1.661, data_time: 0.063, memory: 18425, loss_cls: 0.1034, loss_bbox: 0.2745, d0.loss_cls: 0.1844, d0.loss_bbox: 0.3897, d1.loss_cls: 0.1267, d1.loss_bbox: 0.2936, d2.loss_cls: 0.1096, d2.loss_bbox: 0.2679, d3.loss_cls: 0.1027, d3.loss_bbox: 0.2681, d4.loss_cls: 0.1010, d4.loss_bbox: 0.2689, loss: 2.4904, grad_norm: 34.9080
2025-06-10 08:55:28,829 - mmdet - INFO - Epoch [1][3400/7033]	lr: 1.000e-04, eta: 18:51:14, time: 1.677, data_time: 0.058, memory: 18425, loss_cls: 0.1050, loss_bbox: 0.2675, d0.loss_cls: 0.1842, d0.loss_bbox: 0.3746, d1.loss_cls: 0.1344, d1.loss_bbox: 0.2850, d2.loss_cls: 0.1146, d2.loss_bbox: 0.2591, d3.loss_cls: 0.1054, d3.loss_bbox: 0.2571, d4.loss_cls: 0.1039, d4.loss_bbox: 0.2600, loss: 2.4508, grad_norm: 64.6364
2025-06-10 08:56:53,534 - mmdet - INFO - Epoch [1][3450/7033]	lr: 1.000e-04, eta: 18:49:16, time: 1.694, data_time: 0.052, memory: 18425, loss_cls: 0.0985, loss_bbox: 0.2671, d0.loss_cls: 0.1726, d0.loss_bbox: 0.3735, d1.loss_cls: 0.1233, d1.loss_bbox: 0.2830, d2.loss_cls: 0.1078, d2.loss_bbox: 0.2585, d3.loss_cls: 0.1016, d3.loss_bbox: 0.2584, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2604, loss: 2.4027, grad_norm: 31.4809
2025-06-10 08:58:19,935 - mmdet - INFO - Epoch [1][3500/7033]	lr: 1.000e-04, eta: 18:47:37, time: 1.728, data_time: 0.060, memory: 18425, loss_cls: 0.1006, loss_bbox: 0.2576, d0.loss_cls: 0.1802, d0.loss_bbox: 0.3610, d1.loss_cls: 0.1223, d1.loss_bbox: 0.2749, d2.loss_cls: 0.1071, d2.loss_bbox: 0.2518, d3.loss_cls: 0.1003, d3.loss_bbox: 0.2491, d4.loss_cls: 0.0989, d4.loss_bbox: 0.2512, loss: 2.3549, grad_norm: 74.1410
2025-06-10 08:59:47,821 - mmdet - INFO - Epoch [1][3550/7033]	lr: 1.000e-04, eta: 18:46:15, time: 1.758, data_time: 0.051, memory: 18425, loss_cls: 0.1010, loss_bbox: 0.2578, d0.loss_cls: 0.1833, d0.loss_bbox: 0.3564, d1.loss_cls: 0.1226, d1.loss_bbox: 0.2737, d2.loss_cls: 0.1102, d2.loss_bbox: 0.2494, d3.loss_cls: 0.1011, d3.loss_bbox: 0.2502, d4.loss_cls: 0.0994, d4.loss_bbox: 0.2510, loss: 2.3562, grad_norm: 45.1087
2025-06-10 09:01:16,292 - mmdet - INFO - Epoch [1][3600/7033]	lr: 1.000e-04, eta: 18:44:58, time: 1.769, data_time: 0.059, memory: 18425, loss_cls: 0.0976, loss_bbox: 0.2645, d0.loss_cls: 0.1760, d0.loss_bbox: 0.3591, d1.loss_cls: 0.1216, d1.loss_bbox: 0.2773, d2.loss_cls: 0.1035, d2.loss_bbox: 0.2536, d3.loss_cls: 0.0973, d3.loss_bbox: 0.2544, d4.loss_cls: 0.0968, d4.loss_bbox: 0.2556, loss: 2.3573, grad_norm: 43.6676
2025-06-10 09:02:42,448 - mmdet - INFO - Epoch [1][3650/7033]	lr: 1.000e-04, eta: 18:43:17, time: 1.723, data_time: 0.053, memory: 18425, loss_cls: 0.1075, loss_bbox: 0.2701, d0.loss_cls: 0.1844, d0.loss_bbox: 0.3781, d1.loss_cls: 0.1338, d1.loss_bbox: 0.2916, d2.loss_cls: 0.1165, d2.loss_bbox: 0.2646, d3.loss_cls: 0.1068, d3.loss_bbox: 0.2626, d4.loss_cls: 0.1055, d4.loss_bbox: 0.2652, loss: 2.4868, grad_norm: 47.2691
2025-06-10 09:04:06,478 - mmdet - INFO - Epoch [1][3700/7033]	lr: 1.000e-04, eta: 18:41:15, time: 1.681, data_time: 0.058, memory: 18425, loss_cls: 0.1018, loss_bbox: 0.2720, d0.loss_cls: 0.1783, d0.loss_bbox: 0.3844, d1.loss_cls: 0.1213, d1.loss_bbox: 0.2950, d2.loss_cls: 0.1097, d2.loss_bbox: 0.2665, d3.loss_cls: 0.1018, d3.loss_bbox: 0.2653, d4.loss_cls: 0.0986, d4.loss_bbox: 0.2668, loss: 2.4615, grad_norm: 30.2422
2025-06-10 09:05:31,740 - mmdet - INFO - Epoch [1][3750/7033]	lr: 1.000e-04, eta: 18:39:26, time: 1.705, data_time: 0.056, memory: 18425, loss_cls: 0.0991, loss_bbox: 0.2666, d0.loss_cls: 0.1712, d0.loss_bbox: 0.3675, d1.loss_cls: 0.1194, d1.loss_bbox: 0.2846, d2.loss_cls: 0.1061, d2.loss_bbox: 0.2601, d3.loss_cls: 0.0979, d3.loss_bbox: 0.2626, d4.loss_cls: 0.0981, d4.loss_bbox: 0.2600, loss: 2.3933, grad_norm: 28.0299
2025-06-10 09:06:56,845 - mmdet - INFO - Epoch [1][3800/7033]	lr: 1.000e-04, eta: 18:37:35, time: 1.700, data_time: 0.054, memory: 18425, loss_cls: 0.1014, loss_bbox: 0.2639, d0.loss_cls: 0.1773, d0.loss_bbox: 0.3584, d1.loss_cls: 0.1252, d1.loss_bbox: 0.2773, d2.loss_cls: 0.1093, d2.loss_bbox: 0.2532, d3.loss_cls: 0.1023, d3.loss_bbox: 0.2551, d4.loss_cls: 0.0996, d4.loss_bbox: 0.2567, loss: 2.3796, grad_norm: 36.0968
2025-06-10 09:08:25,726 - mmdet - INFO - Epoch [1][3850/7033]	lr: 1.000e-04, eta: 18:36:24, time: 1.780, data_time: 0.057, memory: 18425, loss_cls: 0.0957, loss_bbox: 0.2656, d0.loss_cls: 0.1772, d0.loss_bbox: 0.3707, d1.loss_cls: 0.1237, d1.loss_bbox: 0.2835, d2.loss_cls: 0.1074, d2.loss_bbox: 0.2596, d3.loss_cls: 0.0964, d3.loss_bbox: 0.2597, d4.loss_cls: 0.0960, d4.loss_bbox: 0.2598, loss: 2.3955, grad_norm: 35.2579
2025-06-10 09:09:53,386 - mmdet - INFO - Epoch [1][3900/7033]	lr: 1.000e-04, eta: 18:35:00, time: 1.753, data_time: 0.052, memory: 18425, loss_cls: 0.1006, loss_bbox: 0.2575, d0.loss_cls: 0.1742, d0.loss_bbox: 0.3588, d1.loss_cls: 0.1240, d1.loss_bbox: 0.2740, d2.loss_cls: 0.1071, d2.loss_bbox: 0.2509, d3.loss_cls: 0.0999, d3.loss_bbox: 0.2521, d4.loss_cls: 0.0987, d4.loss_bbox: 0.2536, loss: 2.3514, grad_norm: 50.8417
2025-06-10 09:11:20,494 - mmdet - INFO - Epoch [1][3950/7033]	lr: 1.000e-04, eta: 18:33:30, time: 1.742, data_time: 0.063, memory: 18425, loss_cls: 0.0976, loss_bbox: 0.2709, d0.loss_cls: 0.1719, d0.loss_bbox: 0.3792, d1.loss_cls: 0.1187, d1.loss_bbox: 0.2909, d2.loss_cls: 0.1039, d2.loss_bbox: 0.2670, d3.loss_cls: 0.0980, d3.loss_bbox: 0.2627, d4.loss_cls: 0.0971, d4.loss_bbox: 0.2649, loss: 2.4228, grad_norm: 32.1877
2025-06-10 09:12:47,533 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 09:12:47,533 - mmdet - INFO - Epoch [1][4000/7033]	lr: 1.000e-04, eta: 18:32:00, time: 1.741, data_time: 0.064, memory: 18425, loss_cls: 0.1055, loss_bbox: 0.2701, d0.loss_cls: 0.1753, d0.loss_bbox: 0.3724, d1.loss_cls: 0.1300, d1.loss_bbox: 0.2858, d2.loss_cls: 0.1135, d2.loss_bbox: 0.2647, d3.loss_cls: 0.1050, d3.loss_bbox: 0.2647, d4.loss_cls: 0.1057, d4.loss_bbox: 0.2634, loss: 2.4560, grad_norm: 48.4586
2025-06-10 09:14:12,112 - mmdet - INFO - Epoch [1][4050/7033]	lr: 1.000e-04, eta: 18:30:07, time: 1.691, data_time: 0.055, memory: 18425, loss_cls: 0.1111, loss_bbox: 0.2763, d0.loss_cls: 0.1792, d0.loss_bbox: 0.3741, d1.loss_cls: 0.1326, d1.loss_bbox: 0.2900, d2.loss_cls: 0.1167, d2.loss_bbox: 0.2671, d3.loss_cls: 0.1108, d3.loss_bbox: 0.2671, d4.loss_cls: 0.1095, d4.loss_bbox: 0.2696, loss: 2.5043, grad_norm: 34.6132
2025-06-10 09:15:38,591 - mmdet - INFO - Epoch [1][4100/7033]	lr: 1.000e-04, eta: 18:28:32, time: 1.730, data_time: 0.060, memory: 18425, loss_cls: 0.1029, loss_bbox: 0.2742, d0.loss_cls: 0.1798, d0.loss_bbox: 0.3691, d1.loss_cls: 0.1291, d1.loss_bbox: 0.2863, d2.loss_cls: 0.1098, d2.loss_bbox: 0.2656, d3.loss_cls: 0.1075, d3.loss_bbox: 0.2659, d4.loss_cls: 0.1033, d4.loss_bbox: 0.2660, loss: 2.4595, grad_norm: 63.1563
2025-06-10 09:17:05,977 - mmdet - INFO - Epoch [1][4150/7033]	lr: 1.000e-04, eta: 18:27:05, time: 1.748, data_time: 0.055, memory: 18425, loss_cls: 0.0996, loss_bbox: 0.2606, d0.loss_cls: 0.1737, d0.loss_bbox: 0.3612, d1.loss_cls: 0.1219, d1.loss_bbox: 0.2722, d2.loss_cls: 0.1064, d2.loss_bbox: 0.2504, d3.loss_cls: 0.0977, d3.loss_bbox: 0.2498, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2529, loss: 2.3414, grad_norm: 119.0968
2025-06-10 09:18:35,585 - mmdet - INFO - Epoch [1][4200/7033]	lr: 1.000e-04, eta: 18:25:59, time: 1.792, data_time: 0.051, memory: 18425, loss_cls: 0.0952, loss_bbox: 0.2639, d0.loss_cls: 0.1839, d0.loss_bbox: 0.3685, d1.loss_cls: 0.1232, d1.loss_bbox: 0.2810, d2.loss_cls: 0.1070, d2.loss_bbox: 0.2577, d3.loss_cls: 0.0984, d3.loss_bbox: 0.2549, d4.loss_cls: 0.0948, d4.loss_bbox: 0.2561, loss: 2.3844, grad_norm: 32.5077
2025-06-10 09:20:02,371 - mmdet - INFO - Epoch [1][4250/7033]	lr: 1.000e-04, eta: 18:24:27, time: 1.736, data_time: 0.057, memory: 18425, loss_cls: 0.0960, loss_bbox: 0.2495, d0.loss_cls: 0.1674, d0.loss_bbox: 0.3542, d1.loss_cls: 0.1203, d1.loss_bbox: 0.2700, d2.loss_cls: 0.1044, d2.loss_bbox: 0.2458, d3.loss_cls: 0.0953, d3.loss_bbox: 0.2453, d4.loss_cls: 0.0956, d4.loss_bbox: 0.2440, loss: 2.2878, grad_norm: 45.7703
2025-06-10 09:21:29,790 - mmdet - INFO - Epoch [1][4300/7033]	lr: 1.000e-04, eta: 18:23:00, time: 1.748, data_time: 0.055, memory: 18425, loss_cls: 0.0972, loss_bbox: 0.2659, d0.loss_cls: 0.1805, d0.loss_bbox: 0.3772, d1.loss_cls: 0.1271, d1.loss_bbox: 0.2830, d2.loss_cls: 0.1078, d2.loss_bbox: 0.2576, d3.loss_cls: 0.0983, d3.loss_bbox: 0.2585, d4.loss_cls: 0.0965, d4.loss_bbox: 0.2592, loss: 2.4086, grad_norm: 39.6277
2025-06-10 09:22:54,801 - mmdet - INFO - Epoch [1][4350/7033]	lr: 1.000e-04, eta: 18:21:13, time: 1.700, data_time: 0.053, memory: 18425, loss_cls: 0.0923, loss_bbox: 0.2651, d0.loss_cls: 0.1678, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1167, d1.loss_bbox: 0.2725, d2.loss_cls: 0.0998, d2.loss_bbox: 0.2534, d3.loss_cls: 0.0933, d3.loss_bbox: 0.2551, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2570, loss: 2.3179, grad_norm: 37.3537
2025-06-10 09:24:17,648 - mmdet - INFO - Epoch [1][4400/7033]	lr: 1.000e-04, eta: 18:19:08, time: 1.657, data_time: 0.054, memory: 18425, loss_cls: 0.0941, loss_bbox: 0.2590, d0.loss_cls: 0.1791, d0.loss_bbox: 0.3685, d1.loss_cls: 0.1238, d1.loss_bbox: 0.2782, d2.loss_cls: 0.1059, d2.loss_bbox: 0.2538, d3.loss_cls: 0.0977, d3.loss_bbox: 0.2542, d4.loss_cls: 0.0966, d4.loss_bbox: 0.2517, loss: 2.3624, grad_norm: 42.9375
2025-06-10 09:25:40,485 - mmdet - INFO - Epoch [1][4450/7033]	lr: 1.000e-04, eta: 18:17:03, time: 1.657, data_time: 0.058, memory: 18425, loss_cls: 0.0976, loss_bbox: 0.2532, d0.loss_cls: 0.1744, d0.loss_bbox: 0.3596, d1.loss_cls: 0.1246, d1.loss_bbox: 0.2700, d2.loss_cls: 0.1085, d2.loss_bbox: 0.2485, d3.loss_cls: 0.0991, d3.loss_bbox: 0.2481, d4.loss_cls: 0.0985, d4.loss_bbox: 0.2479, loss: 2.3300, grad_norm: 32.4732
2025-06-10 09:27:07,209 - mmdet - INFO - Epoch [1][4500/7033]	lr: 1.000e-04, eta: 18:15:32, time: 1.734, data_time: 0.059, memory: 18425, loss_cls: 0.0925, loss_bbox: 0.2531, d0.loss_cls: 0.1686, d0.loss_bbox: 0.3442, d1.loss_cls: 0.1231, d1.loss_bbox: 0.2653, d2.loss_cls: 0.1033, d2.loss_bbox: 0.2463, d3.loss_cls: 0.0945, d3.loss_bbox: 0.2462, d4.loss_cls: 0.0912, d4.loss_bbox: 0.2467, loss: 2.2750, grad_norm: 44.5249
2025-06-10 09:28:32,446 - mmdet - INFO - Epoch [1][4550/7033]	lr: 1.000e-04, eta: 18:13:48, time: 1.704, data_time: 0.058, memory: 18425, loss_cls: 0.1022, loss_bbox: 0.2622, d0.loss_cls: 0.1831, d0.loss_bbox: 0.3690, d1.loss_cls: 0.1254, d1.loss_bbox: 0.2789, d2.loss_cls: 0.1115, d2.loss_bbox: 0.2595, d3.loss_cls: 0.1056, d3.loss_bbox: 0.2572, d4.loss_cls: 0.1013, d4.loss_bbox: 0.2576, loss: 2.4134, grad_norm: 29.5588
2025-06-10 09:29:57,762 - mmdet - INFO - Epoch [1][4600/7033]	lr: 1.000e-04, eta: 18:12:06, time: 1.707, data_time: 0.056, memory: 18425, loss_cls: 0.1011, loss_bbox: 0.2619, d0.loss_cls: 0.1741, d0.loss_bbox: 0.3610, d1.loss_cls: 0.1249, d1.loss_bbox: 0.2758, d2.loss_cls: 0.1122, d2.loss_bbox: 0.2589, d3.loss_cls: 0.1039, d3.loss_bbox: 0.2566, d4.loss_cls: 0.1014, d4.loss_bbox: 0.2566, loss: 2.3884, grad_norm: 61.2269
2025-06-10 09:31:21,195 - mmdet - INFO - Epoch [1][4650/7033]	lr: 1.000e-04, eta: 18:10:09, time: 1.669, data_time: 0.059, memory: 18425, loss_cls: 0.0984, loss_bbox: 0.2526, d0.loss_cls: 0.1776, d0.loss_bbox: 0.3576, d1.loss_cls: 0.1233, d1.loss_bbox: 0.2727, d2.loss_cls: 0.1090, d2.loss_bbox: 0.2496, d3.loss_cls: 0.1003, d3.loss_bbox: 0.2481, d4.loss_cls: 0.0987, d4.loss_bbox: 0.2474, loss: 2.3353, grad_norm: 30.8747
2025-06-10 09:32:44,536 - mmdet - INFO - Epoch [1][4700/7033]	lr: 1.000e-04, eta: 18:08:12, time: 1.667, data_time: 0.060, memory: 18425, loss_cls: 0.0933, loss_bbox: 0.2603, d0.loss_cls: 0.1748, d0.loss_bbox: 0.3620, d1.loss_cls: 0.1176, d1.loss_bbox: 0.2780, d2.loss_cls: 0.1030, d2.loss_bbox: 0.2563, d3.loss_cls: 0.0960, d3.loss_bbox: 0.2552, d4.loss_cls: 0.0928, d4.loss_bbox: 0.2550, loss: 2.3445, grad_norm: 73.9252
2025-06-10 09:34:12,961 - mmdet - INFO - Epoch [1][4750/7033]	lr: 1.000e-04, eta: 18:06:56, time: 1.769, data_time: 0.055, memory: 18425, loss_cls: 0.0878, loss_bbox: 0.2415, d0.loss_cls: 0.1676, d0.loss_bbox: 0.3420, d1.loss_cls: 0.1176, d1.loss_bbox: 0.2605, d2.loss_cls: 0.0993, d2.loss_bbox: 0.2393, d3.loss_cls: 0.0917, d3.loss_bbox: 0.2386, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2374, loss: 2.2124, grad_norm: 27.4637
2025-06-10 09:35:37,218 - mmdet - INFO - Epoch [1][4800/7033]	lr: 1.000e-04, eta: 18:05:07, time: 1.685, data_time: 0.077, memory: 18425, loss_cls: 0.0957, loss_bbox: 0.2426, d0.loss_cls: 0.1685, d0.loss_bbox: 0.3477, d1.loss_cls: 0.1145, d1.loss_bbox: 0.2619, d2.loss_cls: 0.1001, d2.loss_bbox: 0.2410, d3.loss_cls: 0.0959, d3.loss_bbox: 0.2400, d4.loss_cls: 0.0947, d4.loss_bbox: 0.2378, loss: 2.2404, grad_norm: 44.7901
2025-06-10 09:37:03,270 - mmdet - INFO - Epoch [1][4850/7033]	lr: 1.000e-04, eta: 18:03:32, time: 1.721, data_time: 0.054, memory: 18425, loss_cls: 0.1016, loss_bbox: 0.2505, d0.loss_cls: 0.1827, d0.loss_bbox: 0.3583, d1.loss_cls: 0.1304, d1.loss_bbox: 0.2718, d2.loss_cls: 0.1110, d2.loss_bbox: 0.2476, d3.loss_cls: 0.1033, d3.loss_bbox: 0.2462, d4.loss_cls: 0.1010, d4.loss_bbox: 0.2456, loss: 2.3500, grad_norm: 23.2552
2025-06-10 09:38:27,796 - mmdet - INFO - Epoch [1][4900/7033]	lr: 1.000e-04, eta: 18:01:46, time: 1.690, data_time: 0.061, memory: 18425, loss_cls: 0.0974, loss_bbox: 0.2512, d0.loss_cls: 0.1762, d0.loss_bbox: 0.3625, d1.loss_cls: 0.1219, d1.loss_bbox: 0.2705, d2.loss_cls: 0.1075, d2.loss_bbox: 0.2487, d3.loss_cls: 0.0977, d3.loss_bbox: 0.2478, d4.loss_cls: 0.0984, d4.loss_bbox: 0.2457, loss: 2.3255, grad_norm: 29.3569
2025-06-10 09:39:53,284 - mmdet - INFO - Epoch [1][4950/7033]	lr: 1.000e-04, eta: 18:00:08, time: 1.710, data_time: 0.057, memory: 18425, loss_cls: 0.1014, loss_bbox: 0.2563, d0.loss_cls: 0.1817, d0.loss_bbox: 0.3724, d1.loss_cls: 0.1295, d1.loss_bbox: 0.2757, d2.loss_cls: 0.1072, d2.loss_bbox: 0.2533, d3.loss_cls: 0.1010, d3.loss_bbox: 0.2526, d4.loss_cls: 0.1000, d4.loss_bbox: 0.2515, loss: 2.3827, grad_norm: 26.7021
2025-06-10 09:41:17,329 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 09:41:17,330 - mmdet - INFO - Epoch [1][5000/7033]	lr: 1.000e-04, eta: 17:58:19, time: 1.681, data_time: 0.060, memory: 18425, loss_cls: 0.0891, loss_bbox: 0.2491, d0.loss_cls: 0.1640, d0.loss_bbox: 0.3491, d1.loss_cls: 0.1131, d1.loss_bbox: 0.2685, d2.loss_cls: 0.1005, d2.loss_bbox: 0.2436, d3.loss_cls: 0.0906, d3.loss_bbox: 0.2429, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2428, loss: 2.2424, grad_norm: 33.5627
2025-06-10 09:42:46,048 - mmdet - INFO - Epoch [1][5050/7033]	lr: 1.000e-04, eta: 17:57:04, time: 1.774, data_time: 0.078, memory: 18425, loss_cls: 0.0974, loss_bbox: 0.2456, d0.loss_cls: 0.1794, d0.loss_bbox: 0.3513, d1.loss_cls: 0.1263, d1.loss_bbox: 0.2680, d2.loss_cls: 0.1077, d2.loss_bbox: 0.2424, d3.loss_cls: 0.0985, d3.loss_bbox: 0.2448, d4.loss_cls: 0.0968, d4.loss_bbox: 0.2415, loss: 2.2997, grad_norm: 37.3044
2025-06-10 09:44:12,281 - mmdet - INFO - Epoch [1][5100/7033]	lr: 1.000e-04, eta: 17:55:32, time: 1.725, data_time: 0.057, memory: 18425, loss_cls: 0.0962, loss_bbox: 0.2565, d0.loss_cls: 0.1796, d0.loss_bbox: 0.3776, d1.loss_cls: 0.1292, d1.loss_bbox: 0.2798, d2.loss_cls: 0.1100, d2.loss_bbox: 0.2571, d3.loss_cls: 0.0993, d3.loss_bbox: 0.2548, d4.loss_cls: 0.0968, d4.loss_bbox: 0.2531, loss: 2.3901, grad_norm: 46.1980
2025-06-10 09:45:35,315 - mmdet - INFO - Epoch [1][5150/7033]	lr: 1.000e-04, eta: 17:53:37, time: 1.661, data_time: 0.055, memory: 18425, loss_cls: 0.1019, loss_bbox: 0.2567, d0.loss_cls: 0.1868, d0.loss_bbox: 0.3754, d1.loss_cls: 0.1335, d1.loss_bbox: 0.2781, d2.loss_cls: 0.1125, d2.loss_bbox: 0.2541, d3.loss_cls: 0.1047, d3.loss_bbox: 0.2548, d4.loss_cls: 0.1019, d4.loss_bbox: 0.2521, loss: 2.4125, grad_norm: 52.1583
2025-06-10 09:47:04,166 - mmdet - INFO - Epoch [1][5200/7033]	lr: 1.000e-04, eta: 17:52:23, time: 1.777, data_time: 0.050, memory: 18425, loss_cls: 0.1009, loss_bbox: 0.2564, d0.loss_cls: 0.1762, d0.loss_bbox: 0.3647, d1.loss_cls: 0.1245, d1.loss_bbox: 0.2744, d2.loss_cls: 0.1082, d2.loss_bbox: 0.2529, d3.loss_cls: 0.1023, d3.loss_bbox: 0.2520, d4.loss_cls: 0.1004, d4.loss_bbox: 0.2510, loss: 2.3637, grad_norm: 30.3131
2025-06-10 09:48:32,058 - mmdet - INFO - Epoch [1][5250/7033]	lr: 1.000e-04, eta: 17:51:03, time: 1.758, data_time: 0.058, memory: 18425, loss_cls: 0.0959, loss_bbox: 0.2482, d0.loss_cls: 0.1747, d0.loss_bbox: 0.3500, d1.loss_cls: 0.1180, d1.loss_bbox: 0.2646, d2.loss_cls: 0.1001, d2.loss_bbox: 0.2472, d3.loss_cls: 0.0981, d3.loss_bbox: 0.2452, d4.loss_cls: 0.0950, d4.loss_bbox: 0.2451, loss: 2.2820, grad_norm: 29.0636
2025-06-10 09:49:58,726 - mmdet - INFO - Epoch [1][5300/7033]	lr: 1.000e-04, eta: 17:49:34, time: 1.733, data_time: 0.057, memory: 18425, loss_cls: 0.0864, loss_bbox: 0.2407, d0.loss_cls: 0.1659, d0.loss_bbox: 0.3527, d1.loss_cls: 0.1122, d1.loss_bbox: 0.2613, d2.loss_cls: 0.0959, d2.loss_bbox: 0.2393, d3.loss_cls: 0.0885, d3.loss_bbox: 0.2375, d4.loss_cls: 0.0860, d4.loss_bbox: 0.2368, loss: 2.2032, grad_norm: 50.7357
2025-06-10 09:51:23,919 - mmdet - INFO - Epoch [1][5350/7033]	lr: 1.000e-04, eta: 17:47:54, time: 1.702, data_time: 0.054, memory: 18425, loss_cls: 0.1055, loss_bbox: 0.2625, d0.loss_cls: 0.1874, d0.loss_bbox: 0.3742, d1.loss_cls: 0.1287, d1.loss_bbox: 0.2851, d2.loss_cls: 0.1117, d2.loss_bbox: 0.2620, d3.loss_cls: 0.1050, d3.loss_bbox: 0.2616, d4.loss_cls: 0.1058, d4.loss_bbox: 0.2601, loss: 2.4496, grad_norm: 23.0898
2025-06-10 09:52:48,914 - mmdet - INFO - Epoch [1][5400/7033]	lr: 1.000e-04, eta: 17:46:15, time: 1.702, data_time: 0.060, memory: 18425, loss_cls: 0.0950, loss_bbox: 0.2469, d0.loss_cls: 0.1766, d0.loss_bbox: 0.3612, d1.loss_cls: 0.1205, d1.loss_bbox: 0.2694, d2.loss_cls: 0.1043, d2.loss_bbox: 0.2461, d3.loss_cls: 0.0971, d3.loss_bbox: 0.2459, d4.loss_cls: 0.0957, d4.loss_bbox: 0.2446, loss: 2.3032, grad_norm: 21.5375
2025-06-10 09:54:15,830 - mmdet - INFO - Epoch [1][5450/7033]	lr: 1.000e-04, eta: 17:44:48, time: 1.738, data_time: 0.060, memory: 18425, loss_cls: 0.0985, loss_bbox: 0.2527, d0.loss_cls: 0.1739, d0.loss_bbox: 0.3619, d1.loss_cls: 0.1212, d1.loss_bbox: 0.2763, d2.loss_cls: 0.1050, d2.loss_bbox: 0.2537, d3.loss_cls: 0.0979, d3.loss_bbox: 0.2524, d4.loss_cls: 0.0977, d4.loss_bbox: 0.2493, loss: 2.3403, grad_norm: 103.3774
2025-06-10 09:55:42,345 - mmdet - INFO - Epoch [1][5500/7033]	lr: 1.000e-04, eta: 17:43:18, time: 1.730, data_time: 0.065, memory: 18425, loss_cls: 0.0980, loss_bbox: 0.2455, d0.loss_cls: 0.1695, d0.loss_bbox: 0.3431, d1.loss_cls: 0.1192, d1.loss_bbox: 0.2644, d2.loss_cls: 0.1028, d2.loss_bbox: 0.2455, d3.loss_cls: 0.0992, d3.loss_bbox: 0.2443, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2422, loss: 2.2714, grad_norm: 138.7166
2025-06-10 09:57:06,857 - mmdet - INFO - Epoch [1][5550/7033]	lr: 1.000e-04, eta: 17:41:35, time: 1.690, data_time: 0.060, memory: 18425, loss_cls: 0.0926, loss_bbox: 0.2451, d0.loss_cls: 0.1790, d0.loss_bbox: 0.3576, d1.loss_cls: 0.1215, d1.loss_bbox: 0.2660, d2.loss_cls: 0.1033, d2.loss_bbox: 0.2442, d3.loss_cls: 0.0944, d3.loss_bbox: 0.2449, d4.loss_cls: 0.0926, d4.loss_bbox: 0.2425, loss: 2.2838, grad_norm: 42.7241
2025-06-10 09:58:29,921 - mmdet - INFO - Epoch [1][5600/7033]	lr: 1.000e-04, eta: 17:39:43, time: 1.661, data_time: 0.059, memory: 18425, loss_cls: 0.0926, loss_bbox: 0.2498, d0.loss_cls: 0.1689, d0.loss_bbox: 0.3523, d1.loss_cls: 0.1162, d1.loss_bbox: 0.2693, d2.loss_cls: 0.1007, d2.loss_bbox: 0.2511, d3.loss_cls: 0.0952, d3.loss_bbox: 0.2485, d4.loss_cls: 0.0935, d4.loss_bbox: 0.2463, loss: 2.2844, grad_norm: 1260.5065
2025-06-10 09:59:54,842 - mmdet - INFO - Epoch [1][5650/7033]	lr: 1.000e-04, eta: 17:38:03, time: 1.698, data_time: 0.057, memory: 18425, loss_cls: 0.1056, loss_bbox: 0.2582, d0.loss_cls: 0.1787, d0.loss_bbox: 0.3588, d1.loss_cls: 0.1252, d1.loss_bbox: 0.2737, d2.loss_cls: 0.1104, d2.loss_bbox: 0.2559, d3.loss_cls: 0.1074, d3.loss_bbox: 0.2558, d4.loss_cls: 0.1056, d4.loss_bbox: 0.2550, loss: 2.3903, grad_norm: 38.5354
2025-06-10 10:01:20,382 - mmdet - INFO - Epoch [1][5700/7033]	lr: 1.000e-04, eta: 17:36:28, time: 1.711, data_time: 0.062, memory: 18425, loss_cls: 0.0923, loss_bbox: 0.2447, d0.loss_cls: 0.1687, d0.loss_bbox: 0.3500, d1.loss_cls: 0.1141, d1.loss_bbox: 0.2662, d2.loss_cls: 0.0994, d2.loss_bbox: 0.2430, d3.loss_cls: 0.0928, d3.loss_bbox: 0.2433, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2396, loss: 2.2473, grad_norm: 42.4114
2025-06-10 10:02:47,086 - mmdet - INFO - Epoch [1][5750/7033]	lr: 1.000e-04, eta: 17:35:01, time: 1.734, data_time: 0.054, memory: 18425, loss_cls: 0.0829, loss_bbox: 0.2432, d0.loss_cls: 0.1720, d0.loss_bbox: 0.3503, d1.loss_cls: 0.1125, d1.loss_bbox: 0.2656, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2431, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2455, d4.loss_cls: 0.0833, d4.loss_bbox: 0.2413, loss: 2.2192, grad_norm: 24.0369
2025-06-10 10:04:13,965 - mmdet - INFO - Epoch [1][5800/7033]	lr: 1.000e-04, eta: 17:33:34, time: 1.738, data_time: 0.056, memory: 18425, loss_cls: 0.0922, loss_bbox: 0.2409, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3507, d1.loss_cls: 0.1221, d1.loss_bbox: 0.2664, d2.loss_cls: 0.1024, d2.loss_bbox: 0.2420, d3.loss_cls: 0.0946, d3.loss_bbox: 0.2417, d4.loss_cls: 0.0921, d4.loss_bbox: 0.2389, loss: 2.2570, grad_norm: 34.4941
2025-06-10 10:05:42,753 - mmdet - INFO - Epoch [1][5850/7033]	lr: 1.000e-04, eta: 17:32:19, time: 1.776, data_time: 0.065, memory: 18425, loss_cls: 0.0934, loss_bbox: 0.2486, d0.loss_cls: 0.1818, d0.loss_bbox: 0.3562, d1.loss_cls: 0.1210, d1.loss_bbox: 0.2665, d2.loss_cls: 0.1032, d2.loss_bbox: 0.2468, d3.loss_cls: 0.0962, d3.loss_bbox: 0.2464, d4.loss_cls: 0.0928, d4.loss_bbox: 0.2459, loss: 2.2986, grad_norm: 31.2785
2025-06-10 10:07:11,304 - mmdet - INFO - Epoch [1][5900/7033]	lr: 1.000e-04, eta: 17:31:03, time: 1.771, data_time: 0.064, memory: 18425, loss_cls: 0.0922, loss_bbox: 0.2438, d0.loss_cls: 0.1729, d0.loss_bbox: 0.3587, d1.loss_cls: 0.1161, d1.loss_bbox: 0.2690, d2.loss_cls: 0.1015, d2.loss_bbox: 0.2472, d3.loss_cls: 0.0944, d3.loss_bbox: 0.2454, d4.loss_cls: 0.0929, d4.loss_bbox: 0.2420, loss: 2.2762, grad_norm: 21.2408
2025-06-10 10:08:37,825 - mmdet - INFO - Epoch [1][5950/7033]	lr: 1.000e-04, eta: 17:29:34, time: 1.730, data_time: 0.059, memory: 18425, loss_cls: 0.0913, loss_bbox: 0.2478, d0.loss_cls: 0.1681, d0.loss_bbox: 0.3580, d1.loss_cls: 0.1165, d1.loss_bbox: 0.2687, d2.loss_cls: 0.1013, d2.loss_bbox: 0.2475, d3.loss_cls: 0.0936, d3.loss_bbox: 0.2458, d4.loss_cls: 0.0914, d4.loss_bbox: 0.2462, loss: 2.2763, grad_norm: 40.0146
2025-06-10 10:10:08,230 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 10:10:08,231 - mmdet - INFO - Epoch [1][6000/7033]	lr: 1.000e-04, eta: 17:28:28, time: 1.808, data_time: 0.073, memory: 18761, loss_cls: 0.0968, loss_bbox: 0.2508, d0.loss_cls: 0.1744, d0.loss_bbox: 0.3593, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2757, d2.loss_cls: 0.1054, d2.loss_bbox: 0.2549, d3.loss_cls: 0.0984, d3.loss_bbox: 0.2550, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2495, loss: 2.3347, grad_norm: 34.4088
2025-06-10 10:11:37,386 - mmdet - INFO - Epoch [1][6050/7033]	lr: 1.000e-04, eta: 17:27:15, time: 1.783, data_time: 0.053, memory: 18761, loss_cls: 0.0902, loss_bbox: 0.2420, d0.loss_cls: 0.1680, d0.loss_bbox: 0.3513, d1.loss_cls: 0.1159, d1.loss_bbox: 0.2655, d2.loss_cls: 0.0997, d2.loss_bbox: 0.2447, d3.loss_cls: 0.0928, d3.loss_bbox: 0.2433, d4.loss_cls: 0.0914, d4.loss_bbox: 0.2418, loss: 2.2466, grad_norm: 30.0076
2025-06-10 10:13:06,281 - mmdet - INFO - Epoch [1][6100/7033]	lr: 1.000e-04, eta: 17:26:00, time: 1.778, data_time: 0.064, memory: 18761, loss_cls: 0.1009, loss_bbox: 0.2394, d0.loss_cls: 0.1752, d0.loss_bbox: 0.3476, d1.loss_cls: 0.1230, d1.loss_bbox: 0.2612, d2.loss_cls: 0.1086, d2.loss_bbox: 0.2405, d3.loss_cls: 0.1028, d3.loss_bbox: 0.2417, d4.loss_cls: 0.1017, d4.loss_bbox: 0.2396, loss: 2.2822, grad_norm: 49.3203
2025-06-10 10:14:31,373 - mmdet - INFO - Epoch [1][6150/7033]	lr: 1.000e-04, eta: 17:24:22, time: 1.702, data_time: 0.060, memory: 18761, loss_cls: 0.0921, loss_bbox: 0.2439, d0.loss_cls: 0.1616, d0.loss_bbox: 0.3482, d1.loss_cls: 0.1187, d1.loss_bbox: 0.2641, d2.loss_cls: 0.1031, d2.loss_bbox: 0.2443, d3.loss_cls: 0.0943, d3.loss_bbox: 0.2448, d4.loss_cls: 0.0919, d4.loss_bbox: 0.2425, loss: 2.2493, grad_norm: 35.8611
2025-06-10 10:15:58,503 - mmdet - INFO - Epoch [1][6200/7033]	lr: 1.000e-04, eta: 17:22:56, time: 1.743, data_time: 0.057, memory: 18761, loss_cls: 0.0828, loss_bbox: 0.2362, d0.loss_cls: 0.1692, d0.loss_bbox: 0.3339, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2524, d2.loss_cls: 0.0932, d2.loss_bbox: 0.2367, d3.loss_cls: 0.0858, d3.loss_bbox: 0.2372, d4.loss_cls: 0.0852, d4.loss_bbox: 0.2353, loss: 2.1587, grad_norm: 28.5749
2025-06-10 10:17:25,711 - mmdet - INFO - Epoch [1][6250/7033]	lr: 1.000e-04, eta: 17:21:31, time: 1.744, data_time: 0.058, memory: 18761, loss_cls: 0.0952, loss_bbox: 0.2402, d0.loss_cls: 0.1754, d0.loss_bbox: 0.3503, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2646, d2.loss_cls: 0.0994, d2.loss_bbox: 0.2455, d3.loss_cls: 0.0957, d3.loss_bbox: 0.2432, d4.loss_cls: 0.0945, d4.loss_bbox: 0.2402, loss: 2.2615, grad_norm: 23.0077
2025-06-10 10:18:51,938 - mmdet - INFO - Epoch [1][6300/7033]	lr: 1.000e-04, eta: 17:20:00, time: 1.725, data_time: 0.057, memory: 18761, loss_cls: 0.0946, loss_bbox: 0.2450, d0.loss_cls: 0.1699, d0.loss_bbox: 0.3610, d1.loss_cls: 0.1240, d1.loss_bbox: 0.2708, d2.loss_cls: 0.1040, d2.loss_bbox: 0.2518, d3.loss_cls: 0.0968, d3.loss_bbox: 0.2488, d4.loss_cls: 0.0955, d4.loss_bbox: 0.2452, loss: 2.3074, grad_norm: 51.7328
2025-06-10 10:20:19,505 - mmdet - INFO - Epoch [1][6350/7033]	lr: 1.000e-04, eta: 17:18:37, time: 1.751, data_time: 0.057, memory: 18761, loss_cls: 0.0999, loss_bbox: 0.2429, d0.loss_cls: 0.1781, d0.loss_bbox: 0.3560, d1.loss_cls: 0.1285, d1.loss_bbox: 0.2653, d2.loss_cls: 0.1123, d2.loss_bbox: 0.2457, d3.loss_cls: 0.1037, d3.loss_bbox: 0.2437, d4.loss_cls: 0.1011, d4.loss_bbox: 0.2413, loss: 2.3185, grad_norm: 42.0574
2025-06-10 10:21:46,847 - mmdet - INFO - Epoch [1][6400/7033]	lr: 1.000e-04, eta: 17:17:13, time: 1.747, data_time: 0.054, memory: 18761, loss_cls: 0.1037, loss_bbox: 0.2425, d0.loss_cls: 0.1872, d0.loss_bbox: 0.3587, d1.loss_cls: 0.1291, d1.loss_bbox: 0.2717, d2.loss_cls: 0.1142, d2.loss_bbox: 0.2476, d3.loss_cls: 0.1054, d3.loss_bbox: 0.2471, d4.loss_cls: 0.1052, d4.loss_bbox: 0.2412, loss: 2.3533, grad_norm: 286.9358
2025-06-10 10:23:12,584 - mmdet - INFO - Epoch [1][6450/7033]	lr: 1.000e-04, eta: 17:15:39, time: 1.715, data_time: 0.055, memory: 18761, loss_cls: 0.0911, loss_bbox: 0.2347, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3416, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2571, d2.loss_cls: 0.1019, d2.loss_bbox: 0.2367, d3.loss_cls: 0.0932, d3.loss_bbox: 0.2376, d4.loss_cls: 0.0912, d4.loss_bbox: 0.2335, loss: 2.2029, grad_norm: 40.4011
2025-06-10 10:24:39,797 - mmdet - INFO - Epoch [1][6500/7033]	lr: 1.000e-04, eta: 17:14:14, time: 1.744, data_time: 0.053, memory: 18761, loss_cls: 0.1016, loss_bbox: 0.2465, d0.loss_cls: 0.1771, d0.loss_bbox: 0.3555, d1.loss_cls: 0.1265, d1.loss_bbox: 0.2694, d2.loss_cls: 0.1103, d2.loss_bbox: 0.2506, d3.loss_cls: 0.1042, d3.loss_bbox: 0.2501, d4.loss_cls: 0.1020, d4.loss_bbox: 0.2470, loss: 2.3407, grad_norm: 23.2293
2025-06-10 10:26:07,787 - mmdet - INFO - Epoch [1][6550/7033]	lr: 1.000e-04, eta: 17:12:53, time: 1.760, data_time: 0.069, memory: 18761, loss_cls: 0.0975, loss_bbox: 0.2414, d0.loss_cls: 0.1786, d0.loss_bbox: 0.3596, d1.loss_cls: 0.1230, d1.loss_bbox: 0.2680, d2.loss_cls: 0.1072, d2.loss_bbox: 0.2455, d3.loss_cls: 0.0985, d3.loss_bbox: 0.2463, d4.loss_cls: 0.0980, d4.loss_bbox: 0.2419, loss: 2.3057, grad_norm: 34.4132
2025-06-10 10:27:33,314 - mmdet - INFO - Epoch [1][6600/7033]	lr: 1.000e-04, eta: 17:11:18, time: 1.711, data_time: 0.065, memory: 18761, loss_cls: 0.0877, loss_bbox: 0.2354, d0.loss_cls: 0.1683, d0.loss_bbox: 0.3454, d1.loss_cls: 0.1199, d1.loss_bbox: 0.2583, d2.loss_cls: 0.0993, d2.loss_bbox: 0.2387, d3.loss_cls: 0.0918, d3.loss_bbox: 0.2380, d4.loss_cls: 0.0886, d4.loss_bbox: 0.2353, loss: 2.2068, grad_norm: 24.8601
2025-06-10 10:28:59,016 - mmdet - INFO - Epoch [1][6650/7033]	lr: 1.000e-04, eta: 17:09:45, time: 1.714, data_time: 0.056, memory: 18761, loss_cls: 0.0947, loss_bbox: 0.2409, d0.loss_cls: 0.1693, d0.loss_bbox: 0.3502, d1.loss_cls: 0.1236, d1.loss_bbox: 0.2645, d2.loss_cls: 0.1048, d2.loss_bbox: 0.2465, d3.loss_cls: 0.0969, d3.loss_bbox: 0.2435, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2414, loss: 2.2693, grad_norm: 48.8858
2025-06-10 10:30:26,374 - mmdet - INFO - Epoch [1][6700/7033]	lr: 1.000e-04, eta: 17:08:20, time: 1.747, data_time: 0.064, memory: 18761, loss_cls: 0.0890, loss_bbox: 0.2317, d0.loss_cls: 0.1677, d0.loss_bbox: 0.3446, d1.loss_cls: 0.1176, d1.loss_bbox: 0.2555, d2.loss_cls: 0.0991, d2.loss_bbox: 0.2374, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2363, d4.loss_cls: 0.0874, d4.loss_bbox: 0.2345, loss: 2.1918, grad_norm: 49.6228
2025-06-10 10:31:56,207 - mmdet - INFO - Epoch [1][6750/7033]	lr: 1.000e-04, eta: 17:07:09, time: 1.797, data_time: 0.055, memory: 18761, loss_cls: 0.0938, loss_bbox: 0.2381, d0.loss_cls: 0.1743, d0.loss_bbox: 0.3507, d1.loss_cls: 0.1210, d1.loss_bbox: 0.2630, d2.loss_cls: 0.1044, d2.loss_bbox: 0.2441, d3.loss_cls: 0.0975, d3.loss_bbox: 0.2429, d4.loss_cls: 0.0936, d4.loss_bbox: 0.2381, loss: 2.2613, grad_norm: 26.4895
2025-06-10 10:33:24,461 - mmdet - INFO - Epoch [1][6800/7033]	lr: 1.000e-04, eta: 17:05:49, time: 1.765, data_time: 0.058, memory: 18761, loss_cls: 0.0972, loss_bbox: 0.2368, d0.loss_cls: 0.1784, d0.loss_bbox: 0.3462, d1.loss_cls: 0.1222, d1.loss_bbox: 0.2590, d2.loss_cls: 0.1086, d2.loss_bbox: 0.2412, d3.loss_cls: 0.0993, d3.loss_bbox: 0.2406, d4.loss_cls: 0.0979, d4.loss_bbox: 0.2376, loss: 2.2650, grad_norm: 36.9772
2025-06-10 10:34:50,373 - mmdet - INFO - Epoch [1][6850/7033]	lr: 1.000e-04, eta: 17:04:16, time: 1.719, data_time: 0.059, memory: 18761, loss_cls: 0.0868, loss_bbox: 0.2324, d0.loss_cls: 0.1677, d0.loss_bbox: 0.3378, d1.loss_cls: 0.1143, d1.loss_bbox: 0.2542, d2.loss_cls: 0.0961, d2.loss_bbox: 0.2380, d3.loss_cls: 0.0875, d3.loss_bbox: 0.2354, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2328, loss: 2.1683, grad_norm: 35.8297
2025-06-10 10:36:15,674 - mmdet - INFO - Epoch [1][6900/7033]	lr: 1.000e-04, eta: 17:02:41, time: 1.706, data_time: 0.058, memory: 18761, loss_cls: 0.0894, loss_bbox: 0.2416, d0.loss_cls: 0.1740, d0.loss_bbox: 0.3504, d1.loss_cls: 0.1182, d1.loss_bbox: 0.2684, d2.loss_cls: 0.1028, d2.loss_bbox: 0.2482, d3.loss_cls: 0.0957, d3.loss_bbox: 0.2448, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2425, loss: 2.2652, grad_norm: 23.7877
2025-06-10 10:37:45,440 - mmdet - INFO - Epoch [1][6950/7033]	lr: 1.000e-04, eta: 17:01:29, time: 1.795, data_time: 0.058, memory: 18761, loss_cls: 0.0883, loss_bbox: 0.2364, d0.loss_cls: 0.1654, d0.loss_bbox: 0.3498, d1.loss_cls: 0.1163, d1.loss_bbox: 0.2573, d2.loss_cls: 0.0996, d2.loss_bbox: 0.2395, d3.loss_cls: 0.0924, d3.loss_bbox: 0.2363, d4.loss_cls: 0.0882, d4.loss_bbox: 0.2354, loss: 2.2050, grad_norm: 69.9504
2025-06-10 10:39:12,837 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 10:39:12,837 - mmdet - INFO - Epoch [1][7000/7033]	lr: 1.000e-04, eta: 17:00:04, time: 1.748, data_time: 0.064, memory: 18761, loss_cls: 0.1004, loss_bbox: 0.2454, d0.loss_cls: 0.1720, d0.loss_bbox: 0.3562, d1.loss_cls: 0.1248, d1.loss_bbox: 0.2739, d2.loss_cls: 0.1088, d2.loss_bbox: 0.2527, d3.loss_cls: 0.1020, d3.loss_bbox: 0.2492, d4.loss_cls: 0.0993, d4.loss_bbox: 0.2475, loss: 2.3322, grad_norm: 57.8022
2025-06-10 10:40:09,799 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-06-10 11:19:39,268 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 11:19:39,268 - mmdet - INFO - Epoch(val) [1][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.8189, pts_bbox_NuScenes/car_AP_dist_1.0: 0.9175, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9516, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9667, pts_bbox_NuScenes/car_trans_err: 0.1872, pts_bbox_NuScenes/car_scale_err: 0.1340, pts_bbox_NuScenes/car_orient_err: 0.0366, pts_bbox_NuScenes/car_vel_err: 0.2083, pts_bbox_NuScenes/car_attr_err: 0.1961, pts_bbox_NuScenes/mATE: 0.3110, pts_bbox_NuScenes/mASE: 0.2087, pts_bbox_NuScenes/mAOE: 0.1364, pts_bbox_NuScenes/mAVE: 0.2502, pts_bbox_NuScenes/mAAE: 0.1715, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.5055, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.7387, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.8785, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.9256, pts_bbox_NuScenes/truck_trans_err: 0.3500, pts_bbox_NuScenes/truck_scale_err: 0.1560, pts_bbox_NuScenes/truck_orient_err: 0.0402, pts_bbox_NuScenes/truck_vel_err: 0.2248, pts_bbox_NuScenes/truck_attr_err: 0.1903, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0827, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.3299, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.6623, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.7970, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6584, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.3142, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.4699, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1154, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2879, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4666, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7363, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.9326, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9686, pts_bbox_NuScenes/bus_trans_err: 0.3986, pts_bbox_NuScenes/bus_scale_err: 0.1739, pts_bbox_NuScenes/bus_orient_err: 0.0299, pts_bbox_NuScenes/bus_vel_err: 0.4620, pts_bbox_NuScenes/bus_attr_err: 0.1801, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.2131, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.5215, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.7424, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.8625, pts_bbox_NuScenes/trailer_trans_err: 0.5009, pts_bbox_NuScenes/trailer_scale_err: 0.1973, pts_bbox_NuScenes/trailer_orient_err: 0.1367, pts_bbox_NuScenes/trailer_vel_err: 0.1738, pts_bbox_NuScenes/trailer_attr_err: 0.1713, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.7009, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.8246, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.8896, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.9073, pts_bbox_NuScenes/barrier_trans_err: 0.2198, pts_bbox_NuScenes/barrier_scale_err: 0.2017, pts_bbox_NuScenes/barrier_orient_err: 0.0559, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6700, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.8524, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.9052, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.9188, pts_bbox_NuScenes/motorcycle_trans_err: 0.2395, pts_bbox_NuScenes/motorcycle_scale_err: 0.2152, pts_bbox_NuScenes/motorcycle_orient_err: 0.1365, pts_bbox_NuScenes/motorcycle_vel_err: 0.4000, pts_bbox_NuScenes/motorcycle_attr_err: 0.2427, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.7231, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.8157, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.8461, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.8643, pts_bbox_NuScenes/bicycle_trans_err: 0.1869, pts_bbox_NuScenes/bicycle_scale_err: 0.2299, pts_bbox_NuScenes/bicycle_orient_err: 0.1222, pts_bbox_NuScenes/bicycle_vel_err: 0.2150, pts_bbox_NuScenes/bicycle_attr_err: 0.0150, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8557, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.9114, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.9399, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.9537, pts_bbox_NuScenes/pedestrian_trans_err: 0.1835, pts_bbox_NuScenes/pedestrian_scale_err: 0.2325, pts_bbox_NuScenes/pedestrian_orient_err: 0.1993, pts_bbox_NuScenes/pedestrian_vel_err: 0.2023, pts_bbox_NuScenes/pedestrian_attr_err: 0.0887, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7767, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.8365, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.8761, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.9041, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1851, pts_bbox_NuScenes/traffic_cone_scale_err: 0.2322, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7796, pts_bbox_NuScenes/mAP: 0.7748
2025-06-10 11:21:18,371 - mmdet - INFO - Epoch [2][50/7033]	lr: 9.331e-05, eta: 16:53:37, time: 1.907, data_time: 0.260, memory: 18761, loss_cls: 0.0885, loss_bbox: 0.2483, d0.loss_cls: 0.1616, d0.loss_bbox: 0.3493, d1.loss_cls: 0.1167, d1.loss_bbox: 0.2720, d2.loss_cls: 0.1020, d2.loss_bbox: 0.2531, d3.loss_cls: 0.0933, d3.loss_bbox: 0.2530, d4.loss_cls: 0.0888, d4.loss_bbox: 0.2490, loss: 2.2757, grad_norm: 22.0438
2025-06-10 11:22:44,235 - mmdet - INFO - Epoch [2][100/7033]	lr: 9.331e-05, eta: 16:52:07, time: 1.717, data_time: 0.063, memory: 18761, loss_cls: 0.0988, loss_bbox: 0.2525, d0.loss_cls: 0.1745, d0.loss_bbox: 0.3650, d1.loss_cls: 0.1277, d1.loss_bbox: 0.2809, d2.loss_cls: 0.1106, d2.loss_bbox: 0.2605, d3.loss_cls: 0.1033, d3.loss_bbox: 0.2570, d4.loss_cls: 0.1005, d4.loss_bbox: 0.2526, loss: 2.3840, grad_norm: 44.3344
2025-06-10 11:24:12,393 - mmdet - INFO - Epoch [2][150/7033]	lr: 9.331e-05, eta: 16:50:48, time: 1.763, data_time: 0.082, memory: 18761, loss_cls: 0.0860, loss_bbox: 0.2331, d0.loss_cls: 0.1606, d0.loss_bbox: 0.3394, d1.loss_cls: 0.1109, d1.loss_bbox: 0.2596, d2.loss_cls: 0.0969, d2.loss_bbox: 0.2411, d3.loss_cls: 0.0875, d3.loss_bbox: 0.2396, d4.loss_cls: 0.0871, d4.loss_bbox: 0.2340, loss: 2.1757, grad_norm: 27.1017
2025-06-10 11:25:37,637 - mmdet - INFO - Epoch [2][200/7033]	lr: 9.331e-05, eta: 16:49:15, time: 1.705, data_time: 0.064, memory: 18761, loss_cls: 0.0960, loss_bbox: 0.2429, d0.loss_cls: 0.1729, d0.loss_bbox: 0.3573, d1.loss_cls: 0.1227, d1.loss_bbox: 0.2678, d2.loss_cls: 0.1081, d2.loss_bbox: 0.2485, d3.loss_cls: 0.0993, d3.loss_bbox: 0.2453, d4.loss_cls: 0.0979, d4.loss_bbox: 0.2421, loss: 2.3008, grad_norm: 39.9099
2025-06-10 11:27:03,979 - mmdet - INFO - Epoch [2][250/7033]	lr: 9.331e-05, eta: 16:47:47, time: 1.727, data_time: 0.058, memory: 18761, loss_cls: 0.0931, loss_bbox: 0.2347, d0.loss_cls: 0.1693, d0.loss_bbox: 0.3341, d1.loss_cls: 0.1149, d1.loss_bbox: 0.2580, d2.loss_cls: 0.0989, d2.loss_bbox: 0.2381, d3.loss_cls: 0.0948, d3.loss_bbox: 0.2381, d4.loss_cls: 0.0924, d4.loss_bbox: 0.2358, loss: 2.2022, grad_norm: 34.6774
2025-06-10 11:28:31,969 - mmdet - INFO - Epoch [2][300/7033]	lr: 9.331e-05, eta: 16:46:26, time: 1.758, data_time: 0.062, memory: 18761, loss_cls: 0.0824, loss_bbox: 0.2323, d0.loss_cls: 0.1638, d0.loss_bbox: 0.3402, d1.loss_cls: 0.1117, d1.loss_bbox: 0.2581, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2403, d3.loss_cls: 0.0846, d3.loss_bbox: 0.2397, d4.loss_cls: 0.0830, d4.loss_bbox: 0.2348, loss: 2.1629, grad_norm: 35.5278
2025-06-10 11:30:00,538 - mmdet - INFO - Epoch [2][350/7033]	lr: 9.331e-05, eta: 16:45:09, time: 1.773, data_time: 0.062, memory: 18761, loss_cls: 0.0952, loss_bbox: 0.2381, d0.loss_cls: 0.1780, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1247, d1.loss_bbox: 0.2609, d2.loss_cls: 0.1060, d2.loss_bbox: 0.2442, d3.loss_cls: 0.1008, d3.loss_bbox: 0.2425, d4.loss_cls: 0.0963, d4.loss_bbox: 0.2391, loss: 2.2776, grad_norm: 19.0725
2025-06-10 11:31:27,918 - mmdet - INFO - Epoch [2][400/7033]	lr: 9.331e-05, eta: 16:43:46, time: 1.748, data_time: 0.066, memory: 18761, loss_cls: 0.0892, loss_bbox: 0.2290, d0.loss_cls: 0.1669, d0.loss_bbox: 0.3365, d1.loss_cls: 0.1154, d1.loss_bbox: 0.2551, d2.loss_cls: 0.0986, d2.loss_bbox: 0.2358, d3.loss_cls: 0.0924, d3.loss_bbox: 0.2337, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2302, loss: 2.1720, grad_norm: 608.7495
2025-06-10 11:32:56,648 - mmdet - INFO - Epoch [2][450/7033]	lr: 9.331e-05, eta: 16:42:30, time: 1.774, data_time: 0.065, memory: 18761, loss_cls: 0.0934, loss_bbox: 0.2453, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3575, d1.loss_cls: 0.1227, d1.loss_bbox: 0.2716, d2.loss_cls: 0.1052, d2.loss_bbox: 0.2497, d3.loss_cls: 0.0930, d3.loss_bbox: 0.2513, d4.loss_cls: 0.0925, d4.loss_bbox: 0.2467, loss: 2.3051, grad_norm: 73.4145
2025-06-10 11:34:21,879 - mmdet - INFO - Epoch [2][500/7033]	lr: 9.331e-05, eta: 16:40:56, time: 1.705, data_time: 0.066, memory: 18761, loss_cls: 0.0902, loss_bbox: 0.2297, d0.loss_cls: 0.1684, d0.loss_bbox: 0.3379, d1.loss_cls: 0.1188, d1.loss_bbox: 0.2544, d2.loss_cls: 0.1002, d2.loss_bbox: 0.2376, d3.loss_cls: 0.0935, d3.loss_bbox: 0.2347, d4.loss_cls: 0.0899, d4.loss_bbox: 0.2306, loss: 2.1860, grad_norm: 20.9793
2025-06-10 11:35:50,185 - mmdet - INFO - Epoch [2][550/7033]	lr: 9.331e-05, eta: 16:39:38, time: 1.766, data_time: 0.066, memory: 18761, loss_cls: 0.0968, loss_bbox: 0.2501, d0.loss_cls: 0.1808, d0.loss_bbox: 0.3614, d1.loss_cls: 0.1248, d1.loss_bbox: 0.2786, d2.loss_cls: 0.1079, d2.loss_bbox: 0.2584, d3.loss_cls: 0.0976, d3.loss_bbox: 0.2560, d4.loss_cls: 0.0969, d4.loss_bbox: 0.2524, loss: 2.3617, grad_norm: 27.7288
2025-06-10 11:37:18,799 - mmdet - INFO - Epoch [2][600/7033]	lr: 9.331e-05, eta: 16:38:20, time: 1.772, data_time: 0.061, memory: 18761, loss_cls: 0.0927, loss_bbox: 0.2511, d0.loss_cls: 0.1715, d0.loss_bbox: 0.3600, d1.loss_cls: 0.1195, d1.loss_bbox: 0.2789, d2.loss_cls: 0.1033, d2.loss_bbox: 0.2600, d3.loss_cls: 0.0947, d3.loss_bbox: 0.2594, d4.loss_cls: 0.0934, d4.loss_bbox: 0.2529, loss: 2.3375, grad_norm: 33.4380
2025-06-10 11:38:46,063 - mmdet - INFO - Epoch [2][650/7033]	lr: 9.331e-05, eta: 16:36:56, time: 1.745, data_time: 0.065, memory: 18761, loss_cls: 0.0873, loss_bbox: 0.2430, d0.loss_cls: 0.1719, d0.loss_bbox: 0.3588, d1.loss_cls: 0.1184, d1.loss_bbox: 0.2698, d2.loss_cls: 0.0977, d2.loss_bbox: 0.2509, d3.loss_cls: 0.0898, d3.loss_bbox: 0.2487, d4.loss_cls: 0.0862, d4.loss_bbox: 0.2450, loss: 2.2673, grad_norm: 56.9512
2025-06-10 11:40:13,766 - mmdet - INFO - Epoch [2][700/7033]	lr: 9.331e-05, eta: 16:35:34, time: 1.754, data_time: 0.058, memory: 18761, loss_cls: 0.0946, loss_bbox: 0.2505, d0.loss_cls: 0.1764, d0.loss_bbox: 0.3675, d1.loss_cls: 0.1221, d1.loss_bbox: 0.2792, d2.loss_cls: 0.1064, d2.loss_bbox: 0.2602, d3.loss_cls: 0.0992, d3.loss_bbox: 0.2574, d4.loss_cls: 0.0964, d4.loss_bbox: 0.2526, loss: 2.3626, grad_norm: 40.2252
2025-06-10 11:41:42,897 - mmdet - INFO - Epoch [2][750/7033]	lr: 9.331e-05, eta: 16:34:18, time: 1.783, data_time: 0.065, memory: 18761, loss_cls: 0.0918, loss_bbox: 0.2369, d0.loss_cls: 0.1831, d0.loss_bbox: 0.3477, d1.loss_cls: 0.1223, d1.loss_bbox: 0.2629, d2.loss_cls: 0.1038, d2.loss_bbox: 0.2445, d3.loss_cls: 0.0940, d3.loss_bbox: 0.2426, d4.loss_cls: 0.0929, d4.loss_bbox: 0.2375, loss: 2.2599, grad_norm: 26.8600
2025-06-10 11:43:12,241 - mmdet - INFO - Epoch [2][800/7033]	lr: 9.331e-05, eta: 16:33:03, time: 1.787, data_time: 0.059, memory: 18761, loss_cls: 0.0910, loss_bbox: 0.2345, d0.loss_cls: 0.1788, d0.loss_bbox: 0.3455, d1.loss_cls: 0.1208, d1.loss_bbox: 0.2610, d2.loss_cls: 0.1028, d2.loss_bbox: 0.2419, d3.loss_cls: 0.0938, d3.loss_bbox: 0.2409, d4.loss_cls: 0.0913, d4.loss_bbox: 0.2346, loss: 2.2370, grad_norm: 61.8244
2025-06-10 11:44:40,335 - mmdet - INFO - Epoch [2][850/7033]	lr: 9.331e-05, eta: 16:31:43, time: 1.762, data_time: 0.060, memory: 18761, loss_cls: 0.0898, loss_bbox: 0.2318, d0.loss_cls: 0.1695, d0.loss_bbox: 0.3370, d1.loss_cls: 0.1155, d1.loss_bbox: 0.2587, d2.loss_cls: 0.1029, d2.loss_bbox: 0.2401, d3.loss_cls: 0.0941, d3.loss_bbox: 0.2382, d4.loss_cls: 0.0911, d4.loss_bbox: 0.2321, loss: 2.2007, grad_norm: 46.8870
2025-06-10 11:46:07,192 - mmdet - INFO - Epoch [2][900/7033]	lr: 9.331e-05, eta: 16:30:17, time: 1.737, data_time: 0.061, memory: 18761, loss_cls: 0.0870, loss_bbox: 0.2329, d0.loss_cls: 0.1684, d0.loss_bbox: 0.3356, d1.loss_cls: 0.1176, d1.loss_bbox: 0.2577, d2.loss_cls: 0.0988, d2.loss_bbox: 0.2410, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2383, d4.loss_cls: 0.0873, d4.loss_bbox: 0.2336, loss: 2.1893, grad_norm: 22.2320
2025-06-10 11:47:34,252 - mmdet - INFO - Epoch [2][950/7033]	lr: 9.331e-05, eta: 16:28:51, time: 1.741, data_time: 0.054, memory: 18761, loss_cls: 0.0848, loss_bbox: 0.2269, d0.loss_cls: 0.1723, d0.loss_bbox: 0.3321, d1.loss_cls: 0.1155, d1.loss_bbox: 0.2540, d2.loss_cls: 0.0986, d2.loss_bbox: 0.2342, d3.loss_cls: 0.0893, d3.loss_bbox: 0.2339, d4.loss_cls: 0.0854, d4.loss_bbox: 0.2279, loss: 2.1548, grad_norm: 25.4507
2025-06-10 11:49:02,508 - mmdet - INFO - Epoch [2][1000/7033]	lr: 9.331e-05, eta: 16:27:31, time: 1.765, data_time: 0.066, memory: 18761, loss_cls: 0.0845, loss_bbox: 0.2313, d0.loss_cls: 0.1658, d0.loss_bbox: 0.3404, d1.loss_cls: 0.1098, d1.loss_bbox: 0.2585, d2.loss_cls: 0.0955, d2.loss_bbox: 0.2388, d3.loss_cls: 0.0886, d3.loss_bbox: 0.2372, d4.loss_cls: 0.0859, d4.loss_bbox: 0.2324, loss: 2.1687, grad_norm: 29.3802
2025-06-10 11:50:31,372 - mmdet - INFO - Epoch [2][1050/7033]	lr: 9.331e-05, eta: 16:26:14, time: 1.777, data_time: 0.062, memory: 18761, loss_cls: 0.0884, loss_bbox: 0.2327, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3469, d1.loss_cls: 0.1146, d1.loss_bbox: 0.2598, d2.loss_cls: 0.0977, d2.loss_bbox: 0.2408, d3.loss_cls: 0.0906, d3.loss_bbox: 0.2390, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2338, loss: 2.2045, grad_norm: 36.0393
2025-06-10 11:52:02,470 - mmdet - INFO - Epoch [2][1100/7033]	lr: 9.331e-05, eta: 16:25:05, time: 1.822, data_time: 0.065, memory: 18761, loss_cls: 0.0930, loss_bbox: 0.2315, d0.loss_cls: 0.1724, d0.loss_bbox: 0.3395, d1.loss_cls: 0.1180, d1.loss_bbox: 0.2567, d2.loss_cls: 0.1017, d2.loss_bbox: 0.2403, d3.loss_cls: 0.0937, d3.loss_bbox: 0.2379, d4.loss_cls: 0.0934, d4.loss_bbox: 0.2319, loss: 2.2100, grad_norm: 24.1823
2025-06-10 11:53:28,926 - mmdet - INFO - Epoch [2][1150/7033]	lr: 9.331e-05, eta: 16:23:37, time: 1.728, data_time: 0.057, memory: 18761, loss_cls: 0.0821, loss_bbox: 0.2291, d0.loss_cls: 0.1555, d0.loss_bbox: 0.3310, d1.loss_cls: 0.1053, d1.loss_bbox: 0.2528, d2.loss_cls: 0.0933, d2.loss_bbox: 0.2358, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2352, d4.loss_cls: 0.0832, d4.loss_bbox: 0.2295, loss: 2.1188, grad_norm: 31.7146
2025-06-10 11:54:54,670 - mmdet - INFO - Epoch [2][1200/7033]	lr: 9.331e-05, eta: 16:22:06, time: 1.716, data_time: 0.065, memory: 18761, loss_cls: 0.0908, loss_bbox: 0.2266, d0.loss_cls: 0.1638, d0.loss_bbox: 0.3415, d1.loss_cls: 0.1181, d1.loss_bbox: 0.2551, d2.loss_cls: 0.0992, d2.loss_bbox: 0.2380, d3.loss_cls: 0.0943, d3.loss_bbox: 0.2325, d4.loss_cls: 0.0924, d4.loss_bbox: 0.2288, loss: 2.1810, grad_norm: 98.6746
2025-06-10 11:56:25,065 - mmdet - INFO - Epoch [2][1250/7033]	lr: 9.331e-05, eta: 16:20:54, time: 1.808, data_time: 0.056, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2367, d0.loss_cls: 0.1632, d0.loss_bbox: 0.3387, d1.loss_cls: 0.1088, d1.loss_bbox: 0.2573, d2.loss_cls: 0.0905, d2.loss_bbox: 0.2450, d3.loss_cls: 0.0837, d3.loss_bbox: 0.2450, d4.loss_cls: 0.0825, d4.loss_bbox: 0.2376, loss: 2.1707, grad_norm: 22.5630
2025-06-10 11:57:54,229 - mmdet - INFO - Epoch [2][1300/7033]	lr: 9.331e-05, eta: 16:19:37, time: 1.783, data_time: 0.061, memory: 18761, loss_cls: 0.0854, loss_bbox: 0.2293, d0.loss_cls: 0.1670, d0.loss_bbox: 0.3303, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2529, d2.loss_cls: 0.0937, d2.loss_bbox: 0.2366, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2363, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2313, loss: 2.1431, grad_norm: 32.1865
2025-06-10 11:59:21,302 - mmdet - INFO - Epoch [2][1350/7033]	lr: 9.331e-05, eta: 16:18:12, time: 1.742, data_time: 0.064, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2273, d0.loss_cls: 0.1702, d0.loss_bbox: 0.3336, d1.loss_cls: 0.1125, d1.loss_bbox: 0.2504, d2.loss_cls: 0.0966, d2.loss_bbox: 0.2335, d3.loss_cls: 0.0893, d3.loss_bbox: 0.2329, d4.loss_cls: 0.0848, d4.loss_bbox: 0.2281, loss: 2.1431, grad_norm: 97.2301
2025-06-10 12:00:46,646 - mmdet - INFO - Epoch [2][1400/7033]	lr: 9.331e-05, eta: 16:16:39, time: 1.707, data_time: 0.065, memory: 18761, loss_cls: 0.0945, loss_bbox: 0.2282, d0.loss_cls: 0.1791, d0.loss_bbox: 0.3374, d1.loss_cls: 0.1232, d1.loss_bbox: 0.2562, d2.loss_cls: 0.1078, d2.loss_bbox: 0.2374, d3.loss_cls: 0.0992, d3.loss_bbox: 0.2335, d4.loss_cls: 0.0953, d4.loss_bbox: 0.2280, loss: 2.2199, grad_norm: 33.1617
2025-06-10 12:02:18,016 - mmdet - INFO - Epoch [2][1450/7033]	lr: 9.331e-05, eta: 16:15:30, time: 1.825, data_time: 0.064, memory: 18761, loss_cls: 0.0908, loss_bbox: 0.2225, d0.loss_cls: 0.1702, d0.loss_bbox: 0.3355, d1.loss_cls: 0.1217, d1.loss_bbox: 0.2535, d2.loss_cls: 0.1043, d2.loss_bbox: 0.2324, d3.loss_cls: 0.0957, d3.loss_bbox: 0.2322, d4.loss_cls: 0.0901, d4.loss_bbox: 0.2243, loss: 2.1731, grad_norm: 33.6392
2025-06-10 12:03:45,391 - mmdet - INFO - Epoch [2][1500/7033]	lr: 9.331e-05, eta: 16:14:06, time: 1.750, data_time: 0.063, memory: 18761, loss_cls: 0.0836, loss_bbox: 0.2309, d0.loss_cls: 0.1635, d0.loss_bbox: 0.3395, d1.loss_cls: 0.1098, d1.loss_bbox: 0.2574, d2.loss_cls: 0.0930, d2.loss_bbox: 0.2382, d3.loss_cls: 0.0859, d3.loss_bbox: 0.2370, d4.loss_cls: 0.0851, d4.loss_bbox: 0.2324, loss: 2.1563, grad_norm: 20.8623
2025-06-10 12:05:10,753 - mmdet - INFO - Epoch [2][1550/7033]	lr: 9.331e-05, eta: 16:12:34, time: 1.707, data_time: 0.060, memory: 18761, loss_cls: 0.0942, loss_bbox: 0.2329, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3389, d1.loss_cls: 0.1210, d1.loss_bbox: 0.2596, d2.loss_cls: 0.1025, d2.loss_bbox: 0.2401, d3.loss_cls: 0.0954, d3.loss_bbox: 0.2391, d4.loss_cls: 0.0940, d4.loss_bbox: 0.2329, loss: 2.2236, grad_norm: 40.2314
2025-06-10 12:06:37,358 - mmdet - INFO - Epoch [2][1600/7033]	lr: 9.331e-05, eta: 16:11:06, time: 1.732, data_time: 0.071, memory: 18761, loss_cls: 0.0919, loss_bbox: 0.2260, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3349, d1.loss_cls: 0.1181, d1.loss_bbox: 0.2553, d2.loss_cls: 0.1019, d2.loss_bbox: 0.2362, d3.loss_cls: 0.0960, d3.loss_bbox: 0.2337, d4.loss_cls: 0.0911, d4.loss_bbox: 0.2304, loss: 2.1894, grad_norm: 39.6166
2025-06-10 12:08:03,640 - mmdet - INFO - Epoch [2][1650/7033]	lr: 9.331e-05, eta: 16:09:37, time: 1.726, data_time: 0.068, memory: 18761, loss_cls: 0.0893, loss_bbox: 0.2408, d0.loss_cls: 0.1757, d0.loss_bbox: 0.3492, d1.loss_cls: 0.1187, d1.loss_bbox: 0.2661, d2.loss_cls: 0.0991, d2.loss_bbox: 0.2472, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2475, d4.loss_cls: 0.0893, d4.loss_bbox: 0.2432, loss: 2.2566, grad_norm: 32.1091
2025-06-10 12:09:29,740 - mmdet - INFO - Epoch [2][1700/7033]	lr: 9.331e-05, eta: 16:08:08, time: 1.722, data_time: 0.063, memory: 18761, loss_cls: 0.0851, loss_bbox: 0.2361, d0.loss_cls: 0.1691, d0.loss_bbox: 0.3398, d1.loss_cls: 0.1133, d1.loss_bbox: 0.2567, d2.loss_cls: 0.0954, d2.loss_bbox: 0.2418, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2401, d4.loss_cls: 0.0862, d4.loss_bbox: 0.2372, loss: 2.1913, grad_norm: 24.4957
2025-06-10 12:10:57,116 - mmdet - INFO - Epoch [2][1750/7033]	lr: 9.331e-05, eta: 16:06:43, time: 1.748, data_time: 0.063, memory: 18761, loss_cls: 0.0856, loss_bbox: 0.2475, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3528, d1.loss_cls: 0.1158, d1.loss_bbox: 0.2723, d2.loss_cls: 0.0971, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0880, d3.loss_bbox: 0.2556, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2490, loss: 2.2699, grad_norm: 37.6481
2025-06-10 12:12:22,618 - mmdet - INFO - Epoch [2][1800/7033]	lr: 9.331e-05, eta: 16:05:12, time: 1.710, data_time: 0.055, memory: 18761, loss_cls: 0.0905, loss_bbox: 0.2480, d0.loss_cls: 0.1603, d0.loss_bbox: 0.3558, d1.loss_cls: 0.1148, d1.loss_bbox: 0.2712, d2.loss_cls: 0.1002, d2.loss_bbox: 0.2567, d3.loss_cls: 0.0934, d3.loss_bbox: 0.2546, d4.loss_cls: 0.0911, d4.loss_bbox: 0.2490, loss: 2.2856, grad_norm: 33.9241
2025-06-10 12:13:48,850 - mmdet - INFO - Epoch [2][1850/7033]	lr: 9.331e-05, eta: 16:03:43, time: 1.724, data_time: 0.060, memory: 18761, loss_cls: 0.0944, loss_bbox: 0.2482, d0.loss_cls: 0.1641, d0.loss_bbox: 0.3518, d1.loss_cls: 0.1204, d1.loss_bbox: 0.2708, d2.loss_cls: 0.1035, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0946, d3.loss_bbox: 0.2550, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2481, loss: 2.3014, grad_norm: 24.2665
2025-06-10 12:15:12,949 - mmdet - INFO - Epoch [2][1900/7033]	lr: 9.331e-05, eta: 16:02:06, time: 1.682, data_time: 0.058, memory: 18761, loss_cls: 0.0901, loss_bbox: 0.2348, d0.loss_cls: 0.1654, d0.loss_bbox: 0.3396, d1.loss_cls: 0.1157, d1.loss_bbox: 0.2616, d2.loss_cls: 0.1004, d2.loss_bbox: 0.2430, d3.loss_cls: 0.0912, d3.loss_bbox: 0.2434, d4.loss_cls: 0.0902, d4.loss_bbox: 0.2378, loss: 2.2132, grad_norm: 40.1374
2025-06-10 12:16:56,889 - mmdet - INFO - Epoch [2][1950/7033]	lr: 9.331e-05, eta: 16:01:43, time: 2.079, data_time: 0.060, memory: 18761, loss_cls: 0.0857, loss_bbox: 0.2381, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3374, d1.loss_cls: 0.1149, d1.loss_bbox: 0.2596, d2.loss_cls: 0.0971, d2.loss_bbox: 0.2458, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2448, d4.loss_cls: 0.0875, d4.loss_bbox: 0.2393, loss: 2.2118, grad_norm: 30.0389
2025-06-10 12:18:23,296 - mmdet - INFO - Epoch [2][2000/7033]	lr: 9.331e-05, eta: 16:00:14, time: 1.728, data_time: 0.062, memory: 18761, loss_cls: 0.0852, loss_bbox: 0.2310, d0.loss_cls: 0.1735, d0.loss_bbox: 0.3364, d1.loss_cls: 0.1121, d1.loss_bbox: 0.2559, d2.loss_cls: 0.0963, d2.loss_bbox: 0.2385, d3.loss_cls: 0.0863, d3.loss_bbox: 0.2371, d4.loss_cls: 0.0845, d4.loss_bbox: 0.2331, loss: 2.1698, grad_norm: 112.7626
2025-06-10 12:19:48,763 - mmdet - INFO - Epoch [2][2050/7033]	lr: 9.331e-05, eta: 15:58:42, time: 1.708, data_time: 0.058, memory: 18761, loss_cls: 0.0908, loss_bbox: 0.2366, d0.loss_cls: 0.1670, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2651, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2473, d3.loss_cls: 0.0920, d3.loss_bbox: 0.2452, d4.loss_cls: 0.0903, d4.loss_bbox: 0.2394, loss: 2.2366, grad_norm: 61.8824
2025-06-10 12:21:17,937 - mmdet - INFO - Epoch [2][2100/7033]	lr: 9.331e-05, eta: 15:57:24, time: 1.785, data_time: 0.059, memory: 18761, loss_cls: 0.0861, loss_bbox: 0.2308, d0.loss_cls: 0.1616, d0.loss_bbox: 0.3336, d1.loss_cls: 0.1096, d1.loss_bbox: 0.2562, d2.loss_cls: 0.0968, d2.loss_bbox: 0.2396, d3.loss_cls: 0.0893, d3.loss_bbox: 0.2369, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2324, loss: 2.1602, grad_norm: 26.8779
2025-06-10 12:22:45,253 - mmdet - INFO - Epoch [2][2150/7033]	lr: 9.331e-05, eta: 15:55:59, time: 1.746, data_time: 0.055, memory: 18761, loss_cls: 0.0850, loss_bbox: 0.2313, d0.loss_cls: 0.1684, d0.loss_bbox: 0.3374, d1.loss_cls: 0.1119, d1.loss_bbox: 0.2604, d2.loss_cls: 0.0974, d2.loss_bbox: 0.2421, d3.loss_cls: 0.0883, d3.loss_bbox: 0.2395, d4.loss_cls: 0.0854, d4.loss_bbox: 0.2342, loss: 2.1813, grad_norm: 24.9102
2025-06-10 12:24:12,956 - mmdet - INFO - Epoch [2][2200/7033]	lr: 9.331e-05, eta: 15:54:35, time: 1.754, data_time: 0.056, memory: 18761, loss_cls: 0.0884, loss_bbox: 0.2327, d0.loss_cls: 0.1647, d0.loss_bbox: 0.3388, d1.loss_cls: 0.1113, d1.loss_bbox: 0.2680, d2.loss_cls: 0.0966, d2.loss_bbox: 0.2446, d3.loss_cls: 0.0889, d3.loss_bbox: 0.2407, d4.loss_cls: 0.0875, d4.loss_bbox: 0.2339, loss: 2.1960, grad_norm: 25.4804
2025-06-10 12:25:40,946 - mmdet - INFO - Epoch [2][2250/7033]	lr: 9.331e-05, eta: 15:53:12, time: 1.760, data_time: 0.065, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2412, d0.loss_cls: 0.1556, d0.loss_bbox: 0.3528, d1.loss_cls: 0.1086, d1.loss_bbox: 0.2719, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2502, d3.loss_cls: 0.0864, d3.loss_bbox: 0.2486, d4.loss_cls: 0.0836, d4.loss_bbox: 0.2423, loss: 2.2206, grad_norm: 25.7545
2025-06-10 12:27:05,623 - mmdet - INFO - Epoch [2][2300/7033]	lr: 9.331e-05, eta: 15:51:37, time: 1.693, data_time: 0.065, memory: 18761, loss_cls: 0.0919, loss_bbox: 0.2349, d0.loss_cls: 0.1680, d0.loss_bbox: 0.3449, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2661, d2.loss_cls: 0.1050, d2.loss_bbox: 0.2437, d3.loss_cls: 0.0959, d3.loss_bbox: 0.2405, d4.loss_cls: 0.0943, d4.loss_bbox: 0.2363, loss: 2.2388, grad_norm: 37.1087
2025-06-10 12:28:31,345 - mmdet - INFO - Epoch [2][2350/7033]	lr: 9.331e-05, eta: 15:50:06, time: 1.714, data_time: 0.055, memory: 18761, loss_cls: 0.0904, loss_bbox: 0.2266, d0.loss_cls: 0.1664, d0.loss_bbox: 0.3277, d1.loss_cls: 0.1161, d1.loss_bbox: 0.2522, d2.loss_cls: 0.1026, d2.loss_bbox: 0.2342, d3.loss_cls: 0.0941, d3.loss_bbox: 0.2335, d4.loss_cls: 0.0929, d4.loss_bbox: 0.2266, loss: 2.1633, grad_norm: 27.0215
2025-06-10 12:30:02,483 - mmdet - INFO - Epoch [2][2400/7033]	lr: 9.331e-05, eta: 15:48:54, time: 1.823, data_time: 0.053, memory: 18761, loss_cls: 0.0869, loss_bbox: 0.2392, d0.loss_cls: 0.1717, d0.loss_bbox: 0.3476, d1.loss_cls: 0.1166, d1.loss_bbox: 0.2650, d2.loss_cls: 0.0988, d2.loss_bbox: 0.2482, d3.loss_cls: 0.0912, d3.loss_bbox: 0.2451, d4.loss_cls: 0.0880, d4.loss_bbox: 0.2400, loss: 2.2384, grad_norm: 31.0664
2025-06-10 12:31:27,851 - mmdet - INFO - Epoch [2][2450/7033]	lr: 9.331e-05, eta: 15:47:22, time: 1.707, data_time: 0.060, memory: 18761, loss_cls: 0.0859, loss_bbox: 0.2313, d0.loss_cls: 0.1672, d0.loss_bbox: 0.3430, d1.loss_cls: 0.1143, d1.loss_bbox: 0.2609, d2.loss_cls: 0.0969, d2.loss_bbox: 0.2409, d3.loss_cls: 0.0895, d3.loss_bbox: 0.2380, d4.loss_cls: 0.0859, d4.loss_bbox: 0.2320, loss: 2.1857, grad_norm: 27.0763
2025-06-10 12:32:53,362 - mmdet - INFO - Epoch [2][2500/7033]	lr: 9.331e-05, eta: 15:45:51, time: 1.711, data_time: 0.062, memory: 18761, loss_cls: 0.0862, loss_bbox: 0.2348, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3390, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2618, d2.loss_cls: 0.0972, d2.loss_bbox: 0.2458, d3.loss_cls: 0.0885, d3.loss_bbox: 0.2416, d4.loss_cls: 0.0876, d4.loss_bbox: 0.2354, loss: 2.1938, grad_norm: 23.7737
2025-06-10 12:34:20,084 - mmdet - INFO - Epoch [2][2550/7033]	lr: 9.331e-05, eta: 15:44:23, time: 1.734, data_time: 0.070, memory: 18761, loss_cls: 0.0939, loss_bbox: 0.2388, d0.loss_cls: 0.1685, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1180, d1.loss_bbox: 0.2695, d2.loss_cls: 0.1068, d2.loss_bbox: 0.2495, d3.loss_cls: 0.0953, d3.loss_bbox: 0.2487, d4.loss_cls: 0.0940, d4.loss_bbox: 0.2408, loss: 2.2755, grad_norm: 29.4750
2025-06-10 12:35:45,830 - mmdet - INFO - Epoch [2][2600/7033]	lr: 9.331e-05, eta: 15:42:53, time: 1.715, data_time: 0.058, memory: 18761, loss_cls: 0.1019, loss_bbox: 0.2438, d0.loss_cls: 0.1715, d0.loss_bbox: 0.3543, d1.loss_cls: 0.1300, d1.loss_bbox: 0.2766, d2.loss_cls: 0.1155, d2.loss_bbox: 0.2540, d3.loss_cls: 0.1046, d3.loss_bbox: 0.2529, d4.loss_cls: 0.1055, d4.loss_bbox: 0.2460, loss: 2.3566, grad_norm: 75.3649
2025-06-10 12:37:11,851 - mmdet - INFO - Epoch [2][2650/7033]	lr: 9.331e-05, eta: 15:41:23, time: 1.720, data_time: 0.062, memory: 18761, loss_cls: 0.0923, loss_bbox: 0.2336, d0.loss_cls: 0.1680, d0.loss_bbox: 0.3416, d1.loss_cls: 0.1255, d1.loss_bbox: 0.2662, d2.loss_cls: 0.1075, d2.loss_bbox: 0.2450, d3.loss_cls: 0.0972, d3.loss_bbox: 0.2420, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2338, loss: 2.2457, grad_norm: 39.3131
2025-06-10 12:38:39,333 - mmdet - INFO - Epoch [2][2700/7033]	lr: 9.331e-05, eta: 15:39:58, time: 1.750, data_time: 0.057, memory: 18761, loss_cls: 0.0927, loss_bbox: 0.2394, d0.loss_cls: 0.1722, d0.loss_bbox: 0.3433, d1.loss_cls: 0.1254, d1.loss_bbox: 0.2656, d2.loss_cls: 0.1088, d2.loss_bbox: 0.2484, d3.loss_cls: 0.0976, d3.loss_bbox: 0.2481, d4.loss_cls: 0.0937, d4.loss_bbox: 0.2404, loss: 2.2755, grad_norm: 36.0112
2025-06-10 12:40:07,074 - mmdet - INFO - Epoch [2][2750/7033]	lr: 9.331e-05, eta: 15:38:34, time: 1.753, data_time: 0.058, memory: 18761, loss_cls: 0.0878, loss_bbox: 0.2323, d0.loss_cls: 0.1678, d0.loss_bbox: 0.3408, d1.loss_cls: 0.1178, d1.loss_bbox: 0.2598, d2.loss_cls: 0.0998, d2.loss_bbox: 0.2420, d3.loss_cls: 0.0931, d3.loss_bbox: 0.2402, d4.loss_cls: 0.0888, d4.loss_bbox: 0.2338, loss: 2.2040, grad_norm: 29.3224
2025-06-10 12:41:34,311 - mmdet - INFO - Epoch [2][2800/7033]	lr: 9.331e-05, eta: 15:37:09, time: 1.746, data_time: 0.056, memory: 18761, loss_cls: 0.0810, loss_bbox: 0.2294, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3426, d1.loss_cls: 0.1126, d1.loss_bbox: 0.2586, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2426, d3.loss_cls: 0.0857, d3.loss_bbox: 0.2383, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2325, loss: 2.1590, grad_norm: 76.1027
2025-06-10 12:43:00,942 - mmdet - INFO - Epoch [2][2850/7033]	lr: 9.331e-05, eta: 15:35:41, time: 1.732, data_time: 0.063, memory: 18761, loss_cls: 0.0916, loss_bbox: 0.2347, d0.loss_cls: 0.1686, d0.loss_bbox: 0.3500, d1.loss_cls: 0.1159, d1.loss_bbox: 0.2642, d2.loss_cls: 0.1008, d2.loss_bbox: 0.2465, d3.loss_cls: 0.0947, d3.loss_bbox: 0.2434, d4.loss_cls: 0.0909, d4.loss_bbox: 0.2378, loss: 2.2390, grad_norm: 57.0900
2025-06-10 12:44:27,434 - mmdet - INFO - Epoch [2][2900/7033]	lr: 9.331e-05, eta: 15:34:13, time: 1.730, data_time: 0.056, memory: 18761, loss_cls: 0.0828, loss_bbox: 0.2324, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3427, d1.loss_cls: 0.1117, d1.loss_bbox: 0.2590, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2404, d3.loss_cls: 0.0865, d3.loss_bbox: 0.2388, d4.loss_cls: 0.0841, d4.loss_bbox: 0.2335, loss: 2.1700, grad_norm: 26.3466
2025-06-10 12:45:53,939 - mmdet - INFO - Epoch [2][2950/7033]	lr: 9.331e-05, eta: 15:32:45, time: 1.730, data_time: 0.062, memory: 18761, loss_cls: 0.0860, loss_bbox: 0.2238, d0.loss_cls: 0.1600, d0.loss_bbox: 0.3321, d1.loss_cls: 0.1103, d1.loss_bbox: 0.2540, d2.loss_cls: 0.0972, d2.loss_bbox: 0.2339, d3.loss_cls: 0.0899, d3.loss_bbox: 0.2316, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2257, loss: 2.1316, grad_norm: 30.6342
2025-06-10 12:47:20,553 - mmdet - INFO - Epoch [2][3000/7033]	lr: 9.331e-05, eta: 15:31:17, time: 1.732, data_time: 0.063, memory: 18761, loss_cls: 0.0822, loss_bbox: 0.2282, d0.loss_cls: 0.1619, d0.loss_bbox: 0.3323, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2524, d2.loss_cls: 0.0929, d2.loss_bbox: 0.2360, d3.loss_cls: 0.0852, d3.loss_bbox: 0.2351, d4.loss_cls: 0.0831, d4.loss_bbox: 0.2289, loss: 2.1264, grad_norm: 24.4748
2025-06-10 12:48:45,466 - mmdet - INFO - Epoch [2][3050/7033]	lr: 9.331e-05, eta: 15:29:44, time: 1.698, data_time: 0.063, memory: 18761, loss_cls: 0.0908, loss_bbox: 0.2390, d0.loss_cls: 0.1679, d0.loss_bbox: 0.3468, d1.loss_cls: 0.1185, d1.loss_bbox: 0.2674, d2.loss_cls: 0.1001, d2.loss_bbox: 0.2487, d3.loss_cls: 0.0933, d3.loss_bbox: 0.2470, d4.loss_cls: 0.0909, d4.loss_bbox: 0.2407, loss: 2.2511, grad_norm: 48.3001
2025-06-10 12:50:13,070 - mmdet - INFO - Epoch [2][3100/7033]	lr: 9.331e-05, eta: 15:28:20, time: 1.752, data_time: 0.059, memory: 18761, loss_cls: 0.0932, loss_bbox: 0.2438, d0.loss_cls: 0.1716, d0.loss_bbox: 0.3513, d1.loss_cls: 0.1183, d1.loss_bbox: 0.2716, d2.loss_cls: 0.1027, d2.loss_bbox: 0.2544, d3.loss_cls: 0.0957, d3.loss_bbox: 0.2537, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2467, loss: 2.2961, grad_norm: 30.8213
2025-06-10 12:51:38,862 - mmdet - INFO - Epoch [2][3150/7033]	lr: 9.331e-05, eta: 15:26:49, time: 1.716, data_time: 0.058, memory: 18761, loss_cls: 0.0872, loss_bbox: 0.2354, d0.loss_cls: 0.1687, d0.loss_bbox: 0.3483, d1.loss_cls: 0.1171, d1.loss_bbox: 0.2633, d2.loss_cls: 0.1016, d2.loss_bbox: 0.2453, d3.loss_cls: 0.0928, d3.loss_bbox: 0.2443, d4.loss_cls: 0.0883, d4.loss_bbox: 0.2372, loss: 2.2295, grad_norm: 32.1258
2025-06-10 12:53:04,095 - mmdet - INFO - Epoch [2][3200/7033]	lr: 9.331e-05, eta: 15:25:17, time: 1.705, data_time: 0.055, memory: 18761, loss_cls: 0.0999, loss_bbox: 0.2451, d0.loss_cls: 0.1800, d0.loss_bbox: 0.3495, d1.loss_cls: 0.1272, d1.loss_bbox: 0.2717, d2.loss_cls: 0.1096, d2.loss_bbox: 0.2553, d3.loss_cls: 0.1012, d3.loss_bbox: 0.2544, d4.loss_cls: 0.1002, d4.loss_bbox: 0.2481, loss: 2.3421, grad_norm: 32.4118
2025-06-10 12:54:30,458 - mmdet - INFO - Epoch [2][3250/7033]	lr: 9.331e-05, eta: 15:23:49, time: 1.727, data_time: 0.076, memory: 18761, loss_cls: 0.0918, loss_bbox: 0.2421, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3494, d1.loss_cls: 0.1142, d1.loss_bbox: 0.2692, d2.loss_cls: 0.1027, d2.loss_bbox: 0.2508, d3.loss_cls: 0.0944, d3.loss_bbox: 0.2488, d4.loss_cls: 0.0940, d4.loss_bbox: 0.2426, loss: 2.2711, grad_norm: 36.2697
2025-06-10 12:55:57,302 - mmdet - INFO - Epoch [2][3300/7033]	lr: 9.331e-05, eta: 15:22:22, time: 1.737, data_time: 0.054, memory: 18761, loss_cls: 0.0828, loss_bbox: 0.2336, d0.loss_cls: 0.1637, d0.loss_bbox: 0.3344, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2592, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2424, d3.loss_cls: 0.0874, d3.loss_bbox: 0.2399, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2335, loss: 2.1665, grad_norm: 30.4617
2025-06-10 12:57:24,839 - mmdet - INFO - Epoch [2][3350/7033]	lr: 9.331e-05, eta: 15:20:58, time: 1.751, data_time: 0.061, memory: 18761, loss_cls: 0.0831, loss_bbox: 0.2313, d0.loss_cls: 0.1626, d0.loss_bbox: 0.3340, d1.loss_cls: 0.1123, d1.loss_bbox: 0.2538, d2.loss_cls: 0.0946, d2.loss_bbox: 0.2392, d3.loss_cls: 0.0866, d3.loss_bbox: 0.2392, d4.loss_cls: 0.0837, d4.loss_bbox: 0.2314, loss: 2.1518, grad_norm: 35.3137
2025-06-10 12:58:53,404 - mmdet - INFO - Epoch [2][3400/7033]	lr: 9.331e-05, eta: 15:19:36, time: 1.771, data_time: 0.058, memory: 18761, loss_cls: 0.0871, loss_bbox: 0.2421, d0.loss_cls: 0.1685, d0.loss_bbox: 0.3558, d1.loss_cls: 0.1141, d1.loss_bbox: 0.2704, d2.loss_cls: 0.0987, d2.loss_bbox: 0.2505, d3.loss_cls: 0.0900, d3.loss_bbox: 0.2510, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2437, loss: 2.2601, grad_norm: 33.0805
2025-06-10 13:00:20,827 - mmdet - INFO - Epoch [2][3450/7033]	lr: 9.331e-05, eta: 15:18:11, time: 1.748, data_time: 0.059, memory: 18761, loss_cls: 0.0894, loss_bbox: 0.2360, d0.loss_cls: 0.1660, d0.loss_bbox: 0.3440, d1.loss_cls: 0.1124, d1.loss_bbox: 0.2627, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2463, d3.loss_cls: 0.0937, d3.loss_bbox: 0.2452, d4.loss_cls: 0.0910, d4.loss_bbox: 0.2378, loss: 2.2226, grad_norm: 48.2567
2025-06-10 13:01:51,536 - mmdet - INFO - Epoch [2][3500/7033]	lr: 9.331e-05, eta: 15:16:56, time: 1.814, data_time: 0.069, memory: 18761, loss_cls: 0.0883, loss_bbox: 0.2401, d0.loss_cls: 0.1688, d0.loss_bbox: 0.3491, d1.loss_cls: 0.1189, d1.loss_bbox: 0.2660, d2.loss_cls: 0.1015, d2.loss_bbox: 0.2487, d3.loss_cls: 0.0919, d3.loss_bbox: 0.2468, d4.loss_cls: 0.0898, d4.loss_bbox: 0.2408, loss: 2.2506, grad_norm: 31.8949
2025-06-10 13:03:17,522 - mmdet - INFO - Epoch [2][3550/7033]	lr: 9.331e-05, eta: 15:15:26, time: 1.720, data_time: 0.063, memory: 18761, loss_cls: 0.0882, loss_bbox: 0.2356, d0.loss_cls: 0.1697, d0.loss_bbox: 0.3341, d1.loss_cls: 0.1123, d1.loss_bbox: 0.2593, d2.loss_cls: 0.0989, d2.loss_bbox: 0.2429, d3.loss_cls: 0.0899, d3.loss_bbox: 0.2434, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2365, loss: 2.1978, grad_norm: 29.9227
2025-06-10 13:04:43,611 - mmdet - INFO - Epoch [2][3600/7033]	lr: 9.331e-05, eta: 15:13:57, time: 1.721, data_time: 0.060, memory: 18761, loss_cls: 0.0879, loss_bbox: 0.2414, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3411, d1.loss_cls: 0.1158, d1.loss_bbox: 0.2662, d2.loss_cls: 0.1004, d2.loss_bbox: 0.2500, d3.loss_cls: 0.0922, d3.loss_bbox: 0.2487, d4.loss_cls: 0.0903, d4.loss_bbox: 0.2419, loss: 2.2494, grad_norm: 56.7799
2025-06-10 13:06:09,804 - mmdet - INFO - Epoch [2][3650/7033]	lr: 9.331e-05, eta: 15:12:28, time: 1.724, data_time: 0.056, memory: 18761, loss_cls: 0.0869, loss_bbox: 0.2395, d0.loss_cls: 0.1649, d0.loss_bbox: 0.3485, d1.loss_cls: 0.1150, d1.loss_bbox: 0.2652, d2.loss_cls: 0.0979, d2.loss_bbox: 0.2499, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2471, d4.loss_cls: 0.0884, d4.loss_bbox: 0.2394, loss: 2.2332, grad_norm: 25.5135
2025-06-10 13:07:40,328 - mmdet - INFO - Epoch [2][3700/7033]	lr: 9.331e-05, eta: 15:11:12, time: 1.809, data_time: 0.053, memory: 18761, loss_cls: 0.0943, loss_bbox: 0.2423, d0.loss_cls: 0.1706, d0.loss_bbox: 0.3469, d1.loss_cls: 0.1214, d1.loss_bbox: 0.2669, d2.loss_cls: 0.1052, d2.loss_bbox: 0.2511, d3.loss_cls: 0.0979, d3.loss_bbox: 0.2515, d4.loss_cls: 0.0950, d4.loss_bbox: 0.2433, loss: 2.2865, grad_norm: 67.0726
2025-06-10 13:09:13,060 - mmdet - INFO - Epoch [2][3750/7033]	lr: 9.331e-05, eta: 15:10:02, time: 1.856, data_time: 0.065, memory: 18761, loss_cls: 0.0855, loss_bbox: 0.2305, d0.loss_cls: 0.1610, d0.loss_bbox: 0.3392, d1.loss_cls: 0.1079, d1.loss_bbox: 0.2586, d2.loss_cls: 0.0965, d2.loss_bbox: 0.2390, d3.loss_cls: 0.0863, d3.loss_bbox: 0.2389, d4.loss_cls: 0.0844, d4.loss_bbox: 0.2318, loss: 2.1596, grad_norm: 58.2946
2025-06-10 13:10:38,419 - mmdet - INFO - Epoch [2][3800/7033]	lr: 9.331e-05, eta: 15:08:31, time: 1.707, data_time: 0.064, memory: 18761, loss_cls: 0.0793, loss_bbox: 0.2358, d0.loss_cls: 0.1628, d0.loss_bbox: 0.3479, d1.loss_cls: 0.1078, d1.loss_bbox: 0.2635, d2.loss_cls: 0.0943, d2.loss_bbox: 0.2436, d3.loss_cls: 0.0831, d3.loss_bbox: 0.2419, d4.loss_cls: 0.0796, d4.loss_bbox: 0.2372, loss: 2.1771, grad_norm: 37.8645
2025-06-10 13:12:04,362 - mmdet - INFO - Epoch [2][3850/7033]	lr: 9.331e-05, eta: 15:07:01, time: 1.719, data_time: 0.061, memory: 18761, loss_cls: 0.0874, loss_bbox: 0.2365, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3401, d1.loss_cls: 0.1124, d1.loss_bbox: 0.2609, d2.loss_cls: 0.0991, d2.loss_bbox: 0.2439, d3.loss_cls: 0.0901, d3.loss_bbox: 0.2446, d4.loss_cls: 0.0880, d4.loss_bbox: 0.2371, loss: 2.1996, grad_norm: 31.3768
2025-06-10 13:13:31,263 - mmdet - INFO - Epoch [2][3900/7033]	lr: 9.331e-05, eta: 15:05:34, time: 1.738, data_time: 0.058, memory: 18761, loss_cls: 0.0868, loss_bbox: 0.2418, d0.loss_cls: 0.1675, d0.loss_bbox: 0.3452, d1.loss_cls: 0.1123, d1.loss_bbox: 0.2677, d2.loss_cls: 0.0968, d2.loss_bbox: 0.2513, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2485, d4.loss_cls: 0.0879, d4.loss_bbox: 0.2424, loss: 2.2361, grad_norm: 98.9268
2025-06-10 13:14:59,099 - mmdet - INFO - Epoch [2][3950/7033]	lr: 9.331e-05, eta: 15:04:10, time: 1.757, data_time: 0.056, memory: 18761, loss_cls: 0.0864, loss_bbox: 0.2348, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3390, d1.loss_cls: 0.1179, d1.loss_bbox: 0.2638, d2.loss_cls: 0.1005, d2.loss_bbox: 0.2453, d3.loss_cls: 0.0901, d3.loss_bbox: 0.2429, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2360, loss: 2.2148, grad_norm: 20.2026
2025-06-10 13:16:26,992 - mmdet - INFO - Epoch [2][4000/7033]	lr: 9.331e-05, eta: 15:02:46, time: 1.758, data_time: 0.053, memory: 18761, loss_cls: 0.0915, loss_bbox: 0.2539, d0.loss_cls: 0.1735, d0.loss_bbox: 0.3638, d1.loss_cls: 0.1201, d1.loss_bbox: 0.2775, d2.loss_cls: 0.1037, d2.loss_bbox: 0.2621, d3.loss_cls: 0.0946, d3.loss_bbox: 0.2619, d4.loss_cls: 0.0932, d4.loss_bbox: 0.2553, loss: 2.3511, grad_norm: 37.3797
2025-06-10 13:17:57,090 - mmdet - INFO - Epoch [2][4050/7033]	lr: 9.331e-05, eta: 15:01:28, time: 1.801, data_time: 0.068, memory: 18761, loss_cls: 0.0923, loss_bbox: 0.2712, d0.loss_cls: 0.1704, d0.loss_bbox: 0.3825, d1.loss_cls: 0.1183, d1.loss_bbox: 0.3026, d2.loss_cls: 0.1065, d2.loss_bbox: 0.2822, d3.loss_cls: 0.0956, d3.loss_bbox: 0.2811, d4.loss_cls: 0.0918, d4.loss_bbox: 0.2760, loss: 2.4705, grad_norm: 44.1766
2025-06-10 13:19:25,364 - mmdet - INFO - Epoch [2][4100/7033]	lr: 9.331e-05, eta: 15:00:05, time: 1.766, data_time: 0.065, memory: 18761, loss_cls: 0.0941, loss_bbox: 0.2569, d0.loss_cls: 0.1698, d0.loss_bbox: 0.3699, d1.loss_cls: 0.1195, d1.loss_bbox: 0.2902, d2.loss_cls: 0.1062, d2.loss_bbox: 0.2699, d3.loss_cls: 0.0962, d3.loss_bbox: 0.2668, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2603, loss: 2.3949, grad_norm: 52.3035
2025-06-10 13:20:55,691 - mmdet - INFO - Epoch [2][4150/7033]	lr: 9.331e-05, eta: 14:58:47, time: 1.807, data_time: 0.068, memory: 18761, loss_cls: 0.0927, loss_bbox: 0.2513, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3576, d1.loss_cls: 0.1226, d1.loss_bbox: 0.2804, d2.loss_cls: 0.1051, d2.loss_bbox: 0.2618, d3.loss_cls: 0.0953, d3.loss_bbox: 0.2604, d4.loss_cls: 0.0935, d4.loss_bbox: 0.2544, loss: 2.3519, grad_norm: 37.9547
2025-06-10 13:22:25,041 - mmdet - INFO - Epoch [2][4200/7033]	lr: 9.331e-05, eta: 14:57:27, time: 1.787, data_time: 0.079, memory: 18761, loss_cls: 0.0898, loss_bbox: 0.2506, d0.loss_cls: 0.1729, d0.loss_bbox: 0.3563, d1.loss_cls: 0.1175, d1.loss_bbox: 0.2757, d2.loss_cls: 0.1016, d2.loss_bbox: 0.2597, d3.loss_cls: 0.0914, d3.loss_bbox: 0.2591, d4.loss_cls: 0.0901, d4.loss_bbox: 0.2518, loss: 2.3164, grad_norm: 49.1303
2025-06-10 13:23:51,911 - mmdet - INFO - Epoch [2][4250/7033]	lr: 9.331e-05, eta: 14:56:00, time: 1.737, data_time: 0.066, memory: 18761, loss_cls: 0.0884, loss_bbox: 0.2332, d0.loss_cls: 0.1643, d0.loss_bbox: 0.3431, d1.loss_cls: 0.1145, d1.loss_bbox: 0.2641, d2.loss_cls: 0.1007, d2.loss_bbox: 0.2470, d3.loss_cls: 0.0907, d3.loss_bbox: 0.2438, d4.loss_cls: 0.0895, d4.loss_bbox: 0.2366, loss: 2.2158, grad_norm: 39.7199
2025-06-10 13:25:15,527 - mmdet - INFO - Epoch [2][4300/7033]	lr: 9.331e-05, eta: 14:54:24, time: 1.672, data_time: 0.055, memory: 18761, loss_cls: 0.0915, loss_bbox: 0.2438, d0.loss_cls: 0.1645, d0.loss_bbox: 0.3508, d1.loss_cls: 0.1201, d1.loss_bbox: 0.2734, d2.loss_cls: 0.1011, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0945, d3.loss_bbox: 0.2536, d4.loss_cls: 0.0916, d4.loss_bbox: 0.2460, loss: 2.2864, grad_norm: 143.7729
2025-06-10 13:26:40,794 - mmdet - INFO - Epoch [2][4350/7033]	lr: 9.331e-05, eta: 14:52:52, time: 1.705, data_time: 0.059, memory: 18761, loss_cls: 0.0958, loss_bbox: 0.2432, d0.loss_cls: 0.1682, d0.loss_bbox: 0.3489, d1.loss_cls: 0.1233, d1.loss_bbox: 0.2690, d2.loss_cls: 0.1064, d2.loss_bbox: 0.2530, d3.loss_cls: 0.0997, d3.loss_bbox: 0.2498, d4.loss_cls: 0.0966, d4.loss_bbox: 0.2435, loss: 2.2973, grad_norm: 30.1331
2025-06-10 13:28:05,283 - mmdet - INFO - Epoch [2][4400/7033]	lr: 9.331e-05, eta: 14:51:19, time: 1.690, data_time: 0.060, memory: 18761, loss_cls: 0.0796, loss_bbox: 0.2320, d0.loss_cls: 0.1551, d0.loss_bbox: 0.3297, d1.loss_cls: 0.1063, d1.loss_bbox: 0.2569, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2396, d3.loss_cls: 0.0841, d3.loss_bbox: 0.2378, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2319, loss: 2.1253, grad_norm: 120.9644
2025-06-10 13:29:33,993 - mmdet - INFO - Epoch [2][4450/7033]	lr: 9.331e-05, eta: 14:49:57, time: 1.774, data_time: 0.053, memory: 18761, loss_cls: 0.0923, loss_bbox: 0.2493, d0.loss_cls: 0.1679, d0.loss_bbox: 0.3506, d1.loss_cls: 0.1185, d1.loss_bbox: 0.2743, d2.loss_cls: 0.1027, d2.loss_bbox: 0.2566, d3.loss_cls: 0.0951, d3.loss_bbox: 0.2544, d4.loss_cls: 0.0922, d4.loss_bbox: 0.2495, loss: 2.3036, grad_norm: 38.2883
2025-06-10 13:30:59,414 - mmdet - INFO - Epoch [2][4500/7033]	lr: 9.331e-05, eta: 14:48:26, time: 1.708, data_time: 0.055, memory: 18761, loss_cls: 0.0944, loss_bbox: 0.2511, d0.loss_cls: 0.1741, d0.loss_bbox: 0.3568, d1.loss_cls: 0.1214, d1.loss_bbox: 0.2778, d2.loss_cls: 0.1062, d2.loss_bbox: 0.2602, d3.loss_cls: 0.0978, d3.loss_bbox: 0.2577, d4.loss_cls: 0.0946, d4.loss_bbox: 0.2518, loss: 2.3441, grad_norm: 51.5473
2025-06-10 13:32:26,394 - mmdet - INFO - Epoch [2][4550/7033]	lr: 9.331e-05, eta: 14:46:59, time: 1.739, data_time: 0.050, memory: 18761, loss_cls: 0.0912, loss_bbox: 0.2383, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3387, d1.loss_cls: 0.1171, d1.loss_bbox: 0.2645, d2.loss_cls: 0.1010, d2.loss_bbox: 0.2506, d3.loss_cls: 0.0945, d3.loss_bbox: 0.2477, d4.loss_cls: 0.0906, d4.loss_bbox: 0.2419, loss: 2.2500, grad_norm: 23.5050
2025-06-10 13:33:53,655 - mmdet - INFO - Epoch [2][4600/7033]	lr: 9.331e-05, eta: 14:45:33, time: 1.745, data_time: 0.061, memory: 18761, loss_cls: 0.0897, loss_bbox: 0.2345, d0.loss_cls: 0.1643, d0.loss_bbox: 0.3390, d1.loss_cls: 0.1155, d1.loss_bbox: 0.2605, d2.loss_cls: 0.1005, d2.loss_bbox: 0.2447, d3.loss_cls: 0.0929, d3.loss_bbox: 0.2418, d4.loss_cls: 0.0906, d4.loss_bbox: 0.2357, loss: 2.2095, grad_norm: 81.7827
2025-06-10 13:35:19,556 - mmdet - INFO - Epoch [2][4650/7033]	lr: 9.331e-05, eta: 14:44:03, time: 1.718, data_time: 0.057, memory: 18761, loss_cls: 0.0868, loss_bbox: 0.2305, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3345, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2549, d2.loss_cls: 0.0967, d2.loss_bbox: 0.2398, d3.loss_cls: 0.0889, d3.loss_bbox: 0.2377, d4.loss_cls: 0.0886, d4.loss_bbox: 0.2312, loss: 2.1696, grad_norm: 22.4606
2025-06-10 13:36:44,371 - mmdet - INFO - Epoch [2][4700/7033]	lr: 9.331e-05, eta: 14:42:31, time: 1.696, data_time: 0.060, memory: 18761, loss_cls: 0.0843, loss_bbox: 0.2373, d0.loss_cls: 0.1652, d0.loss_bbox: 0.3372, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2655, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2477, d3.loss_cls: 0.0869, d3.loss_bbox: 0.2463, d4.loss_cls: 0.0861, d4.loss_bbox: 0.2383, loss: 2.2002, grad_norm: 73.5045
2025-06-10 13:38:08,571 - mmdet - INFO - Epoch [2][4750/7033]	lr: 9.331e-05, eta: 14:40:57, time: 1.684, data_time: 0.059, memory: 18761, loss_cls: 0.0824, loss_bbox: 0.2242, d0.loss_cls: 0.1562, d0.loss_bbox: 0.3397, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2565, d2.loss_cls: 0.0949, d2.loss_bbox: 0.2359, d3.loss_cls: 0.0849, d3.loss_bbox: 0.2323, d4.loss_cls: 0.0837, d4.loss_bbox: 0.2267, loss: 2.1305, grad_norm: 51.9330
2025-06-10 13:39:33,741 - mmdet - INFO - Epoch [2][4800/7033]	lr: 9.331e-05, eta: 14:39:26, time: 1.703, data_time: 0.059, memory: 18761, loss_cls: 0.0879, loss_bbox: 0.2285, d0.loss_cls: 0.1646, d0.loss_bbox: 0.3338, d1.loss_cls: 0.1175, d1.loss_bbox: 0.2529, d2.loss_cls: 0.1002, d2.loss_bbox: 0.2363, d3.loss_cls: 0.0924, d3.loss_bbox: 0.2350, d4.loss_cls: 0.0899, d4.loss_bbox: 0.2273, loss: 2.1664, grad_norm: 41.7676
2025-06-10 13:41:00,482 - mmdet - INFO - Epoch [2][4850/7033]	lr: 9.331e-05, eta: 14:37:59, time: 1.735, data_time: 0.056, memory: 18761, loss_cls: 0.0760, loss_bbox: 0.2188, d0.loss_cls: 0.1660, d0.loss_bbox: 0.3326, d1.loss_cls: 0.1077, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2272, d3.loss_cls: 0.0789, d3.loss_bbox: 0.2270, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2205, loss: 2.0692, grad_norm: 35.5132
2025-06-10 13:42:27,212 - mmdet - INFO - Epoch [2][4900/7033]	lr: 9.331e-05, eta: 14:36:31, time: 1.733, data_time: 0.062, memory: 18761, loss_cls: 0.0952, loss_bbox: 0.2401, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3429, d1.loss_cls: 0.1247, d1.loss_bbox: 0.2663, d2.loss_cls: 0.1125, d2.loss_bbox: 0.2488, d3.loss_cls: 0.1001, d3.loss_bbox: 0.2483, d4.loss_cls: 0.0969, d4.loss_bbox: 0.2403, loss: 2.2922, grad_norm: 31.4409
2025-06-10 13:43:55,976 - mmdet - INFO - Epoch [2][4950/7033]	lr: 9.331e-05, eta: 14:35:09, time: 1.777, data_time: 0.060, memory: 18761, loss_cls: 0.0890, loss_bbox: 0.2329, d0.loss_cls: 0.1752, d0.loss_bbox: 0.3373, d1.loss_cls: 0.1178, d1.loss_bbox: 0.2608, d2.loss_cls: 0.1027, d2.loss_bbox: 0.2417, d3.loss_cls: 0.0930, d3.loss_bbox: 0.2407, d4.loss_cls: 0.0911, d4.loss_bbox: 0.2348, loss: 2.2171, grad_norm: 27.2672
2025-06-10 13:45:25,173 - mmdet - INFO - Epoch [2][5000/7033]	lr: 9.331e-05, eta: 14:33:48, time: 1.784, data_time: 0.059, memory: 18761, loss_cls: 0.0880, loss_bbox: 0.2305, d0.loss_cls: 0.1661, d0.loss_bbox: 0.3358, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2588, d2.loss_cls: 0.0994, d2.loss_bbox: 0.2399, d3.loss_cls: 0.0892, d3.loss_bbox: 0.2399, d4.loss_cls: 0.0896, d4.loss_bbox: 0.2321, loss: 2.1822, grad_norm: 324.9500
2025-06-10 13:46:50,888 - mmdet - INFO - Epoch [2][5050/7033]	lr: 9.331e-05, eta: 14:32:18, time: 1.714, data_time: 0.061, memory: 18761, loss_cls: 0.0912, loss_bbox: 0.2350, d0.loss_cls: 0.1714, d0.loss_bbox: 0.3414, d1.loss_cls: 0.1185, d1.loss_bbox: 0.2666, d2.loss_cls: 0.1034, d2.loss_bbox: 0.2453, d3.loss_cls: 0.0956, d3.loss_bbox: 0.2439, d4.loss_cls: 0.0913, d4.loss_bbox: 0.2358, loss: 2.2395, grad_norm: 31.4168
2025-06-10 13:48:22,003 - mmdet - INFO - Epoch [2][5100/7033]	lr: 9.331e-05, eta: 14:31:02, time: 1.822, data_time: 0.056, memory: 18761, loss_cls: 0.0827, loss_bbox: 0.2352, d0.loss_cls: 0.1703, d0.loss_bbox: 0.3379, d1.loss_cls: 0.1152, d1.loss_bbox: 0.2619, d2.loss_cls: 0.0973, d2.loss_bbox: 0.2449, d3.loss_cls: 0.0891, d3.loss_bbox: 0.2437, d4.loss_cls: 0.0843, d4.loss_bbox: 0.2368, loss: 2.1991, grad_norm: 60.9638
2025-06-10 13:49:49,817 - mmdet - INFO - Epoch [2][5150/7033]	lr: 9.331e-05, eta: 14:29:37, time: 1.756, data_time: 0.058, memory: 18761, loss_cls: 0.0896, loss_bbox: 0.2510, d0.loss_cls: 0.1681, d0.loss_bbox: 0.3579, d1.loss_cls: 0.1151, d1.loss_bbox: 0.2778, d2.loss_cls: 0.0994, d2.loss_bbox: 0.2626, d3.loss_cls: 0.0918, d3.loss_bbox: 0.2588, d4.loss_cls: 0.0898, d4.loss_bbox: 0.2524, loss: 2.3144, grad_norm: 34.0388
2025-06-10 13:51:16,054 - mmdet - INFO - Epoch [2][5200/7033]	lr: 9.331e-05, eta: 14:28:08, time: 1.725, data_time: 0.058, memory: 18761, loss_cls: 0.0949, loss_bbox: 0.2384, d0.loss_cls: 0.1765, d0.loss_bbox: 0.3470, d1.loss_cls: 0.1200, d1.loss_bbox: 0.2641, d2.loss_cls: 0.1046, d2.loss_bbox: 0.2472, d3.loss_cls: 0.0968, d3.loss_bbox: 0.2465, d4.loss_cls: 0.0935, d4.loss_bbox: 0.2399, loss: 2.2693, grad_norm: 44.3865
2025-06-10 13:52:44,826 - mmdet - INFO - Epoch [2][5250/7033]	lr: 9.331e-05, eta: 14:26:46, time: 1.775, data_time: 0.071, memory: 18761, loss_cls: 0.0971, loss_bbox: 0.2400, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3456, d1.loss_cls: 0.1252, d1.loss_bbox: 0.2673, d2.loss_cls: 0.1100, d2.loss_bbox: 0.2499, d3.loss_cls: 0.1015, d3.loss_bbox: 0.2478, d4.loss_cls: 0.0994, d4.loss_bbox: 0.2411, loss: 2.3010, grad_norm: 44.3990
2025-06-10 13:54:11,906 - mmdet - INFO - Epoch [2][5300/7033]	lr: 9.331e-05, eta: 14:25:20, time: 1.742, data_time: 0.065, memory: 18761, loss_cls: 0.0887, loss_bbox: 0.2390, d0.loss_cls: 0.1649, d0.loss_bbox: 0.3470, d1.loss_cls: 0.1136, d1.loss_bbox: 0.2713, d2.loss_cls: 0.0991, d2.loss_bbox: 0.2516, d3.loss_cls: 0.0913, d3.loss_bbox: 0.2481, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2412, loss: 2.2439, grad_norm: 35.2165
2025-06-10 13:55:37,514 - mmdet - INFO - Epoch [2][5350/7033]	lr: 9.331e-05, eta: 14:23:49, time: 1.712, data_time: 0.058, memory: 18761, loss_cls: 0.0908, loss_bbox: 0.2369, d0.loss_cls: 0.1692, d0.loss_bbox: 0.3438, d1.loss_cls: 0.1171, d1.loss_bbox: 0.2627, d2.loss_cls: 0.1019, d2.loss_bbox: 0.2465, d3.loss_cls: 0.0927, d3.loss_bbox: 0.2463, d4.loss_cls: 0.0921, d4.loss_bbox: 0.2395, loss: 2.2393, grad_norm: 51.1884
2025-06-10 13:57:04,891 - mmdet - INFO - Epoch [2][5400/7033]	lr: 9.331e-05, eta: 14:22:24, time: 1.747, data_time: 0.056, memory: 18761, loss_cls: 0.0873, loss_bbox: 0.2233, d0.loss_cls: 0.1677, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1172, d1.loss_bbox: 0.2499, d2.loss_cls: 0.1023, d2.loss_bbox: 0.2333, d3.loss_cls: 0.0917, d3.loss_bbox: 0.2324, d4.loss_cls: 0.0884, d4.loss_bbox: 0.2254, loss: 2.1523, grad_norm: 30.3993
2025-06-10 13:58:32,320 - mmdet - INFO - Epoch [2][5450/7033]	lr: 9.331e-05, eta: 14:20:58, time: 1.748, data_time: 0.055, memory: 18761, loss_cls: 0.0799, loss_bbox: 0.2270, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3366, d1.loss_cls: 0.1034, d1.loss_bbox: 0.2558, d2.loss_cls: 0.0907, d2.loss_bbox: 0.2378, d3.loss_cls: 0.0835, d3.loss_bbox: 0.2341, d4.loss_cls: 0.0798, d4.loss_bbox: 0.2287, loss: 2.1170, grad_norm: 30.8138
2025-06-10 13:59:59,401 - mmdet - INFO - Epoch [2][5500/7033]	lr: 9.331e-05, eta: 14:19:31, time: 1.742, data_time: 0.051, memory: 18761, loss_cls: 0.0837, loss_bbox: 0.2351, d0.loss_cls: 0.1675, d0.loss_bbox: 0.3336, d1.loss_cls: 0.1136, d1.loss_bbox: 0.2580, d2.loss_cls: 0.0955, d2.loss_bbox: 0.2447, d3.loss_cls: 0.0859, d3.loss_bbox: 0.2426, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2368, loss: 2.1805, grad_norm: 28.4136
2025-06-10 14:01:26,715 - mmdet - INFO - Epoch [2][5550/7033]	lr: 9.331e-05, eta: 14:18:05, time: 1.746, data_time: 0.056, memory: 18761, loss_cls: 0.0875, loss_bbox: 0.2366, d0.loss_cls: 0.1675, d0.loss_bbox: 0.3398, d1.loss_cls: 0.1139, d1.loss_bbox: 0.2642, d2.loss_cls: 0.1010, d2.loss_bbox: 0.2462, d3.loss_cls: 0.0916, d3.loss_bbox: 0.2436, d4.loss_cls: 0.0886, d4.loss_bbox: 0.2376, loss: 2.2181, grad_norm: 24.4312
2025-06-10 14:02:56,890 - mmdet - INFO - Epoch [2][5600/7033]	lr: 9.331e-05, eta: 14:16:46, time: 1.804, data_time: 0.059, memory: 18761, loss_cls: 0.0858, loss_bbox: 0.2292, d0.loss_cls: 0.1628, d0.loss_bbox: 0.3262, d1.loss_cls: 0.1153, d1.loss_bbox: 0.2568, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2387, d3.loss_cls: 0.0895, d3.loss_bbox: 0.2385, d4.loss_cls: 0.0866, d4.loss_bbox: 0.2310, loss: 2.1588, grad_norm: 43.3412
2025-06-10 14:04:22,432 - mmdet - INFO - Epoch [2][5650/7033]	lr: 9.331e-05, eta: 14:15:16, time: 1.709, data_time: 0.057, memory: 18761, loss_cls: 0.0833, loss_bbox: 0.2392, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3533, d1.loss_cls: 0.1124, d1.loss_bbox: 0.2662, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2497, d3.loss_cls: 0.0856, d3.loss_bbox: 0.2466, d4.loss_cls: 0.0833, d4.loss_bbox: 0.2411, loss: 2.2242, grad_norm: 35.7141
2025-06-10 14:05:49,646 - mmdet - INFO - Epoch [2][5700/7033]	lr: 9.331e-05, eta: 14:13:50, time: 1.746, data_time: 0.059, memory: 18761, loss_cls: 0.0798, loss_bbox: 0.2212, d0.loss_cls: 0.1575, d0.loss_bbox: 0.3190, d1.loss_cls: 0.1065, d1.loss_bbox: 0.2489, d2.loss_cls: 0.0892, d2.loss_bbox: 0.2331, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2289, d4.loss_cls: 0.0801, d4.loss_bbox: 0.2226, loss: 2.0687, grad_norm: 31.4563
2025-06-10 14:07:18,342 - mmdet - INFO - Epoch [2][5750/7033]	lr: 9.331e-05, eta: 14:12:27, time: 1.774, data_time: 0.056, memory: 18761, loss_cls: 0.0890, loss_bbox: 0.2332, d0.loss_cls: 0.1757, d0.loss_bbox: 0.3349, d1.loss_cls: 0.1175, d1.loss_bbox: 0.2557, d2.loss_cls: 0.1026, d2.loss_bbox: 0.2415, d3.loss_cls: 0.0930, d3.loss_bbox: 0.2405, d4.loss_cls: 0.0906, d4.loss_bbox: 0.2328, loss: 2.2071, grad_norm: 37.1288
2025-06-10 14:08:47,225 - mmdet - INFO - Epoch [2][5800/7033]	lr: 9.331e-05, eta: 14:11:04, time: 1.778, data_time: 0.067, memory: 18761, loss_cls: 0.0804, loss_bbox: 0.2206, d0.loss_cls: 0.1608, d0.loss_bbox: 0.3193, d1.loss_cls: 0.1061, d1.loss_bbox: 0.2483, d2.loss_cls: 0.0917, d2.loss_bbox: 0.2317, d3.loss_cls: 0.0825, d3.loss_bbox: 0.2291, d4.loss_cls: 0.0799, d4.loss_bbox: 0.2226, loss: 2.0731, grad_norm: 24.2652
2025-06-10 14:10:14,536 - mmdet - INFO - Epoch [2][5850/7033]	lr: 9.331e-05, eta: 14:09:38, time: 1.746, data_time: 0.060, memory: 18761, loss_cls: 0.0851, loss_bbox: 0.2286, d0.loss_cls: 0.1668, d0.loss_bbox: 0.3337, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2561, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2390, d3.loss_cls: 0.0884, d3.loss_bbox: 0.2372, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2312, loss: 2.1578, grad_norm: 27.1398
2025-06-10 14:11:43,777 - mmdet - INFO - Epoch [2][5900/7033]	lr: 9.331e-05, eta: 14:08:16, time: 1.784, data_time: 0.056, memory: 18761, loss_cls: 0.0818, loss_bbox: 0.2213, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3308, d1.loss_cls: 0.1087, d1.loss_bbox: 0.2518, d2.loss_cls: 0.0927, d2.loss_bbox: 0.2335, d3.loss_cls: 0.0849, d3.loss_bbox: 0.2300, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2234, loss: 2.1070, grad_norm: 46.9446
2025-06-10 14:13:10,261 - mmdet - INFO - Epoch [2][5950/7033]	lr: 9.331e-05, eta: 14:06:48, time: 1.730, data_time: 0.057, memory: 18761, loss_cls: 0.0841, loss_bbox: 0.2373, d0.loss_cls: 0.1734, d0.loss_bbox: 0.3467, d1.loss_cls: 0.1143, d1.loss_bbox: 0.2653, d2.loss_cls: 0.0972, d2.loss_bbox: 0.2481, d3.loss_cls: 0.0876, d3.loss_bbox: 0.2464, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2399, loss: 2.2260, grad_norm: 58.1142
2025-06-10 14:14:34,132 - mmdet - INFO - Epoch [2][6000/7033]	lr: 9.331e-05, eta: 14:05:14, time: 1.677, data_time: 0.058, memory: 18761, loss_cls: 0.0774, loss_bbox: 0.2226, d0.loss_cls: 0.1581, d0.loss_bbox: 0.3282, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2492, d2.loss_cls: 0.0912, d2.loss_bbox: 0.2333, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2316, d4.loss_cls: 0.0787, d4.loss_bbox: 0.2260, loss: 2.0833, grad_norm: 22.0836
2025-06-10 14:16:03,794 - mmdet - INFO - Epoch [2][6050/7033]	lr: 9.331e-05, eta: 14:03:53, time: 1.793, data_time: 0.061, memory: 18761, loss_cls: 0.0876, loss_bbox: 0.2350, d0.loss_cls: 0.1664, d0.loss_bbox: 0.3428, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2645, d2.loss_cls: 0.0966, d2.loss_bbox: 0.2490, d3.loss_cls: 0.0903, d3.loss_bbox: 0.2456, d4.loss_cls: 0.0873, d4.loss_bbox: 0.2389, loss: 2.2168, grad_norm: 225.6312
2025-06-10 14:17:30,872 - mmdet - INFO - Epoch [2][6100/7033]	lr: 9.331e-05, eta: 14:02:27, time: 1.741, data_time: 0.054, memory: 18761, loss_cls: 0.0826, loss_bbox: 0.2224, d0.loss_cls: 0.1665, d0.loss_bbox: 0.3252, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2513, d2.loss_cls: 0.0967, d2.loss_bbox: 0.2352, d3.loss_cls: 0.0861, d3.loss_bbox: 0.2322, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2241, loss: 2.1176, grad_norm: 42.0715
2025-06-10 14:18:56,188 - mmdet - INFO - Epoch [2][6150/7033]	lr: 9.331e-05, eta: 14:00:56, time: 1.706, data_time: 0.056, memory: 18761, loss_cls: 0.0850, loss_bbox: 0.2258, d0.loss_cls: 0.1620, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1156, d1.loss_bbox: 0.2576, d2.loss_cls: 0.0990, d2.loss_bbox: 0.2399, d3.loss_cls: 0.0891, d3.loss_bbox: 0.2356, d4.loss_cls: 0.0860, d4.loss_bbox: 0.2275, loss: 2.1563, grad_norm: 25.2810
2025-06-10 14:20:24,843 - mmdet - INFO - Epoch [2][6200/7033]	lr: 9.331e-05, eta: 13:59:33, time: 1.771, data_time: 0.058, memory: 18761, loss_cls: 0.0857, loss_bbox: 0.2313, d0.loss_cls: 0.1624, d0.loss_bbox: 0.3420, d1.loss_cls: 0.1142, d1.loss_bbox: 0.2623, d2.loss_cls: 0.0969, d2.loss_bbox: 0.2458, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2419, d4.loss_cls: 0.0873, d4.loss_bbox: 0.2330, loss: 2.1907, grad_norm: 22.2736
2025-06-10 14:21:52,991 - mmdet - INFO - Epoch [2][6250/7033]	lr: 9.331e-05, eta: 13:58:08, time: 1.763, data_time: 0.059, memory: 18761, loss_cls: 0.0849, loss_bbox: 0.2356, d0.loss_cls: 0.1624, d0.loss_bbox: 0.3397, d1.loss_cls: 0.1159, d1.loss_bbox: 0.2645, d2.loss_cls: 0.1015, d2.loss_bbox: 0.2467, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2422, d4.loss_cls: 0.0876, d4.loss_bbox: 0.2353, loss: 2.2073, grad_norm: 63.4304
2025-06-10 14:23:19,476 - mmdet - INFO - Epoch [2][6300/7033]	lr: 9.331e-05, eta: 13:56:41, time: 1.732, data_time: 0.064, memory: 18761, loss_cls: 0.0824, loss_bbox: 0.2291, d0.loss_cls: 0.1585, d0.loss_bbox: 0.3448, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2596, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2410, d3.loss_cls: 0.0866, d3.loss_bbox: 0.2382, d4.loss_cls: 0.0837, d4.loss_bbox: 0.2307, loss: 2.1607, grad_norm: 36.9541
2025-06-10 14:24:49,773 - mmdet - INFO - Epoch [2][6350/7033]	lr: 9.331e-05, eta: 13:55:21, time: 1.806, data_time: 0.064, memory: 18761, loss_cls: 0.0915, loss_bbox: 0.2323, d0.loss_cls: 0.1720, d0.loss_bbox: 0.3480, d1.loss_cls: 0.1215, d1.loss_bbox: 0.2681, d2.loss_cls: 0.1040, d2.loss_bbox: 0.2456, d3.loss_cls: 0.0955, d3.loss_bbox: 0.2433, d4.loss_cls: 0.0917, d4.loss_bbox: 0.2357, loss: 2.2493, grad_norm: 22.8241
2025-06-10 14:26:16,465 - mmdet - INFO - Epoch [2][6400/7033]	lr: 9.331e-05, eta: 13:53:53, time: 1.734, data_time: 0.065, memory: 18761, loss_cls: 0.0876, loss_bbox: 0.2295, d0.loss_cls: 0.1641, d0.loss_bbox: 0.3322, d1.loss_cls: 0.1145, d1.loss_bbox: 0.2562, d2.loss_cls: 0.0981, d2.loss_bbox: 0.2385, d3.loss_cls: 0.0884, d3.loss_bbox: 0.2373, d4.loss_cls: 0.0869, d4.loss_bbox: 0.2318, loss: 2.1652, grad_norm: 47.2341
2025-06-10 14:27:45,291 - mmdet - INFO - Epoch [2][6450/7033]	lr: 9.331e-05, eta: 13:52:30, time: 1.777, data_time: 0.068, memory: 18761, loss_cls: 0.0807, loss_bbox: 0.2279, d0.loss_cls: 0.1536, d0.loss_bbox: 0.3379, d1.loss_cls: 0.1102, d1.loss_bbox: 0.2589, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2411, d3.loss_cls: 0.0847, d3.loss_bbox: 0.2383, d4.loss_cls: 0.0819, d4.loss_bbox: 0.2292, loss: 2.1385, grad_norm: 26.1088
2025-06-10 14:29:12,278 - mmdet - INFO - Epoch [2][6500/7033]	lr: 9.331e-05, eta: 13:51:03, time: 1.738, data_time: 0.056, memory: 18761, loss_cls: 0.0896, loss_bbox: 0.2228, d0.loss_cls: 0.1682, d0.loss_bbox: 0.3307, d1.loss_cls: 0.1201, d1.loss_bbox: 0.2495, d2.loss_cls: 0.1020, d2.loss_bbox: 0.2324, d3.loss_cls: 0.0941, d3.loss_bbox: 0.2306, d4.loss_cls: 0.0898, d4.loss_bbox: 0.2243, loss: 2.1541, grad_norm: 24.4366
2025-06-10 14:30:41,725 - mmdet - INFO - Epoch [2][6550/7033]	lr: 9.331e-05, eta: 13:49:41, time: 1.790, data_time: 0.060, memory: 18761, loss_cls: 0.0788, loss_bbox: 0.2229, d0.loss_cls: 0.1602, d0.loss_bbox: 0.3245, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2493, d2.loss_cls: 0.0879, d2.loss_bbox: 0.2322, d3.loss_cls: 0.0822, d3.loss_bbox: 0.2318, d4.loss_cls: 0.0793, d4.loss_bbox: 0.2261, loss: 2.0811, grad_norm: 29.1095
2025-06-10 14:32:09,488 - mmdet - INFO - Epoch [2][6600/7033]	lr: 9.331e-05, eta: 13:48:16, time: 1.756, data_time: 0.056, memory: 18761, loss_cls: 0.0819, loss_bbox: 0.2189, d0.loss_cls: 0.1640, d0.loss_bbox: 0.3390, d1.loss_cls: 0.1122, d1.loss_bbox: 0.2497, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2305, d3.loss_cls: 0.0855, d3.loss_bbox: 0.2278, d4.loss_cls: 0.0837, d4.loss_bbox: 0.2194, loss: 2.1078, grad_norm: 30.4773
2025-06-10 14:33:43,905 - mmdet - INFO - Epoch [2][6650/7033]	lr: 9.331e-05, eta: 13:47:05, time: 1.888, data_time: 0.056, memory: 18761, loss_cls: 0.0887, loss_bbox: 0.2295, d0.loss_cls: 0.1685, d0.loss_bbox: 0.3372, d1.loss_cls: 0.1168, d1.loss_bbox: 0.2600, d2.loss_cls: 0.1015, d2.loss_bbox: 0.2402, d3.loss_cls: 0.0952, d3.loss_bbox: 0.2373, d4.loss_cls: 0.0914, d4.loss_bbox: 0.2311, loss: 2.1974, grad_norm: 28.0326
2025-06-10 14:35:11,126 - mmdet - INFO - Epoch [2][6700/7033]	lr: 9.331e-05, eta: 13:45:38, time: 1.745, data_time: 0.067, memory: 18761, loss_cls: 0.0865, loss_bbox: 0.2279, d0.loss_cls: 0.1622, d0.loss_bbox: 0.3366, d1.loss_cls: 0.1128, d1.loss_bbox: 0.2568, d2.loss_cls: 0.0975, d2.loss_bbox: 0.2401, d3.loss_cls: 0.0906, d3.loss_bbox: 0.2358, d4.loss_cls: 0.0868, d4.loss_bbox: 0.2310, loss: 2.1644, grad_norm: 28.2707
2025-06-10 14:36:39,352 - mmdet - INFO - Epoch [2][6750/7033]	lr: 9.331e-05, eta: 13:44:14, time: 1.764, data_time: 0.081, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2264, d0.loss_cls: 0.1619, d0.loss_bbox: 0.3295, d1.loss_cls: 0.1132, d1.loss_bbox: 0.2532, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2373, d3.loss_cls: 0.0857, d3.loss_bbox: 0.2349, d4.loss_cls: 0.0830, d4.loss_bbox: 0.2277, loss: 2.1301, grad_norm: 355.9412
2025-06-10 14:38:09,868 - mmdet - INFO - Epoch [2][6800/7033]	lr: 9.331e-05, eta: 13:42:54, time: 1.810, data_time: 0.053, memory: 18761, loss_cls: 0.0836, loss_bbox: 0.2223, d0.loss_cls: 0.1627, d0.loss_bbox: 0.3382, d1.loss_cls: 0.1116, d1.loss_bbox: 0.2565, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2350, d3.loss_cls: 0.0853, d3.loss_bbox: 0.2323, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2232, loss: 2.1302, grad_norm: 37.7754
2025-06-10 14:39:38,820 - mmdet - INFO - Epoch [2][6850/7033]	lr: 9.331e-05, eta: 13:41:31, time: 1.779, data_time: 0.065, memory: 18761, loss_cls: 0.0855, loss_bbox: 0.2284, d0.loss_cls: 0.1692, d0.loss_bbox: 0.3463, d1.loss_cls: 0.1131, d1.loss_bbox: 0.2631, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2412, d3.loss_cls: 0.0890, d3.loss_bbox: 0.2376, d4.loss_cls: 0.0865, d4.loss_bbox: 0.2314, loss: 2.1897, grad_norm: 30.4538
2025-06-10 14:41:09,373 - mmdet - INFO - Epoch [2][6900/7033]	lr: 9.331e-05, eta: 13:40:11, time: 1.811, data_time: 0.063, memory: 18761, loss_cls: 0.0938, loss_bbox: 0.2348, d0.loss_cls: 0.1799, d0.loss_bbox: 0.3562, d1.loss_cls: 0.1234, d1.loss_bbox: 0.2691, d2.loss_cls: 0.1076, d2.loss_bbox: 0.2471, d3.loss_cls: 0.0974, d3.loss_bbox: 0.2454, d4.loss_cls: 0.0947, d4.loss_bbox: 0.2374, loss: 2.2869, grad_norm: 41.3846
2025-06-10 14:42:39,266 - mmdet - INFO - Epoch [2][6950/7033]	lr: 9.331e-05, eta: 13:38:49, time: 1.798, data_time: 0.070, memory: 18761, loss_cls: 0.0803, loss_bbox: 0.2205, d0.loss_cls: 0.1692, d0.loss_bbox: 0.3328, d1.loss_cls: 0.1105, d1.loss_bbox: 0.2528, d2.loss_cls: 0.0924, d2.loss_bbox: 0.2345, d3.loss_cls: 0.0843, d3.loss_bbox: 0.2307, d4.loss_cls: 0.0814, d4.loss_bbox: 0.2230, loss: 2.1124, grad_norm: 80.6481
2025-06-10 14:44:05,438 - mmdet - INFO - Epoch [2][7000/7033]	lr: 9.331e-05, eta: 13:37:21, time: 1.723, data_time: 0.060, memory: 18761, loss_cls: 0.0876, loss_bbox: 0.2267, d0.loss_cls: 0.1749, d0.loss_bbox: 0.3387, d1.loss_cls: 0.1174, d1.loss_bbox: 0.2549, d2.loss_cls: 0.1026, d2.loss_bbox: 0.2376, d3.loss_cls: 0.0923, d3.loss_bbox: 0.2335, d4.loss_cls: 0.0864, d4.loss_bbox: 0.2293, loss: 2.1818, grad_norm: 30.9188
2025-06-10 14:45:03,422 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-06-10 15:27:00,930 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 15:27:00,930 - mmdet - INFO - Epoch(val) [2][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.8297, pts_bbox_NuScenes/car_AP_dist_1.0: 0.9329, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9654, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9781, pts_bbox_NuScenes/car_trans_err: 0.1869, pts_bbox_NuScenes/car_scale_err: 0.1393, pts_bbox_NuScenes/car_orient_err: 0.0359, pts_bbox_NuScenes/car_vel_err: 0.2163, pts_bbox_NuScenes/car_attr_err: 0.1890, pts_bbox_NuScenes/mATE: 0.2945, pts_bbox_NuScenes/mASE: 0.2166, pts_bbox_NuScenes/mAOE: 0.1261, pts_bbox_NuScenes/mAVE: 0.2503, pts_bbox_NuScenes/mAAE: 0.1706, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.5085, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.7565, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.8932, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.9349, pts_bbox_NuScenes/truck_trans_err: 0.3491, pts_bbox_NuScenes/truck_scale_err: 0.1709, pts_bbox_NuScenes/truck_orient_err: 0.0374, pts_bbox_NuScenes/truck_vel_err: 0.2343, pts_bbox_NuScenes/truck_attr_err: 0.2114, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.1222, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.3837, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.6961, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.8216, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6166, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.3372, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.4247, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1191, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2776, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4951, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7630, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.9358, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9692, pts_bbox_NuScenes/bus_trans_err: 0.3672, pts_bbox_NuScenes/bus_scale_err: 0.1730, pts_bbox_NuScenes/bus_orient_err: 0.0236, pts_bbox_NuScenes/bus_vel_err: 0.4815, pts_bbox_NuScenes/bus_attr_err: 0.1721, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.2182, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.5415, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.7528, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.8662, pts_bbox_NuScenes/trailer_trans_err: 0.4917, pts_bbox_NuScenes/trailer_scale_err: 0.2201, pts_bbox_NuScenes/trailer_orient_err: 0.1424, pts_bbox_NuScenes/trailer_vel_err: 0.1776, pts_bbox_NuScenes/trailer_attr_err: 0.1521, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.7259, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.8518, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.9102, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.9248, pts_bbox_NuScenes/barrier_trans_err: 0.2163, pts_bbox_NuScenes/barrier_scale_err: 0.2049, pts_bbox_NuScenes/barrier_orient_err: 0.0502, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6924, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.8764, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.9259, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.9327, pts_bbox_NuScenes/motorcycle_trans_err: 0.2238, pts_bbox_NuScenes/motorcycle_scale_err: 0.2108, pts_bbox_NuScenes/motorcycle_orient_err: 0.1151, pts_bbox_NuScenes/motorcycle_vel_err: 0.3525, pts_bbox_NuScenes/motorcycle_attr_err: 0.2605, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.7670, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.8635, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.8938, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.9078, pts_bbox_NuScenes/bicycle_trans_err: 0.1836, pts_bbox_NuScenes/bicycle_scale_err: 0.2359, pts_bbox_NuScenes/bicycle_orient_err: 0.1068, pts_bbox_NuScenes/bicycle_vel_err: 0.2222, pts_bbox_NuScenes/bicycle_attr_err: 0.0160, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8826, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.9302, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.9515, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.9635, pts_bbox_NuScenes/pedestrian_trans_err: 0.1591, pts_bbox_NuScenes/pedestrian_scale_err: 0.2376, pts_bbox_NuScenes/pedestrian_orient_err: 0.1987, pts_bbox_NuScenes/pedestrian_vel_err: 0.1988, pts_bbox_NuScenes/pedestrian_attr_err: 0.0860, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.8365, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.8899, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.9155, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.9352, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1510, pts_bbox_NuScenes/traffic_cone_scale_err: 0.2359, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7935, pts_bbox_NuScenes/mAP: 0.7985
2025-06-10 15:28:39,924 - mmdet - INFO - Epoch [3][50/7033]	lr: 7.503e-05, eta: 13:33:17, time: 1.894, data_time: 0.202, memory: 18761, loss_cls: 0.0830, loss_bbox: 0.2153, d0.loss_cls: 0.1718, d0.loss_bbox: 0.3355, d1.loss_cls: 0.1138, d1.loss_bbox: 0.2519, d2.loss_cls: 0.1004, d2.loss_bbox: 0.2298, d3.loss_cls: 0.0872, d3.loss_bbox: 0.2257, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2182, loss: 2.1185, grad_norm: 24.4253
2025-06-10 15:30:26,958 - mmdet - INFO - Epoch [3][100/7033]	lr: 7.503e-05, eta: 13:32:30, time: 2.141, data_time: 0.067, memory: 18761, loss_cls: 0.0826, loss_bbox: 0.2269, d0.loss_cls: 0.1717, d0.loss_bbox: 0.3354, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2580, d2.loss_cls: 0.0973, d2.loss_bbox: 0.2396, d3.loss_cls: 0.0889, d3.loss_bbox: 0.2355, d4.loss_cls: 0.0852, d4.loss_bbox: 0.2297, loss: 2.1636, grad_norm: 67.0463
2025-06-10 15:31:55,296 - mmdet - INFO - Epoch [3][150/7033]	lr: 7.503e-05, eta: 13:31:06, time: 1.767, data_time: 0.062, memory: 18761, loss_cls: 0.0794, loss_bbox: 0.2119, d0.loss_cls: 0.1641, d0.loss_bbox: 0.3251, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2383, d2.loss_cls: 0.0901, d2.loss_bbox: 0.2234, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2189, d4.loss_cls: 0.0803, d4.loss_bbox: 0.2138, loss: 2.0370, grad_norm: 33.2223
2025-06-10 15:33:20,581 - mmdet - INFO - Epoch [3][200/7033]	lr: 7.503e-05, eta: 13:29:35, time: 1.705, data_time: 0.058, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2226, d0.loss_cls: 0.1713, d0.loss_bbox: 0.3421, d1.loss_cls: 0.1116, d1.loss_bbox: 0.2590, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2377, d3.loss_cls: 0.0880, d3.loss_bbox: 0.2322, d4.loss_cls: 0.0846, d4.loss_bbox: 0.2245, loss: 2.1513, grad_norm: 28.3439
2025-06-10 15:34:48,288 - mmdet - INFO - Epoch [3][250/7033]	lr: 7.503e-05, eta: 13:28:10, time: 1.755, data_time: 0.055, memory: 18761, loss_cls: 0.0818, loss_bbox: 0.2137, d0.loss_cls: 0.1607, d0.loss_bbox: 0.3209, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2460, d2.loss_cls: 0.0905, d2.loss_bbox: 0.2281, d3.loss_cls: 0.0841, d3.loss_bbox: 0.2233, d4.loss_cls: 0.0827, d4.loss_bbox: 0.2156, loss: 2.0574, grad_norm: 30.9610
2025-06-10 15:36:17,855 - mmdet - INFO - Epoch [3][300/7033]	lr: 7.503e-05, eta: 13:26:48, time: 1.791, data_time: 0.057, memory: 18761, loss_cls: 0.0808, loss_bbox: 0.2153, d0.loss_cls: 0.1706, d0.loss_bbox: 0.3284, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2484, d2.loss_cls: 0.0928, d2.loss_bbox: 0.2283, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2228, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2167, loss: 2.0794, grad_norm: 28.5018
2025-06-10 15:37:44,409 - mmdet - INFO - Epoch [3][350/7033]	lr: 7.503e-05, eta: 13:25:20, time: 1.731, data_time: 0.056, memory: 18761, loss_cls: 0.0802, loss_bbox: 0.2263, d0.loss_cls: 0.1609, d0.loss_bbox: 0.3344, d1.loss_cls: 0.1085, d1.loss_bbox: 0.2567, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2394, d3.loss_cls: 0.0857, d3.loss_bbox: 0.2345, d4.loss_cls: 0.0813, d4.loss_bbox: 0.2270, loss: 2.1283, grad_norm: 18.8301
2025-06-10 15:39:09,499 - mmdet - INFO - Epoch [3][400/7033]	lr: 7.503e-05, eta: 13:23:50, time: 1.702, data_time: 0.064, memory: 18761, loss_cls: 0.0815, loss_bbox: 0.2207, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3204, d1.loss_cls: 0.1110, d1.loss_bbox: 0.2481, d2.loss_cls: 0.0971, d2.loss_bbox: 0.2321, d3.loss_cls: 0.0875, d3.loss_bbox: 0.2292, d4.loss_cls: 0.0823, d4.loss_bbox: 0.2218, loss: 2.0949, grad_norm: 35.5655
2025-06-10 15:40:37,322 - mmdet - INFO - Epoch [3][450/7033]	lr: 7.503e-05, eta: 13:22:24, time: 1.756, data_time: 0.058, memory: 18761, loss_cls: 0.0834, loss_bbox: 0.2190, d0.loss_cls: 0.1605, d0.loss_bbox: 0.3243, d1.loss_cls: 0.1107, d1.loss_bbox: 0.2496, d2.loss_cls: 0.0988, d2.loss_bbox: 0.2298, d3.loss_cls: 0.0890, d3.loss_bbox: 0.2262, d4.loss_cls: 0.0841, d4.loss_bbox: 0.2216, loss: 2.0969, grad_norm: 32.5047
2025-06-10 15:42:04,923 - mmdet - INFO - Epoch [3][500/7033]	lr: 7.503e-05, eta: 13:20:59, time: 1.753, data_time: 0.062, memory: 18761, loss_cls: 0.0805, loss_bbox: 0.2112, d0.loss_cls: 0.1662, d0.loss_bbox: 0.3168, d1.loss_cls: 0.1094, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0943, d2.loss_bbox: 0.2231, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2191, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2134, loss: 2.0398, grad_norm: 26.9297
2025-06-10 15:43:31,413 - mmdet - INFO - Epoch [3][550/7033]	lr: 7.503e-05, eta: 13:19:31, time: 1.728, data_time: 0.060, memory: 18761, loss_cls: 0.0717, loss_bbox: 0.2174, d0.loss_cls: 0.1586, d0.loss_bbox: 0.3256, d1.loss_cls: 0.1015, d1.loss_bbox: 0.2468, d2.loss_cls: 0.0838, d2.loss_bbox: 0.2295, d3.loss_cls: 0.0768, d3.loss_bbox: 0.2277, d4.loss_cls: 0.0733, d4.loss_bbox: 0.2198, loss: 2.0326, grad_norm: 22.5416
2025-06-10 15:44:58,845 - mmdet - INFO - Epoch [3][600/7033]	lr: 7.503e-05, eta: 13:18:05, time: 1.750, data_time: 0.068, memory: 18761, loss_cls: 0.0873, loss_bbox: 0.2207, d0.loss_cls: 0.1681, d0.loss_bbox: 0.3292, d1.loss_cls: 0.1147, d1.loss_bbox: 0.2508, d2.loss_cls: 0.0982, d2.loss_bbox: 0.2343, d3.loss_cls: 0.0936, d3.loss_bbox: 0.2291, d4.loss_cls: 0.0901, d4.loss_bbox: 0.2227, loss: 2.1388, grad_norm: 70.0017
2025-06-10 15:46:25,509 - mmdet - INFO - Epoch [3][650/7033]	lr: 7.503e-05, eta: 13:16:37, time: 1.733, data_time: 0.066, memory: 18761, loss_cls: 0.0793, loss_bbox: 0.2113, d0.loss_cls: 0.1583, d0.loss_bbox: 0.3179, d1.loss_cls: 0.1063, d1.loss_bbox: 0.2457, d2.loss_cls: 0.0914, d2.loss_bbox: 0.2257, d3.loss_cls: 0.0832, d3.loss_bbox: 0.2231, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2133, loss: 2.0359, grad_norm: 32.3425
2025-06-10 15:47:53,171 - mmdet - INFO - Epoch [3][700/7033]	lr: 7.503e-05, eta: 13:15:11, time: 1.753, data_time: 0.058, memory: 18761, loss_cls: 0.0849, loss_bbox: 0.2149, d0.loss_cls: 0.1759, d0.loss_bbox: 0.3256, d1.loss_cls: 0.1184, d1.loss_bbox: 0.2477, d2.loss_cls: 0.0979, d2.loss_bbox: 0.2273, d3.loss_cls: 0.0895, d3.loss_bbox: 0.2232, d4.loss_cls: 0.0866, d4.loss_bbox: 0.2160, loss: 2.1079, grad_norm: 39.9867
2025-06-10 15:49:21,067 - mmdet - INFO - Epoch [3][750/7033]	lr: 7.503e-05, eta: 13:13:46, time: 1.758, data_time: 0.057, memory: 18761, loss_cls: 0.0812, loss_bbox: 0.2270, d0.loss_cls: 0.1659, d0.loss_bbox: 0.3375, d1.loss_cls: 0.1153, d1.loss_bbox: 0.2603, d2.loss_cls: 0.0954, d2.loss_bbox: 0.2431, d3.loss_cls: 0.0871, d3.loss_bbox: 0.2369, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2290, loss: 2.1623, grad_norm: 23.6069
2025-06-10 15:50:47,641 - mmdet - INFO - Epoch [3][800/7033]	lr: 7.503e-05, eta: 13:12:19, time: 1.731, data_time: 0.054, memory: 18761, loss_cls: 0.0883, loss_bbox: 0.2200, d0.loss_cls: 0.1643, d0.loss_bbox: 0.3323, d1.loss_cls: 0.1133, d1.loss_bbox: 0.2481, d2.loss_cls: 0.0977, d2.loss_bbox: 0.2322, d3.loss_cls: 0.0922, d3.loss_bbox: 0.2283, d4.loss_cls: 0.0891, d4.loss_bbox: 0.2220, loss: 2.1278, grad_norm: 20.9394
2025-06-10 15:52:18,715 - mmdet - INFO - Epoch [3][850/7033]	lr: 7.503e-05, eta: 13:10:59, time: 1.821, data_time: 0.052, memory: 18761, loss_cls: 0.0779, loss_bbox: 0.2165, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3240, d1.loss_cls: 0.1079, d1.loss_bbox: 0.2470, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2283, d3.loss_cls: 0.0827, d3.loss_bbox: 0.2247, d4.loss_cls: 0.0796, d4.loss_bbox: 0.2185, loss: 2.0530, grad_norm: 24.3045
2025-06-10 15:53:47,005 - mmdet - INFO - Epoch [3][900/7033]	lr: 7.503e-05, eta: 13:09:34, time: 1.766, data_time: 0.061, memory: 18761, loss_cls: 0.0807, loss_bbox: 0.2215, d0.loss_cls: 0.1703, d0.loss_bbox: 0.3374, d1.loss_cls: 0.1091, d1.loss_bbox: 0.2543, d2.loss_cls: 0.0949, d2.loss_bbox: 0.2378, d3.loss_cls: 0.0850, d3.loss_bbox: 0.2331, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2240, loss: 2.1303, grad_norm: 33.4848
2025-06-10 15:55:13,362 - mmdet - INFO - Epoch [3][950/7033]	lr: 7.503e-05, eta: 13:08:06, time: 1.727, data_time: 0.059, memory: 18761, loss_cls: 0.0787, loss_bbox: 0.2168, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3304, d1.loss_cls: 0.1076, d1.loss_bbox: 0.2484, d2.loss_cls: 0.0907, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0833, d3.loss_bbox: 0.2286, d4.loss_cls: 0.0802, d4.loss_bbox: 0.2200, loss: 2.0742, grad_norm: 26.6073
2025-06-10 15:56:40,078 - mmdet - INFO - Epoch [3][1000/7033]	lr: 7.503e-05, eta: 13:06:39, time: 1.734, data_time: 0.058, memory: 18761, loss_cls: 0.0777, loss_bbox: 0.2161, d0.loss_cls: 0.1604, d0.loss_bbox: 0.3225, d1.loss_cls: 0.1092, d1.loss_bbox: 0.2467, d2.loss_cls: 0.0912, d2.loss_bbox: 0.2299, d3.loss_cls: 0.0805, d3.loss_bbox: 0.2256, d4.loss_cls: 0.0784, d4.loss_bbox: 0.2174, loss: 2.0557, grad_norm: 39.9729
2025-06-10 15:58:04,424 - mmdet - INFO - Epoch [3][1050/7033]	lr: 7.503e-05, eta: 13:05:07, time: 1.687, data_time: 0.062, memory: 18761, loss_cls: 0.0781, loss_bbox: 0.2187, d0.loss_cls: 0.1565, d0.loss_bbox: 0.3181, d1.loss_cls: 0.1089, d1.loss_bbox: 0.2478, d2.loss_cls: 0.0894, d2.loss_bbox: 0.2330, d3.loss_cls: 0.0806, d3.loss_bbox: 0.2284, d4.loss_cls: 0.0786, d4.loss_bbox: 0.2215, loss: 2.0597, grad_norm: 27.0293
2025-06-10 15:59:32,622 - mmdet - INFO - Epoch [3][1100/7033]	lr: 7.503e-05, eta: 13:03:42, time: 1.764, data_time: 0.062, memory: 18761, loss_cls: 0.0754, loss_bbox: 0.2133, d0.loss_cls: 0.1513, d0.loss_bbox: 0.3203, d1.loss_cls: 0.1010, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0858, d2.loss_bbox: 0.2283, d3.loss_cls: 0.0776, d3.loss_bbox: 0.2233, d4.loss_cls: 0.0763, d4.loss_bbox: 0.2143, loss: 2.0108, grad_norm: 20.3575
2025-06-10 16:00:59,201 - mmdet - INFO - Epoch [3][1150/7033]	lr: 7.503e-05, eta: 13:02:15, time: 1.732, data_time: 0.056, memory: 18761, loss_cls: 0.0831, loss_bbox: 0.2293, d0.loss_cls: 0.1646, d0.loss_bbox: 0.3391, d1.loss_cls: 0.1132, d1.loss_bbox: 0.2604, d2.loss_cls: 0.0972, d2.loss_bbox: 0.2433, d3.loss_cls: 0.0894, d3.loss_bbox: 0.2386, d4.loss_cls: 0.0845, d4.loss_bbox: 0.2311, loss: 2.1739, grad_norm: 30.9825
2025-06-10 16:02:26,636 - mmdet - INFO - Epoch [3][1200/7033]	lr: 7.503e-05, eta: 13:00:49, time: 1.749, data_time: 0.063, memory: 18761, loss_cls: 0.0818, loss_bbox: 0.2225, d0.loss_cls: 0.1665, d0.loss_bbox: 0.3306, d1.loss_cls: 0.1109, d1.loss_bbox: 0.2553, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2352, d3.loss_cls: 0.0862, d3.loss_bbox: 0.2304, d4.loss_cls: 0.0825, d4.loss_bbox: 0.2247, loss: 2.1207, grad_norm: 181.2507
2025-06-10 16:03:56,352 - mmdet - INFO - Epoch [3][1250/7033]	lr: 7.503e-05, eta: 12:59:26, time: 1.793, data_time: 0.093, memory: 18761, loss_cls: 0.0870, loss_bbox: 0.2277, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3400, d1.loss_cls: 0.1127, d1.loss_bbox: 0.2615, d2.loss_cls: 0.1018, d2.loss_bbox: 0.2416, d3.loss_cls: 0.0921, d3.loss_bbox: 0.2385, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2309, loss: 2.1844, grad_norm: 24.4077
2025-06-10 16:05:25,419 - mmdet - INFO - Epoch [3][1300/7033]	lr: 7.503e-05, eta: 12:58:03, time: 1.783, data_time: 0.070, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2196, d0.loss_cls: 0.1663, d0.loss_bbox: 0.3311, d1.loss_cls: 0.1107, d1.loss_bbox: 0.2522, d2.loss_cls: 0.0945, d2.loss_bbox: 0.2322, d3.loss_cls: 0.0864, d3.loss_bbox: 0.2282, d4.loss_cls: 0.0827, d4.loss_bbox: 0.2213, loss: 2.1070, grad_norm: 38.5834
2025-06-10 16:06:55,439 - mmdet - INFO - Epoch [3][1350/7033]	lr: 7.503e-05, eta: 12:56:41, time: 1.799, data_time: 0.067, memory: 18761, loss_cls: 0.0832, loss_bbox: 0.2210, d0.loss_cls: 0.1669, d0.loss_bbox: 0.3286, d1.loss_cls: 0.1118, d1.loss_bbox: 0.2548, d2.loss_cls: 0.0958, d2.loss_bbox: 0.2363, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2344, d4.loss_cls: 0.0833, d4.loss_bbox: 0.2249, loss: 2.1272, grad_norm: 35.3754
2025-06-10 16:08:23,298 - mmdet - INFO - Epoch [3][1400/7033]	lr: 7.503e-05, eta: 12:55:16, time: 1.759, data_time: 0.065, memory: 18761, loss_cls: 0.0798, loss_bbox: 0.2198, d0.loss_cls: 0.1626, d0.loss_bbox: 0.3324, d1.loss_cls: 0.1086, d1.loss_bbox: 0.2507, d2.loss_cls: 0.0898, d2.loss_bbox: 0.2338, d3.loss_cls: 0.0847, d3.loss_bbox: 0.2283, d4.loss_cls: 0.0817, d4.loss_bbox: 0.2224, loss: 2.0947, grad_norm: 40.0136
2025-06-10 16:09:49,685 - mmdet - INFO - Epoch [3][1450/7033]	lr: 7.503e-05, eta: 12:53:48, time: 1.728, data_time: 0.060, memory: 18761, loss_cls: 0.0822, loss_bbox: 0.2243, d0.loss_cls: 0.1663, d0.loss_bbox: 0.3436, d1.loss_cls: 0.1120, d1.loss_bbox: 0.2574, d2.loss_cls: 0.0978, d2.loss_bbox: 0.2394, d3.loss_cls: 0.0869, d3.loss_bbox: 0.2366, d4.loss_cls: 0.0836, d4.loss_bbox: 0.2279, loss: 2.1579, grad_norm: 33.7146
2025-06-10 16:11:16,497 - mmdet - INFO - Epoch [3][1500/7033]	lr: 7.503e-05, eta: 12:52:20, time: 1.736, data_time: 0.057, memory: 18761, loss_cls: 0.0815, loss_bbox: 0.2191, d0.loss_cls: 0.1656, d0.loss_bbox: 0.3281, d1.loss_cls: 0.1116, d1.loss_bbox: 0.2487, d2.loss_cls: 0.0972, d2.loss_bbox: 0.2299, d3.loss_cls: 0.0873, d3.loss_bbox: 0.2292, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2206, loss: 2.1042, grad_norm: 20.2551
2025-06-10 16:12:46,205 - mmdet - INFO - Epoch [3][1550/7033]	lr: 7.503e-05, eta: 12:50:58, time: 1.793, data_time: 0.062, memory: 18761, loss_cls: 0.0791, loss_bbox: 0.2146, d0.loss_cls: 0.1625, d0.loss_bbox: 0.3309, d1.loss_cls: 0.1087, d1.loss_bbox: 0.2474, d2.loss_cls: 0.0937, d2.loss_bbox: 0.2275, d3.loss_cls: 0.0833, d3.loss_bbox: 0.2223, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2174, loss: 2.0664, grad_norm: 93.4661
2025-06-10 16:14:14,806 - mmdet - INFO - Epoch [3][1600/7033]	lr: 7.503e-05, eta: 12:49:34, time: 1.773, data_time: 0.060, memory: 18761, loss_cls: 0.0820, loss_bbox: 0.2188, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3310, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2505, d2.loss_cls: 0.0950, d2.loss_bbox: 0.2338, d3.loss_cls: 0.0862, d3.loss_bbox: 0.2293, d4.loss_cls: 0.0840, d4.loss_bbox: 0.2207, loss: 2.1106, grad_norm: 20.2381
2025-06-10 16:15:40,516 - mmdet - INFO - Epoch [3][1650/7033]	lr: 7.503e-05, eta: 12:48:04, time: 1.714, data_time: 0.059, memory: 18761, loss_cls: 0.0814, loss_bbox: 0.2224, d0.loss_cls: 0.1647, d0.loss_bbox: 0.3340, d1.loss_cls: 0.1071, d1.loss_bbox: 0.2577, d2.loss_cls: 0.0973, d2.loss_bbox: 0.2369, d3.loss_cls: 0.0878, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0855, d4.loss_bbox: 0.2231, loss: 2.1306, grad_norm: 35.2451
2025-06-10 16:17:09,187 - mmdet - INFO - Epoch [3][1700/7033]	lr: 7.503e-05, eta: 12:46:40, time: 1.773, data_time: 0.059, memory: 18761, loss_cls: 0.0758, loss_bbox: 0.2021, d0.loss_cls: 0.1506, d0.loss_bbox: 0.3185, d1.loss_cls: 0.1045, d1.loss_bbox: 0.2356, d2.loss_cls: 0.0878, d2.loss_bbox: 0.2173, d3.loss_cls: 0.0794, d3.loss_bbox: 0.2120, d4.loss_cls: 0.0770, d4.loss_bbox: 0.2038, loss: 1.9642, grad_norm: 24.1038
2025-06-10 16:18:35,541 - mmdet - INFO - Epoch [3][1750/7033]	lr: 7.503e-05, eta: 12:45:12, time: 1.727, data_time: 0.061, memory: 18761, loss_cls: 0.0770, loss_bbox: 0.2119, d0.loss_cls: 0.1594, d0.loss_bbox: 0.3213, d1.loss_cls: 0.1048, d1.loss_bbox: 0.2434, d2.loss_cls: 0.0904, d2.loss_bbox: 0.2250, d3.loss_cls: 0.0809, d3.loss_bbox: 0.2214, d4.loss_cls: 0.0784, d4.loss_bbox: 0.2144, loss: 2.0282, grad_norm: 26.3960
2025-06-10 16:20:01,680 - mmdet - INFO - Epoch [3][1800/7033]	lr: 7.503e-05, eta: 12:43:44, time: 1.723, data_time: 0.054, memory: 18761, loss_cls: 0.0830, loss_bbox: 0.2133, d0.loss_cls: 0.1598, d0.loss_bbox: 0.3239, d1.loss_cls: 0.1069, d1.loss_bbox: 0.2499, d2.loss_cls: 0.0947, d2.loss_bbox: 0.2277, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2225, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2150, loss: 2.0703, grad_norm: 22.6860
2025-06-10 16:21:28,931 - mmdet - INFO - Epoch [3][1850/7033]	lr: 7.503e-05, eta: 12:42:17, time: 1.745, data_time: 0.063, memory: 18761, loss_cls: 0.0791, loss_bbox: 0.2117, d0.loss_cls: 0.1550, d0.loss_bbox: 0.3290, d1.loss_cls: 0.1061, d1.loss_bbox: 0.2471, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2230, d4.loss_cls: 0.0800, d4.loss_bbox: 0.2143, loss: 2.0490, grad_norm: 24.1526
2025-06-10 16:22:53,060 - mmdet - INFO - Epoch [3][1900/7033]	lr: 7.503e-05, eta: 12:40:45, time: 1.683, data_time: 0.063, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2209, d0.loss_cls: 0.1689, d0.loss_bbox: 0.3388, d1.loss_cls: 0.1113, d1.loss_bbox: 0.2582, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2366, d3.loss_cls: 0.0843, d3.loss_bbox: 0.2328, d4.loss_cls: 0.0840, d4.loss_bbox: 0.2243, loss: 2.1392, grad_norm: 29.3129
2025-06-10 16:24:22,192 - mmdet - INFO - Epoch [3][1950/7033]	lr: 7.503e-05, eta: 12:39:22, time: 1.783, data_time: 0.059, memory: 18761, loss_cls: 0.0782, loss_bbox: 0.2163, d0.loss_cls: 0.1625, d0.loss_bbox: 0.3264, d1.loss_cls: 0.1092, d1.loss_bbox: 0.2474, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2296, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2265, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2188, loss: 2.0664, grad_norm: 44.2196
2025-06-10 16:25:58,907 - mmdet - INFO - Epoch [3][2000/7033]	lr: 7.503e-05, eta: 12:38:10, time: 1.934, data_time: 0.139, memory: 18761, loss_cls: 0.0763, loss_bbox: 0.2153, d0.loss_cls: 0.1599, d0.loss_bbox: 0.3275, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2476, d2.loss_cls: 0.0883, d2.loss_bbox: 0.2313, d3.loss_cls: 0.0790, d3.loss_bbox: 0.2265, d4.loss_cls: 0.0772, d4.loss_bbox: 0.2179, loss: 2.0510, grad_norm: 24.8135
2025-06-10 16:27:25,169 - mmdet - INFO - Epoch [3][2050/7033]	lr: 7.503e-05, eta: 12:36:42, time: 1.725, data_time: 0.057, memory: 18761, loss_cls: 0.0793, loss_bbox: 0.2152, d0.loss_cls: 0.1592, d0.loss_bbox: 0.3243, d1.loss_cls: 0.1068, d1.loss_bbox: 0.2458, d2.loss_cls: 0.0899, d2.loss_bbox: 0.2291, d3.loss_cls: 0.0831, d3.loss_bbox: 0.2229, d4.loss_cls: 0.0805, d4.loss_bbox: 0.2171, loss: 2.0531, grad_norm: 40.6582
2025-06-10 16:28:50,891 - mmdet - INFO - Epoch [3][2100/7033]	lr: 7.503e-05, eta: 12:35:13, time: 1.713, data_time: 0.055, memory: 18761, loss_cls: 0.0868, loss_bbox: 0.2299, d0.loss_cls: 0.1741, d0.loss_bbox: 0.3461, d1.loss_cls: 0.1201, d1.loss_bbox: 0.2591, d2.loss_cls: 0.1010, d2.loss_bbox: 0.2423, d3.loss_cls: 0.0908, d3.loss_bbox: 0.2393, d4.loss_cls: 0.0869, d4.loss_bbox: 0.2324, loss: 2.2088, grad_norm: 54.1159
2025-06-10 16:30:18,556 - mmdet - INFO - Epoch [3][2150/7033]	lr: 7.503e-05, eta: 12:33:47, time: 1.755, data_time: 0.060, memory: 18761, loss_cls: 0.0793, loss_bbox: 0.2068, d0.loss_cls: 0.1594, d0.loss_bbox: 0.3237, d1.loss_cls: 0.1111, d1.loss_bbox: 0.2406, d2.loss_cls: 0.0912, d2.loss_bbox: 0.2226, d3.loss_cls: 0.0835, d3.loss_bbox: 0.2165, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2102, loss: 2.0241, grad_norm: 20.1197
2025-06-10 16:31:44,859 - mmdet - INFO - Epoch [3][2200/7033]	lr: 7.503e-05, eta: 12:32:19, time: 1.726, data_time: 0.054, memory: 18761, loss_cls: 0.0821, loss_bbox: 0.2097, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0964, d2.loss_bbox: 0.2271, d3.loss_cls: 0.0848, d3.loss_bbox: 0.2214, d4.loss_cls: 0.0829, d4.loss_bbox: 0.2126, loss: 2.0603, grad_norm: 25.5930
2025-06-10 16:33:12,518 - mmdet - INFO - Epoch [3][2250/7033]	lr: 7.503e-05, eta: 12:30:53, time: 1.753, data_time: 0.056, memory: 18761, loss_cls: 0.0792, loss_bbox: 0.2150, d0.loss_cls: 0.1562, d0.loss_bbox: 0.3237, d1.loss_cls: 0.1082, d1.loss_bbox: 0.2467, d2.loss_cls: 0.0957, d2.loss_bbox: 0.2289, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2238, d4.loss_cls: 0.0811, d4.loss_bbox: 0.2162, loss: 2.0587, grad_norm: 39.1150
2025-06-10 16:34:38,414 - mmdet - INFO - Epoch [3][2300/7033]	lr: 7.503e-05, eta: 12:29:24, time: 1.718, data_time: 0.054, memory: 18761, loss_cls: 0.0893, loss_bbox: 0.2196, d0.loss_cls: 0.1699, d0.loss_bbox: 0.3245, d1.loss_cls: 0.1186, d1.loss_bbox: 0.2496, d2.loss_cls: 0.1044, d2.loss_bbox: 0.2325, d3.loss_cls: 0.0935, d3.loss_bbox: 0.2294, d4.loss_cls: 0.0901, d4.loss_bbox: 0.2216, loss: 2.1430, grad_norm: 28.4707
2025-06-10 16:36:04,956 - mmdet - INFO - Epoch [3][2350/7033]	lr: 7.503e-05, eta: 12:27:56, time: 1.729, data_time: 0.053, memory: 18761, loss_cls: 0.0885, loss_bbox: 0.2247, d0.loss_cls: 0.1637, d0.loss_bbox: 0.3409, d1.loss_cls: 0.1122, d1.loss_bbox: 0.2583, d2.loss_cls: 0.0993, d2.loss_bbox: 0.2397, d3.loss_cls: 0.0912, d3.loss_bbox: 0.2371, d4.loss_cls: 0.0886, d4.loss_bbox: 0.2299, loss: 2.1742, grad_norm: 42.4865
2025-06-10 16:37:34,638 - mmdet - INFO - Epoch [3][2400/7033]	lr: 7.503e-05, eta: 12:26:33, time: 1.795, data_time: 0.059, memory: 18761, loss_cls: 0.0807, loss_bbox: 0.2193, d0.loss_cls: 0.1631, d0.loss_bbox: 0.3327, d1.loss_cls: 0.1106, d1.loss_bbox: 0.2543, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2332, d3.loss_cls: 0.0865, d3.loss_bbox: 0.2281, d4.loss_cls: 0.0827, d4.loss_bbox: 0.2209, loss: 2.1075, grad_norm: 27.9529
2025-06-10 16:39:04,388 - mmdet - INFO - Epoch [3][2450/7033]	lr: 7.503e-05, eta: 12:25:10, time: 1.795, data_time: 0.057, memory: 18761, loss_cls: 0.0806, loss_bbox: 0.2116, d0.loss_cls: 0.1668, d0.loss_bbox: 0.3302, d1.loss_cls: 0.1132, d1.loss_bbox: 0.2449, d2.loss_cls: 0.0944, d2.loss_bbox: 0.2257, d3.loss_cls: 0.0837, d3.loss_bbox: 0.2220, d4.loss_cls: 0.0831, d4.loss_bbox: 0.2141, loss: 2.0704, grad_norm: 39.8389
2025-06-10 16:40:30,908 - mmdet - INFO - Epoch [3][2500/7033]	lr: 7.503e-05, eta: 12:23:42, time: 1.730, data_time: 0.058, memory: 18761, loss_cls: 0.0819, loss_bbox: 0.2099, d0.loss_cls: 0.1601, d0.loss_bbox: 0.3315, d1.loss_cls: 0.1101, d1.loss_bbox: 0.2478, d2.loss_cls: 0.0931, d2.loss_bbox: 0.2275, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2241, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2140, loss: 2.0664, grad_norm: 31.3666
2025-06-10 16:41:55,856 - mmdet - INFO - Epoch [3][2550/7033]	lr: 7.503e-05, eta: 12:22:12, time: 1.699, data_time: 0.053, memory: 18761, loss_cls: 0.0785, loss_bbox: 0.2197, d0.loss_cls: 0.1597, d0.loss_bbox: 0.3281, d1.loss_cls: 0.1060, d1.loss_bbox: 0.2512, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2326, d3.loss_cls: 0.0828, d3.loss_bbox: 0.2315, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2222, loss: 2.0848, grad_norm: 28.3024
2025-06-10 16:43:21,475 - mmdet - INFO - Epoch [3][2600/7033]	lr: 7.503e-05, eta: 12:20:43, time: 1.712, data_time: 0.057, memory: 18761, loss_cls: 0.0884, loss_bbox: 0.2232, d0.loss_cls: 0.1617, d0.loss_bbox: 0.3266, d1.loss_cls: 0.1151, d1.loss_bbox: 0.2515, d2.loss_cls: 0.0999, d2.loss_bbox: 0.2347, d3.loss_cls: 0.0922, d3.loss_bbox: 0.2312, d4.loss_cls: 0.0886, d4.loss_bbox: 0.2266, loss: 2.1398, grad_norm: 80.9041
2025-06-10 16:44:49,316 - mmdet - INFO - Epoch [3][2650/7033]	lr: 7.503e-05, eta: 12:19:17, time: 1.757, data_time: 0.060, memory: 18761, loss_cls: 0.0791, loss_bbox: 0.2128, d0.loss_cls: 0.1554, d0.loss_bbox: 0.3247, d1.loss_cls: 0.1061, d1.loss_bbox: 0.2442, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2273, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2221, d4.loss_cls: 0.0801, d4.loss_bbox: 0.2159, loss: 2.0377, grad_norm: 35.1769
2025-06-10 16:46:17,119 - mmdet - INFO - Epoch [3][2700/7033]	lr: 7.503e-05, eta: 12:17:51, time: 1.756, data_time: 0.067, memory: 18761, loss_cls: 0.0846, loss_bbox: 0.2250, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3352, d1.loss_cls: 0.1124, d1.loss_bbox: 0.2568, d2.loss_cls: 0.0957, d2.loss_bbox: 0.2396, d3.loss_cls: 0.0865, d3.loss_bbox: 0.2355, d4.loss_cls: 0.0853, d4.loss_bbox: 0.2277, loss: 2.1476, grad_norm: 48.4557
2025-06-10 16:47:43,977 - mmdet - INFO - Epoch [3][2750/7033]	lr: 7.503e-05, eta: 12:16:24, time: 1.737, data_time: 0.064, memory: 18761, loss_cls: 0.0872, loss_bbox: 0.2171, d0.loss_cls: 0.1661, d0.loss_bbox: 0.3280, d1.loss_cls: 0.1135, d1.loss_bbox: 0.2490, d2.loss_cls: 0.0974, d2.loss_bbox: 0.2309, d3.loss_cls: 0.0913, d3.loss_bbox: 0.2268, d4.loss_cls: 0.0888, d4.loss_bbox: 0.2202, loss: 2.1163, grad_norm: 33.1591
2025-06-10 16:49:14,214 - mmdet - INFO - Epoch [3][2800/7033]	lr: 7.503e-05, eta: 12:15:02, time: 1.803, data_time: 0.058, memory: 18761, loss_cls: 0.0840, loss_bbox: 0.2259, d0.loss_cls: 0.1633, d0.loss_bbox: 0.3406, d1.loss_cls: 0.1153, d1.loss_bbox: 0.2581, d2.loss_cls: 0.1000, d2.loss_bbox: 0.2405, d3.loss_cls: 0.0893, d3.loss_bbox: 0.2369, d4.loss_cls: 0.0863, d4.loss_bbox: 0.2294, loss: 2.1696, grad_norm: 377.8422
2025-06-10 16:50:46,904 - mmdet - INFO - Epoch [3][2850/7033]	lr: 7.503e-05, eta: 12:13:43, time: 1.856, data_time: 0.059, memory: 18761, loss_cls: 0.0861, loss_bbox: 0.2245, d0.loss_cls: 0.1690, d0.loss_bbox: 0.3330, d1.loss_cls: 0.1123, d1.loss_bbox: 0.2574, d2.loss_cls: 0.0987, d2.loss_bbox: 0.2392, d3.loss_cls: 0.0892, d3.loss_bbox: 0.2369, d4.loss_cls: 0.0860, d4.loss_bbox: 0.2278, loss: 2.1601, grad_norm: 22.1649
2025-06-10 16:52:12,322 - mmdet - INFO - Epoch [3][2900/7033]	lr: 7.503e-05, eta: 12:12:14, time: 1.708, data_time: 0.064, memory: 18761, loss_cls: 0.0782, loss_bbox: 0.2125, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3185, d1.loss_cls: 0.1078, d1.loss_bbox: 0.2415, d2.loss_cls: 0.0909, d2.loss_bbox: 0.2263, d3.loss_cls: 0.0828, d3.loss_bbox: 0.2229, d4.loss_cls: 0.0793, d4.loss_bbox: 0.2155, loss: 2.0353, grad_norm: 22.0911
2025-06-10 16:53:39,503 - mmdet - INFO - Epoch [3][2950/7033]	lr: 7.503e-05, eta: 12:10:47, time: 1.744, data_time: 0.065, memory: 18761, loss_cls: 0.0725, loss_bbox: 0.2148, d0.loss_cls: 0.1571, d0.loss_bbox: 0.3228, d1.loss_cls: 0.1041, d1.loss_bbox: 0.2464, d2.loss_cls: 0.0856, d2.loss_bbox: 0.2285, d3.loss_cls: 0.0756, d3.loss_bbox: 0.2248, d4.loss_cls: 0.0737, d4.loss_bbox: 0.2181, loss: 2.0241, grad_norm: 39.6139
2025-06-10 16:55:03,762 - mmdet - INFO - Epoch [3][3000/7033]	lr: 7.503e-05, eta: 12:09:16, time: 1.685, data_time: 0.057, memory: 18761, loss_cls: 0.0808, loss_bbox: 0.2175, d0.loss_cls: 0.1650, d0.loss_bbox: 0.3305, d1.loss_cls: 0.1115, d1.loss_bbox: 0.2504, d2.loss_cls: 0.0927, d2.loss_bbox: 0.2317, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2276, d4.loss_cls: 0.0819, d4.loss_bbox: 0.2221, loss: 2.0970, grad_norm: 39.2411
2025-06-10 16:56:32,994 - mmdet - INFO - Epoch [3][3050/7033]	lr: 7.503e-05, eta: 12:07:52, time: 1.784, data_time: 0.054, memory: 18761, loss_cls: 0.0788, loss_bbox: 0.2171, d0.loss_cls: 0.1601, d0.loss_bbox: 0.3263, d1.loss_cls: 0.1065, d1.loss_bbox: 0.2461, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2298, d3.loss_cls: 0.0828, d3.loss_bbox: 0.2269, d4.loss_cls: 0.0795, d4.loss_bbox: 0.2206, loss: 2.0645, grad_norm: 126.8547
2025-06-10 16:57:56,606 - mmdet - INFO - Epoch [3][3100/7033]	lr: 7.503e-05, eta: 12:06:20, time: 1.672, data_time: 0.058, memory: 18761, loss_cls: 0.0871, loss_bbox: 0.2188, d0.loss_cls: 0.1653, d0.loss_bbox: 0.3282, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2489, d2.loss_cls: 0.1019, d2.loss_bbox: 0.2318, d3.loss_cls: 0.0928, d3.loss_bbox: 0.2286, d4.loss_cls: 0.0882, d4.loss_bbox: 0.2216, loss: 2.1261, grad_norm: 29.8130
2025-06-10 16:59:23,247 - mmdet - INFO - Epoch [3][3150/7033]	lr: 7.503e-05, eta: 12:04:52, time: 1.733, data_time: 0.052, memory: 18761, loss_cls: 0.0822, loss_bbox: 0.2171, d0.loss_cls: 0.1559, d0.loss_bbox: 0.3265, d1.loss_cls: 0.1103, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0940, d2.loss_bbox: 0.2297, d3.loss_cls: 0.0857, d3.loss_bbox: 0.2270, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2197, loss: 2.0757, grad_norm: 24.5595
2025-06-10 17:00:51,785 - mmdet - INFO - Epoch [3][3200/7033]	lr: 7.503e-05, eta: 12:03:27, time: 1.771, data_time: 0.066, memory: 18761, loss_cls: 0.0820, loss_bbox: 0.2246, d0.loss_cls: 0.1651, d0.loss_bbox: 0.3417, d1.loss_cls: 0.1122, d1.loss_bbox: 0.2536, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2375, d3.loss_cls: 0.0868, d3.loss_bbox: 0.2330, d4.loss_cls: 0.0845, d4.loss_bbox: 0.2263, loss: 2.1425, grad_norm: 30.3644
2025-06-10 17:02:22,129 - mmdet - INFO - Epoch [3][3250/7033]	lr: 7.503e-05, eta: 12:02:05, time: 1.807, data_time: 0.059, memory: 18761, loss_cls: 0.0863, loss_bbox: 0.2179, d0.loss_cls: 0.1577, d0.loss_bbox: 0.3213, d1.loss_cls: 0.1101, d1.loss_bbox: 0.2462, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2306, d3.loss_cls: 0.0882, d3.loss_bbox: 0.2272, d4.loss_cls: 0.0874, d4.loss_bbox: 0.2215, loss: 2.0895, grad_norm: 199.3142
2025-06-10 17:03:50,099 - mmdet - INFO - Epoch [3][3300/7033]	lr: 7.503e-05, eta: 12:00:39, time: 1.759, data_time: 0.061, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2205, d0.loss_cls: 0.1628, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1118, d1.loss_bbox: 0.2522, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2336, d3.loss_cls: 0.0885, d3.loss_bbox: 0.2298, d4.loss_cls: 0.0854, d4.loss_bbox: 0.2230, loss: 2.1228, grad_norm: 27.6189
2025-06-10 17:05:18,890 - mmdet - INFO - Epoch [3][3350/7033]	lr: 7.503e-05, eta: 11:59:14, time: 1.775, data_time: 0.060, memory: 18761, loss_cls: 0.0776, loss_bbox: 0.2224, d0.loss_cls: 0.1602, d0.loss_bbox: 0.3320, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2541, d2.loss_cls: 0.0882, d2.loss_bbox: 0.2355, d3.loss_cls: 0.0800, d3.loss_bbox: 0.2321, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2249, loss: 2.0896, grad_norm: 22.7781
2025-06-10 17:06:47,477 - mmdet - INFO - Epoch [3][3400/7033]	lr: 7.503e-05, eta: 11:57:49, time: 1.773, data_time: 0.060, memory: 18761, loss_cls: 0.0734, loss_bbox: 0.2181, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3322, d1.loss_cls: 0.1019, d1.loss_bbox: 0.2499, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2318, d3.loss_cls: 0.0774, d3.loss_bbox: 0.2283, d4.loss_cls: 0.0744, d4.loss_bbox: 0.2210, loss: 2.0480, grad_norm: 21.2031
2025-06-10 17:08:16,327 - mmdet - INFO - Epoch [3][3450/7033]	lr: 7.503e-05, eta: 11:56:25, time: 1.776, data_time: 0.068, memory: 18761, loss_cls: 0.0820, loss_bbox: 0.2278, d0.loss_cls: 0.1581, d0.loss_bbox: 0.3416, d1.loss_cls: 0.1128, d1.loss_bbox: 0.2584, d2.loss_cls: 0.0962, d2.loss_bbox: 0.2423, d3.loss_cls: 0.0878, d3.loss_bbox: 0.2399, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2307, loss: 2.1611, grad_norm: 28.7540
2025-06-10 17:09:43,180 - mmdet - INFO - Epoch [3][3500/7033]	lr: 7.503e-05, eta: 11:54:57, time: 1.738, data_time: 0.055, memory: 18761, loss_cls: 0.0810, loss_bbox: 0.2183, d0.loss_cls: 0.1585, d0.loss_bbox: 0.3255, d1.loss_cls: 0.1100, d1.loss_bbox: 0.2488, d2.loss_cls: 0.0932, d2.loss_bbox: 0.2326, d3.loss_cls: 0.0846, d3.loss_bbox: 0.2287, d4.loss_cls: 0.0823, d4.loss_bbox: 0.2211, loss: 2.0846, grad_norm: 37.1055
2025-06-10 17:11:11,178 - mmdet - INFO - Epoch [3][3550/7033]	lr: 7.503e-05, eta: 11:53:32, time: 1.760, data_time: 0.060, memory: 18761, loss_cls: 0.0748, loss_bbox: 0.2140, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3227, d1.loss_cls: 0.1056, d1.loss_bbox: 0.2427, d2.loss_cls: 0.0882, d2.loss_bbox: 0.2273, d3.loss_cls: 0.0793, d3.loss_bbox: 0.2250, d4.loss_cls: 0.0744, d4.loss_bbox: 0.2178, loss: 2.0256, grad_norm: 34.6966
2025-06-10 17:12:38,953 - mmdet - INFO - Epoch [3][3600/7033]	lr: 7.503e-05, eta: 11:52:05, time: 1.754, data_time: 0.059, memory: 18761, loss_cls: 0.0768, loss_bbox: 0.2204, d0.loss_cls: 0.1586, d0.loss_bbox: 0.3306, d1.loss_cls: 0.1070, d1.loss_bbox: 0.2516, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2346, d3.loss_cls: 0.0814, d3.loss_bbox: 0.2303, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2238, loss: 2.0834, grad_norm: 106.6227
2025-06-10 17:14:06,608 - mmdet - INFO - Epoch [3][3650/7033]	lr: 7.503e-05, eta: 11:50:39, time: 1.754, data_time: 0.062, memory: 18761, loss_cls: 0.0858, loss_bbox: 0.2207, d0.loss_cls: 0.1615, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2567, d2.loss_cls: 0.0977, d2.loss_bbox: 0.2384, d3.loss_cls: 0.0892, d3.loss_bbox: 0.2331, d4.loss_cls: 0.0875, d4.loss_bbox: 0.2234, loss: 2.1399, grad_norm: 30.5288
2025-06-10 17:15:40,316 - mmdet - INFO - Epoch [3][3700/7033]	lr: 7.503e-05, eta: 11:49:21, time: 1.874, data_time: 0.069, memory: 18761, loss_cls: 0.0971, loss_bbox: 0.2233, d0.loss_cls: 0.1809, d0.loss_bbox: 0.3284, d1.loss_cls: 0.1250, d1.loss_bbox: 0.2535, d2.loss_cls: 0.1085, d2.loss_bbox: 0.2359, d3.loss_cls: 0.0998, d3.loss_bbox: 0.2315, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2255, loss: 2.2067, grad_norm: 36.6004
2025-06-10 17:17:10,331 - mmdet - INFO - Epoch [3][3750/7033]	lr: 7.503e-05, eta: 11:47:58, time: 1.800, data_time: 0.061, memory: 18761, loss_cls: 0.0857, loss_bbox: 0.2236, d0.loss_cls: 0.1603, d0.loss_bbox: 0.3385, d1.loss_cls: 0.1142, d1.loss_bbox: 0.2578, d2.loss_cls: 0.0986, d2.loss_bbox: 0.2372, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2335, d4.loss_cls: 0.0875, d4.loss_bbox: 0.2264, loss: 2.1538, grad_norm: 23.3794
2025-06-10 17:18:37,945 - mmdet - INFO - Epoch [3][3800/7033]	lr: 7.503e-05, eta: 11:46:32, time: 1.752, data_time: 0.052, memory: 18761, loss_cls: 0.0849, loss_bbox: 0.2205, d0.loss_cls: 0.1620, d0.loss_bbox: 0.3343, d1.loss_cls: 0.1131, d1.loss_bbox: 0.2542, d2.loss_cls: 0.0985, d2.loss_bbox: 0.2352, d3.loss_cls: 0.0894, d3.loss_bbox: 0.2316, d4.loss_cls: 0.0850, d4.loss_bbox: 0.2240, loss: 2.1327, grad_norm: 23.3976
2025-06-10 17:20:04,999 - mmdet - INFO - Epoch [3][3850/7033]	lr: 7.503e-05, eta: 11:45:05, time: 1.740, data_time: 0.053, memory: 18761, loss_cls: 0.0870, loss_bbox: 0.2278, d0.loss_cls: 0.1635, d0.loss_bbox: 0.3319, d1.loss_cls: 0.1135, d1.loss_bbox: 0.2572, d2.loss_cls: 0.1012, d2.loss_bbox: 0.2398, d3.loss_cls: 0.0917, d3.loss_bbox: 0.2363, d4.loss_cls: 0.0891, d4.loss_bbox: 0.2292, loss: 2.1682, grad_norm: 20.2588
2025-06-10 17:21:33,131 - mmdet - INFO - Epoch [3][3900/7033]	lr: 7.503e-05, eta: 11:43:39, time: 1.763, data_time: 0.068, memory: 18761, loss_cls: 0.0836, loss_bbox: 0.2166, d0.loss_cls: 0.1688, d0.loss_bbox: 0.3230, d1.loss_cls: 0.1105, d1.loss_bbox: 0.2481, d2.loss_cls: 0.0964, d2.loss_bbox: 0.2308, d3.loss_cls: 0.0900, d3.loss_bbox: 0.2260, d4.loss_cls: 0.0850, d4.loss_bbox: 0.2184, loss: 2.0971, grad_norm: 32.8605
2025-06-10 17:23:01,418 - mmdet - INFO - Epoch [3][3950/7033]	lr: 7.503e-05, eta: 11:42:13, time: 1.765, data_time: 0.060, memory: 18761, loss_cls: 0.0789, loss_bbox: 0.2168, d0.loss_cls: 0.1614, d0.loss_bbox: 0.3331, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2490, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2331, d3.loss_cls: 0.0839, d3.loss_bbox: 0.2269, d4.loss_cls: 0.0799, d4.loss_bbox: 0.2203, loss: 2.0824, grad_norm: 48.4969
2025-06-10 17:24:27,835 - mmdet - INFO - Epoch [3][4000/7033]	lr: 7.503e-05, eta: 11:40:45, time: 1.727, data_time: 0.062, memory: 18761, loss_cls: 0.0797, loss_bbox: 0.2134, d0.loss_cls: 0.1549, d0.loss_bbox: 0.3197, d1.loss_cls: 0.1056, d1.loss_bbox: 0.2460, d2.loss_cls: 0.0915, d2.loss_bbox: 0.2284, d3.loss_cls: 0.0812, d3.loss_bbox: 0.2242, d4.loss_cls: 0.0805, d4.loss_bbox: 0.2154, loss: 2.0406, grad_norm: 28.5512
2025-06-10 17:25:53,182 - mmdet - INFO - Epoch [3][4050/7033]	lr: 7.503e-05, eta: 11:39:16, time: 1.708, data_time: 0.057, memory: 18761, loss_cls: 0.0756, loss_bbox: 0.2100, d0.loss_cls: 0.1606, d0.loss_bbox: 0.3107, d1.loss_cls: 0.1036, d1.loss_bbox: 0.2391, d2.loss_cls: 0.0872, d2.loss_bbox: 0.2249, d3.loss_cls: 0.0795, d3.loss_bbox: 0.2213, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2125, loss: 2.0029, grad_norm: 18.6558
2025-06-10 17:27:20,607 - mmdet - INFO - Epoch [3][4100/7033]	lr: 7.503e-05, eta: 11:37:49, time: 1.749, data_time: 0.056, memory: 18761, loss_cls: 0.0814, loss_bbox: 0.2239, d0.loss_cls: 0.1605, d0.loss_bbox: 0.3297, d1.loss_cls: 0.1102, d1.loss_bbox: 0.2527, d2.loss_cls: 0.0961, d2.loss_bbox: 0.2367, d3.loss_cls: 0.0873, d3.loss_bbox: 0.2324, d4.loss_cls: 0.0819, d4.loss_bbox: 0.2265, loss: 2.1193, grad_norm: 110.4940
2025-06-10 17:28:46,893 - mmdet - INFO - Epoch [3][4150/7033]	lr: 7.503e-05, eta: 11:36:21, time: 1.726, data_time: 0.051, memory: 18761, loss_cls: 0.0754, loss_bbox: 0.2197, d0.loss_cls: 0.1577, d0.loss_bbox: 0.3233, d1.loss_cls: 0.1044, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0864, d2.loss_bbox: 0.2323, d3.loss_cls: 0.0781, d3.loss_bbox: 0.2318, d4.loss_cls: 0.0757, d4.loss_bbox: 0.2218, loss: 2.0505, grad_norm: 35.7231
2025-06-10 17:30:17,709 - mmdet - INFO - Epoch [3][4200/7033]	lr: 7.503e-05, eta: 11:34:59, time: 1.816, data_time: 0.066, memory: 18761, loss_cls: 0.0778, loss_bbox: 0.2151, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3187, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2436, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0804, d3.loss_bbox: 0.2252, d4.loss_cls: 0.0782, d4.loss_bbox: 0.2180, loss: 2.0498, grad_norm: 26.7808
2025-06-10 17:31:44,398 - mmdet - INFO - Epoch [3][4250/7033]	lr: 7.503e-05, eta: 11:33:31, time: 1.734, data_time: 0.059, memory: 18761, loss_cls: 0.0855, loss_bbox: 0.2236, d0.loss_cls: 0.1661, d0.loss_bbox: 0.3399, d1.loss_cls: 0.1147, d1.loss_bbox: 0.2553, d2.loss_cls: 0.0987, d2.loss_bbox: 0.2387, d3.loss_cls: 0.0902, d3.loss_bbox: 0.2335, d4.loss_cls: 0.0879, d4.loss_bbox: 0.2263, loss: 2.1606, grad_norm: 25.1973
2025-06-10 17:33:15,733 - mmdet - INFO - Epoch [3][4300/7033]	lr: 7.503e-05, eta: 11:32:09, time: 1.827, data_time: 0.062, memory: 18761, loss_cls: 0.0870, loss_bbox: 0.2272, d0.loss_cls: 0.1595, d0.loss_bbox: 0.3423, d1.loss_cls: 0.1121, d1.loss_bbox: 0.2620, d2.loss_cls: 0.1001, d2.loss_bbox: 0.2431, d3.loss_cls: 0.0913, d3.loss_bbox: 0.2369, d4.loss_cls: 0.0878, d4.loss_bbox: 0.2305, loss: 2.1798, grad_norm: 44.4500
2025-06-10 17:34:43,001 - mmdet - INFO - Epoch [3][4350/7033]	lr: 7.503e-05, eta: 11:30:42, time: 1.745, data_time: 0.060, memory: 18761, loss_cls: 0.0862, loss_bbox: 0.2207, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3278, d1.loss_cls: 0.1116, d1.loss_bbox: 0.2498, d2.loss_cls: 0.0976, d2.loss_bbox: 0.2355, d3.loss_cls: 0.0914, d3.loss_bbox: 0.2281, d4.loss_cls: 0.0878, d4.loss_bbox: 0.2212, loss: 2.1249, grad_norm: 149.8628
2025-06-10 17:36:10,746 - mmdet - INFO - Epoch [3][4400/7033]	lr: 7.503e-05, eta: 11:29:16, time: 1.755, data_time: 0.068, memory: 18761, loss_cls: 0.0819, loss_bbox: 0.2190, d0.loss_cls: 0.1608, d0.loss_bbox: 0.3241, d1.loss_cls: 0.1085, d1.loss_bbox: 0.2465, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2327, d3.loss_cls: 0.0855, d3.loss_bbox: 0.2289, d4.loss_cls: 0.0815, d4.loss_bbox: 0.2224, loss: 2.0856, grad_norm: 39.0332
2025-06-10 17:37:38,038 - mmdet - INFO - Epoch [3][4450/7033]	lr: 7.503e-05, eta: 11:27:49, time: 1.746, data_time: 0.085, memory: 18761, loss_cls: 0.0741, loss_bbox: 0.2096, d0.loss_cls: 0.1545, d0.loss_bbox: 0.3154, d1.loss_cls: 0.1028, d1.loss_bbox: 0.2387, d2.loss_cls: 0.0879, d2.loss_bbox: 0.2214, d3.loss_cls: 0.0777, d3.loss_bbox: 0.2188, d4.loss_cls: 0.0765, d4.loss_bbox: 0.2118, loss: 1.9892, grad_norm: 30.1615
2025-06-10 17:39:02,827 - mmdet - INFO - Epoch [3][4500/7033]	lr: 7.503e-05, eta: 11:26:19, time: 1.696, data_time: 0.066, memory: 18761, loss_cls: 0.0796, loss_bbox: 0.2125, d0.loss_cls: 0.1613, d0.loss_bbox: 0.3265, d1.loss_cls: 0.1071, d1.loss_bbox: 0.2459, d2.loss_cls: 0.0947, d2.loss_bbox: 0.2254, d3.loss_cls: 0.0842, d3.loss_bbox: 0.2222, d4.loss_cls: 0.0808, d4.loss_bbox: 0.2159, loss: 2.0561, grad_norm: 22.1759
2025-06-10 17:40:31,909 - mmdet - INFO - Epoch [3][4550/7033]	lr: 7.503e-05, eta: 11:24:54, time: 1.782, data_time: 0.076, memory: 18761, loss_cls: 0.0836, loss_bbox: 0.2234, d0.loss_cls: 0.1616, d0.loss_bbox: 0.3303, d1.loss_cls: 0.1089, d1.loss_bbox: 0.2529, d2.loss_cls: 0.0973, d2.loss_bbox: 0.2360, d3.loss_cls: 0.0886, d3.loss_bbox: 0.2332, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2268, loss: 2.1260, grad_norm: 50.0163
2025-06-10 17:41:59,600 - mmdet - INFO - Epoch [3][4600/7033]	lr: 7.503e-05, eta: 11:23:28, time: 1.754, data_time: 0.065, memory: 18761, loss_cls: 0.0819, loss_bbox: 0.2142, d0.loss_cls: 0.1548, d0.loss_bbox: 0.3248, d1.loss_cls: 0.1055, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2287, d3.loss_cls: 0.0843, d3.loss_bbox: 0.2239, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2188, loss: 2.0546, grad_norm: 35.4307
2025-06-10 17:43:27,724 - mmdet - INFO - Epoch [3][4650/7033]	lr: 7.503e-05, eta: 11:22:02, time: 1.762, data_time: 0.060, memory: 18761, loss_cls: 0.0818, loss_bbox: 0.2170, d0.loss_cls: 0.1558, d0.loss_bbox: 0.3266, d1.loss_cls: 0.1086, d1.loss_bbox: 0.2520, d2.loss_cls: 0.0967, d2.loss_bbox: 0.2326, d3.loss_cls: 0.0867, d3.loss_bbox: 0.2271, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2192, loss: 2.0866, grad_norm: 52.7444
2025-06-10 17:44:57,437 - mmdet - INFO - Epoch [3][4700/7033]	lr: 7.503e-05, eta: 11:20:38, time: 1.794, data_time: 0.053, memory: 18761, loss_cls: 0.0843, loss_bbox: 0.2211, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3286, d1.loss_cls: 0.1088, d1.loss_bbox: 0.2512, d2.loss_cls: 0.0956, d2.loss_bbox: 0.2361, d3.loss_cls: 0.0876, d3.loss_bbox: 0.2321, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2238, loss: 2.1139, grad_norm: 23.9032
2025-06-10 17:46:24,067 - mmdet - INFO - Epoch [3][4750/7033]	lr: 7.503e-05, eta: 11:19:10, time: 1.733, data_time: 0.061, memory: 18761, loss_cls: 0.0749, loss_bbox: 0.2108, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3204, d1.loss_cls: 0.1069, d1.loss_bbox: 0.2415, d2.loss_cls: 0.0905, d2.loss_bbox: 0.2244, d3.loss_cls: 0.0803, d3.loss_bbox: 0.2207, d4.loss_cls: 0.0771, d4.loss_bbox: 0.2130, loss: 2.0240, grad_norm: 23.8899
2025-06-10 17:47:50,306 - mmdet - INFO - Epoch [3][4800/7033]	lr: 7.503e-05, eta: 11:17:42, time: 1.724, data_time: 0.065, memory: 18761, loss_cls: 0.0838, loss_bbox: 0.2161, d0.loss_cls: 0.1648, d0.loss_bbox: 0.3225, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2441, d2.loss_cls: 0.0957, d2.loss_bbox: 0.2264, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2234, d4.loss_cls: 0.0854, d4.loss_bbox: 0.2187, loss: 2.0795, grad_norm: 19.7896
2025-06-10 17:49:18,120 - mmdet - INFO - Epoch [3][4850/7033]	lr: 7.503e-05, eta: 11:16:16, time: 1.756, data_time: 0.054, memory: 18761, loss_cls: 0.0740, loss_bbox: 0.2071, d0.loss_cls: 0.1514, d0.loss_bbox: 0.3109, d1.loss_cls: 0.1027, d1.loss_bbox: 0.2376, d2.loss_cls: 0.0879, d2.loss_bbox: 0.2193, d3.loss_cls: 0.0779, d3.loss_bbox: 0.2173, d4.loss_cls: 0.0757, d4.loss_bbox: 0.2100, loss: 1.9718, grad_norm: 23.2482
2025-06-10 17:50:46,456 - mmdet - INFO - Epoch [3][4900/7033]	lr: 7.503e-05, eta: 11:14:50, time: 1.767, data_time: 0.052, memory: 18761, loss_cls: 0.0761, loss_bbox: 0.2079, d0.loss_cls: 0.1595, d0.loss_bbox: 0.3220, d1.loss_cls: 0.1053, d1.loss_bbox: 0.2408, d2.loss_cls: 0.0884, d2.loss_bbox: 0.2244, d3.loss_cls: 0.0808, d3.loss_bbox: 0.2193, d4.loss_cls: 0.0776, d4.loss_bbox: 0.2107, loss: 2.0127, grad_norm: 42.3917
2025-06-10 17:52:17,957 - mmdet - INFO - Epoch [3][4950/7033]	lr: 7.503e-05, eta: 11:13:28, time: 1.828, data_time: 0.077, memory: 18761, loss_cls: 0.0728, loss_bbox: 0.2080, d0.loss_cls: 0.1545, d0.loss_bbox: 0.3145, d1.loss_cls: 0.0996, d1.loss_bbox: 0.2341, d2.loss_cls: 0.0853, d2.loss_bbox: 0.2203, d3.loss_cls: 0.0784, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2093, loss: 1.9659, grad_norm: 23.3229
2025-06-10 17:53:48,601 - mmdet - INFO - Epoch [3][5000/7033]	lr: 7.503e-05, eta: 11:12:05, time: 1.815, data_time: 0.054, memory: 18761, loss_cls: 0.0783, loss_bbox: 0.2179, d0.loss_cls: 0.1617, d0.loss_bbox: 0.3208, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2513, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2307, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2277, d4.loss_cls: 0.0809, d4.loss_bbox: 0.2215, loss: 2.0804, grad_norm: 43.4387
2025-06-10 17:55:19,732 - mmdet - INFO - Epoch [3][5050/7033]	lr: 7.503e-05, eta: 11:10:43, time: 1.823, data_time: 0.072, memory: 18761, loss_cls: 0.0860, loss_bbox: 0.2183, d0.loss_cls: 0.1615, d0.loss_bbox: 0.3221, d1.loss_cls: 0.1118, d1.loss_bbox: 0.2457, d2.loss_cls: 0.0978, d2.loss_bbox: 0.2295, d3.loss_cls: 0.0899, d3.loss_bbox: 0.2272, d4.loss_cls: 0.0871, d4.loss_bbox: 0.2209, loss: 2.0977, grad_norm: 38.9978
2025-06-10 17:56:48,010 - mmdet - INFO - Epoch [3][5100/7033]	lr: 7.503e-05, eta: 11:09:17, time: 1.765, data_time: 0.053, memory: 18761, loss_cls: 0.0733, loss_bbox: 0.2094, d0.loss_cls: 0.1546, d0.loss_bbox: 0.3232, d1.loss_cls: 0.1028, d1.loss_bbox: 0.2425, d2.loss_cls: 0.0846, d2.loss_bbox: 0.2245, d3.loss_cls: 0.0781, d3.loss_bbox: 0.2210, d4.loss_cls: 0.0750, d4.loss_bbox: 0.2117, loss: 2.0005, grad_norm: 34.8982
2025-06-10 17:58:16,939 - mmdet - INFO - Epoch [3][5150/7033]	lr: 7.503e-05, eta: 11:07:52, time: 1.779, data_time: 0.058, memory: 18761, loss_cls: 0.0759, loss_bbox: 0.2153, d0.loss_cls: 0.1604, d0.loss_bbox: 0.3191, d1.loss_cls: 0.1049, d1.loss_bbox: 0.2442, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0806, d3.loss_bbox: 0.2256, d4.loss_cls: 0.0768, d4.loss_bbox: 0.2185, loss: 2.0415, grad_norm: 29.8209
2025-06-10 17:59:44,961 - mmdet - INFO - Epoch [3][5200/7033]	lr: 7.503e-05, eta: 11:06:26, time: 1.760, data_time: 0.055, memory: 18761, loss_cls: 0.0767, loss_bbox: 0.2129, d0.loss_cls: 0.1609, d0.loss_bbox: 0.3237, d1.loss_cls: 0.1023, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0910, d2.loss_bbox: 0.2244, d3.loss_cls: 0.0819, d3.loss_bbox: 0.2232, d4.loss_cls: 0.0765, d4.loss_bbox: 0.2159, loss: 2.0331, grad_norm: 32.7273
2025-06-10 18:01:10,877 - mmdet - INFO - Epoch [3][5250/7033]	lr: 7.503e-05, eta: 11:04:57, time: 1.718, data_time: 0.062, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2164, d0.loss_cls: 0.1603, d0.loss_bbox: 0.3185, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2452, d2.loss_cls: 0.0947, d2.loss_bbox: 0.2295, d3.loss_cls: 0.0843, d3.loss_bbox: 0.2263, d4.loss_cls: 0.0829, d4.loss_bbox: 0.2193, loss: 2.0690, grad_norm: 86.8517
2025-06-10 18:02:39,855 - mmdet - INFO - Epoch [3][5300/7033]	lr: 7.503e-05, eta: 11:03:32, time: 1.779, data_time: 0.056, memory: 18761, loss_cls: 0.0777, loss_bbox: 0.2190, d0.loss_cls: 0.1627, d0.loss_bbox: 0.3253, d1.loss_cls: 0.1107, d1.loss_bbox: 0.2488, d2.loss_cls: 0.0924, d2.loss_bbox: 0.2319, d3.loss_cls: 0.0830, d3.loss_bbox: 0.2287, d4.loss_cls: 0.0784, d4.loss_bbox: 0.2211, loss: 2.0799, grad_norm: 64.0638
2025-06-10 18:04:10,375 - mmdet - INFO - Epoch [3][5350/7033]	lr: 7.503e-05, eta: 11:02:09, time: 1.811, data_time: 0.054, memory: 18761, loss_cls: 0.0750, loss_bbox: 0.2102, d0.loss_cls: 0.1552, d0.loss_bbox: 0.3119, d1.loss_cls: 0.1038, d1.loss_bbox: 0.2368, d2.loss_cls: 0.0883, d2.loss_bbox: 0.2225, d3.loss_cls: 0.0792, d3.loss_bbox: 0.2197, d4.loss_cls: 0.0760, d4.loss_bbox: 0.2132, loss: 1.9917, grad_norm: 20.6010
2025-06-10 18:05:37,536 - mmdet - INFO - Epoch [3][5400/7033]	lr: 7.503e-05, eta: 11:00:42, time: 1.743, data_time: 0.060, memory: 18761, loss_cls: 0.0880, loss_bbox: 0.2212, d0.loss_cls: 0.1615, d0.loss_bbox: 0.3282, d1.loss_cls: 0.1118, d1.loss_bbox: 0.2520, d2.loss_cls: 0.0959, d2.loss_bbox: 0.2356, d3.loss_cls: 0.0918, d3.loss_bbox: 0.2311, d4.loss_cls: 0.0891, d4.loss_bbox: 0.2247, loss: 2.1309, grad_norm: 35.2221
2025-06-10 18:07:06,483 - mmdet - INFO - Epoch [3][5450/7033]	lr: 7.503e-05, eta: 10:59:16, time: 1.779, data_time: 0.058, memory: 18761, loss_cls: 0.0858, loss_bbox: 0.2184, d0.loss_cls: 0.1649, d0.loss_bbox: 0.3270, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2518, d2.loss_cls: 0.0980, d2.loss_bbox: 0.2353, d3.loss_cls: 0.0898, d3.loss_bbox: 0.2293, d4.loss_cls: 0.0865, d4.loss_bbox: 0.2222, loss: 2.1228, grad_norm: 24.4024
2025-06-10 18:08:31,203 - mmdet - INFO - Epoch [3][5500/7033]	lr: 7.503e-05, eta: 10:57:46, time: 1.695, data_time: 0.058, memory: 18761, loss_cls: 0.0762, loss_bbox: 0.2162, d0.loss_cls: 0.1629, d0.loss_bbox: 0.3298, d1.loss_cls: 0.1061, d1.loss_bbox: 0.2483, d2.loss_cls: 0.0917, d2.loss_bbox: 0.2316, d3.loss_cls: 0.0812, d3.loss_bbox: 0.2267, d4.loss_cls: 0.0768, d4.loss_bbox: 0.2193, loss: 2.0667, grad_norm: 72.1057
2025-06-10 18:09:53,649 - mmdet - INFO - Epoch [3][5550/7033]	lr: 7.503e-05, eta: 10:56:14, time: 1.649, data_time: 0.060, memory: 18761, loss_cls: 0.0753, loss_bbox: 0.2128, d0.loss_cls: 0.1524, d0.loss_bbox: 0.3147, d1.loss_cls: 0.1008, d1.loss_bbox: 0.2428, d2.loss_cls: 0.0879, d2.loss_bbox: 0.2275, d3.loss_cls: 0.0788, d3.loss_bbox: 0.2235, d4.loss_cls: 0.0763, d4.loss_bbox: 0.2162, loss: 2.0091, grad_norm: 54.7193
2025-06-10 18:11:22,189 - mmdet - INFO - Epoch [3][5600/7033]	lr: 7.503e-05, eta: 10:54:48, time: 1.771, data_time: 0.058, memory: 18761, loss_cls: 0.0795, loss_bbox: 0.2132, d0.loss_cls: 0.1593, d0.loss_bbox: 0.3275, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2294, d3.loss_cls: 0.0832, d3.loss_bbox: 0.2243, d4.loss_cls: 0.0810, d4.loss_bbox: 0.2157, loss: 2.0552, grad_norm: 29.3677
2025-06-10 18:12:50,002 - mmdet - INFO - Epoch [3][5650/7033]	lr: 7.503e-05, eta: 10:53:21, time: 1.756, data_time: 0.061, memory: 18761, loss_cls: 0.0759, loss_bbox: 0.2126, d0.loss_cls: 0.1575, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1061, d1.loss_bbox: 0.2460, d2.loss_cls: 0.0893, d2.loss_bbox: 0.2276, d3.loss_cls: 0.0801, d3.loss_bbox: 0.2221, d4.loss_cls: 0.0763, d4.loss_bbox: 0.2166, loss: 2.0363, grad_norm: 51.9553
2025-06-10 18:14:21,082 - mmdet - INFO - Epoch [3][5700/7033]	lr: 7.503e-05, eta: 10:51:59, time: 1.822, data_time: 0.059, memory: 18761, loss_cls: 0.0770, loss_bbox: 0.2131, d0.loss_cls: 0.1617, d0.loss_bbox: 0.3265, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0884, d2.loss_bbox: 0.2291, d3.loss_cls: 0.0809, d3.loss_bbox: 0.2246, d4.loss_cls: 0.0781, d4.loss_bbox: 0.2159, loss: 2.0484, grad_norm: 35.1595
2025-06-10 18:15:49,727 - mmdet - INFO - Epoch [3][5750/7033]	lr: 7.503e-05, eta: 10:50:33, time: 1.773, data_time: 0.072, memory: 18761, loss_cls: 0.0808, loss_bbox: 0.2117, d0.loss_cls: 0.1623, d0.loss_bbox: 0.3295, d1.loss_cls: 0.1095, d1.loss_bbox: 0.2450, d2.loss_cls: 0.0929, d2.loss_bbox: 0.2291, d3.loss_cls: 0.0846, d3.loss_bbox: 0.2233, d4.loss_cls: 0.0827, d4.loss_bbox: 0.2165, loss: 2.0680, grad_norm: 29.1823
2025-06-10 18:17:12,982 - mmdet - INFO - Epoch [3][5800/7033]	lr: 7.503e-05, eta: 10:49:02, time: 1.665, data_time: 0.065, memory: 18761, loss_cls: 0.0780, loss_bbox: 0.2198, d0.loss_cls: 0.1623, d0.loss_bbox: 0.3331, d1.loss_cls: 0.1091, d1.loss_bbox: 0.2504, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2334, d3.loss_cls: 0.0829, d3.loss_bbox: 0.2287, d4.loss_cls: 0.0799, d4.loss_bbox: 0.2227, loss: 2.0914, grad_norm: 50.5847
2025-06-10 18:18:38,580 - mmdet - INFO - Epoch [3][5850/7033]	lr: 7.503e-05, eta: 10:47:33, time: 1.712, data_time: 0.063, memory: 18761, loss_cls: 0.0784, loss_bbox: 0.2226, d0.loss_cls: 0.1633, d0.loss_bbox: 0.3381, d1.loss_cls: 0.1115, d1.loss_bbox: 0.2560, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2392, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0797, d4.loss_bbox: 0.2254, loss: 2.1255, grad_norm: 29.0804
2025-06-10 18:20:05,516 - mmdet - INFO - Epoch [3][5900/7033]	lr: 7.503e-05, eta: 10:46:05, time: 1.739, data_time: 0.065, memory: 18761, loss_cls: 0.0853, loss_bbox: 0.2253, d0.loss_cls: 0.1708, d0.loss_bbox: 0.3331, d1.loss_cls: 0.1171, d1.loss_bbox: 0.2545, d2.loss_cls: 0.0997, d2.loss_bbox: 0.2393, d3.loss_cls: 0.0909, d3.loss_bbox: 0.2340, d4.loss_cls: 0.0893, d4.loss_bbox: 0.2264, loss: 2.1656, grad_norm: 31.5195
2025-06-10 18:21:31,571 - mmdet - INFO - Epoch [3][5950/7033]	lr: 7.503e-05, eta: 10:44:37, time: 1.721, data_time: 0.060, memory: 18761, loss_cls: 0.0782, loss_bbox: 0.2175, d0.loss_cls: 0.1674, d0.loss_bbox: 0.3219, d1.loss_cls: 0.1087, d1.loss_bbox: 0.2457, d2.loss_cls: 0.0940, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0829, d3.loss_bbox: 0.2258, d4.loss_cls: 0.0803, d4.loss_bbox: 0.2185, loss: 2.0690, grad_norm: 25.8030
2025-06-10 18:23:00,598 - mmdet - INFO - Epoch [3][6000/7033]	lr: 7.503e-05, eta: 10:43:12, time: 1.781, data_time: 0.057, memory: 18761, loss_cls: 0.0834, loss_bbox: 0.2144, d0.loss_cls: 0.1629, d0.loss_bbox: 0.3289, d1.loss_cls: 0.1142, d1.loss_bbox: 0.2495, d2.loss_cls: 0.0957, d2.loss_bbox: 0.2325, d3.loss_cls: 0.0869, d3.loss_bbox: 0.2262, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2165, loss: 2.0971, grad_norm: 47.7876
2025-06-10 18:24:29,029 - mmdet - INFO - Epoch [3][6050/7033]	lr: 7.503e-05, eta: 10:41:46, time: 1.768, data_time: 0.055, memory: 18761, loss_cls: 0.0774, loss_bbox: 0.2088, d0.loss_cls: 0.1620, d0.loss_bbox: 0.3189, d1.loss_cls: 0.1069, d1.loss_bbox: 0.2406, d2.loss_cls: 0.0899, d2.loss_bbox: 0.2242, d3.loss_cls: 0.0797, d3.loss_bbox: 0.2182, d4.loss_cls: 0.0771, d4.loss_bbox: 0.2119, loss: 2.0156, grad_norm: 24.6265
2025-06-10 18:25:55,657 - mmdet - INFO - Epoch [3][6100/7033]	lr: 7.503e-05, eta: 10:40:18, time: 1.731, data_time: 0.062, memory: 18761, loss_cls: 0.0827, loss_bbox: 0.2106, d0.loss_cls: 0.1658, d0.loss_bbox: 0.3119, d1.loss_cls: 0.1102, d1.loss_bbox: 0.2376, d2.loss_cls: 0.0965, d2.loss_bbox: 0.2230, d3.loss_cls: 0.0853, d3.loss_bbox: 0.2196, d4.loss_cls: 0.0822, d4.loss_bbox: 0.2133, loss: 2.0386, grad_norm: 76.3838
2025-06-10 18:27:19,177 - mmdet - INFO - Epoch [3][6150/7033]	lr: 7.503e-05, eta: 10:38:47, time: 1.672, data_time: 0.060, memory: 18761, loss_cls: 0.0859, loss_bbox: 0.2233, d0.loss_cls: 0.1688, d0.loss_bbox: 0.3304, d1.loss_cls: 0.1189, d1.loss_bbox: 0.2539, d2.loss_cls: 0.0998, d2.loss_bbox: 0.2386, d3.loss_cls: 0.0912, d3.loss_bbox: 0.2319, d4.loss_cls: 0.0871, d4.loss_bbox: 0.2252, loss: 2.1552, grad_norm: 49.5110
2025-06-10 18:28:46,565 - mmdet - INFO - Epoch [3][6200/7033]	lr: 7.503e-05, eta: 10:37:20, time: 1.748, data_time: 0.078, memory: 18761, loss_cls: 0.0797, loss_bbox: 0.2124, d0.loss_cls: 0.1758, d0.loss_bbox: 0.3235, d1.loss_cls: 0.1106, d1.loss_bbox: 0.2423, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2272, d3.loss_cls: 0.0845, d3.loss_bbox: 0.2224, d4.loss_cls: 0.0798, d4.loss_bbox: 0.2140, loss: 2.0664, grad_norm: 82.5866
2025-06-10 18:30:16,604 - mmdet - INFO - Epoch [3][6250/7033]	lr: 7.503e-05, eta: 10:35:56, time: 1.801, data_time: 0.063, memory: 18761, loss_cls: 0.0840, loss_bbox: 0.2224, d0.loss_cls: 0.1649, d0.loss_bbox: 0.3233, d1.loss_cls: 0.1113, d1.loss_bbox: 0.2500, d2.loss_cls: 0.0941, d2.loss_bbox: 0.2369, d3.loss_cls: 0.0896, d3.loss_bbox: 0.2310, d4.loss_cls: 0.0866, d4.loss_bbox: 0.2245, loss: 2.1186, grad_norm: 19.2009
2025-06-10 18:31:45,761 - mmdet - INFO - Epoch [3][6300/7033]	lr: 7.503e-05, eta: 10:34:31, time: 1.783, data_time: 0.059, memory: 18761, loss_cls: 0.0791, loss_bbox: 0.2129, d0.loss_cls: 0.1616, d0.loss_bbox: 0.3219, d1.loss_cls: 0.1113, d1.loss_bbox: 0.2438, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2287, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2243, d4.loss_cls: 0.0812, d4.loss_bbox: 0.2169, loss: 2.0604, grad_norm: 32.6170
2025-06-10 18:33:16,738 - mmdet - INFO - Epoch [3][6350/7033]	lr: 7.503e-05, eta: 10:33:07, time: 1.820, data_time: 0.055, memory: 18761, loss_cls: 0.0841, loss_bbox: 0.2218, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3311, d1.loss_cls: 0.1167, d1.loss_bbox: 0.2495, d2.loss_cls: 0.0998, d2.loss_bbox: 0.2333, d3.loss_cls: 0.0896, d3.loss_bbox: 0.2304, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2234, loss: 2.1366, grad_norm: 49.1804
2025-06-10 18:34:51,854 - mmdet - INFO - Epoch [3][6400/7033]	lr: 7.503e-05, eta: 10:31:49, time: 1.902, data_time: 0.078, memory: 18761, loss_cls: 0.0750, loss_bbox: 0.2135, d0.loss_cls: 0.1570, d0.loss_bbox: 0.3115, d1.loss_cls: 0.1044, d1.loss_bbox: 0.2419, d2.loss_cls: 0.0896, d2.loss_bbox: 0.2260, d3.loss_cls: 0.0798, d3.loss_bbox: 0.2221, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2149, loss: 2.0134, grad_norm: 22.6226
2025-06-10 18:36:24,398 - mmdet - INFO - Epoch [3][6450/7033]	lr: 7.503e-05, eta: 10:30:27, time: 1.851, data_time: 0.084, memory: 18761, loss_cls: 0.0814, loss_bbox: 0.2204, d0.loss_cls: 0.1598, d0.loss_bbox: 0.3371, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2520, d2.loss_cls: 0.0962, d2.loss_bbox: 0.2354, d3.loss_cls: 0.0853, d3.loss_bbox: 0.2312, d4.loss_cls: 0.0830, d4.loss_bbox: 0.2225, loss: 2.1152, grad_norm: 23.5037
2025-06-10 18:37:54,946 - mmdet - INFO - Epoch [3][6500/7033]	lr: 7.503e-05, eta: 10:29:03, time: 1.811, data_time: 0.062, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2190, d0.loss_cls: 0.1656, d0.loss_bbox: 0.3295, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2518, d2.loss_cls: 0.0957, d2.loss_bbox: 0.2347, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2287, d4.loss_cls: 0.0836, d4.loss_bbox: 0.2218, loss: 2.1130, grad_norm: 26.7712
2025-06-10 18:39:23,636 - mmdet - INFO - Epoch [3][6550/7033]	lr: 7.503e-05, eta: 10:27:38, time: 1.774, data_time: 0.077, memory: 18761, loss_cls: 0.0795, loss_bbox: 0.2196, d0.loss_cls: 0.1625, d0.loss_bbox: 0.3348, d1.loss_cls: 0.1107, d1.loss_bbox: 0.2534, d2.loss_cls: 0.0919, d2.loss_bbox: 0.2367, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2323, d4.loss_cls: 0.0793, d4.loss_bbox: 0.2239, loss: 2.1063, grad_norm: 71.0754
2025-06-10 18:40:56,713 - mmdet - INFO - Epoch [3][6600/7033]	lr: 7.503e-05, eta: 10:26:16, time: 1.861, data_time: 0.055, memory: 18761, loss_cls: 0.0759, loss_bbox: 0.2256, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3308, d1.loss_cls: 0.1008, d1.loss_bbox: 0.2554, d2.loss_cls: 0.0854, d2.loss_bbox: 0.2424, d3.loss_cls: 0.0787, d3.loss_bbox: 0.2382, d4.loss_cls: 0.0765, d4.loss_bbox: 0.2295, loss: 2.0963, grad_norm: 40.1116
2025-06-10 18:42:26,651 - mmdet - INFO - Epoch [3][6650/7033]	lr: 7.503e-05, eta: 10:24:52, time: 1.799, data_time: 0.061, memory: 18761, loss_cls: 0.0753, loss_bbox: 0.2102, d0.loss_cls: 0.1555, d0.loss_bbox: 0.3272, d1.loss_cls: 0.1034, d1.loss_bbox: 0.2449, d2.loss_cls: 0.0879, d2.loss_bbox: 0.2268, d3.loss_cls: 0.0798, d3.loss_bbox: 0.2223, d4.loss_cls: 0.0749, d4.loss_bbox: 0.2145, loss: 2.0228, grad_norm: 25.6034
2025-06-10 18:43:56,190 - mmdet - INFO - Epoch [3][6700/7033]	lr: 7.503e-05, eta: 10:23:27, time: 1.791, data_time: 0.050, memory: 18761, loss_cls: 0.0761, loss_bbox: 0.2109, d0.loss_cls: 0.1509, d0.loss_bbox: 0.3099, d1.loss_cls: 0.1036, d1.loss_bbox: 0.2424, d2.loss_cls: 0.0903, d2.loss_bbox: 0.2257, d3.loss_cls: 0.0816, d3.loss_bbox: 0.2212, d4.loss_cls: 0.0768, d4.loss_bbox: 0.2146, loss: 2.0040, grad_norm: 27.3992
2025-06-10 18:45:26,361 - mmdet - INFO - Epoch [3][6750/7033]	lr: 7.503e-05, eta: 10:22:03, time: 1.803, data_time: 0.048, memory: 18761, loss_cls: 0.0742, loss_bbox: 0.2170, d0.loss_cls: 0.1586, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1040, d1.loss_bbox: 0.2494, d2.loss_cls: 0.0878, d2.loss_bbox: 0.2320, d3.loss_cls: 0.0792, d3.loss_bbox: 0.2281, d4.loss_cls: 0.0759, d4.loss_bbox: 0.2207, loss: 2.0530, grad_norm: 70.2183
2025-06-10 18:46:56,913 - mmdet - INFO - Epoch [3][6800/7033]	lr: 7.503e-05, eta: 10:20:39, time: 1.811, data_time: 0.049, memory: 18761, loss_cls: 0.0790, loss_bbox: 0.2127, d0.loss_cls: 0.1618, d0.loss_bbox: 0.3218, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2442, d2.loss_cls: 0.0914, d2.loss_bbox: 0.2283, d3.loss_cls: 0.0831, d3.loss_bbox: 0.2240, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2153, loss: 2.0482, grad_norm: 38.6960
2025-06-10 18:48:31,852 - mmdet - INFO - Epoch [3][6850/7033]	lr: 7.503e-05, eta: 10:19:19, time: 1.899, data_time: 0.059, memory: 18761, loss_cls: 0.0877, loss_bbox: 0.2253, d0.loss_cls: 0.1651, d0.loss_bbox: 0.3329, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2553, d2.loss_cls: 0.0985, d2.loss_bbox: 0.2405, d3.loss_cls: 0.0918, d3.loss_bbox: 0.2353, d4.loss_cls: 0.0890, d4.loss_bbox: 0.2278, loss: 2.1633, grad_norm: 29.4201
2025-06-10 18:50:04,921 - mmdet - INFO - Epoch [3][6900/7033]	lr: 7.503e-05, eta: 10:17:58, time: 1.861, data_time: 0.088, memory: 18761, loss_cls: 0.0832, loss_bbox: 0.2194, d0.loss_cls: 0.1644, d0.loss_bbox: 0.3217, d1.loss_cls: 0.1128, d1.loss_bbox: 0.2475, d2.loss_cls: 0.0966, d2.loss_bbox: 0.2318, d3.loss_cls: 0.0870, d3.loss_bbox: 0.2297, d4.loss_cls: 0.0851, d4.loss_bbox: 0.2214, loss: 2.1007, grad_norm: 20.5764
2025-06-10 18:51:31,782 - mmdet - INFO - Epoch [3][6950/7033]	lr: 7.503e-05, eta: 10:16:30, time: 1.737, data_time: 0.065, memory: 18761, loss_cls: 0.0778, loss_bbox: 0.2187, d0.loss_cls: 0.1594, d0.loss_bbox: 0.3218, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2446, d2.loss_cls: 0.0908, d2.loss_bbox: 0.2325, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2278, d4.loss_cls: 0.0798, d4.loss_bbox: 0.2213, loss: 2.0643, grad_norm: 32.0388
2025-06-10 18:53:03,949 - mmdet - INFO - Epoch [3][7000/7033]	lr: 7.503e-05, eta: 10:15:08, time: 1.843, data_time: 0.053, memory: 18761, loss_cls: 0.0772, loss_bbox: 0.2088, d0.loss_cls: 0.1657, d0.loss_bbox: 0.3219, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2408, d2.loss_cls: 0.0890, d2.loss_bbox: 0.2249, d3.loss_cls: 0.0793, d3.loss_bbox: 0.2209, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2122, loss: 2.0247, grad_norm: 35.6813
2025-06-10 18:54:01,468 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-06-10 19:37:16,440 - mmdet - INFO - Exp name: lidar_0075v_cam_vov_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs2.py
2025-06-10 19:37:16,440 - mmdet - INFO - Epoch(val) [3][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.8358, pts_bbox_NuScenes/car_AP_dist_1.0: 0.9315, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9649, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9789, pts_bbox_NuScenes/car_trans_err: 0.1764, pts_bbox_NuScenes/car_scale_err: 0.1361, pts_bbox_NuScenes/car_orient_err: 0.0322, pts_bbox_NuScenes/car_vel_err: 0.1949, pts_bbox_NuScenes/car_attr_err: 0.2012, pts_bbox_NuScenes/mATE: 0.2821, pts_bbox_NuScenes/mASE: 0.2129, pts_bbox_NuScenes/mAOE: 0.1290, pts_bbox_NuScenes/mAVE: 0.2106, pts_bbox_NuScenes/mAAE: 0.1875, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.5362, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.7705, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.9044, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.9428, pts_bbox_NuScenes/truck_trans_err: 0.3310, pts_bbox_NuScenes/truck_scale_err: 0.1629, pts_bbox_NuScenes/truck_orient_err: 0.0317, pts_bbox_NuScenes/truck_vel_err: 0.1752, pts_bbox_NuScenes/truck_attr_err: 0.2170, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.1289, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.3970, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.7213, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.8433, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6255, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.3330, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.4232, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1148, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2954, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5311, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7680, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.9460, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9717, pts_bbox_NuScenes/bus_trans_err: 0.3413, pts_bbox_NuScenes/bus_scale_err: 0.1773, pts_bbox_NuScenes/bus_orient_err: 0.0222, pts_bbox_NuScenes/bus_vel_err: 0.3597, pts_bbox_NuScenes/bus_attr_err: 0.2447, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.2350, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.5648, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.7924, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.8814, pts_bbox_NuScenes/trailer_trans_err: 0.4833, pts_bbox_NuScenes/trailer_scale_err: 0.2193, pts_bbox_NuScenes/trailer_orient_err: 0.1322, pts_bbox_NuScenes/trailer_vel_err: 0.1768, pts_bbox_NuScenes/trailer_attr_err: 0.1590, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.7387, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.8645, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.9213, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.9356, pts_bbox_NuScenes/barrier_trans_err: 0.2058, pts_bbox_NuScenes/barrier_scale_err: 0.2126, pts_bbox_NuScenes/barrier_orient_err: 0.0470, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.7054, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.8761, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.9263, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.9419, pts_bbox_NuScenes/motorcycle_trans_err: 0.2119, pts_bbox_NuScenes/motorcycle_scale_err: 0.2131, pts_bbox_NuScenes/motorcycle_orient_err: 0.1422, pts_bbox_NuScenes/motorcycle_vel_err: 0.2835, pts_bbox_NuScenes/motorcycle_attr_err: 0.2638, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.7823, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.8870, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.9118, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.9223, pts_bbox_NuScenes/bicycle_trans_err: 0.1757, pts_bbox_NuScenes/bicycle_scale_err: 0.2205, pts_bbox_NuScenes/bicycle_orient_err: 0.1227, pts_bbox_NuScenes/bicycle_vel_err: 0.1889, pts_bbox_NuScenes/bicycle_attr_err: 0.0150, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8800, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.9285, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.9545, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.9672, pts_bbox_NuScenes/pedestrian_trans_err: 0.1450, pts_bbox_NuScenes/pedestrian_scale_err: 0.2266, pts_bbox_NuScenes/pedestrian_orient_err: 0.2081, pts_bbox_NuScenes/pedestrian_vel_err: 0.1914, pts_bbox_NuScenes/pedestrian_attr_err: 0.1041, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.8462, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.8894, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.9151, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.9357, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1245, pts_bbox_NuScenes/traffic_cone_scale_err: 0.2278, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.8025, pts_bbox_NuScenes/mAP: 0.8094
2025-06-10 19:39:03,973 - mmdet - INFO - Epoch [4][50/7033]	lr: 5.005e-05, eta: 10:12:02, time: 2.074, data_time: 0.312, memory: 18761, loss_cls: 0.0763, loss_bbox: 0.2099, d0.loss_cls: 0.1611, d0.loss_bbox: 0.3309, d1.loss_cls: 0.1088, d1.loss_bbox: 0.2449, d2.loss_cls: 0.0885, d2.loss_bbox: 0.2290, d3.loss_cls: 0.0793, d3.loss_bbox: 0.2227, d4.loss_cls: 0.0767, d4.loss_bbox: 0.2149, loss: 2.0431, grad_norm: 38.1609
2025-06-10 19:40:36,141 - mmdet - INFO - Epoch [4][100/7033]	lr: 5.005e-05, eta: 10:10:39, time: 1.843, data_time: 0.061, memory: 18761, loss_cls: 0.0739, loss_bbox: 0.2080, d0.loss_cls: 0.1613, d0.loss_bbox: 0.3111, d1.loss_cls: 0.1030, d1.loss_bbox: 0.2365, d2.loss_cls: 0.0875, d2.loss_bbox: 0.2219, d3.loss_cls: 0.0787, d3.loss_bbox: 0.2190, d4.loss_cls: 0.0758, d4.loss_bbox: 0.2111, loss: 1.9879, grad_norm: 35.6654
2025-06-10 19:42:04,823 - mmdet - INFO - Epoch [4][150/7033]	lr: 5.005e-05, eta: 10:09:13, time: 1.774, data_time: 0.067, memory: 18761, loss_cls: 0.0783, loss_bbox: 0.2062, d0.loss_cls: 0.1573, d0.loss_bbox: 0.3154, d1.loss_cls: 0.1057, d1.loss_bbox: 0.2378, d2.loss_cls: 0.0903, d2.loss_bbox: 0.2216, d3.loss_cls: 0.0829, d3.loss_bbox: 0.2170, d4.loss_cls: 0.0781, d4.loss_bbox: 0.2107, loss: 2.0013, grad_norm: 36.6540
2025-06-10 19:43:34,479 - mmdet - INFO - Epoch [4][200/7033]	lr: 5.005e-05, eta: 10:07:49, time: 1.793, data_time: 0.059, memory: 18761, loss_cls: 0.0750, loss_bbox: 0.2104, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3140, d1.loss_cls: 0.1025, d1.loss_bbox: 0.2421, d2.loss_cls: 0.0867, d2.loss_bbox: 0.2266, d3.loss_cls: 0.0791, d3.loss_bbox: 0.2214, d4.loss_cls: 0.0746, d4.loss_bbox: 0.2146, loss: 2.0066, grad_norm: 40.7646
2025-06-10 19:45:05,969 - mmdet - INFO - Epoch [4][250/7033]	lr: 5.005e-05, eta: 10:06:25, time: 1.830, data_time: 0.068, memory: 18761, loss_cls: 0.0758, loss_bbox: 0.2049, d0.loss_cls: 0.1541, d0.loss_bbox: 0.3142, d1.loss_cls: 0.1036, d1.loss_bbox: 0.2381, d2.loss_cls: 0.0889, d2.loss_bbox: 0.2203, d3.loss_cls: 0.0807, d3.loss_bbox: 0.2160, d4.loss_cls: 0.0776, d4.loss_bbox: 0.2075, loss: 1.9816, grad_norm: 23.0452
2025-06-10 19:46:36,476 - mmdet - INFO - Epoch [4][300/7033]	lr: 5.005e-05, eta: 10:05:01, time: 1.810, data_time: 0.065, memory: 18761, loss_cls: 0.0704, loss_bbox: 0.2102, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3280, d1.loss_cls: 0.0992, d1.loss_bbox: 0.2425, d2.loss_cls: 0.0845, d2.loss_bbox: 0.2249, d3.loss_cls: 0.0747, d3.loss_bbox: 0.2198, d4.loss_cls: 0.0707, d4.loss_bbox: 0.2132, loss: 1.9911, grad_norm: 23.4933
2025-06-10 19:48:04,254 - mmdet - INFO - Epoch [4][350/7033]	lr: 5.005e-05, eta: 10:03:35, time: 1.756, data_time: 0.073, memory: 18761, loss_cls: 0.0740, loss_bbox: 0.2141, d0.loss_cls: 0.1563, d0.loss_bbox: 0.3149, d1.loss_cls: 0.1015, d1.loss_bbox: 0.2433, d2.loss_cls: 0.0876, d2.loss_bbox: 0.2289, d3.loss_cls: 0.0811, d3.loss_bbox: 0.2240, d4.loss_cls: 0.0746, d4.loss_bbox: 0.2162, loss: 2.0166, grad_norm: 32.8191
2025-06-10 19:49:29,869 - mmdet - INFO - Epoch [4][400/7033]	lr: 5.005e-05, eta: 10:02:06, time: 1.712, data_time: 0.061, memory: 18761, loss_cls: 0.0801, loss_bbox: 0.2125, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3253, d1.loss_cls: 0.1086, d1.loss_bbox: 0.2433, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2271, d3.loss_cls: 0.0866, d3.loss_bbox: 0.2222, d4.loss_cls: 0.0830, d4.loss_bbox: 0.2161, loss: 2.0580, grad_norm: 41.0735
2025-06-10 19:51:01,811 - mmdet - INFO - Epoch [4][450/7033]	lr: 5.005e-05, eta: 10:00:43, time: 1.839, data_time: 0.063, memory: 18761, loss_cls: 0.0712, loss_bbox: 0.2086, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3110, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2386, d2.loss_cls: 0.0864, d2.loss_bbox: 0.2245, d3.loss_cls: 0.0777, d3.loss_bbox: 0.2188, d4.loss_cls: 0.0726, d4.loss_bbox: 0.2111, loss: 1.9777, grad_norm: 82.5797
2025-06-10 19:52:33,556 - mmdet - INFO - Epoch [4][500/7033]	lr: 5.005e-05, eta: 9:59:20, time: 1.835, data_time: 0.064, memory: 18761, loss_cls: 0.0798, loss_bbox: 0.2090, d0.loss_cls: 0.1644, d0.loss_bbox: 0.3173, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2431, d2.loss_cls: 0.0946, d2.loss_bbox: 0.2272, d3.loss_cls: 0.0850, d3.loss_bbox: 0.2217, d4.loss_cls: 0.0816, d4.loss_bbox: 0.2129, loss: 2.0469, grad_norm: 32.7269
2025-06-10 19:54:01,227 - mmdet - INFO - Epoch [4][550/7033]	lr: 5.005e-05, eta: 9:57:53, time: 1.753, data_time: 0.071, memory: 18761, loss_cls: 0.0729, loss_bbox: 0.2116, d0.loss_cls: 0.1553, d0.loss_bbox: 0.3251, d1.loss_cls: 0.1040, d1.loss_bbox: 0.2448, d2.loss_cls: 0.0861, d2.loss_bbox: 0.2265, d3.loss_cls: 0.0786, d3.loss_bbox: 0.2222, d4.loss_cls: 0.0745, d4.loss_bbox: 0.2151, loss: 2.0165, grad_norm: 19.2645
2025-06-10 19:55:29,294 - mmdet - INFO - Epoch [4][600/7033]	lr: 5.005e-05, eta: 9:56:26, time: 1.761, data_time: 0.060, memory: 18761, loss_cls: 0.0784, loss_bbox: 0.2062, d0.loss_cls: 0.1576, d0.loss_bbox: 0.3074, d1.loss_cls: 0.1070, d1.loss_bbox: 0.2345, d2.loss_cls: 0.0895, d2.loss_bbox: 0.2189, d3.loss_cls: 0.0827, d3.loss_bbox: 0.2142, d4.loss_cls: 0.0795, d4.loss_bbox: 0.2089, loss: 1.9848, grad_norm: 20.7334
2025-06-10 19:57:00,754 - mmdet - INFO - Epoch [4][650/7033]	lr: 5.005e-05, eta: 9:55:03, time: 1.829, data_time: 0.084, memory: 18761, loss_cls: 0.0766, loss_bbox: 0.2156, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3222, d1.loss_cls: 0.1060, d1.loss_bbox: 0.2459, d2.loss_cls: 0.0918, d2.loss_bbox: 0.2298, d3.loss_cls: 0.0833, d3.loss_bbox: 0.2248, d4.loss_cls: 0.0784, d4.loss_bbox: 0.2172, loss: 2.0496, grad_norm: 46.9543
2025-06-10 19:58:29,334 - mmdet - INFO - Epoch [4][700/7033]	lr: 5.005e-05, eta: 9:53:37, time: 1.772, data_time: 0.070, memory: 18761, loss_cls: 0.0767, loss_bbox: 0.2092, d0.loss_cls: 0.1635, d0.loss_bbox: 0.3264, d1.loss_cls: 0.1053, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0916, d2.loss_bbox: 0.2260, d3.loss_cls: 0.0817, d3.loss_bbox: 0.2211, d4.loss_cls: 0.0780, d4.loss_bbox: 0.2128, loss: 2.0361, grad_norm: 21.3425
2025-06-10 19:59:57,125 - mmdet - INFO - Epoch [4][750/7033]	lr: 5.005e-05, eta: 9:52:10, time: 1.756, data_time: 0.063, memory: 18761, loss_cls: 0.0730, loss_bbox: 0.2056, d0.loss_cls: 0.1519, d0.loss_bbox: 0.3140, d1.loss_cls: 0.1025, d1.loss_bbox: 0.2388, d2.loss_cls: 0.0884, d2.loss_bbox: 0.2213, d3.loss_cls: 0.0783, d3.loss_bbox: 0.2159, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2090, loss: 1.9734, grad_norm: 19.7170
2025-06-10 20:01:26,568 - mmdet - INFO - Epoch [4][800/7033]	lr: 5.005e-05, eta: 9:50:45, time: 1.789, data_time: 0.062, memory: 18761, loss_cls: 0.0792, loss_bbox: 0.2133, d0.loss_cls: 0.1528, d0.loss_bbox: 0.3197, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2450, d2.loss_cls: 0.0927, d2.loss_bbox: 0.2290, d3.loss_cls: 0.0844, d3.loss_bbox: 0.2238, d4.loss_cls: 0.0803, d4.loss_bbox: 0.2153, loss: 2.0407, grad_norm: 39.3644
2025-06-10 20:02:53,983 - mmdet - INFO - Epoch [4][850/7033]	lr: 5.005e-05, eta: 9:49:18, time: 1.748, data_time: 0.062, memory: 18761, loss_cls: 0.0773, loss_bbox: 0.2138, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3195, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2445, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2297, d3.loss_cls: 0.0828, d3.loss_bbox: 0.2254, d4.loss_cls: 0.0782, d4.loss_bbox: 0.2169, loss: 2.0440, grad_norm: 544.9325
2025-06-10 20:04:24,425 - mmdet - INFO - Epoch [4][900/7033]	lr: 5.005e-05, eta: 9:47:53, time: 1.809, data_time: 0.057, memory: 18761, loss_cls: 0.0699, loss_bbox: 0.2044, d0.loss_cls: 0.1490, d0.loss_bbox: 0.3117, d1.loss_cls: 0.0986, d1.loss_bbox: 0.2383, d2.loss_cls: 0.0821, d2.loss_bbox: 0.2214, d3.loss_cls: 0.0746, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0725, d4.loss_bbox: 0.2062, loss: 1.9431, grad_norm: 22.0332
2025-06-10 20:05:55,057 - mmdet - INFO - Epoch [4][950/7033]	lr: 5.005e-05, eta: 9:46:29, time: 1.813, data_time: 0.079, memory: 18761, loss_cls: 0.0733, loss_bbox: 0.2136, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1005, d1.loss_bbox: 0.2452, d2.loss_cls: 0.0870, d2.loss_bbox: 0.2305, d3.loss_cls: 0.0784, d3.loss_bbox: 0.2239, d4.loss_cls: 0.0745, d4.loss_bbox: 0.2168, loss: 2.0286, grad_norm: 42.8747
2025-06-10 20:07:26,085 - mmdet - INFO - Epoch [4][1000/7033]	lr: 5.005e-05, eta: 9:45:05, time: 1.820, data_time: 0.083, memory: 18761, loss_cls: 0.0796, loss_bbox: 0.2153, d0.loss_cls: 0.1562, d0.loss_bbox: 0.3166, d1.loss_cls: 0.1084, d1.loss_bbox: 0.2449, d2.loss_cls: 0.0907, d2.loss_bbox: 0.2301, d3.loss_cls: 0.0839, d3.loss_bbox: 0.2254, d4.loss_cls: 0.0811, d4.loss_bbox: 0.2171, loss: 2.0495, grad_norm: 149.6254
2025-06-10 20:08:56,350 - mmdet - INFO - Epoch [4][1050/7033]	lr: 5.005e-05, eta: 9:43:40, time: 1.805, data_time: 0.065, memory: 18761, loss_cls: 0.0684, loss_bbox: 0.2033, d0.loss_cls: 0.1444, d0.loss_bbox: 0.3090, d1.loss_cls: 0.0955, d1.loss_bbox: 0.2341, d2.loss_cls: 0.0848, d2.loss_bbox: 0.2195, d3.loss_cls: 0.0741, d3.loss_bbox: 0.2130, d4.loss_cls: 0.0693, d4.loss_bbox: 0.2065, loss: 1.9220, grad_norm: 39.3883
2025-06-10 20:10:26,109 - mmdet - INFO - Epoch [4][1100/7033]	lr: 5.005e-05, eta: 9:42:15, time: 1.795, data_time: 0.058, memory: 18761, loss_cls: 0.0739, loss_bbox: 0.2132, d0.loss_cls: 0.1584, d0.loss_bbox: 0.3173, d1.loss_cls: 0.0998, d1.loss_bbox: 0.2426, d2.loss_cls: 0.0870, d2.loss_bbox: 0.2268, d3.loss_cls: 0.0786, d3.loss_bbox: 0.2215, d4.loss_cls: 0.0743, d4.loss_bbox: 0.2167, loss: 2.0100, grad_norm: 21.7378
2025-06-10 20:11:54,521 - mmdet - INFO - Epoch [4][1150/7033]	lr: 5.005e-05, eta: 9:40:49, time: 1.768, data_time: 0.056, memory: 18761, loss_cls: 0.0740, loss_bbox: 0.2048, d0.loss_cls: 0.1536, d0.loss_bbox: 0.3164, d1.loss_cls: 0.1019, d1.loss_bbox: 0.2400, d2.loss_cls: 0.0882, d2.loss_bbox: 0.2222, d3.loss_cls: 0.0799, d3.loss_bbox: 0.2163, d4.loss_cls: 0.0748, d4.loss_bbox: 0.2088, loss: 1.9810, grad_norm: 18.9908
2025-06-10 20:13:24,597 - mmdet - INFO - Epoch [4][1200/7033]	lr: 5.005e-05, eta: 9:39:24, time: 1.802, data_time: 0.052, memory: 18761, loss_cls: 0.0695, loss_bbox: 0.2072, d0.loss_cls: 0.1541, d0.loss_bbox: 0.3160, d1.loss_cls: 0.0988, d1.loss_bbox: 0.2384, d2.loss_cls: 0.0825, d2.loss_bbox: 0.2200, d3.loss_cls: 0.0738, d3.loss_bbox: 0.2151, d4.loss_cls: 0.0705, d4.loss_bbox: 0.2103, loss: 1.9562, grad_norm: 40.1255
2025-06-10 20:14:55,077 - mmdet - INFO - Epoch [4][1250/7033]	lr: 5.005e-05, eta: 9:37:59, time: 1.810, data_time: 0.057, memory: 18761, loss_cls: 0.0810, loss_bbox: 0.2166, d0.loss_cls: 0.1631, d0.loss_bbox: 0.3281, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2495, d2.loss_cls: 0.0955, d2.loss_bbox: 0.2335, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2259, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2184, loss: 2.0887, grad_norm: 43.0435
2025-06-10 20:16:24,014 - mmdet - INFO - Epoch [4][1300/7033]	lr: 5.005e-05, eta: 9:36:33, time: 1.777, data_time: 0.073, memory: 18761, loss_cls: 0.0749, loss_bbox: 0.2113, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3217, d1.loss_cls: 0.1055, d1.loss_bbox: 0.2425, d2.loss_cls: 0.0897, d2.loss_bbox: 0.2288, d3.loss_cls: 0.0798, d3.loss_bbox: 0.2241, d4.loss_cls: 0.0758, d4.loss_bbox: 0.2143, loss: 2.0251, grad_norm: 25.7442
2025-06-10 20:17:52,910 - mmdet - INFO - Epoch [4][1350/7033]	lr: 5.005e-05, eta: 9:35:07, time: 1.780, data_time: 0.110, memory: 18761, loss_cls: 0.0727, loss_bbox: 0.2069, d0.loss_cls: 0.1539, d0.loss_bbox: 0.3153, d1.loss_cls: 0.1040, d1.loss_bbox: 0.2389, d2.loss_cls: 0.0846, d2.loss_bbox: 0.2241, d3.loss_cls: 0.0781, d3.loss_bbox: 0.2178, d4.loss_cls: 0.0741, d4.loss_bbox: 0.2096, loss: 1.9798, grad_norm: 32.1992
2025-06-10 20:19:22,242 - mmdet - INFO - Epoch [4][1400/7033]	lr: 5.005e-05, eta: 9:33:42, time: 1.787, data_time: 0.087, memory: 18761, loss_cls: 0.0724, loss_bbox: 0.2089, d0.loss_cls: 0.1605, d0.loss_bbox: 0.3135, d1.loss_cls: 0.1028, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0870, d2.loss_bbox: 0.2242, d3.loss_cls: 0.0776, d3.loss_bbox: 0.2195, d4.loss_cls: 0.0737, d4.loss_bbox: 0.2116, loss: 1.9927, grad_norm: 50.6904
2025-06-10 20:20:51,463 - mmdet - INFO - Epoch [4][1450/7033]	lr: 5.005e-05, eta: 9:32:16, time: 1.784, data_time: 0.056, memory: 18761, loss_cls: 0.0738, loss_bbox: 0.2053, d0.loss_cls: 0.1576, d0.loss_bbox: 0.3207, d1.loss_cls: 0.1034, d1.loss_bbox: 0.2400, d2.loss_cls: 0.0852, d2.loss_bbox: 0.2233, d3.loss_cls: 0.0789, d3.loss_bbox: 0.2160, d4.loss_cls: 0.0749, d4.loss_bbox: 0.2085, loss: 1.9876, grad_norm: 23.9127
2025-06-10 20:22:25,102 - mmdet - INFO - Epoch [4][1500/7033]	lr: 5.005e-05, eta: 9:30:54, time: 1.872, data_time: 0.140, memory: 18761, loss_cls: 0.0706, loss_bbox: 0.2072, d0.loss_cls: 0.1508, d0.loss_bbox: 0.3205, d1.loss_cls: 0.0984, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0844, d2.loss_bbox: 0.2248, d3.loss_cls: 0.0750, d3.loss_bbox: 0.2192, d4.loss_cls: 0.0713, d4.loss_bbox: 0.2113, loss: 1.9745, grad_norm: 46.3296
2025-06-10 20:23:58,939 - mmdet - INFO - Epoch [4][1550/7033]	lr: 5.005e-05, eta: 9:29:32, time: 1.878, data_time: 0.097, memory: 18761, loss_cls: 0.0715, loss_bbox: 0.2102, d0.loss_cls: 0.1516, d0.loss_bbox: 0.3104, d1.loss_cls: 0.0993, d1.loss_bbox: 0.2418, d2.loss_cls: 0.0877, d2.loss_bbox: 0.2247, d3.loss_cls: 0.0770, d3.loss_bbox: 0.2203, d4.loss_cls: 0.0729, d4.loss_bbox: 0.2132, loss: 1.9805, grad_norm: 50.1518
2025-06-10 20:25:30,403 - mmdet - INFO - Epoch [4][1600/7033]	lr: 5.005e-05, eta: 9:28:08, time: 1.829, data_time: 0.058, memory: 18761, loss_cls: 0.0676, loss_bbox: 0.2102, d0.loss_cls: 0.1512, d0.loss_bbox: 0.3198, d1.loss_cls: 0.0992, d1.loss_bbox: 0.2412, d2.loss_cls: 0.0828, d2.loss_bbox: 0.2258, d3.loss_cls: 0.0737, d3.loss_bbox: 0.2211, d4.loss_cls: 0.0684, d4.loss_bbox: 0.2122, loss: 1.9732, grad_norm: 19.7750
2025-06-10 20:27:00,748 - mmdet - INFO - Epoch [4][1650/7033]	lr: 5.005e-05, eta: 9:26:43, time: 1.807, data_time: 0.060, memory: 18761, loss_cls: 0.0707, loss_bbox: 0.2054, d0.loss_cls: 0.1508, d0.loss_bbox: 0.3216, d1.loss_cls: 0.0991, d1.loss_bbox: 0.2434, d2.loss_cls: 0.0831, d2.loss_bbox: 0.2251, d3.loss_cls: 0.0761, d3.loss_bbox: 0.2173, d4.loss_cls: 0.0715, d4.loss_bbox: 0.2099, loss: 1.9739, grad_norm: 30.6791
2025-06-10 20:28:31,797 - mmdet - INFO - Epoch [4][1700/7033]	lr: 5.005e-05, eta: 9:25:19, time: 1.821, data_time: 0.100, memory: 18761, loss_cls: 0.0722, loss_bbox: 0.2166, d0.loss_cls: 0.1542, d0.loss_bbox: 0.3257, d1.loss_cls: 0.1024, d1.loss_bbox: 0.2477, d2.loss_cls: 0.0877, d2.loss_bbox: 0.2336, d3.loss_cls: 0.0785, d3.loss_bbox: 0.2270, d4.loss_cls: 0.0732, d4.loss_bbox: 0.2201, loss: 2.0390, grad_norm: 29.0122
2025-06-10 20:30:05,143 - mmdet - INFO - Epoch [4][1750/7033]	lr: 5.005e-05, eta: 9:23:56, time: 1.865, data_time: 0.119, memory: 18761, loss_cls: 0.0775, loss_bbox: 0.2075, d0.loss_cls: 0.1545, d0.loss_bbox: 0.3154, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2378, d2.loss_cls: 0.0916, d2.loss_bbox: 0.2212, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2184, d4.loss_cls: 0.0780, d4.loss_bbox: 0.2117, loss: 2.0002, grad_norm: 25.4534
2025-06-10 20:31:32,955 - mmdet - INFO - Epoch [4][1800/7033]	lr: 5.005e-05, eta: 9:22:29, time: 1.758, data_time: 0.078, memory: 18761, loss_cls: 0.0685, loss_bbox: 0.2049, d0.loss_cls: 0.1526, d0.loss_bbox: 0.3160, d1.loss_cls: 0.0975, d1.loss_bbox: 0.2384, d2.loss_cls: 0.0824, d2.loss_bbox: 0.2220, d3.loss_cls: 0.0724, d3.loss_bbox: 0.2157, d4.loss_cls: 0.0692, d4.loss_bbox: 0.2084, loss: 1.9482, grad_norm: 78.5343
2025-06-10 20:33:03,162 - mmdet - INFO - Epoch [4][1850/7033]	lr: 5.005e-05, eta: 9:21:04, time: 1.804, data_time: 0.065, memory: 18761, loss_cls: 0.0721, loss_bbox: 0.2091, d0.loss_cls: 0.1551, d0.loss_bbox: 0.3135, d1.loss_cls: 0.1024, d1.loss_bbox: 0.2379, d2.loss_cls: 0.0880, d2.loss_bbox: 0.2216, d3.loss_cls: 0.0785, d3.loss_bbox: 0.2180, d4.loss_cls: 0.0732, d4.loss_bbox: 0.2117, loss: 1.9810, grad_norm: 83.8026
2025-06-10 20:34:34,630 - mmdet - INFO - Epoch [4][1900/7033]	lr: 5.005e-05, eta: 9:19:40, time: 1.829, data_time: 0.078, memory: 18761, loss_cls: 0.0740, loss_bbox: 0.2151, d0.loss_cls: 0.1595, d0.loss_bbox: 0.3193, d1.loss_cls: 0.1068, d1.loss_bbox: 0.2454, d2.loss_cls: 0.0882, d2.loss_bbox: 0.2307, d3.loss_cls: 0.0800, d3.loss_bbox: 0.2264, d4.loss_cls: 0.0762, d4.loss_bbox: 0.2182, loss: 2.0398, grad_norm: 23.8087
2025-06-10 20:36:02,842 - mmdet - INFO - Epoch [4][1950/7033]	lr: 5.005e-05, eta: 9:18:13, time: 1.764, data_time: 0.084, memory: 18761, loss_cls: 0.0789, loss_bbox: 0.2170, d0.loss_cls: 0.1599, d0.loss_bbox: 0.3264, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0948, d2.loss_bbox: 0.2308, d3.loss_cls: 0.0847, d3.loss_bbox: 0.2282, d4.loss_cls: 0.0797, d4.loss_bbox: 0.2203, loss: 2.0753, grad_norm: 28.4091
2025-06-10 20:37:28,705 - mmdet - INFO - Epoch [4][2000/7033]	lr: 5.005e-05, eta: 9:16:45, time: 1.717, data_time: 0.085, memory: 18761, loss_cls: 0.0749, loss_bbox: 0.2108, d0.loss_cls: 0.1546, d0.loss_bbox: 0.3179, d1.loss_cls: 0.1044, d1.loss_bbox: 0.2440, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2274, d3.loss_cls: 0.0811, d3.loss_bbox: 0.2223, d4.loss_cls: 0.0764, d4.loss_bbox: 0.2141, loss: 2.0189, grad_norm: 31.2735
2025-06-10 20:38:58,727 - mmdet - INFO - Epoch [4][2050/7033]	lr: 5.005e-05, eta: 9:15:19, time: 1.799, data_time: 0.065, memory: 18761, loss_cls: 0.0716, loss_bbox: 0.2092, d0.loss_cls: 0.1536, d0.loss_bbox: 0.3254, d1.loss_cls: 0.1006, d1.loss_bbox: 0.2432, d2.loss_cls: 0.0863, d2.loss_bbox: 0.2277, d3.loss_cls: 0.0777, d3.loss_bbox: 0.2198, d4.loss_cls: 0.0734, d4.loss_bbox: 0.2131, loss: 2.0015, grad_norm: 27.6768
2025-06-10 20:40:28,423 - mmdet - INFO - Epoch [4][2100/7033]	lr: 5.005e-05, eta: 9:13:54, time: 1.795, data_time: 0.065, memory: 18761, loss_cls: 0.0728, loss_bbox: 0.2017, d0.loss_cls: 0.1531, d0.loss_bbox: 0.3093, d1.loss_cls: 0.0998, d1.loss_bbox: 0.2361, d2.loss_cls: 0.0874, d2.loss_bbox: 0.2208, d3.loss_cls: 0.0766, d3.loss_bbox: 0.2145, d4.loss_cls: 0.0734, d4.loss_bbox: 0.2057, loss: 1.9511, grad_norm: 36.7798
2025-06-10 20:41:55,945 - mmdet - INFO - Epoch [4][2150/7033]	lr: 5.005e-05, eta: 9:12:26, time: 1.750, data_time: 0.071, memory: 18761, loss_cls: 0.0848, loss_bbox: 0.2173, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3166, d1.loss_cls: 0.1126, d1.loss_bbox: 0.2474, d2.loss_cls: 0.0987, d2.loss_bbox: 0.2324, d3.loss_cls: 0.0905, d3.loss_bbox: 0.2276, d4.loss_cls: 0.0858, d4.loss_bbox: 0.2206, loss: 2.0998, grad_norm: 70.8133
2025-06-10 20:43:22,509 - mmdet - INFO - Epoch [4][2200/7033]	lr: 5.005e-05, eta: 9:10:58, time: 1.731, data_time: 0.061, memory: 18761, loss_cls: 0.0787, loss_bbox: 0.2106, d0.loss_cls: 0.1577, d0.loss_bbox: 0.3254, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2462, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2306, d3.loss_cls: 0.0847, d3.loss_bbox: 0.2229, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2143, loss: 2.0541, grad_norm: 29.6993
2025-06-10 20:44:52,619 - mmdet - INFO - Epoch [4][2250/7033]	lr: 5.005e-05, eta: 9:09:33, time: 1.802, data_time: 0.082, memory: 18761, loss_cls: 0.0738, loss_bbox: 0.2023, d0.loss_cls: 0.1496, d0.loss_bbox: 0.3026, d1.loss_cls: 0.1013, d1.loss_bbox: 0.2309, d2.loss_cls: 0.0854, d2.loss_bbox: 0.2186, d3.loss_cls: 0.0779, d3.loss_bbox: 0.2116, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2047, loss: 1.9333, grad_norm: 45.5290
2025-06-10 20:46:22,610 - mmdet - INFO - Epoch [4][2300/7033]	lr: 5.005e-05, eta: 9:08:07, time: 1.800, data_time: 0.090, memory: 18761, loss_cls: 0.0795, loss_bbox: 0.2144, d0.loss_cls: 0.1625, d0.loss_bbox: 0.3179, d1.loss_cls: 0.1079, d1.loss_bbox: 0.2458, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2306, d3.loss_cls: 0.0861, d3.loss_bbox: 0.2246, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2185, loss: 2.0634, grad_norm: 44.4738
2025-06-10 20:47:51,785 - mmdet - INFO - Epoch [4][2350/7033]	lr: 5.005e-05, eta: 9:06:41, time: 1.783, data_time: 0.078, memory: 18761, loss_cls: 0.0717, loss_bbox: 0.2029, d0.loss_cls: 0.1488, d0.loss_bbox: 0.3073, d1.loss_cls: 0.1002, d1.loss_bbox: 0.2341, d2.loss_cls: 0.0838, d2.loss_bbox: 0.2211, d3.loss_cls: 0.0759, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0730, d4.loss_bbox: 0.2059, loss: 1.9390, grad_norm: 35.2521
2025-06-10 20:49:24,676 - mmdet - INFO - Epoch [4][2400/7033]	lr: 5.005e-05, eta: 9:05:18, time: 1.858, data_time: 0.169, memory: 18761, loss_cls: 0.0783, loss_bbox: 0.2125, d0.loss_cls: 0.1544, d0.loss_bbox: 0.3183, d1.loss_cls: 0.1051, d1.loss_bbox: 0.2436, d2.loss_cls: 0.0905, d2.loss_bbox: 0.2302, d3.loss_cls: 0.0824, d3.loss_bbox: 0.2228, d4.loss_cls: 0.0789, d4.loss_bbox: 0.2161, loss: 2.0332, grad_norm: 26.8006
2025-06-10 20:50:55,972 - mmdet - INFO - Epoch [4][2450/7033]	lr: 5.005e-05, eta: 9:03:53, time: 1.826, data_time: 0.117, memory: 18761, loss_cls: 0.0758, loss_bbox: 0.2144, d0.loss_cls: 0.1553, d0.loss_bbox: 0.3200, d1.loss_cls: 0.1022, d1.loss_bbox: 0.2435, d2.loss_cls: 0.0887, d2.loss_bbox: 0.2300, d3.loss_cls: 0.0815, d3.loss_bbox: 0.2256, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2179, loss: 2.0315, grad_norm: 22.6159
2025-06-10 20:52:29,968 - mmdet - INFO - Epoch [4][2500/7033]	lr: 5.005e-05, eta: 9:02:31, time: 1.880, data_time: 0.071, memory: 18761, loss_cls: 0.0728, loss_bbox: 0.2153, d0.loss_cls: 0.1627, d0.loss_bbox: 0.3202, d1.loss_cls: 0.1026, d1.loss_bbox: 0.2455, d2.loss_cls: 0.0884, d2.loss_bbox: 0.2301, d3.loss_cls: 0.0803, d3.loss_bbox: 0.2268, d4.loss_cls: 0.0764, d4.loss_bbox: 0.2181, loss: 2.0391, grad_norm: 35.1666
2025-06-10 20:53:58,152 - mmdet - INFO - Epoch [4][2550/7033]	lr: 5.005e-05, eta: 9:01:04, time: 1.764, data_time: 0.081, memory: 18761, loss_cls: 0.0782, loss_bbox: 0.2122, d0.loss_cls: 0.1641, d0.loss_bbox: 0.3226, d1.loss_cls: 0.1096, d1.loss_bbox: 0.2447, d2.loss_cls: 0.0949, d2.loss_bbox: 0.2287, d3.loss_cls: 0.0871, d3.loss_bbox: 0.2224, d4.loss_cls: 0.0795, d4.loss_bbox: 0.2147, loss: 2.0586, grad_norm: 34.6648
2025-06-10 20:55:25,814 - mmdet - INFO - Epoch [4][2600/7033]	lr: 5.005e-05, eta: 8:59:37, time: 1.753, data_time: 0.059, memory: 18761, loss_cls: 0.0723, loss_bbox: 0.2162, d0.loss_cls: 0.1567, d0.loss_bbox: 0.3185, d1.loss_cls: 0.0994, d1.loss_bbox: 0.2458, d2.loss_cls: 0.0877, d2.loss_bbox: 0.2287, d3.loss_cls: 0.0787, d3.loss_bbox: 0.2250, d4.loss_cls: 0.0743, d4.loss_bbox: 0.2190, loss: 2.0223, grad_norm: 24.9609
2025-06-10 20:56:50,618 - mmdet - INFO - Epoch [4][2650/7033]	lr: 5.005e-05, eta: 8:58:07, time: 1.696, data_time: 0.064, memory: 18761, loss_cls: 0.0771, loss_bbox: 0.2127, d0.loss_cls: 0.1572, d0.loss_bbox: 0.3136, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2406, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2259, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2218, d4.loss_cls: 0.0778, d4.loss_bbox: 0.2157, loss: 2.0231, grad_norm: 28.6341
2025-06-10 20:58:17,882 - mmdet - INFO - Epoch [4][2700/7033]	lr: 5.005e-05, eta: 8:56:39, time: 1.745, data_time: 0.063, memory: 18761, loss_cls: 0.0747, loss_bbox: 0.2064, d0.loss_cls: 0.1524, d0.loss_bbox: 0.3116, d1.loss_cls: 0.1055, d1.loss_bbox: 0.2367, d2.loss_cls: 0.0901, d2.loss_bbox: 0.2217, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2163, d4.loss_cls: 0.0761, d4.loss_bbox: 0.2097, loss: 1.9825, grad_norm: 18.2519
2025-06-10 20:59:45,938 - mmdet - INFO - Epoch [4][2750/7033]	lr: 5.005e-05, eta: 8:55:12, time: 1.761, data_time: 0.065, memory: 18761, loss_cls: 0.0740, loss_bbox: 0.2033, d0.loss_cls: 0.1560, d0.loss_bbox: 0.3170, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2371, d2.loss_cls: 0.0906, d2.loss_bbox: 0.2209, d3.loss_cls: 0.0806, d3.loss_bbox: 0.2152, d4.loss_cls: 0.0743, d4.loss_bbox: 0.2084, loss: 1.9834, grad_norm: 21.5697
2025-06-10 21:01:11,094 - mmdet - INFO - Epoch [4][2800/7033]	lr: 5.005e-05, eta: 8:53:43, time: 1.703, data_time: 0.062, memory: 18761, loss_cls: 0.0773, loss_bbox: 0.2064, d0.loss_cls: 0.1519, d0.loss_bbox: 0.3209, d1.loss_cls: 0.1041, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0933, d2.loss_bbox: 0.2239, d3.loss_cls: 0.0820, d3.loss_bbox: 0.2188, d4.loss_cls: 0.0785, d4.loss_bbox: 0.2102, loss: 2.0127, grad_norm: 21.8646
2025-06-10 21:02:38,143 - mmdet - INFO - Epoch [4][2850/7033]	lr: 5.005e-05, eta: 8:52:15, time: 1.741, data_time: 0.060, memory: 18761, loss_cls: 0.0723, loss_bbox: 0.2166, d0.loss_cls: 0.1555, d0.loss_bbox: 0.3312, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2505, d2.loss_cls: 0.0905, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0785, d3.loss_bbox: 0.2261, d4.loss_cls: 0.0748, d4.loss_bbox: 0.2191, loss: 2.0525, grad_norm: 19.7847
2025-06-10 21:04:04,848 - mmdet - INFO - Epoch [4][2900/7033]	lr: 5.005e-05, eta: 8:50:47, time: 1.734, data_time: 0.083, memory: 18761, loss_cls: 0.0730, loss_bbox: 0.2072, d0.loss_cls: 0.1534, d0.loss_bbox: 0.3203, d1.loss_cls: 0.1019, d1.loss_bbox: 0.2434, d2.loss_cls: 0.0877, d2.loss_bbox: 0.2273, d3.loss_cls: 0.0782, d3.loss_bbox: 0.2205, d4.loss_cls: 0.0740, d4.loss_bbox: 0.2124, loss: 1.9992, grad_norm: 25.8703
2025-06-10 21:05:27,855 - mmdet - INFO - Epoch [4][2950/7033]	lr: 5.005e-05, eta: 8:49:16, time: 1.660, data_time: 0.054, memory: 18761, loss_cls: 0.0695, loss_bbox: 0.2038, d0.loss_cls: 0.1557, d0.loss_bbox: 0.3083, d1.loss_cls: 0.1007, d1.loss_bbox: 0.2327, d2.loss_cls: 0.0860, d2.loss_bbox: 0.2189, d3.loss_cls: 0.0738, d3.loss_bbox: 0.2136, d4.loss_cls: 0.0693, d4.loss_bbox: 0.2078, loss: 1.9402, grad_norm: 22.3746
2025-06-10 21:06:51,989 - mmdet - INFO - Epoch [4][3000/7033]	lr: 5.005e-05, eta: 8:47:46, time: 1.683, data_time: 0.081, memory: 18761, loss_cls: 0.0760, loss_bbox: 0.2155, d0.loss_cls: 0.1609, d0.loss_bbox: 0.3269, d1.loss_cls: 0.1081, d1.loss_bbox: 0.2492, d2.loss_cls: 0.0899, d2.loss_bbox: 0.2332, d3.loss_cls: 0.0822, d3.loss_bbox: 0.2272, d4.loss_cls: 0.0774, d4.loss_bbox: 0.2193, loss: 2.0658, grad_norm: 31.4746
2025-06-10 21:08:16,300 - mmdet - INFO - Epoch [4][3050/7033]	lr: 5.005e-05, eta: 8:46:16, time: 1.686, data_time: 0.072, memory: 18761, loss_cls: 0.0817, loss_bbox: 0.2152, d0.loss_cls: 0.1642, d0.loss_bbox: 0.3280, d1.loss_cls: 0.1147, d1.loss_bbox: 0.2478, d2.loss_cls: 0.0961, d2.loss_bbox: 0.2329, d3.loss_cls: 0.0863, d3.loss_bbox: 0.2267, d4.loss_cls: 0.0827, d4.loss_bbox: 0.2190, loss: 2.0954, grad_norm: 25.0217
2025-06-10 21:09:44,506 - mmdet - INFO - Epoch [4][3100/7033]	lr: 5.005e-05, eta: 8:44:49, time: 1.763, data_time: 0.082, memory: 18761, loss_cls: 0.0759, loss_bbox: 0.2103, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3221, d1.loss_cls: 0.1040, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0910, d2.loss_bbox: 0.2265, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2212, d4.loss_cls: 0.0769, d4.loss_bbox: 0.2134, loss: 2.0253, grad_norm: 54.2149
2025-06-10 21:11:12,592 - mmdet - INFO - Epoch [4][3150/7033]	lr: 5.005e-05, eta: 8:43:22, time: 1.763, data_time: 0.058, memory: 18761, loss_cls: 0.0746, loss_bbox: 0.2078, d0.loss_cls: 0.1573, d0.loss_bbox: 0.3217, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2430, d2.loss_cls: 0.0928, d2.loss_bbox: 0.2234, d3.loss_cls: 0.0793, d3.loss_bbox: 0.2186, d4.loss_cls: 0.0763, d4.loss_bbox: 0.2094, loss: 2.0125, grad_norm: 99.6727
2025-06-10 21:12:42,650 - mmdet - INFO - Epoch [4][3200/7033]	lr: 5.005e-05, eta: 8:41:57, time: 1.801, data_time: 0.069, memory: 18761, loss_cls: 0.0757, loss_bbox: 0.2139, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3176, d1.loss_cls: 0.1038, d1.loss_bbox: 0.2439, d2.loss_cls: 0.0902, d2.loss_bbox: 0.2315, d3.loss_cls: 0.0809, d3.loss_bbox: 0.2257, d4.loss_cls: 0.0774, d4.loss_bbox: 0.2169, loss: 2.0355, grad_norm: 28.7644
2025-06-10 21:14:09,241 - mmdet - INFO - Epoch [4][3250/7033]	lr: 5.005e-05, eta: 8:40:29, time: 1.732, data_time: 0.066, memory: 18761, loss_cls: 0.0795, loss_bbox: 0.2193, d0.loss_cls: 0.1566, d0.loss_bbox: 0.3361, d1.loss_cls: 0.1093, d1.loss_bbox: 0.2544, d2.loss_cls: 0.0942, d2.loss_bbox: 0.2385, d3.loss_cls: 0.0856, d3.loss_bbox: 0.2317, d4.loss_cls: 0.0813, d4.loss_bbox: 0.2231, loss: 2.1096, grad_norm: 27.6548
2025-06-10 21:15:41,840 - mmdet - INFO - Epoch [4][3300/7033]	lr: 5.005e-05, eta: 8:39:05, time: 1.852, data_time: 0.104, memory: 18761, loss_cls: 0.0718, loss_bbox: 0.1998, d0.loss_cls: 0.1588, d0.loss_bbox: 0.3105, d1.loss_cls: 0.1063, d1.loss_bbox: 0.2327, d2.loss_cls: 0.0906, d2.loss_bbox: 0.2171, d3.loss_cls: 0.0796, d3.loss_bbox: 0.2120, d4.loss_cls: 0.0739, d4.loss_bbox: 0.2032, loss: 1.9563, grad_norm: 28.3938
2025-06-10 21:17:07,461 - mmdet - INFO - Epoch [4][3350/7033]	lr: 5.005e-05, eta: 8:37:36, time: 1.712, data_time: 0.066, memory: 18761, loss_cls: 0.0797, loss_bbox: 0.2152, d0.loss_cls: 0.1620, d0.loss_bbox: 0.3245, d1.loss_cls: 0.1125, d1.loss_bbox: 0.2481, d2.loss_cls: 0.0986, d2.loss_bbox: 0.2301, d3.loss_cls: 0.0877, d3.loss_bbox: 0.2250, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2177, loss: 2.0830, grad_norm: 26.2229
2025-06-10 21:18:32,527 - mmdet - INFO - Epoch [4][3400/7033]	lr: 5.005e-05, eta: 8:36:07, time: 1.701, data_time: 0.066, memory: 18761, loss_cls: 0.0708, loss_bbox: 0.2127, d0.loss_cls: 0.1531, d0.loss_bbox: 0.3214, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2437, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0788, d3.loss_bbox: 0.2224, d4.loss_cls: 0.0729, d4.loss_bbox: 0.2159, loss: 2.0141, grad_norm: 61.4585
2025-06-10 21:19:59,165 - mmdet - INFO - Epoch [4][3450/7033]	lr: 5.005e-05, eta: 8:34:39, time: 1.733, data_time: 0.064, memory: 18761, loss_cls: 0.0777, loss_bbox: 0.2154, d0.loss_cls: 0.1569, d0.loss_bbox: 0.3281, d1.loss_cls: 0.1073, d1.loss_bbox: 0.2484, d2.loss_cls: 0.0904, d2.loss_bbox: 0.2318, d3.loss_cls: 0.0814, d3.loss_bbox: 0.2283, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2199, loss: 2.0636, grad_norm: 40.8508
2025-06-10 21:21:24,355 - mmdet - INFO - Epoch [4][3500/7033]	lr: 5.005e-05, eta: 8:33:10, time: 1.704, data_time: 0.063, memory: 18761, loss_cls: 0.0767, loss_bbox: 0.2104, d0.loss_cls: 0.1552, d0.loss_bbox: 0.3157, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2401, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2246, d3.loss_cls: 0.0831, d3.loss_bbox: 0.2196, d4.loss_cls: 0.0789, d4.loss_bbox: 0.2126, loss: 2.0148, grad_norm: 29.6480
2025-06-10 21:22:55,814 - mmdet - INFO - Epoch [4][3550/7033]	lr: 5.005e-05, eta: 8:31:45, time: 1.829, data_time: 0.084, memory: 18761, loss_cls: 0.0816, loss_bbox: 0.2184, d0.loss_cls: 0.1580, d0.loss_bbox: 0.3363, d1.loss_cls: 0.1119, d1.loss_bbox: 0.2542, d2.loss_cls: 0.1030, d2.loss_bbox: 0.2362, d3.loss_cls: 0.0904, d3.loss_bbox: 0.2300, d4.loss_cls: 0.0841, d4.loss_bbox: 0.2214, loss: 2.1256, grad_norm: 29.0487
2025-06-10 21:24:25,920 - mmdet - INFO - Epoch [4][3600/7033]	lr: 5.005e-05, eta: 8:30:19, time: 1.802, data_time: 0.128, memory: 18761, loss_cls: 0.0856, loss_bbox: 0.2219, d0.loss_cls: 0.1621, d0.loss_bbox: 0.3266, d1.loss_cls: 0.1154, d1.loss_bbox: 0.2549, d2.loss_cls: 0.1030, d2.loss_bbox: 0.2402, d3.loss_cls: 0.0914, d3.loss_bbox: 0.2341, d4.loss_cls: 0.0868, d4.loss_bbox: 0.2262, loss: 2.1482, grad_norm: 52.0620
2025-06-10 21:25:56,253 - mmdet - INFO - Epoch [4][3650/7033]	lr: 5.005e-05, eta: 8:28:54, time: 1.807, data_time: 0.072, memory: 18761, loss_cls: 0.0765, loss_bbox: 0.2107, d0.loss_cls: 0.1584, d0.loss_bbox: 0.3193, d1.loss_cls: 0.1039, d1.loss_bbox: 0.2468, d2.loss_cls: 0.0902, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0819, d3.loss_bbox: 0.2233, d4.loss_cls: 0.0772, d4.loss_bbox: 0.2144, loss: 2.0340, grad_norm: 33.2845
2025-06-10 21:27:23,181 - mmdet - INFO - Epoch [4][3700/7033]	lr: 5.005e-05, eta: 8:27:26, time: 1.739, data_time: 0.064, memory: 18761, loss_cls: 0.0780, loss_bbox: 0.2161, d0.loss_cls: 0.1573, d0.loss_bbox: 0.3175, d1.loss_cls: 0.1069, d1.loss_bbox: 0.2462, d2.loss_cls: 0.0965, d2.loss_bbox: 0.2327, d3.loss_cls: 0.0825, d3.loss_bbox: 0.2294, d4.loss_cls: 0.0781, d4.loss_bbox: 0.2213, loss: 2.0623, grad_norm: 60.6356
2025-06-10 21:28:51,377 - mmdet - INFO - Epoch [4][3750/7033]	lr: 5.005e-05, eta: 8:25:59, time: 1.764, data_time: 0.061, memory: 18761, loss_cls: 0.0731, loss_bbox: 0.2045, d0.loss_cls: 0.1563, d0.loss_bbox: 0.3151, d1.loss_cls: 0.1049, d1.loss_bbox: 0.2372, d2.loss_cls: 0.0910, d2.loss_bbox: 0.2234, d3.loss_cls: 0.0790, d3.loss_bbox: 0.2169, d4.loss_cls: 0.0752, d4.loss_bbox: 0.2088, loss: 1.9856, grad_norm: 33.1933
2025-06-10 21:30:20,802 - mmdet - INFO - Epoch [4][3800/7033]	lr: 5.005e-05, eta: 8:24:33, time: 1.789, data_time: 0.083, memory: 18761, loss_cls: 0.0757, loss_bbox: 0.2112, d0.loss_cls: 0.1559, d0.loss_bbox: 0.3152, d1.loss_cls: 0.1050, d1.loss_bbox: 0.2415, d2.loss_cls: 0.0897, d2.loss_bbox: 0.2276, d3.loss_cls: 0.0815, d3.loss_bbox: 0.2224, d4.loss_cls: 0.0767, d4.loss_bbox: 0.2154, loss: 2.0177, grad_norm: 37.8568
2025-06-10 21:31:51,686 - mmdet - INFO - Epoch [4][3850/7033]	lr: 5.005e-05, eta: 8:23:08, time: 1.818, data_time: 0.083, memory: 18761, loss_cls: 0.0687, loss_bbox: 0.2032, d0.loss_cls: 0.1445, d0.loss_bbox: 0.2992, d1.loss_cls: 0.0963, d1.loss_bbox: 0.2311, d2.loss_cls: 0.0829, d2.loss_bbox: 0.2177, d3.loss_cls: 0.0752, d3.loss_bbox: 0.2135, d4.loss_cls: 0.0698, d4.loss_bbox: 0.2057, loss: 1.9078, grad_norm: 39.7855
2025-06-10 21:33:20,131 - mmdet - INFO - Epoch [4][3900/7033]	lr: 5.005e-05, eta: 8:21:41, time: 1.769, data_time: 0.064, memory: 18761, loss_cls: 0.0732, loss_bbox: 0.2047, d0.loss_cls: 0.1561, d0.loss_bbox: 0.3122, d1.loss_cls: 0.1038, d1.loss_bbox: 0.2382, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2233, d3.loss_cls: 0.0795, d3.loss_bbox: 0.2178, d4.loss_cls: 0.0744, d4.loss_bbox: 0.2092, loss: 1.9809, grad_norm: 17.5963
2025-06-10 21:34:49,052 - mmdet - INFO - Epoch [4][3950/7033]	lr: 5.005e-05, eta: 8:20:14, time: 1.778, data_time: 0.060, memory: 18761, loss_cls: 0.0788, loss_bbox: 0.2127, d0.loss_cls: 0.1588, d0.loss_bbox: 0.3124, d1.loss_cls: 0.1100, d1.loss_bbox: 0.2424, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2295, d3.loss_cls: 0.0855, d3.loss_bbox: 0.2242, d4.loss_cls: 0.0799, d4.loss_bbox: 0.2154, loss: 2.0432, grad_norm: 35.6218
2025-06-10 21:36:25,154 - mmdet - INFO - Epoch [4][4000/7033]	lr: 5.005e-05, eta: 8:18:53, time: 1.922, data_time: 0.232, memory: 18761, loss_cls: 0.0823, loss_bbox: 0.2163, d0.loss_cls: 0.1619, d0.loss_bbox: 0.3312, d1.loss_cls: 0.1143, d1.loss_bbox: 0.2501, d2.loss_cls: 0.0990, d2.loss_bbox: 0.2340, d3.loss_cls: 0.0897, d3.loss_bbox: 0.2273, d4.loss_cls: 0.0841, d4.loss_bbox: 0.2183, loss: 2.1085, grad_norm: 20.2770
2025-06-10 21:37:53,316 - mmdet - INFO - Epoch [4][4050/7033]	lr: 5.005e-05, eta: 8:17:25, time: 1.762, data_time: 0.080, memory: 18761, loss_cls: 0.0693, loss_bbox: 0.2125, d0.loss_cls: 0.1510, d0.loss_bbox: 0.3193, d1.loss_cls: 0.0988, d1.loss_bbox: 0.2452, d2.loss_cls: 0.0842, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0759, d3.loss_bbox: 0.2207, d4.loss_cls: 0.0709, d4.loss_bbox: 0.2148, loss: 1.9907, grad_norm: 28.5524
2025-06-10 21:39:18,008 - mmdet - INFO - Epoch [4][4100/7033]	lr: 5.005e-05, eta: 8:15:56, time: 1.695, data_time: 0.069, memory: 18761, loss_cls: 0.0759, loss_bbox: 0.2171, d0.loss_cls: 0.1623, d0.loss_bbox: 0.3212, d1.loss_cls: 0.1072, d1.loss_bbox: 0.2486, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2333, d3.loss_cls: 0.0808, d3.loss_bbox: 0.2289, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2188, loss: 2.0669, grad_norm: 64.7641
2025-06-10 21:40:49,206 - mmdet - INFO - Epoch [4][4150/7033]	lr: 5.005e-05, eta: 8:14:31, time: 1.824, data_time: 0.082, memory: 18761, loss_cls: 0.0784, loss_bbox: 0.2096, d0.loss_cls: 0.1611, d0.loss_bbox: 0.3084, d1.loss_cls: 0.1110, d1.loss_bbox: 0.2411, d2.loss_cls: 0.0970, d2.loss_bbox: 0.2248, d3.loss_cls: 0.0849, d3.loss_bbox: 0.2196, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2127, loss: 2.0277, grad_norm: 29.5576
2025-06-10 21:42:25,221 - mmdet - INFO - Epoch [4][4200/7033]	lr: 5.005e-05, eta: 8:13:09, time: 1.920, data_time: 0.209, memory: 18761, loss_cls: 0.0714, loss_bbox: 0.2152, d0.loss_cls: 0.1552, d0.loss_bbox: 0.3268, d1.loss_cls: 0.1006, d1.loss_bbox: 0.2505, d2.loss_cls: 0.0844, d2.loss_bbox: 0.2319, d3.loss_cls: 0.0744, d3.loss_bbox: 0.2266, d4.loss_cls: 0.0715, d4.loss_bbox: 0.2202, loss: 2.0288, grad_norm: 30.2690
2025-06-10 21:43:52,247 - mmdet - INFO - Epoch [4][4250/7033]	lr: 5.005e-05, eta: 8:11:41, time: 1.741, data_time: 0.115, memory: 18761, loss_cls: 0.0786, loss_bbox: 0.2128, d0.loss_cls: 0.1657, d0.loss_bbox: 0.3234, d1.loss_cls: 0.1076, d1.loss_bbox: 0.2448, d2.loss_cls: 0.0924, d2.loss_bbox: 0.2270, d3.loss_cls: 0.0824, d3.loss_bbox: 0.2212, d4.loss_cls: 0.0808, d4.loss_bbox: 0.2143, loss: 2.0510, grad_norm: 31.4353
2025-06-10 21:45:20,602 - mmdet - INFO - Epoch [4][4300/7033]	lr: 5.005e-05, eta: 8:10:14, time: 1.767, data_time: 0.086, memory: 18761, loss_cls: 0.0792, loss_bbox: 0.2221, d0.loss_cls: 0.1606, d0.loss_bbox: 0.3249, d1.loss_cls: 0.1087, d1.loss_bbox: 0.2538, d2.loss_cls: 0.0954, d2.loss_bbox: 0.2366, d3.loss_cls: 0.0857, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0806, d4.loss_bbox: 0.2246, loss: 2.1048, grad_norm: 42.5085
2025-06-10 21:46:57,009 - mmdet - INFO - Epoch [4][4350/7033]	lr: 5.005e-05, eta: 8:08:52, time: 1.927, data_time: 0.108, memory: 18761, loss_cls: 0.0761, loss_bbox: 0.2150, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3232, d1.loss_cls: 0.1029, d1.loss_bbox: 0.2466, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2303, d3.loss_cls: 0.0802, d3.loss_bbox: 0.2250, d4.loss_cls: 0.0775, d4.loss_bbox: 0.2177, loss: 2.0421, grad_norm: 40.4773
2025-06-10 21:48:24,102 - mmdet - INFO - Epoch [4][4400/7033]	lr: 5.005e-05, eta: 8:07:25, time: 1.743, data_time: 0.082, memory: 18761, loss_cls: 0.0824, loss_bbox: 0.2211, d0.loss_cls: 0.1609, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1074, d1.loss_bbox: 0.2557, d2.loss_cls: 0.0917, d2.loss_bbox: 0.2378, d3.loss_cls: 0.0849, d3.loss_bbox: 0.2339, d4.loss_cls: 0.0832, d4.loss_bbox: 0.2248, loss: 2.1170, grad_norm: 27.1514
2025-06-10 21:49:52,856 - mmdet - INFO - Epoch [4][4450/7033]	lr: 5.005e-05, eta: 8:05:58, time: 1.775, data_time: 0.067, memory: 18761, loss_cls: 0.0717, loss_bbox: 0.2003, d0.loss_cls: 0.1511, d0.loss_bbox: 0.3033, d1.loss_cls: 0.0981, d1.loss_bbox: 0.2315, d2.loss_cls: 0.0814, d2.loss_bbox: 0.2163, d3.loss_cls: 0.0751, d3.loss_bbox: 0.2109, d4.loss_cls: 0.0734, d4.loss_bbox: 0.2028, loss: 1.9158, grad_norm: 23.4993
2025-06-10 21:51:23,221 - mmdet - INFO - Epoch [4][4500/7033]	lr: 5.005e-05, eta: 8:04:32, time: 1.808, data_time: 0.068, memory: 18761, loss_cls: 0.0739, loss_bbox: 0.2060, d0.loss_cls: 0.1524, d0.loss_bbox: 0.3076, d1.loss_cls: 0.1005, d1.loss_bbox: 0.2376, d2.loss_cls: 0.0849, d2.loss_bbox: 0.2226, d3.loss_cls: 0.0778, d3.loss_bbox: 0.2174, d4.loss_cls: 0.0755, d4.loss_bbox: 0.2091, loss: 1.9653, grad_norm: 25.4868
2025-06-10 21:52:52,897 - mmdet - INFO - Epoch [4][4550/7033]	lr: 5.005e-05, eta: 8:03:06, time: 1.793, data_time: 0.060, memory: 18761, loss_cls: 0.0774, loss_bbox: 0.2126, d0.loss_cls: 0.1609, d0.loss_bbox: 0.3176, d1.loss_cls: 0.1047, d1.loss_bbox: 0.2425, d2.loss_cls: 0.0914, d2.loss_bbox: 0.2267, d3.loss_cls: 0.0836, d3.loss_bbox: 0.2211, d4.loss_cls: 0.0790, d4.loss_bbox: 0.2145, loss: 2.0321, grad_norm: 27.2143
2025-06-10 21:54:23,765 - mmdet - INFO - Epoch [4][4600/7033]	lr: 5.005e-05, eta: 8:01:40, time: 1.817, data_time: 0.106, memory: 18761, loss_cls: 0.0790, loss_bbox: 0.2216, d0.loss_cls: 0.1632, d0.loss_bbox: 0.3309, d1.loss_cls: 0.1084, d1.loss_bbox: 0.2576, d2.loss_cls: 0.0945, d2.loss_bbox: 0.2390, d3.loss_cls: 0.0839, d3.loss_bbox: 0.2345, d4.loss_cls: 0.0804, d4.loss_bbox: 0.2252, loss: 2.1182, grad_norm: 33.8850
2025-06-10 21:55:49,747 - mmdet - INFO - Epoch [4][4650/7033]	lr: 5.005e-05, eta: 8:00:12, time: 1.719, data_time: 0.055, memory: 18761, loss_cls: 0.0758, loss_bbox: 0.2074, d0.loss_cls: 0.1583, d0.loss_bbox: 0.3123, d1.loss_cls: 0.1033, d1.loss_bbox: 0.2408, d2.loss_cls: 0.0894, d2.loss_bbox: 0.2228, d3.loss_cls: 0.0800, d3.loss_bbox: 0.2172, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2113, loss: 1.9953, grad_norm: 18.5670
2025-06-10 21:57:17,904 - mmdet - INFO - Epoch [4][4700/7033]	lr: 5.005e-05, eta: 7:58:45, time: 1.763, data_time: 0.060, memory: 18761, loss_cls: 0.0760, loss_bbox: 0.2132, d0.loss_cls: 0.1584, d0.loss_bbox: 0.3236, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2479, d2.loss_cls: 0.0934, d2.loss_bbox: 0.2295, d3.loss_cls: 0.0835, d3.loss_bbox: 0.2231, d4.loss_cls: 0.0785, d4.loss_bbox: 0.2158, loss: 2.0481, grad_norm: 38.4971
2025-06-10 21:59:09,369 - mmdet - INFO - Epoch [4][4750/7033]	lr: 5.005e-05, eta: 7:57:32, time: 2.229, data_time: 0.064, memory: 18761, loss_cls: 0.0785, loss_bbox: 0.2136, d0.loss_cls: 0.1650, d0.loss_bbox: 0.3202, d1.loss_cls: 0.1095, d1.loss_bbox: 0.2477, d2.loss_cls: 0.0952, d2.loss_bbox: 0.2275, d3.loss_cls: 0.0824, d3.loss_bbox: 0.2242, d4.loss_cls: 0.0784, d4.loss_bbox: 0.2168, loss: 2.0590, grad_norm: 91.4230
2025-06-10 22:00:35,891 - mmdet - INFO - Epoch [4][4800/7033]	lr: 5.005e-05, eta: 7:56:04, time: 1.730, data_time: 0.074, memory: 18761, loss_cls: 0.0769, loss_bbox: 0.2132, d0.loss_cls: 0.1588, d0.loss_bbox: 0.3142, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2421, d2.loss_cls: 0.0913, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2226, d4.loss_cls: 0.0790, d4.loss_bbox: 0.2168, loss: 2.0308, grad_norm: 35.8010
2025-06-10 22:02:06,784 - mmdet - INFO - Epoch [4][4850/7033]	lr: 5.005e-05, eta: 7:54:38, time: 1.818, data_time: 0.065, memory: 18761, loss_cls: 0.0733, loss_bbox: 0.2047, d0.loss_cls: 0.1502, d0.loss_bbox: 0.3123, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2365, d2.loss_cls: 0.0874, d2.loss_bbox: 0.2205, d3.loss_cls: 0.0782, d3.loss_bbox: 0.2136, d4.loss_cls: 0.0748, d4.loss_bbox: 0.2071, loss: 1.9603, grad_norm: 30.0319
2025-06-10 22:03:37,231 - mmdet - INFO - Epoch [4][4900/7033]	lr: 5.005e-05, eta: 7:53:12, time: 1.809, data_time: 0.059, memory: 18761, loss_cls: 0.0809, loss_bbox: 0.2135, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3227, d1.loss_cls: 0.1076, d1.loss_bbox: 0.2500, d2.loss_cls: 0.0963, d2.loss_bbox: 0.2309, d3.loss_cls: 0.0859, d3.loss_bbox: 0.2253, d4.loss_cls: 0.0831, d4.loss_bbox: 0.2166, loss: 2.0762, grad_norm: 34.3574
2025-06-10 22:05:05,579 - mmdet - INFO - Epoch [4][4950/7033]	lr: 5.005e-05, eta: 7:51:45, time: 1.767, data_time: 0.061, memory: 18761, loss_cls: 0.0678, loss_bbox: 0.2094, d0.loss_cls: 0.1566, d0.loss_bbox: 0.3224, d1.loss_cls: 0.0994, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0832, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0736, d3.loss_bbox: 0.2220, d4.loss_cls: 0.0692, d4.loss_bbox: 0.2140, loss: 1.9909, grad_norm: 28.2587
2025-06-10 22:06:31,320 - mmdet - INFO - Epoch [4][5000/7033]	lr: 5.005e-05, eta: 7:50:16, time: 1.715, data_time: 0.068, memory: 18761, loss_cls: 0.0789, loss_bbox: 0.2129, d0.loss_cls: 0.1612, d0.loss_bbox: 0.3171, d1.loss_cls: 0.1103, d1.loss_bbox: 0.2423, d2.loss_cls: 0.0933, d2.loss_bbox: 0.2286, d3.loss_cls: 0.0844, d3.loss_bbox: 0.2245, d4.loss_cls: 0.0801, d4.loss_bbox: 0.2164, loss: 2.0499, grad_norm: 27.8816
2025-06-10 22:07:58,847 - mmdet - INFO - Epoch [4][5050/7033]	lr: 5.005e-05, eta: 7:48:49, time: 1.751, data_time: 0.065, memory: 18761, loss_cls: 0.0721, loss_bbox: 0.2051, d0.loss_cls: 0.1524, d0.loss_bbox: 0.3086, d1.loss_cls: 0.1014, d1.loss_bbox: 0.2360, d2.loss_cls: 0.0865, d2.loss_bbox: 0.2205, d3.loss_cls: 0.0780, d3.loss_bbox: 0.2137, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2062, loss: 1.9552, grad_norm: 24.9811
2025-06-10 22:09:27,909 - mmdet - INFO - Epoch [4][5100/7033]	lr: 5.005e-05, eta: 7:47:22, time: 1.781, data_time: 0.057, memory: 18761, loss_cls: 0.0876, loss_bbox: 0.2243, d0.loss_cls: 0.1724, d0.loss_bbox: 0.3335, d1.loss_cls: 0.1149, d1.loss_bbox: 0.2558, d2.loss_cls: 0.0983, d2.loss_bbox: 0.2402, d3.loss_cls: 0.0907, d3.loss_bbox: 0.2352, d4.loss_cls: 0.0879, d4.loss_bbox: 0.2278, loss: 2.1687, grad_norm: 31.7293
2025-06-10 22:10:54,619 - mmdet - INFO - Epoch [4][5150/7033]	lr: 5.005e-05, eta: 7:45:54, time: 1.734, data_time: 0.056, memory: 18761, loss_cls: 0.0729, loss_bbox: 0.2065, d0.loss_cls: 0.1622, d0.loss_bbox: 0.3163, d1.loss_cls: 0.1047, d1.loss_bbox: 0.2381, d2.loss_cls: 0.0894, d2.loss_bbox: 0.2228, d3.loss_cls: 0.0801, d3.loss_bbox: 0.2178, d4.loss_cls: 0.0742, d4.loss_bbox: 0.2092, loss: 1.9942, grad_norm: 22.2601
2025-06-10 22:12:23,101 - mmdet - INFO - Epoch [4][5200/7033]	lr: 5.005e-05, eta: 7:44:26, time: 1.770, data_time: 0.050, memory: 18761, loss_cls: 0.0748, loss_bbox: 0.2036, d0.loss_cls: 0.1652, d0.loss_bbox: 0.3081, d1.loss_cls: 0.1050, d1.loss_bbox: 0.2304, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2166, d3.loss_cls: 0.0795, d3.loss_bbox: 0.2130, d4.loss_cls: 0.0749, d4.loss_bbox: 0.2064, loss: 1.9656, grad_norm: 18.7673
2025-06-10 22:13:48,079 - mmdet - INFO - Epoch [4][5250/7033]	lr: 5.005e-05, eta: 7:42:57, time: 1.700, data_time: 0.054, memory: 18761, loss_cls: 0.0706, loss_bbox: 0.1993, d0.loss_cls: 0.1560, d0.loss_bbox: 0.2987, d1.loss_cls: 0.1019, d1.loss_bbox: 0.2266, d2.loss_cls: 0.0828, d2.loss_bbox: 0.2132, d3.loss_cls: 0.0754, d3.loss_bbox: 0.2087, d4.loss_cls: 0.0710, d4.loss_bbox: 0.2029, loss: 1.9068, grad_norm: 23.6339
2025-06-10 22:15:13,811 - mmdet - INFO - Epoch [4][5300/7033]	lr: 5.005e-05, eta: 7:41:28, time: 1.713, data_time: 0.049, memory: 18761, loss_cls: 0.0777, loss_bbox: 0.2077, d0.loss_cls: 0.1505, d0.loss_bbox: 0.3101, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2382, d2.loss_cls: 0.0887, d2.loss_bbox: 0.2225, d3.loss_cls: 0.0809, d3.loss_bbox: 0.2182, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2111, loss: 1.9877, grad_norm: 29.0609
2025-06-10 22:16:40,279 - mmdet - INFO - Epoch [4][5350/7033]	lr: 5.005e-05, eta: 7:40:00, time: 1.731, data_time: 0.056, memory: 18761, loss_cls: 0.0701, loss_bbox: 0.2050, d0.loss_cls: 0.1477, d0.loss_bbox: 0.3154, d1.loss_cls: 0.0988, d1.loss_bbox: 0.2398, d2.loss_cls: 0.0847, d2.loss_bbox: 0.2229, d3.loss_cls: 0.0756, d3.loss_bbox: 0.2165, d4.loss_cls: 0.0719, d4.loss_bbox: 0.2078, loss: 1.9563, grad_norm: 54.0736
2025-06-10 22:18:06,276 - mmdet - INFO - Epoch [4][5400/7033]	lr: 5.005e-05, eta: 7:38:32, time: 1.720, data_time: 0.053, memory: 18761, loss_cls: 0.0781, loss_bbox: 0.2098, d0.loss_cls: 0.1545, d0.loss_bbox: 0.3145, d1.loss_cls: 0.1088, d1.loss_bbox: 0.2387, d2.loss_cls: 0.0927, d2.loss_bbox: 0.2230, d3.loss_cls: 0.0846, d3.loss_bbox: 0.2185, d4.loss_cls: 0.0813, d4.loss_bbox: 0.2117, loss: 2.0165, grad_norm: 66.7863
2025-06-10 22:19:34,485 - mmdet - INFO - Epoch [4][5450/7033]	lr: 5.005e-05, eta: 7:37:04, time: 1.764, data_time: 0.054, memory: 18761, loss_cls: 0.0713, loss_bbox: 0.1996, d0.loss_cls: 0.1515, d0.loss_bbox: 0.3067, d1.loss_cls: 0.0999, d1.loss_bbox: 0.2271, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2121, d3.loss_cls: 0.0764, d3.loss_bbox: 0.2080, d4.loss_cls: 0.0722, d4.loss_bbox: 0.2022, loss: 1.9130, grad_norm: 34.6698
2025-06-10 22:21:02,527 - mmdet - INFO - Epoch [4][5500/7033]	lr: 5.005e-05, eta: 7:35:37, time: 1.761, data_time: 0.061, memory: 18761, loss_cls: 0.0754, loss_bbox: 0.2053, d0.loss_cls: 0.1557, d0.loss_bbox: 0.3126, d1.loss_cls: 0.1037, d1.loss_bbox: 0.2381, d2.loss_cls: 0.0889, d2.loss_bbox: 0.2222, d3.loss_cls: 0.0810, d3.loss_bbox: 0.2167, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2083, loss: 1.9851, grad_norm: 26.7511
2025-06-10 22:22:28,350 - mmdet - INFO - Epoch [4][5550/7033]	lr: 5.005e-05, eta: 7:34:08, time: 1.716, data_time: 0.057, memory: 18761, loss_cls: 0.0750, loss_bbox: 0.2050, d0.loss_cls: 0.1536, d0.loss_bbox: 0.3112, d1.loss_cls: 0.1031, d1.loss_bbox: 0.2380, d2.loss_cls: 0.0877, d2.loss_bbox: 0.2208, d3.loss_cls: 0.0791, d3.loss_bbox: 0.2163, d4.loss_cls: 0.0754, d4.loss_bbox: 0.2087, loss: 1.9739, grad_norm: 27.2132
2025-06-10 22:23:57,156 - mmdet - INFO - Epoch [4][5600/7033]	lr: 5.005e-05, eta: 7:32:41, time: 1.776, data_time: 0.056, memory: 18761, loss_cls: 0.0678, loss_bbox: 0.2003, d0.loss_cls: 0.1490, d0.loss_bbox: 0.3037, d1.loss_cls: 0.0967, d1.loss_bbox: 0.2294, d2.loss_cls: 0.0824, d2.loss_bbox: 0.2144, d3.loss_cls: 0.0732, d3.loss_bbox: 0.2101, d4.loss_cls: 0.0701, d4.loss_bbox: 0.2022, loss: 1.8992, grad_norm: 33.1213
2025-06-10 22:25:22,187 - mmdet - INFO - Epoch [4][5650/7033]	lr: 5.005e-05, eta: 7:31:12, time: 1.701, data_time: 0.063, memory: 18761, loss_cls: 0.0779, loss_bbox: 0.2140, d0.loss_cls: 0.1525, d0.loss_bbox: 0.3238, d1.loss_cls: 0.1073, d1.loss_bbox: 0.2440, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2303, d3.loss_cls: 0.0826, d3.loss_bbox: 0.2231, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2173, loss: 2.0419, grad_norm: 50.2977
2025-06-10 22:26:48,384 - mmdet - INFO - Epoch [4][5700/7033]	lr: 5.005e-05, eta: 7:29:44, time: 1.724, data_time: 0.060, memory: 18761, loss_cls: 0.0807, loss_bbox: 0.2102, d0.loss_cls: 0.1578, d0.loss_bbox: 0.3205, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2481, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2306, d3.loss_cls: 0.0873, d3.loss_bbox: 0.2213, d4.loss_cls: 0.0829, d4.loss_bbox: 0.2133, loss: 2.0521, grad_norm: 34.4577
2025-06-10 22:28:15,349 - mmdet - INFO - Epoch [4][5750/7033]	lr: 5.005e-05, eta: 7:28:16, time: 1.739, data_time: 0.065, memory: 18761, loss_cls: 0.0729, loss_bbox: 0.2125, d0.loss_cls: 0.1560, d0.loss_bbox: 0.3241, d1.loss_cls: 0.0987, d1.loss_bbox: 0.2482, d2.loss_cls: 0.0855, d2.loss_bbox: 0.2297, d3.loss_cls: 0.0783, d3.loss_bbox: 0.2234, d4.loss_cls: 0.0738, d4.loss_bbox: 0.2156, loss: 2.0188, grad_norm: 54.2363
2025-06-10 22:29:41,706 - mmdet - INFO - Epoch [4][5800/7033]	lr: 5.005e-05, eta: 7:26:47, time: 1.727, data_time: 0.059, memory: 18761, loss_cls: 0.0797, loss_bbox: 0.2030, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3125, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2390, d2.loss_cls: 0.0911, d2.loss_bbox: 0.2229, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2155, d4.loss_cls: 0.0798, d4.loss_bbox: 0.2077, loss: 2.0002, grad_norm: 32.9233
2025-06-10 22:31:10,617 - mmdet - INFO - Epoch [4][5850/7033]	lr: 5.005e-05, eta: 7:25:20, time: 1.778, data_time: 0.056, memory: 18761, loss_cls: 0.0806, loss_bbox: 0.2170, d0.loss_cls: 0.1584, d0.loss_bbox: 0.3275, d1.loss_cls: 0.1092, d1.loss_bbox: 0.2536, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2353, d3.loss_cls: 0.0855, d3.loss_bbox: 0.2270, d4.loss_cls: 0.0824, d4.loss_bbox: 0.2198, loss: 2.0899, grad_norm: 27.1515
2025-06-10 22:32:38,003 - mmdet - INFO - Epoch [4][5900/7033]	lr: 5.005e-05, eta: 7:23:53, time: 1.748, data_time: 0.059, memory: 18761, loss_cls: 0.0763, loss_bbox: 0.2091, d0.loss_cls: 0.1578, d0.loss_bbox: 0.3132, d1.loss_cls: 0.1068, d1.loss_bbox: 0.2383, d2.loss_cls: 0.0902, d2.loss_bbox: 0.2242, d3.loss_cls: 0.0816, d3.loss_bbox: 0.2192, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2119, loss: 2.0065, grad_norm: 28.2608
2025-06-10 22:34:07,332 - mmdet - INFO - Epoch [4][5950/7033]	lr: 5.005e-05, eta: 7:22:26, time: 1.787, data_time: 0.061, memory: 18761, loss_cls: 0.0771, loss_bbox: 0.2005, d0.loss_cls: 0.1533, d0.loss_bbox: 0.3176, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2374, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2203, d3.loss_cls: 0.0810, d3.loss_bbox: 0.2133, d4.loss_cls: 0.0781, d4.loss_bbox: 0.2042, loss: 1.9768, grad_norm: 18.1237
2025-06-10 22:35:34,431 - mmdet - INFO - Epoch [4][6000/7033]	lr: 5.005e-05, eta: 7:20:58, time: 1.742, data_time: 0.067, memory: 18761, loss_cls: 0.0771, loss_bbox: 0.2082, d0.loss_cls: 0.1611, d0.loss_bbox: 0.3171, d1.loss_cls: 0.1037, d1.loss_bbox: 0.2407, d2.loss_cls: 0.0907, d2.loss_bbox: 0.2260, d3.loss_cls: 0.0817, d3.loss_bbox: 0.2205, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2125, loss: 2.0170, grad_norm: 30.4656
2025-06-10 22:37:02,128 - mmdet - INFO - Epoch [4][6050/7033]	lr: 5.005e-05, eta: 7:19:31, time: 1.754, data_time: 0.052, memory: 18761, loss_cls: 0.0715, loss_bbox: 0.2022, d0.loss_cls: 0.1553, d0.loss_bbox: 0.3179, d1.loss_cls: 0.1001, d1.loss_bbox: 0.2404, d2.loss_cls: 0.0876, d2.loss_bbox: 0.2206, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2149, d4.loss_cls: 0.0731, d4.loss_bbox: 0.2055, loss: 1.9648, grad_norm: 29.6399
2025-06-10 22:38:30,398 - mmdet - INFO - Epoch [4][6100/7033]	lr: 5.005e-05, eta: 7:18:03, time: 1.766, data_time: 0.061, memory: 18761, loss_cls: 0.0683, loss_bbox: 0.2037, d0.loss_cls: 0.1549, d0.loss_bbox: 0.3152, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2385, d2.loss_cls: 0.0847, d2.loss_bbox: 0.2218, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2140, d4.loss_cls: 0.0695, d4.loss_bbox: 0.2070, loss: 1.9592, grad_norm: 32.9235
2025-06-10 22:40:02,726 - mmdet - INFO - Epoch [4][6150/7033]	lr: 5.005e-05, eta: 7:16:38, time: 1.847, data_time: 0.064, memory: 18761, loss_cls: 0.0788, loss_bbox: 0.2162, d0.loss_cls: 0.1622, d0.loss_bbox: 0.3277, d1.loss_cls: 0.1131, d1.loss_bbox: 0.2511, d2.loss_cls: 0.0964, d2.loss_bbox: 0.2329, d3.loss_cls: 0.0850, d3.loss_bbox: 0.2291, d4.loss_cls: 0.0800, d4.loss_bbox: 0.2208, loss: 2.0934, grad_norm: 210.8694
2025-06-10 22:42:34,267 - mmdet - INFO - Epoch [4][6200/7033]	lr: 5.005e-05, eta: 7:15:46, time: 3.031, data_time: 1.303, memory: 18761, loss_cls: 0.0749, loss_bbox: 0.2077, d0.loss_cls: 0.1546, d0.loss_bbox: 0.3181, d1.loss_cls: 0.1066, d1.loss_bbox: 0.2447, d2.loss_cls: 0.0904, d2.loss_bbox: 0.2271, d3.loss_cls: 0.0800, d3.loss_bbox: 0.2215, d4.loss_cls: 0.0762, d4.loss_bbox: 0.2116, loss: 2.0133, grad_norm: 29.8124
