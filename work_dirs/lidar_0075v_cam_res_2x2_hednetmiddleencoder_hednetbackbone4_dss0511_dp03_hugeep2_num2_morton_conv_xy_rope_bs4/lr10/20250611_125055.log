2025-06-11 12:50:56,123 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0+cu116
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0+cu116
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+unknown
spconv2.0: True
------------------------------------------------------------

2025-06-11 12:50:56,680 - mmdet - INFO - 分布式训练: True
2025-06-11 12:50:57,211 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['points', 'img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/lr10'
load_from = 'pretrained/hedres_forced.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_grid_mask=True,
    freeze_backbone=True,
    img_backbone=dict(
        type='ResNet',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN2d', requires_grad=False),
        norm_eval=True,
        style='caffe',
        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),
        stage_with_dcn=(False, False, True, True)),
    img_neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_output',
        num_outs=4,
        relu_before_extra_convs=True),
    pts_voxel_layer=dict(
        max_num_points=-1,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(-1, -1),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(
        type='DynamicVFE',
        in_channels=5,
        feat_channels=[64, 128],
        with_distance=False,
        with_cluster_center=True,
        with_voxel_center=True,
        voxel_size=[0.075, 0.075, 0.2],
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_middle_encoder=dict(
        type='HEDNet',
        in_channels=128,
        sparse_shape=[41, 1440, 1440],
        model_cfg=dict(
            FEATURE_DIM=128,
            NUM_LAYERS=2,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDE=[1, 2, 2],
            DOWN_KERNEL_SIZE=[3, 3, 3])),
    pts_backbone=dict(
        type='CascadeDEDBackbone',
        in_channels=256,
        model_cfg=dict(
            USE_SECONDMAMBA=False,
            FEATURE_DIM=256,
            NUM_LAYERS=4,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDES=[1, 2, 2])),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        dss_date_version='0511',
        dss_drop_prob=0.3,
        dss_mamba_version='DSSMamba_Huge_EP2',
        dss_num_layers=2,
        dss_use_morton=True,
        dss_use_conv=True,
        dss_use_xy=True,
        dss_use_rope=True,
        dss_stack=True,
        dss_strong_cls=True,
        anchor_size=3,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='FUTR3DAttention',
                            use_lidar=True,
                            use_camera=True,
                            use_radar=False,
                            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
db_sampler = dict(
    data_root='data/nuscenes/',
    info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
    rate=1.0,
    prepare=dict(
        filter_by_difficulty=[-1],
        filter_by_min_points=dict(
            car=5,
            truck=5,
            bus=5,
            trailer=5,
            construction_vehicle=5,
            traffic_cone=5,
            barrier=5,
            motorcycle=5,
            bicycle=5,
            pedestrian=5)),
    classes=[
        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
    ],
    sample_groups=dict(
        car=2,
        truck=3,
        construction_vehicle=7,
        bus=4,
        trailer=6,
        barrier=2,
        motorcycle=6,
        bicycle=6,
        pedestrian=2,
        traffic_cone=2),
    points_loader=dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk')))
find_unused_parameters = True
runner = dict(type='EpochBasedRunner', max_epochs=6)
optimizer = dict(
    type='AdamW',
    lr=0.002,
    paramwise_cfg=dict(
        custom_keys=dict(
            img_backbone=dict(lr_mult=0.1),
            img_neck=dict(lr_mult=0.1),
            pts_middle_encoder=dict(lr_mult=0.1),
            pts_backbone=dict(lr_mult=0.1),
            pts_neck=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
gpu_ids = range(0, 2)

2025-06-11 12:50:57,212 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-06-11 12:50:57,962 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-06-11 12:50:58,162 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2025-06-11 12:50:58,223 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,224 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,224 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,224 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,225 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,225 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,225 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,225 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,227 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,229 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,231 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,232 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,234 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,236 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,237 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,239 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,241 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,242 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,244 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,246 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,247 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,249 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,250 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,252 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,254 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,255 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,257 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,259 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,261 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,262 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,270 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,277 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,283 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-11 12:50:58,302 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_voxel_encoder.vfe_layers.0.0.weight - torch.Size([64, 11]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.0.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.0.weight - torch.Size([16, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.0.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.0.weight - torch.Size([32, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.3.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.0.weight - torch.Size([64, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.0.weight - torch.Size([128, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.3.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.0.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.1.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.1.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.2.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.2.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.3.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.3.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.3.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.4.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.4.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.4.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.5.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.5.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.5.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.6.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.6.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.6.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.6.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.6.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.7.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.7.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.7.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.7.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.7.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.8.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.8.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.8.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.8.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.8.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.9.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.9.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.9.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.9.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.9.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.10.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.10.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.10.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.10.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.10.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.11.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.11.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.11.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.11.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.11.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.12.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.12.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.12.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.12.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.12.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.13.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.13.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.13.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.13.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.13.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.14.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.14.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.14.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.14.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.14.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.15.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.15.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.15.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.15.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.15.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.16.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.16.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.16.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.16.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.16.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.17.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.17.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.17.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.17.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.17.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.18.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.18.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.18.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.18.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.18.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.19.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.19.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.19.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.19.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.19.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.20.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.20.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.20.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.20.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.20.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.21.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.21.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.21.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.21.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.21.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.22.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.22.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.22.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.22.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.22.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.0.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.1.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.1.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.2.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.2.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-06-11 12:50:58,318 - mmdet - INFO - Model:
FUTR3D(
  (grid_mask): GridMask()
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=-1, max_voxels=(-1, -1), deterministic=True)
  (pts_voxel_encoder): DynamicVFE(
    (scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
    (vfe_layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=11, out_features=64, bias=False)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (vfe_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=False)
    (cluster_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
  )
  (pts_middle_encoder): HEDNet(
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SubMConv3d(128, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (3): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv2): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv3): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[1, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (layers): ModuleList(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (4): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU()
    )
  )
  (pts_backbone): CascadeDEDBackbone(
    (layers): ModuleList(
      (0): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (2): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (3): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (1): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (2): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (3): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (4): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (5): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
)
2025-06-11 12:51:24,682 - mmdet - INFO - load checkpoint from local path: pretrained/hedres_forced.pth
2025-06-11 12:51:26,222 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.code_weights, pts_bbox_head.query_embedding.weight, pts_bbox_head.aux_head.shared_conv.conv.weight, pts_bbox_head.aux_head.shared_conv.bn.weight, pts_bbox_head.aux_head.shared_conv.bn.bias, pts_bbox_head.aux_head.shared_conv.bn.running_mean, pts_bbox_head.aux_head.shared_conv.bn.running_var, pts_bbox_head.aux_head.shared_conv.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.1.weight, pts_bbox_head.aux_head.task_heads.0.reg.1.bias, pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.height.1.weight, pts_bbox_head.aux_head.task_heads.0.height.1.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.dim.1.weight, pts_bbox_head.aux_head.task_heads.0.dim.1.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.rot.1.weight, pts_bbox_head.aux_head.task_heads.0.rot.1.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.vel.1.weight, pts_bbox_head.aux_head.task_heads.0.vel.1.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.reg.1.weight, pts_bbox_head.aux_head.task_heads.1.reg.1.bias, pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.height.1.weight, pts_bbox_head.aux_head.task_heads.1.height.1.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.dim.1.weight, pts_bbox_head.aux_head.task_heads.1.dim.1.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.rot.1.weight, pts_bbox_head.aux_head.task_heads.1.rot.1.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.vel.1.weight, pts_bbox_head.aux_head.task_heads.1.vel.1.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.reg.1.weight, pts_bbox_head.aux_head.task_heads.2.reg.1.bias, pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.height.1.weight, pts_bbox_head.aux_head.task_heads.2.height.1.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.dim.1.weight, pts_bbox_head.aux_head.task_heads.2.dim.1.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.rot.1.weight, pts_bbox_head.aux_head.task_heads.2.rot.1.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.vel.1.weight, pts_bbox_head.aux_head.task_heads.2.vel.1.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.reg.1.weight, pts_bbox_head.aux_head.task_heads.3.reg.1.bias, pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.height.1.weight, pts_bbox_head.aux_head.task_heads.3.height.1.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.dim.1.weight, pts_bbox_head.aux_head.task_heads.3.dim.1.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.rot.1.weight, pts_bbox_head.aux_head.task_heads.3.rot.1.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.vel.1.weight, pts_bbox_head.aux_head.task_heads.3.vel.1.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.reg.1.weight, pts_bbox_head.aux_head.task_heads.4.reg.1.bias, pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.height.1.weight, pts_bbox_head.aux_head.task_heads.4.height.1.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.dim.1.weight, pts_bbox_head.aux_head.task_heads.4.dim.1.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.rot.1.weight, pts_bbox_head.aux_head.task_heads.4.rot.1.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.vel.1.weight, pts_bbox_head.aux_head.task_heads.4.vel.1.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.reg.1.weight, pts_bbox_head.aux_head.task_heads.5.reg.1.bias, pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.height.1.weight, pts_bbox_head.aux_head.task_heads.5.height.1.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.dim.1.weight, pts_bbox_head.aux_head.task_heads.5.dim.1.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.rot.1.weight, pts_bbox_head.aux_head.task_heads.5.rot.1.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.vel.1.weight, pts_bbox_head.aux_head.task_heads.5.vel.1.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.sin_cached, pts_bbox_head.cls_branches.0.0.weight, pts_bbox_head.cls_branches.0.0.bias, pts_bbox_head.cls_branches.0.1.weight, pts_bbox_head.cls_branches.0.1.bias, pts_bbox_head.cls_branches.0.3.weight, pts_bbox_head.cls_branches.0.3.bias, pts_bbox_head.cls_branches.0.4.weight, pts_bbox_head.cls_branches.0.4.bias, pts_bbox_head.cls_branches.0.6.weight, pts_bbox_head.cls_branches.0.6.bias, pts_bbox_head.cls_branches.1.0.weight, pts_bbox_head.cls_branches.1.0.bias, pts_bbox_head.cls_branches.1.1.weight, pts_bbox_head.cls_branches.1.1.bias, pts_bbox_head.cls_branches.1.3.weight, pts_bbox_head.cls_branches.1.3.bias, pts_bbox_head.cls_branches.1.4.weight, pts_bbox_head.cls_branches.1.4.bias, pts_bbox_head.cls_branches.1.6.weight, pts_bbox_head.cls_branches.1.6.bias, pts_bbox_head.cls_branches.2.0.weight, pts_bbox_head.cls_branches.2.0.bias, pts_bbox_head.cls_branches.2.1.weight, pts_bbox_head.cls_branches.2.1.bias, pts_bbox_head.cls_branches.2.3.weight, pts_bbox_head.cls_branches.2.3.bias, pts_bbox_head.cls_branches.2.4.weight, pts_bbox_head.cls_branches.2.4.bias, pts_bbox_head.cls_branches.2.6.weight, pts_bbox_head.cls_branches.2.6.bias, pts_bbox_head.cls_branches.3.0.weight, pts_bbox_head.cls_branches.3.0.bias, pts_bbox_head.cls_branches.3.1.weight, pts_bbox_head.cls_branches.3.1.bias, pts_bbox_head.cls_branches.3.3.weight, pts_bbox_head.cls_branches.3.3.bias, pts_bbox_head.cls_branches.3.4.weight, pts_bbox_head.cls_branches.3.4.bias, pts_bbox_head.cls_branches.3.6.weight, pts_bbox_head.cls_branches.3.6.bias, pts_bbox_head.cls_branches.4.0.weight, pts_bbox_head.cls_branches.4.0.bias, pts_bbox_head.cls_branches.4.1.weight, pts_bbox_head.cls_branches.4.1.bias, pts_bbox_head.cls_branches.4.3.weight, pts_bbox_head.cls_branches.4.3.bias, pts_bbox_head.cls_branches.4.4.weight, pts_bbox_head.cls_branches.4.4.bias, pts_bbox_head.cls_branches.4.6.weight, pts_bbox_head.cls_branches.4.6.bias, pts_bbox_head.cls_branches.5.0.weight, pts_bbox_head.cls_branches.5.0.bias, pts_bbox_head.cls_branches.5.1.weight, pts_bbox_head.cls_branches.5.1.bias, pts_bbox_head.cls_branches.5.3.weight, pts_bbox_head.cls_branches.5.3.bias, pts_bbox_head.cls_branches.5.4.weight, pts_bbox_head.cls_branches.5.4.bias, pts_bbox_head.cls_branches.5.6.weight, pts_bbox_head.cls_branches.5.6.bias

missing keys in source state_dict: pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias

2025-06-11 12:51:26,239 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/lr10
2025-06-11 12:51:26,240 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-06-11 12:51:26,240 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-06-11 12:51:26,241 - mmdet - INFO - Checkpoints will be saved to /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/lr10 by HardDiskBackend.
2025-06-11 12:53:22,633 - mmdet - INFO - Epoch [1][50/3517]	lr: 7.973e-04, eta: 13:32:16, time: 2.315, data_time: 0.240, memory: 30457, loss_cls: 0.8191, loss_bbox: 1.2306, d0.loss_cls: 0.8177, d0.loss_bbox: 1.3209, d1.loss_cls: 0.7630, d1.loss_bbox: 1.2505, d2.loss_cls: 0.7544, d2.loss_bbox: 1.2290, d3.loss_cls: 0.7847, d3.loss_bbox: 1.2433, d4.loss_cls: 0.8124, d4.loss_bbox: 1.2353, loss: 12.2608, grad_norm: 10.3912
2025-06-11 12:54:57,136 - mmdet - INFO - Epoch [1][100/3517]	lr: 9.307e-04, eta: 12:15:56, time: 1.890, data_time: 0.082, memory: 30826, loss_cls: 0.5161, loss_bbox: 0.9989, d0.loss_cls: 0.6250, d0.loss_bbox: 1.1488, d1.loss_cls: 0.4921, d1.loss_bbox: 1.0327, d2.loss_cls: 0.5004, d2.loss_bbox: 0.9996, d3.loss_cls: 0.5067, d3.loss_bbox: 1.0071, d4.loss_cls: 0.5035, d4.loss_bbox: 1.0036, loss: 9.3345, grad_norm: 8.1086
2025-06-11 12:56:30,773 - mmdet - INFO - Epoch [1][150/3517]	lr: 1.064e-03, eta: 11:47:27, time: 1.873, data_time: 0.061, memory: 30826, loss_cls: 0.3638, loss_bbox: 0.9878, d0.loss_cls: 0.5393, d0.loss_bbox: 1.1158, d1.loss_cls: 0.3400, d1.loss_bbox: 0.9692, d2.loss_cls: 0.3284, d2.loss_bbox: 0.9260, d3.loss_cls: 0.3361, d3.loss_bbox: 0.9390, d4.loss_cls: 0.3402, d4.loss_bbox: 0.9653, loss: 8.1509, grad_norm: 12.7221
2025-06-11 12:58:04,573 - mmdet - INFO - Epoch [1][200/3517]	lr: 1.197e-03, eta: 11:32:42, time: 1.876, data_time: 0.062, memory: 30895, loss_cls: 0.3108, loss_bbox: 0.8798, d0.loss_cls: 0.4014, d0.loss_bbox: 1.0181, d1.loss_cls: 0.3015, d1.loss_bbox: 0.8592, d2.loss_cls: 0.2834, d2.loss_bbox: 0.8040, d3.loss_cls: 0.2852, d3.loss_bbox: 0.8182, d4.loss_cls: 0.2912, d4.loss_bbox: 0.8464, loss: 7.0993, grad_norm: 13.2101
2025-06-11 12:59:38,205 - mmdet - INFO - Epoch [1][250/3517]	lr: 1.331e-03, eta: 11:22:59, time: 1.873, data_time: 0.055, memory: 30895, loss_cls: 0.3116, loss_bbox: 0.8468, d0.loss_cls: 0.3325, d0.loss_bbox: 0.8466, d1.loss_cls: 0.2954, d1.loss_bbox: 0.7105, d2.loss_cls: 0.2844, d2.loss_bbox: 0.6677, d3.loss_cls: 0.2801, d3.loss_bbox: 0.7124, d4.loss_cls: 0.2904, d4.loss_bbox: 0.7813, loss: 6.3595, grad_norm: 22.9678
2025-06-11 13:01:11,527 - mmdet - INFO - Epoch [1][300/3517]	lr: 1.464e-03, eta: 11:15:39, time: 1.867, data_time: 0.053, memory: 31070, loss_cls: 0.2590, loss_bbox: 0.7314, d0.loss_cls: 0.3091, d0.loss_bbox: 0.7182, d1.loss_cls: 0.2882, d1.loss_bbox: 0.6030, d2.loss_cls: 0.2613, d2.loss_bbox: 0.5673, d3.loss_cls: 0.2505, d3.loss_bbox: 0.5947, d4.loss_cls: 0.2497, d4.loss_bbox: 0.6638, loss: 5.4963, grad_norm: 22.5910
2025-06-11 13:02:48,421 - mmdet - INFO - Epoch [1][350/3517]	lr: 1.597e-03, eta: 11:13:29, time: 1.938, data_time: 0.057, memory: 31070, loss_cls: 0.2833, loss_bbox: 0.7543, d0.loss_cls: 0.3625, d0.loss_bbox: 0.7191, d1.loss_cls: 0.3268, d1.loss_bbox: 0.5898, d2.loss_cls: 0.2953, d2.loss_bbox: 0.5809, d3.loss_cls: 0.2748, d3.loss_bbox: 0.6227, d4.loss_cls: 0.2695, d4.loss_bbox: 0.6897, loss: 5.7687, grad_norm: 29.2005
2025-06-11 13:04:23,265 - mmdet - INFO - Epoch [1][400/3517]	lr: 1.731e-03, eta: 11:09:40, time: 1.897, data_time: 0.075, memory: 31244, loss_cls: 0.2767, loss_bbox: 0.6846, d0.loss_cls: 0.3455, d0.loss_bbox: 0.6935, d1.loss_cls: 0.4320, d1.loss_bbox: 0.6083, d2.loss_cls: 0.4204, d2.loss_bbox: 0.5848, d3.loss_cls: 0.3351, d3.loss_bbox: 0.6162, d4.loss_cls: 0.2853, d4.loss_bbox: 0.6577, loss: 5.9400, grad_norm: 21.0274
2025-06-11 13:05:57,257 - mmdet - INFO - Epoch [1][450/3517]	lr: 1.864e-03, eta: 11:05:44, time: 1.880, data_time: 0.053, memory: 31244, loss_cls: 0.2790, loss_bbox: 0.6671, d0.loss_cls: 0.2792, d0.loss_bbox: 0.5792, d1.loss_cls: 0.3604, d1.loss_bbox: 0.4974, d2.loss_cls: 0.4458, d2.loss_bbox: 0.5287, d3.loss_cls: 0.3782, d3.loss_bbox: 0.5714, d4.loss_cls: 0.3026, d4.loss_bbox: 0.6183, loss: 5.5073, grad_norm: 21.0202
2025-06-11 13:07:29,781 - mmdet - INFO - Epoch [1][500/3517]	lr: 1.997e-03, eta: 11:01:15, time: 1.850, data_time: 0.051, memory: 31244, loss_cls: 0.2475, loss_bbox: 0.5877, d0.loss_cls: 0.2534, d0.loss_bbox: 0.5357, d1.loss_cls: 0.3513, d1.loss_bbox: 0.4403, d2.loss_cls: 0.4082, d2.loss_bbox: 0.4582, d3.loss_cls: 0.3251, d3.loss_bbox: 0.4962, d4.loss_cls: 0.2698, d4.loss_bbox: 0.5402, loss: 4.9136, grad_norm: 19.0820
2025-06-11 13:09:02,316 - mmdet - INFO - Epoch [1][550/3517]	lr: 2.000e-03, eta: 10:57:18, time: 1.851, data_time: 0.051, memory: 31264, loss_cls: 0.2338, loss_bbox: 0.5982, d0.loss_cls: 0.2800, d0.loss_bbox: 0.5599, d1.loss_cls: 0.3064, d1.loss_bbox: 0.4606, d2.loss_cls: 0.3458, d2.loss_bbox: 0.4685, d3.loss_cls: 0.2880, d3.loss_bbox: 0.5127, d4.loss_cls: 0.2512, d4.loss_bbox: 0.5593, loss: 4.8642, grad_norm: 23.6735
2025-06-11 13:10:37,551 - mmdet - INFO - Epoch [1][600/3517]	lr: 2.000e-03, eta: 10:55:18, time: 1.905, data_time: 0.051, memory: 31547, loss_cls: 0.2210, loss_bbox: 0.5670, d0.loss_cls: 0.2868, d0.loss_bbox: 0.5522, d1.loss_cls: 0.3050, d1.loss_bbox: 0.4488, d2.loss_cls: 0.3321, d2.loss_bbox: 0.4522, d3.loss_cls: 0.2580, d3.loss_bbox: 0.4861, d4.loss_cls: 0.2212, d4.loss_bbox: 0.5203, loss: 4.6506, grad_norm: 19.9101
2025-06-11 13:12:10,098 - mmdet - INFO - Epoch [1][650/3517]	lr: 2.000e-03, eta: 10:51:56, time: 1.851, data_time: 0.051, memory: 31547, loss_cls: 0.2527, loss_bbox: 0.6343, d0.loss_cls: 0.3348, d0.loss_bbox: 0.6150, d1.loss_cls: 0.3311, d1.loss_bbox: 0.4797, d2.loss_cls: 0.3566, d2.loss_bbox: 0.4918, d3.loss_cls: 0.2930, d3.loss_bbox: 0.5371, d4.loss_cls: 0.2661, d4.loss_bbox: 0.5775, loss: 5.1697, grad_norm: 25.5842
2025-06-11 13:13:42,592 - mmdet - INFO - Epoch [1][700/3517]	lr: 2.000e-03, eta: 10:48:49, time: 1.850, data_time: 0.056, memory: 31547, loss_cls: 0.2351, loss_bbox: 0.6105, d0.loss_cls: 0.3328, d0.loss_bbox: 0.6351, d1.loss_cls: 0.3266, d1.loss_bbox: 0.4810, d2.loss_cls: 0.3410, d2.loss_bbox: 0.4840, d3.loss_cls: 0.2805, d3.loss_bbox: 0.5234, d4.loss_cls: 0.2435, d4.loss_bbox: 0.5605, loss: 5.0539, grad_norm: 24.8411
2025-06-11 13:15:15,911 - mmdet - INFO - Epoch [1][750/3517]	lr: 2.000e-03, eta: 10:46:17, time: 1.866, data_time: 0.057, memory: 31547, loss_cls: 0.2179, loss_bbox: 0.5526, d0.loss_cls: 0.3273, d0.loss_bbox: 0.6141, d1.loss_cls: 0.3309, d1.loss_bbox: 0.4702, d2.loss_cls: 0.3442, d2.loss_bbox: 0.4763, d3.loss_cls: 0.2771, d3.loss_bbox: 0.5087, d4.loss_cls: 0.2341, d4.loss_bbox: 0.5205, loss: 4.8738, grad_norm: 23.9767
2025-06-11 13:16:48,456 - mmdet - INFO - Epoch [1][800/3517]	lr: 2.000e-03, eta: 10:43:33, time: 1.851, data_time: 0.055, memory: 31547, loss_cls: 0.2317, loss_bbox: 0.5802, d0.loss_cls: 0.3256, d0.loss_bbox: 0.6062, d1.loss_cls: 0.3386, d1.loss_bbox: 0.4746, d2.loss_cls: 0.3630, d2.loss_bbox: 0.4991, d3.loss_cls: 0.3128, d3.loss_bbox: 0.5280, d4.loss_cls: 0.2474, d4.loss_bbox: 0.5441, loss: 5.0512, grad_norm: 20.4829
2025-06-11 13:18:21,782 - mmdet - INFO - Epoch [1][850/3517]	lr: 2.000e-03, eta: 10:41:16, time: 1.866, data_time: 0.056, memory: 31547, loss_cls: 0.2059, loss_bbox: 0.5323, d0.loss_cls: 0.3042, d0.loss_bbox: 0.5887, d1.loss_cls: 0.2921, d1.loss_bbox: 0.4481, d2.loss_cls: 0.3085, d2.loss_bbox: 0.4637, d3.loss_cls: 0.2672, d3.loss_bbox: 0.4972, d4.loss_cls: 0.2283, d4.loss_bbox: 0.5066, loss: 4.6426, grad_norm: 20.8169
2025-06-11 13:19:55,570 - mmdet - INFO - Epoch [1][900/3517]	lr: 2.000e-03, eta: 10:39:14, time: 1.876, data_time: 0.054, memory: 31547, loss_cls: 0.1876, loss_bbox: 0.4767, d0.loss_cls: 0.2910, d0.loss_bbox: 0.5208, d1.loss_cls: 0.2795, d1.loss_bbox: 0.3998, d2.loss_cls: 0.2851, d2.loss_bbox: 0.4147, d3.loss_cls: 0.2528, d3.loss_bbox: 0.4519, d4.loss_cls: 0.2095, d4.loss_bbox: 0.4633, loss: 4.2328, grad_norm: 21.9134
2025-06-11 13:21:29,354 - mmdet - INFO - Epoch [1][950/3517]	lr: 2.000e-03, eta: 10:37:14, time: 1.876, data_time: 0.056, memory: 31547, loss_cls: 0.1881, loss_bbox: 0.5017, d0.loss_cls: 0.2801, d0.loss_bbox: 0.5491, d1.loss_cls: 0.2644, d1.loss_bbox: 0.4183, d2.loss_cls: 0.2709, d2.loss_bbox: 0.4328, d3.loss_cls: 0.2337, d3.loss_bbox: 0.4668, d4.loss_cls: 0.2021, d4.loss_bbox: 0.4816, loss: 4.2898, grad_norm: 24.8760
2025-06-11 13:23:01,765 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 13:23:01,765 - mmdet - INFO - Epoch [1][1000/3517]	lr: 2.000e-03, eta: 10:34:50, time: 1.848, data_time: 0.055, memory: 31547, loss_cls: 0.2182, loss_bbox: 0.4770, d0.loss_cls: 0.2978, d0.loss_bbox: 0.5940, d1.loss_cls: 0.2975, d1.loss_bbox: 0.4376, d2.loss_cls: 0.3056, d2.loss_bbox: 0.4422, d3.loss_cls: 0.2680, d3.loss_bbox: 0.4678, d4.loss_cls: 0.2393, d4.loss_bbox: 0.4696, loss: 4.5146, grad_norm: 21.6257
2025-06-11 13:24:34,814 - mmdet - INFO - Epoch [1][1050/3517]	lr: 2.000e-03, eta: 10:32:43, time: 1.861, data_time: 0.052, memory: 31547, loss_cls: 0.1897, loss_bbox: 0.4396, d0.loss_cls: 0.2938, d0.loss_bbox: 0.5437, d1.loss_cls: 0.2812, d1.loss_bbox: 0.4027, d2.loss_cls: 0.2866, d2.loss_bbox: 0.4160, d3.loss_cls: 0.2350, d3.loss_bbox: 0.4367, d4.loss_cls: 0.2023, d4.loss_bbox: 0.4347, loss: 4.1621, grad_norm: 23.9869
2025-06-11 13:26:08,064 - mmdet - INFO - Epoch [1][1100/3517]	lr: 2.000e-03, eta: 10:30:43, time: 1.865, data_time: 0.050, memory: 31547, loss_cls: 0.1784, loss_bbox: 0.4606, d0.loss_cls: 0.2785, d0.loss_bbox: 0.5206, d1.loss_cls: 0.2710, d1.loss_bbox: 0.4147, d2.loss_cls: 0.2829, d2.loss_bbox: 0.4425, d3.loss_cls: 0.2245, d3.loss_bbox: 0.4720, d4.loss_cls: 0.1960, d4.loss_bbox: 0.4781, loss: 4.2198, grad_norm: 23.7176
2025-06-11 13:27:41,014 - mmdet - INFO - Epoch [1][1150/3517]	lr: 2.000e-03, eta: 10:28:40, time: 1.859, data_time: 0.050, memory: 31547, loss_cls: 0.2110, loss_bbox: 0.4647, d0.loss_cls: 0.3038, d0.loss_bbox: 0.5608, d1.loss_cls: 0.2897, d1.loss_bbox: 0.4209, d2.loss_cls: 0.2982, d2.loss_bbox: 0.4375, d3.loss_cls: 0.2523, d3.loss_bbox: 0.4602, d4.loss_cls: 0.2274, d4.loss_bbox: 0.4611, loss: 4.3877, grad_norm: 27.7640
2025-06-11 13:29:13,189 - mmdet - INFO - Epoch [1][1200/3517]	lr: 2.000e-03, eta: 10:26:26, time: 1.844, data_time: 0.051, memory: 31547, loss_cls: 0.1839, loss_bbox: 0.4216, d0.loss_cls: 0.2970, d0.loss_bbox: 0.5463, d1.loss_cls: 0.2745, d1.loss_bbox: 0.3940, d2.loss_cls: 0.2874, d2.loss_bbox: 0.4094, d3.loss_cls: 0.2293, d3.loss_bbox: 0.4350, d4.loss_cls: 0.2053, d4.loss_bbox: 0.4258, loss: 4.1095, grad_norm: 19.1026
2025-06-11 13:30:45,458 - mmdet - INFO - Epoch [1][1250/3517]	lr: 2.000e-03, eta: 10:24:17, time: 1.845, data_time: 0.049, memory: 31547, loss_cls: 0.1946, loss_bbox: 0.3918, d0.loss_cls: 0.2868, d0.loss_bbox: 0.5353, d1.loss_cls: 0.2794, d1.loss_bbox: 0.3949, d2.loss_cls: 0.2901, d2.loss_bbox: 0.4068, d3.loss_cls: 0.2485, d3.loss_bbox: 0.4287, d4.loss_cls: 0.2173, d4.loss_bbox: 0.4037, loss: 4.0781, grad_norm: 18.0592
2025-06-11 13:32:18,027 - mmdet - INFO - Epoch [1][1300/3517]	lr: 2.000e-03, eta: 10:22:16, time: 1.851, data_time: 0.051, memory: 32518, loss_cls: 0.1920, loss_bbox: 0.3853, d0.loss_cls: 0.2901, d0.loss_bbox: 0.5280, d1.loss_cls: 0.2811, d1.loss_bbox: 0.3926, d2.loss_cls: 0.2849, d2.loss_bbox: 0.4015, d3.loss_cls: 0.2354, d3.loss_bbox: 0.4186, d4.loss_cls: 0.2148, d4.loss_bbox: 0.3992, loss: 4.0235, grad_norm: 24.1225
2025-06-11 13:33:50,134 - mmdet - INFO - Epoch [1][1350/3517]	lr: 2.000e-03, eta: 10:20:10, time: 1.842, data_time: 0.052, memory: 32518, loss_cls: 0.1744, loss_bbox: 0.3815, d0.loss_cls: 0.2797, d0.loss_bbox: 0.5214, d1.loss_cls: 0.2701, d1.loss_bbox: 0.3754, d2.loss_cls: 0.2764, d2.loss_bbox: 0.3771, d3.loss_cls: 0.2323, d3.loss_bbox: 0.4002, d4.loss_cls: 0.1942, d4.loss_bbox: 0.3888, loss: 3.8716, grad_norm: 17.8740
2025-06-11 13:35:22,451 - mmdet - INFO - Epoch [1][1400/3517]	lr: 2.000e-03, eta: 10:18:09, time: 1.846, data_time: 0.053, memory: 32518, loss_cls: 0.1821, loss_bbox: 0.3911, d0.loss_cls: 0.2937, d0.loss_bbox: 0.5561, d1.loss_cls: 0.2705, d1.loss_bbox: 0.4041, d2.loss_cls: 0.2794, d2.loss_bbox: 0.4147, d3.loss_cls: 0.2274, d3.loss_bbox: 0.4380, d4.loss_cls: 0.2028, d4.loss_bbox: 0.4102, loss: 4.0701, grad_norm: 42.3635
2025-06-11 13:36:54,850 - mmdet - INFO - Epoch [1][1450/3517]	lr: 2.000e-03, eta: 10:16:12, time: 1.848, data_time: 0.052, memory: 32518, loss_cls: 0.1723, loss_bbox: 0.3873, d0.loss_cls: 0.2845, d0.loss_bbox: 0.5119, d1.loss_cls: 0.2667, d1.loss_bbox: 0.3688, d2.loss_cls: 0.2695, d2.loss_bbox: 0.3753, d3.loss_cls: 0.2114, d3.loss_bbox: 0.3993, d4.loss_cls: 0.1870, d4.loss_bbox: 0.3859, loss: 3.8198, grad_norm: 18.5893
2025-06-11 13:38:28,156 - mmdet - INFO - Epoch [1][1500/3517]	lr: 2.000e-03, eta: 10:14:28, time: 1.866, data_time: 0.051, memory: 32518, loss_cls: 0.1593, loss_bbox: 0.3676, d0.loss_cls: 0.2732, d0.loss_bbox: 0.4758, d1.loss_cls: 0.2572, d1.loss_bbox: 0.3579, d2.loss_cls: 0.2588, d2.loss_bbox: 0.3610, d3.loss_cls: 0.1976, d3.loss_bbox: 0.3927, d4.loss_cls: 0.1724, d4.loss_bbox: 0.3847, loss: 3.6583, grad_norm: 19.6356
2025-06-11 13:40:00,604 - mmdet - INFO - Epoch [1][1550/3517]	lr: 2.000e-03, eta: 10:12:33, time: 1.849, data_time: 0.051, memory: 32518, loss_cls: 0.1561, loss_bbox: 0.3959, d0.loss_cls: 0.2745, d0.loss_bbox: 0.5108, d1.loss_cls: 0.2581, d1.loss_bbox: 0.3809, d2.loss_cls: 0.2577, d2.loss_bbox: 0.3872, d3.loss_cls: 0.2042, d3.loss_bbox: 0.4064, d4.loss_cls: 0.1742, d4.loss_bbox: 0.4044, loss: 3.8102, grad_norm: 18.6010
2025-06-11 13:41:33,511 - mmdet - INFO - Epoch [1][1600/3517]	lr: 2.000e-03, eta: 10:10:46, time: 1.858, data_time: 0.055, memory: 32518, loss_cls: 0.1495, loss_bbox: 0.3967, d0.loss_cls: 0.2665, d0.loss_bbox: 0.5002, d1.loss_cls: 0.2453, d1.loss_bbox: 0.3722, d2.loss_cls: 0.2471, d2.loss_bbox: 0.3808, d3.loss_cls: 0.1922, d3.loss_bbox: 0.4087, d4.loss_cls: 0.1665, d4.loss_bbox: 0.4001, loss: 3.7255, grad_norm: 24.1682
2025-06-11 13:43:06,718 - mmdet - INFO - Epoch [1][1650/3517]	lr: 2.000e-03, eta: 10:09:04, time: 1.864, data_time: 0.054, memory: 32518, loss_cls: 0.1548, loss_bbox: 0.3867, d0.loss_cls: 0.2645, d0.loss_bbox: 0.4884, d1.loss_cls: 0.2452, d1.loss_bbox: 0.3643, d2.loss_cls: 0.2471, d2.loss_bbox: 0.3718, d3.loss_cls: 0.1904, d3.loss_bbox: 0.3909, d4.loss_cls: 0.1664, d4.loss_bbox: 0.3881, loss: 3.6585, grad_norm: 23.5749
2025-06-11 13:44:40,070 - mmdet - INFO - Epoch [1][1700/3517]	lr: 2.000e-03, eta: 10:07:23, time: 1.867, data_time: 0.054, memory: 32518, loss_cls: 0.1493, loss_bbox: 0.3781, d0.loss_cls: 0.2733, d0.loss_bbox: 0.4960, d1.loss_cls: 0.2533, d1.loss_bbox: 0.3653, d2.loss_cls: 0.2574, d2.loss_bbox: 0.3728, d3.loss_cls: 0.2142, d3.loss_bbox: 0.3951, d4.loss_cls: 0.1674, d4.loss_bbox: 0.3971, loss: 3.7192, grad_norm: 25.6353
2025-06-11 13:46:13,362 - mmdet - INFO - Epoch [1][1750/3517]	lr: 2.000e-03, eta: 10:05:42, time: 1.866, data_time: 0.053, memory: 32518, loss_cls: 0.1570, loss_bbox: 0.3635, d0.loss_cls: 0.2685, d0.loss_bbox: 0.4838, d1.loss_cls: 0.2548, d1.loss_bbox: 0.3722, d2.loss_cls: 0.2668, d2.loss_bbox: 0.3939, d3.loss_cls: 0.2075, d3.loss_bbox: 0.4020, d4.loss_cls: 0.1733, d4.loss_bbox: 0.3878, loss: 3.7312, grad_norm: 31.2428
2025-06-11 13:48:04,395 - mmdet - INFO - Epoch [1][1800/3517]	lr: 2.000e-03, eta: 10:07:12, time: 2.221, data_time: 0.369, memory: 32518, loss_cls: 0.1589, loss_bbox: 0.3801, d0.loss_cls: 0.2765, d0.loss_bbox: 0.4976, d1.loss_cls: 0.2601, d1.loss_bbox: 0.3707, d2.loss_cls: 0.2702, d2.loss_bbox: 0.3867, d3.loss_cls: 0.2057, d3.loss_bbox: 0.3980, d4.loss_cls: 0.1747, d4.loss_bbox: 0.3786, loss: 3.7579, grad_norm: 29.3475
2025-06-11 13:49:37,438 - mmdet - INFO - Epoch [1][1850/3517]	lr: 2.000e-03, eta: 10:05:24, time: 1.861, data_time: 0.051, memory: 32518, loss_cls: 0.1830, loss_bbox: 0.3830, d0.loss_cls: 0.3231, d0.loss_bbox: 0.5720, d1.loss_cls: 0.3043, d1.loss_bbox: 0.3881, d2.loss_cls: 0.3160, d2.loss_bbox: 0.4141, d3.loss_cls: 0.2390, d3.loss_bbox: 0.4158, d4.loss_cls: 0.2037, d4.loss_bbox: 0.4029, loss: 4.1451, grad_norm: 22.8333
2025-06-11 13:51:10,126 - mmdet - INFO - Epoch [1][1900/3517]	lr: 2.000e-03, eta: 10:03:33, time: 1.854, data_time: 0.052, memory: 32518, loss_cls: 0.1774, loss_bbox: 0.3831, d0.loss_cls: 0.3162, d0.loss_bbox: 0.5708, d1.loss_cls: 0.2911, d1.loss_bbox: 0.4146, d2.loss_cls: 0.2974, d2.loss_bbox: 0.4273, d3.loss_cls: 0.2311, d3.loss_bbox: 0.4325, d4.loss_cls: 0.1975, d4.loss_bbox: 0.4124, loss: 4.1514, grad_norm: 21.7154
2025-06-11 13:52:43,484 - mmdet - INFO - Epoch [1][1950/3517]	lr: 2.000e-03, eta: 10:01:49, time: 1.867, data_time: 0.059, memory: 32518, loss_cls: 0.1785, loss_bbox: 0.3762, d0.loss_cls: 0.3056, d0.loss_bbox: 0.5443, d1.loss_cls: 0.2980, d1.loss_bbox: 0.4148, d2.loss_cls: 0.3201, d2.loss_bbox: 0.4382, d3.loss_cls: 0.2431, d3.loss_bbox: 0.4298, d4.loss_cls: 0.2060, d4.loss_bbox: 0.3935, loss: 4.1480, grad_norm: 21.8990
2025-06-11 13:54:16,411 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 13:54:16,411 - mmdet - INFO - Epoch [1][2000/3517]	lr: 2.000e-03, eta: 10:00:02, time: 1.859, data_time: 0.062, memory: 32518, loss_cls: 0.1854, loss_bbox: 0.3831, d0.loss_cls: 0.2933, d0.loss_bbox: 0.5314, d1.loss_cls: 0.2974, d1.loss_bbox: 0.4437, d2.loss_cls: 0.3399, d2.loss_bbox: 0.5050, d3.loss_cls: 0.2536, d3.loss_bbox: 0.4549, d4.loss_cls: 0.2156, d4.loss_bbox: 0.4155, loss: 4.3187, grad_norm: 26.5904
2025-06-11 13:55:50,284 - mmdet - INFO - Epoch [1][2050/3517]	lr: 2.000e-03, eta: 9:58:24, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.1906, loss_bbox: 0.3744, d0.loss_cls: 0.3075, d0.loss_bbox: 0.5503, d1.loss_cls: 0.3144, d1.loss_bbox: 0.4195, d2.loss_cls: 0.3598, d2.loss_bbox: 0.5047, d3.loss_cls: 0.2583, d3.loss_bbox: 0.4399, d4.loss_cls: 0.2169, d4.loss_bbox: 0.4189, loss: 4.3552, grad_norm: 20.8712
2025-06-11 13:57:23,623 - mmdet - INFO - Epoch [1][2100/3517]	lr: 2.000e-03, eta: 9:56:42, time: 1.867, data_time: 0.058, memory: 32518, loss_cls: 0.1822, loss_bbox: 0.3877, d0.loss_cls: 0.2912, d0.loss_bbox: 0.5286, d1.loss_cls: 0.2855, d1.loss_bbox: 0.4134, d2.loss_cls: 0.3165, d2.loss_bbox: 0.4609, d3.loss_cls: 0.2493, d3.loss_bbox: 0.4288, d4.loss_cls: 0.2098, d4.loss_bbox: 0.4046, loss: 4.1583, grad_norm: 20.1729
2025-06-11 13:58:57,135 - mmdet - INFO - Epoch [1][2150/3517]	lr: 2.000e-03, eta: 9:55:02, time: 1.870, data_time: 0.065, memory: 32518, loss_cls: 0.1631, loss_bbox: 0.3677, d0.loss_cls: 0.2890, d0.loss_bbox: 0.5085, d1.loss_cls: 0.2726, d1.loss_bbox: 0.3824, d2.loss_cls: 0.2979, d2.loss_bbox: 0.4189, d3.loss_cls: 0.2319, d3.loss_bbox: 0.4021, d4.loss_cls: 0.1900, d4.loss_bbox: 0.3863, loss: 3.9105, grad_norm: 28.9344
2025-06-11 14:00:31,114 - mmdet - INFO - Epoch [1][2200/3517]	lr: 2.000e-03, eta: 9:53:26, time: 1.880, data_time: 0.069, memory: 32518, loss_cls: 0.1552, loss_bbox: 0.3528, d0.loss_cls: 0.2827, d0.loss_bbox: 0.4914, d1.loss_cls: 0.2711, d1.loss_bbox: 0.3664, d2.loss_cls: 0.2862, d2.loss_bbox: 0.3912, d3.loss_cls: 0.2158, d3.loss_bbox: 0.3859, d4.loss_cls: 0.1734, d4.loss_bbox: 0.3687, loss: 3.7409, grad_norm: 31.2590
2025-06-11 14:02:03,527 - mmdet - INFO - Epoch [1][2250/3517]	lr: 2.000e-03, eta: 9:51:37, time: 1.848, data_time: 0.053, memory: 32518, loss_cls: 0.1569, loss_bbox: 0.3666, d0.loss_cls: 0.2823, d0.loss_bbox: 0.5013, d1.loss_cls: 0.2694, d1.loss_bbox: 0.3766, d2.loss_cls: 0.2891, d2.loss_bbox: 0.4026, d3.loss_cls: 0.2121, d3.loss_bbox: 0.4078, d4.loss_cls: 0.1761, d4.loss_bbox: 0.3915, loss: 3.8323, grad_norm: 28.3122
2025-06-11 14:03:36,396 - mmdet - INFO - Epoch [1][2300/3517]	lr: 2.000e-03, eta: 9:49:52, time: 1.857, data_time: 0.050, memory: 32518, loss_cls: 0.1598, loss_bbox: 0.3753, d0.loss_cls: 0.2837, d0.loss_bbox: 0.4932, d1.loss_cls: 0.2755, d1.loss_bbox: 0.3797, d2.loss_cls: 0.2931, d2.loss_bbox: 0.4095, d3.loss_cls: 0.2173, d3.loss_bbox: 0.4194, d4.loss_cls: 0.1753, d4.loss_bbox: 0.3975, loss: 3.8794, grad_norm: 26.1690
2025-06-11 14:05:12,768 - mmdet - INFO - Epoch [1][2350/3517]	lr: 2.000e-03, eta: 9:48:36, time: 1.927, data_time: 0.054, memory: 32518, loss_cls: 0.2032, loss_bbox: 0.3919, d0.loss_cls: 0.3218, d0.loss_bbox: 0.5867, d1.loss_cls: 0.3015, d1.loss_bbox: 0.4445, d2.loss_cls: 0.3120, d2.loss_bbox: 0.4538, d3.loss_cls: 0.2479, d3.loss_bbox: 0.4510, d4.loss_cls: 0.2187, d4.loss_bbox: 0.4237, loss: 4.3566, grad_norm: 32.6866
2025-06-11 14:06:45,782 - mmdet - INFO - Epoch [1][2400/3517]	lr: 2.000e-03, eta: 9:46:53, time: 1.860, data_time: 0.064, memory: 32518, loss_cls: 0.3471, loss_bbox: 0.6212, d0.loss_cls: 0.7774, d0.loss_bbox: 1.2667, d1.loss_cls: 0.6141, d1.loss_bbox: 0.9705, d2.loss_cls: 0.4806, d2.loss_bbox: 0.8279, d3.loss_cls: 0.4202, d3.loss_bbox: 0.8257, d4.loss_cls: 0.3772, d4.loss_bbox: 0.7128, loss: 8.2414, grad_norm: 157.7465
2025-06-11 14:08:18,569 - mmdet - INFO - Epoch [1][2450/3517]	lr: 2.000e-03, eta: 9:45:08, time: 1.856, data_time: 0.053, memory: 32518, loss_cls: 0.3029, loss_bbox: 0.5610, d0.loss_cls: 1.1130, d0.loss_bbox: 1.5056, d1.loss_cls: 0.5469, d1.loss_bbox: 0.9089, d2.loss_cls: 0.4454, d2.loss_bbox: 0.7678, d3.loss_cls: 0.3790, d3.loss_bbox: 0.7687, d4.loss_cls: 0.3309, d4.loss_bbox: 0.6582, loss: 8.2884, grad_norm: 91.5396
2025-06-11 14:09:51,846 - mmdet - INFO - Epoch [1][2500/3517]	lr: 2.000e-03, eta: 9:43:28, time: 1.866, data_time: 0.057, memory: 32518, loss_cls: 0.2382, loss_bbox: 0.4642, d0.loss_cls: 0.9412, d0.loss_bbox: 1.3399, d1.loss_cls: 0.4077, d1.loss_bbox: 0.6335, d2.loss_cls: 0.3953, d2.loss_bbox: 0.5742, d3.loss_cls: 0.3166, d3.loss_bbox: 0.5988, d4.loss_cls: 0.2666, d4.loss_bbox: 0.5362, loss: 6.7125, grad_norm: 16.6020
2025-06-11 14:11:25,107 - mmdet - INFO - Epoch [1][2550/3517]	lr: 2.000e-03, eta: 9:41:48, time: 1.865, data_time: 0.055, memory: 32518, loss_cls: 0.2295, loss_bbox: 0.4607, d0.loss_cls: 0.7034, d0.loss_bbox: 1.2224, d1.loss_cls: 0.3974, d1.loss_bbox: 0.6209, d2.loss_cls: 0.4110, d2.loss_bbox: 0.5817, d3.loss_cls: 0.3076, d3.loss_bbox: 0.5894, d4.loss_cls: 0.2616, d4.loss_bbox: 0.5251, loss: 6.3107, grad_norm: 16.7645
2025-06-11 14:13:00,892 - mmdet - INFO - Epoch [1][2600/3517]	lr: 2.000e-03, eta: 9:40:26, time: 1.916, data_time: 0.053, memory: 32518, loss_cls: 0.2361, loss_bbox: 0.4410, d0.loss_cls: 0.6229, d0.loss_bbox: 1.0780, d1.loss_cls: 0.4211, d1.loss_bbox: 0.6024, d2.loss_cls: 0.4883, d2.loss_bbox: 0.6248, d3.loss_cls: 0.3565, d3.loss_bbox: 0.5837, d4.loss_cls: 0.2732, d4.loss_bbox: 0.4956, loss: 6.2237, grad_norm: 21.1556
2025-06-11 14:14:32,909 - mmdet - INFO - Epoch [1][2650/3517]	lr: 2.000e-03, eta: 9:38:37, time: 1.840, data_time: 0.049, memory: 32518, loss_cls: 0.2478, loss_bbox: 0.4438, d0.loss_cls: 0.6304, d0.loss_bbox: 1.0608, d1.loss_cls: 0.4437, d1.loss_bbox: 0.6700, d2.loss_cls: 0.6153, d2.loss_bbox: 0.7924, d3.loss_cls: 0.4187, d3.loss_bbox: 0.6341, d4.loss_cls: 0.3123, d4.loss_bbox: 0.5072, loss: 6.7765, grad_norm: 32.1940
2025-06-11 14:16:06,250 - mmdet - INFO - Epoch [1][2700/3517]	lr: 2.000e-03, eta: 9:36:58, time: 1.867, data_time: 0.050, memory: 32518, loss_cls: 0.3550, loss_bbox: 0.5978, d0.loss_cls: 9.7058, d0.loss_bbox: 2.6949, d1.loss_cls: 0.8321, d1.loss_bbox: 1.2778, d2.loss_cls: 0.7665, d2.loss_bbox: 1.2087, d3.loss_cls: 0.4776, d3.loss_bbox: 0.9137, d4.loss_cls: 0.3865, d4.loss_bbox: 0.7271, loss: 19.9433, grad_norm: 377.6469
2025-06-11 14:17:39,179 - mmdet - INFO - Epoch [1][2750/3517]	lr: 2.000e-03, eta: 9:35:16, time: 1.859, data_time: 0.050, memory: 32518, loss_cls: 0.2834, loss_bbox: 0.4828, d0.loss_cls: 0.7158, d0.loss_bbox: 1.1716, d1.loss_cls: 0.4667, d1.loss_bbox: 0.7516, d2.loss_cls: 0.4821, d2.loss_bbox: 0.6921, d3.loss_cls: 0.4253, d3.loss_bbox: 0.6268, d4.loss_cls: 0.3192, d4.loss_bbox: 0.5548, loss: 6.9722, grad_norm: 20.5404
2025-06-11 14:19:12,514 - mmdet - INFO - Epoch [1][2800/3517]	lr: 2.000e-03, eta: 9:33:38, time: 1.867, data_time: 0.051, memory: 32518, loss_cls: 0.2538, loss_bbox: 0.4101, d0.loss_cls: 0.4790, d0.loss_bbox: 0.8797, d1.loss_cls: 0.4075, d1.loss_bbox: 0.5243, d2.loss_cls: 0.4532, d2.loss_bbox: 0.5071, d3.loss_cls: 0.4530, d3.loss_bbox: 0.4842, d4.loss_cls: 0.3158, d4.loss_bbox: 0.4514, loss: 5.6192, grad_norm: 12.9696
2025-06-11 14:20:45,831 - mmdet - INFO - Epoch [1][2850/3517]	lr: 2.000e-03, eta: 9:31:59, time: 1.866, data_time: 0.049, memory: 32518, loss_cls: 0.2448, loss_bbox: 0.3890, d0.loss_cls: 0.3889, d0.loss_bbox: 0.7040, d1.loss_cls: 0.3861, d1.loss_bbox: 0.4663, d2.loss_cls: 0.4416, d2.loss_bbox: 0.4615, d3.loss_cls: 0.4737, d3.loss_bbox: 0.4496, d4.loss_cls: 0.3202, d4.loss_bbox: 0.4220, loss: 5.1476, grad_norm: 15.3647
2025-06-11 14:22:18,677 - mmdet - INFO - Epoch [1][2900/3517]	lr: 2.000e-03, eta: 9:30:18, time: 1.857, data_time: 0.050, memory: 32518, loss_cls: 0.2308, loss_bbox: 0.4042, d0.loss_cls: 0.3577, d0.loss_bbox: 0.6440, d1.loss_cls: 0.3674, d1.loss_bbox: 0.4340, d2.loss_cls: 0.4508, d2.loss_bbox: 0.4656, d3.loss_cls: 0.4672, d3.loss_bbox: 0.4317, d4.loss_cls: 0.3166, d4.loss_bbox: 0.4216, loss: 4.9915, grad_norm: 24.6043
2025-06-11 14:23:50,870 - mmdet - INFO - Epoch [1][2950/3517]	lr: 2.000e-03, eta: 9:28:33, time: 1.844, data_time: 0.052, memory: 32518, loss_cls: 0.2551, loss_bbox: 0.4001, d0.loss_cls: 0.4076, d0.loss_bbox: 0.7409, d1.loss_cls: 0.3873, d1.loss_bbox: 0.4461, d2.loss_cls: 0.5158, d2.loss_bbox: 0.5004, d3.loss_cls: 0.4838, d3.loss_bbox: 0.4729, d4.loss_cls: 0.3264, d4.loss_bbox: 0.4201, loss: 5.3565, grad_norm: 22.0641
2025-06-11 14:25:22,943 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 14:25:22,943 - mmdet - INFO - Epoch [1][3000/3517]	lr: 2.000e-03, eta: 9:26:47, time: 1.842, data_time: 0.050, memory: 32518, loss_cls: 0.2266, loss_bbox: 0.3712, d0.loss_cls: 0.3296, d0.loss_bbox: 0.6016, d1.loss_cls: 0.3829, d1.loss_bbox: 0.4195, d2.loss_cls: 0.5199, d2.loss_bbox: 0.4840, d3.loss_cls: 0.4366, d3.loss_bbox: 0.4326, d4.loss_cls: 0.2953, d4.loss_bbox: 0.4010, loss: 4.9007, grad_norm: 17.0688
2025-06-11 14:26:54,921 - mmdet - INFO - Epoch [1][3050/3517]	lr: 2.000e-03, eta: 9:25:02, time: 1.840, data_time: 0.051, memory: 32518, loss_cls: 0.2288, loss_bbox: 0.3905, d0.loss_cls: 0.3309, d0.loss_bbox: 0.6052, d1.loss_cls: 0.3685, d1.loss_bbox: 0.4230, d2.loss_cls: 0.4235, d2.loss_bbox: 0.4563, d3.loss_cls: 0.4677, d3.loss_bbox: 0.5078, d4.loss_cls: 0.3039, d4.loss_bbox: 0.4203, loss: 4.9261, grad_norm: 18.0969
2025-06-11 14:28:26,634 - mmdet - INFO - Epoch [1][3100/3517]	lr: 2.000e-03, eta: 9:23:15, time: 1.834, data_time: 0.051, memory: 32518, loss_cls: 0.2249, loss_bbox: 0.3534, d0.loss_cls: 0.3196, d0.loss_bbox: 0.5902, d1.loss_cls: 0.3548, d1.loss_bbox: 0.3948, d2.loss_cls: 0.3876, d2.loss_bbox: 0.4152, d3.loss_cls: 0.5292, d3.loss_bbox: 0.5121, d4.loss_cls: 0.3169, d4.loss_bbox: 0.3861, loss: 4.7848, grad_norm: 12.1482
2025-06-11 14:29:58,916 - mmdet - INFO - Epoch [1][3150/3517]	lr: 2.000e-03, eta: 9:21:32, time: 1.846, data_time: 0.048, memory: 32518, loss_cls: 0.2372, loss_bbox: 0.3489, d0.loss_cls: 0.2952, d0.loss_bbox: 0.5430, d1.loss_cls: 0.3074, d1.loss_bbox: 0.3806, d2.loss_cls: 0.3397, d2.loss_bbox: 0.4010, d3.loss_cls: 0.4787, d3.loss_bbox: 0.4657, d4.loss_cls: 0.3297, d4.loss_bbox: 0.3776, loss: 4.5047, grad_norm: 11.4765
2025-06-11 14:31:31,593 - mmdet - INFO - Epoch [1][3200/3517]	lr: 2.000e-03, eta: 9:19:52, time: 1.854, data_time: 0.054, memory: 32518, loss_cls: 0.2324, loss_bbox: 0.3530, d0.loss_cls: 0.2838, d0.loss_bbox: 0.5233, d1.loss_cls: 0.2772, d1.loss_bbox: 0.3825, d2.loss_cls: 0.2989, d2.loss_bbox: 0.4053, d3.loss_cls: 0.3722, d3.loss_bbox: 0.4217, d4.loss_cls: 0.3172, d4.loss_bbox: 0.3744, loss: 4.2420, grad_norm: 15.1184
2025-06-11 14:33:04,285 - mmdet - INFO - Epoch [1][3250/3517]	lr: 2.000e-03, eta: 9:18:12, time: 1.853, data_time: 0.051, memory: 32518, loss_cls: 0.2265, loss_bbox: 0.3529, d0.loss_cls: 0.2961, d0.loss_bbox: 0.5305, d1.loss_cls: 0.2967, d1.loss_bbox: 0.3870, d2.loss_cls: 0.3214, d2.loss_bbox: 0.4061, d3.loss_cls: 0.3483, d3.loss_bbox: 0.4395, d4.loss_cls: 0.3092, d4.loss_bbox: 0.3828, loss: 4.2970, grad_norm: 17.1400
2025-06-11 14:34:37,679 - mmdet - INFO - Epoch [1][3300/3517]	lr: 2.000e-03, eta: 9:16:36, time: 1.868, data_time: 0.049, memory: 32518, loss_cls: 0.2108, loss_bbox: 0.3516, d0.loss_cls: 0.2929, d0.loss_bbox: 0.5201, d1.loss_cls: 0.2794, d1.loss_bbox: 0.3849, d2.loss_cls: 0.3099, d2.loss_bbox: 0.4032, d3.loss_cls: 0.3160, d3.loss_bbox: 0.4408, d4.loss_cls: 0.2785, d4.loss_bbox: 0.3829, loss: 4.1710, grad_norm: 17.3802
2025-06-11 14:36:11,411 - mmdet - INFO - Epoch [1][3350/3517]	lr: 2.000e-03, eta: 9:15:02, time: 1.875, data_time: 0.053, memory: 32518, loss_cls: 0.1992, loss_bbox: 0.3523, d0.loss_cls: 0.2931, d0.loss_bbox: 0.5169, d1.loss_cls: 0.2817, d1.loss_bbox: 0.3802, d2.loss_cls: 0.3001, d2.loss_bbox: 0.3931, d3.loss_cls: 0.3083, d3.loss_bbox: 0.4247, d4.loss_cls: 0.2605, d4.loss_bbox: 0.3763, loss: 4.0864, grad_norm: 18.2686
2025-06-11 14:37:44,986 - mmdet - INFO - Epoch [1][3400/3517]	lr: 2.000e-03, eta: 9:13:27, time: 1.872, data_time: 0.050, memory: 32518, loss_cls: 0.1916, loss_bbox: 0.3513, d0.loss_cls: 0.3018, d0.loss_bbox: 0.5219, d1.loss_cls: 0.2826, d1.loss_bbox: 0.3789, d2.loss_cls: 0.3035, d2.loss_bbox: 0.3915, d3.loss_cls: 0.3128, d3.loss_bbox: 0.4213, d4.loss_cls: 0.2344, d4.loss_bbox: 0.3794, loss: 4.0709, grad_norm: 24.0631
2025-06-11 14:39:17,855 - mmdet - INFO - Epoch [1][3450/3517]	lr: 2.000e-03, eta: 9:11:48, time: 1.857, data_time: 0.046, memory: 32518, loss_cls: 0.1957, loss_bbox: 0.3392, d0.loss_cls: 0.2953, d0.loss_bbox: 0.5067, d1.loss_cls: 0.2865, d1.loss_bbox: 0.3713, d2.loss_cls: 0.3039, d2.loss_bbox: 0.3907, d3.loss_cls: 0.3266, d3.loss_bbox: 0.4217, d4.loss_cls: 0.2734, d4.loss_bbox: 0.3690, loss: 4.0800, grad_norm: 17.1969
2025-06-11 14:40:50,343 - mmdet - INFO - Epoch [1][3500/3517]	lr: 2.000e-03, eta: 9:10:08, time: 1.850, data_time: 0.051, memory: 32518, loss_cls: 0.1946, loss_bbox: 0.3493, d0.loss_cls: 0.3411, d0.loss_bbox: 0.5609, d1.loss_cls: 0.3075, d1.loss_bbox: 0.3814, d2.loss_cls: 0.3153, d2.loss_bbox: 0.3911, d3.loss_cls: 0.3080, d3.loss_bbox: 0.4262, d4.loss_cls: 0.2661, d4.loss_bbox: 0.3763, loss: 4.2177, grad_norm: 21.1131
2025-06-11 14:41:22,323 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-06-11 15:09:20,942 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 15:09:20,942 - mmdet - INFO - Epoch(val) [1][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.6691, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8378, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8708, pts_bbox_NuScenes/car_AP_dist_4.0: 0.8897, pts_bbox_NuScenes/car_trans_err: 0.2521, pts_bbox_NuScenes/car_scale_err: 0.1593, pts_bbox_NuScenes/car_orient_err: 0.0834, pts_bbox_NuScenes/car_vel_err: 0.3494, pts_bbox_NuScenes/car_attr_err: 0.1865, pts_bbox_NuScenes/mATE: 0.3721, pts_bbox_NuScenes/mASE: 0.2766, pts_bbox_NuScenes/mAOE: 0.2802, pts_bbox_NuScenes/mAVE: 0.3421, pts_bbox_NuScenes/mAAE: 0.1797, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.3370, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5557, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6425, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7010, pts_bbox_NuScenes/truck_trans_err: 0.3891, pts_bbox_NuScenes/truck_scale_err: 0.2133, pts_bbox_NuScenes/truck_orient_err: 0.1026, pts_bbox_NuScenes/truck_vel_err: 0.2854, pts_bbox_NuScenes/truck_attr_err: 0.2031, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0276, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1434, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3133, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.3686, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.7115, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4778, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7939, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1182, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2959, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.3302, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.6626, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8318, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.8583, pts_bbox_NuScenes/bus_trans_err: 0.4832, pts_bbox_NuScenes/bus_scale_err: 0.2037, pts_bbox_NuScenes/bus_orient_err: 0.0750, pts_bbox_NuScenes/bus_vel_err: 0.6437, pts_bbox_NuScenes/bus_attr_err: 0.2773, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1212, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3746, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.4918, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.5704, pts_bbox_NuScenes/trailer_trans_err: 0.5276, pts_bbox_NuScenes/trailer_scale_err: 0.2277, pts_bbox_NuScenes/trailer_orient_err: 0.4454, pts_bbox_NuScenes/trailer_vel_err: 0.2382, pts_bbox_NuScenes/trailer_attr_err: 0.1774, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.4781, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6043, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.6661, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7015, pts_bbox_NuScenes/barrier_trans_err: 0.3305, pts_bbox_NuScenes/barrier_scale_err: 0.2901, pts_bbox_NuScenes/barrier_orient_err: 0.0872, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.4446, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.6830, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7343, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7432, pts_bbox_NuScenes/motorcycle_trans_err: 0.3325, pts_bbox_NuScenes/motorcycle_scale_err: 0.2594, pts_bbox_NuScenes/motorcycle_orient_err: 0.2507, pts_bbox_NuScenes/motorcycle_vel_err: 0.6762, pts_bbox_NuScenes/motorcycle_attr_err: 0.1800, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5025, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5631, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5741, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.5854, pts_bbox_NuScenes/bicycle_trans_err: 0.2190, pts_bbox_NuScenes/bicycle_scale_err: 0.2919, pts_bbox_NuScenes/bicycle_orient_err: 0.3264, pts_bbox_NuScenes/bicycle_vel_err: 0.1721, pts_bbox_NuScenes/bicycle_attr_err: 0.0062, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7141, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.7897, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8215, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8387, pts_bbox_NuScenes/pedestrian_trans_err: 0.2295, pts_bbox_NuScenes/pedestrian_scale_err: 0.2977, pts_bbox_NuScenes/pedestrian_orient_err: 0.3575, pts_bbox_NuScenes/pedestrian_vel_err: 0.2540, pts_bbox_NuScenes/pedestrian_attr_err: 0.1109, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.5990, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.6607, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.6994, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7384, pts_bbox_NuScenes/traffic_cone_trans_err: 0.2457, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3451, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6517, pts_bbox_NuScenes/mAP: 0.5935
2025-06-11 15:11:04,319 - mmdet - INFO - Epoch [2][50/3517]	lr: 1.866e-03, eta: 9:05:52, time: 1.983, data_time: 0.173, memory: 32518, loss_cls: 0.1741, loss_bbox: 0.3375, d0.loss_cls: 0.2910, d0.loss_bbox: 0.5002, d1.loss_cls: 0.2691, d1.loss_bbox: 0.3607, d2.loss_cls: 0.2764, d2.loss_bbox: 0.3714, d3.loss_cls: 0.2759, d3.loss_bbox: 0.4027, d4.loss_cls: 0.2232, d4.loss_bbox: 0.3655, loss: 3.8476, grad_norm: 24.5737
2025-06-11 15:12:37,911 - mmdet - INFO - Epoch [2][100/3517]	lr: 1.866e-03, eta: 9:04:20, time: 1.872, data_time: 0.049, memory: 32518, loss_cls: 0.1659, loss_bbox: 0.3386, d0.loss_cls: 0.2812, d0.loss_bbox: 0.4947, d1.loss_cls: 0.2586, d1.loss_bbox: 0.3634, d2.loss_cls: 0.2678, d2.loss_bbox: 0.3756, d3.loss_cls: 0.2619, d3.loss_bbox: 0.4044, d4.loss_cls: 0.2041, d4.loss_bbox: 0.3625, loss: 3.7786, grad_norm: 16.6957
2025-06-11 15:14:11,565 - mmdet - INFO - Epoch [2][150/3517]	lr: 1.866e-03, eta: 9:02:47, time: 1.873, data_time: 0.048, memory: 32518, loss_cls: 0.1652, loss_bbox: 0.3464, d0.loss_cls: 0.2762, d0.loss_bbox: 0.4889, d1.loss_cls: 0.2517, d1.loss_bbox: 0.3609, d2.loss_cls: 0.2567, d2.loss_bbox: 0.3745, d3.loss_cls: 0.2548, d3.loss_bbox: 0.3988, d4.loss_cls: 0.2029, d4.loss_bbox: 0.3627, loss: 3.7397, grad_norm: 19.4279
2025-06-11 15:15:45,051 - mmdet - INFO - Epoch [2][200/3517]	lr: 1.866e-03, eta: 9:01:14, time: 1.870, data_time: 0.048, memory: 32518, loss_cls: 0.1597, loss_bbox: 0.3360, d0.loss_cls: 0.2749, d0.loss_bbox: 0.4780, d1.loss_cls: 0.2448, d1.loss_bbox: 0.3523, d2.loss_cls: 0.2498, d2.loss_bbox: 0.3623, d3.loss_cls: 0.2422, d3.loss_bbox: 0.3802, d4.loss_cls: 0.1980, d4.loss_bbox: 0.3475, loss: 3.6257, grad_norm: 14.5344
2025-06-11 15:17:18,551 - mmdet - INFO - Epoch [2][250/3517]	lr: 1.866e-03, eta: 8:59:41, time: 1.870, data_time: 0.049, memory: 32518, loss_cls: 0.1465, loss_bbox: 0.3379, d0.loss_cls: 0.2598, d0.loss_bbox: 0.4640, d1.loss_cls: 0.2297, d1.loss_bbox: 0.3470, d2.loss_cls: 0.2356, d2.loss_bbox: 0.3608, d3.loss_cls: 0.2303, d3.loss_bbox: 0.3812, d4.loss_cls: 0.1804, d4.loss_bbox: 0.3553, loss: 3.5286, grad_norm: 15.4382
2025-06-11 15:18:52,504 - mmdet - INFO - Epoch [2][300/3517]	lr: 1.866e-03, eta: 8:58:10, time: 1.879, data_time: 0.052, memory: 32518, loss_cls: 0.1468, loss_bbox: 0.3318, d0.loss_cls: 0.2628, d0.loss_bbox: 0.4639, d1.loss_cls: 0.2372, d1.loss_bbox: 0.3411, d2.loss_cls: 0.2441, d2.loss_bbox: 0.3500, d3.loss_cls: 0.2371, d3.loss_bbox: 0.3693, d4.loss_cls: 0.1814, d4.loss_bbox: 0.3446, loss: 3.5100, grad_norm: 18.0004
2025-06-11 15:20:26,361 - mmdet - INFO - Epoch [2][350/3517]	lr: 1.866e-03, eta: 8:56:39, time: 1.877, data_time: 0.051, memory: 32518, loss_cls: 0.1645, loss_bbox: 0.3157, d0.loss_cls: 0.2757, d0.loss_bbox: 0.4738, d1.loss_cls: 0.2571, d1.loss_bbox: 0.3452, d2.loss_cls: 0.2665, d2.loss_bbox: 0.3520, d3.loss_cls: 0.2663, d3.loss_bbox: 0.3672, d4.loss_cls: 0.2053, d4.loss_bbox: 0.3328, loss: 3.6221, grad_norm: 27.3638
2025-06-11 15:22:00,413 - mmdet - INFO - Epoch [2][400/3517]	lr: 1.866e-03, eta: 8:55:08, time: 1.881, data_time: 0.050, memory: 32518, loss_cls: 0.1650, loss_bbox: 0.3096, d0.loss_cls: 0.2704, d0.loss_bbox: 0.4688, d1.loss_cls: 0.2518, d1.loss_bbox: 0.3462, d2.loss_cls: 0.2615, d2.loss_bbox: 0.3539, d3.loss_cls: 0.2542, d3.loss_bbox: 0.3686, d4.loss_cls: 0.1973, d4.loss_bbox: 0.3396, loss: 3.5868, grad_norm: 16.1088
2025-06-11 15:23:35,033 - mmdet - INFO - Epoch [2][450/3517]	lr: 1.866e-03, eta: 8:53:40, time: 1.892, data_time: 0.070, memory: 32518, loss_cls: 0.1585, loss_bbox: 0.3023, d0.loss_cls: 0.2629, d0.loss_bbox: 0.4476, d1.loss_cls: 0.2437, d1.loss_bbox: 0.3280, d2.loss_cls: 0.2485, d2.loss_bbox: 0.3352, d3.loss_cls: 0.2409, d3.loss_bbox: 0.3524, d4.loss_cls: 0.1940, d4.loss_bbox: 0.3245, loss: 3.4387, grad_norm: 15.6683
2025-06-11 15:25:08,601 - mmdet - INFO - Epoch [2][500/3517]	lr: 1.866e-03, eta: 8:52:07, time: 1.871, data_time: 0.048, memory: 32518, loss_cls: 0.1629, loss_bbox: 0.3112, d0.loss_cls: 0.2615, d0.loss_bbox: 0.4623, d1.loss_cls: 0.2359, d1.loss_bbox: 0.3397, d2.loss_cls: 0.2443, d2.loss_bbox: 0.3530, d3.loss_cls: 0.2431, d3.loss_bbox: 0.3656, d4.loss_cls: 0.1969, d4.loss_bbox: 0.3415, loss: 3.5180, grad_norm: 22.8984
2025-06-11 15:26:42,958 - mmdet - INFO - Epoch [2][550/3517]	lr: 1.866e-03, eta: 8:50:38, time: 1.887, data_time: 0.051, memory: 32518, loss_cls: 0.1500, loss_bbox: 0.3268, d0.loss_cls: 0.2559, d0.loss_bbox: 0.4638, d1.loss_cls: 0.2295, d1.loss_bbox: 0.3406, d2.loss_cls: 0.2354, d2.loss_bbox: 0.3503, d3.loss_cls: 0.2271, d3.loss_bbox: 0.3675, d4.loss_cls: 0.1834, d4.loss_bbox: 0.3383, loss: 3.4686, grad_norm: 15.7279
2025-06-11 15:28:16,649 - mmdet - INFO - Epoch [2][600/3517]	lr: 1.866e-03, eta: 8:49:05, time: 1.874, data_time: 0.047, memory: 32518, loss_cls: 0.1495, loss_bbox: 0.3158, d0.loss_cls: 0.2474, d0.loss_bbox: 0.4505, d1.loss_cls: 0.2233, d1.loss_bbox: 0.3313, d2.loss_cls: 0.2257, d2.loss_bbox: 0.3440, d3.loss_cls: 0.2179, d3.loss_bbox: 0.3644, d4.loss_cls: 0.1807, d4.loss_bbox: 0.3347, loss: 3.3850, grad_norm: 15.1258
2025-06-11 15:29:50,230 - mmdet - INFO - Epoch [2][650/3517]	lr: 1.866e-03, eta: 8:47:32, time: 1.872, data_time: 0.050, memory: 32518, loss_cls: 0.1585, loss_bbox: 0.3220, d0.loss_cls: 0.2555, d0.loss_bbox: 0.4674, d1.loss_cls: 0.2291, d1.loss_bbox: 0.3446, d2.loss_cls: 0.2328, d2.loss_bbox: 0.3501, d3.loss_cls: 0.2256, d3.loss_bbox: 0.3635, d4.loss_cls: 0.1890, d4.loss_bbox: 0.3417, loss: 3.4798, grad_norm: 14.4350
2025-06-11 15:31:23,856 - mmdet - INFO - Epoch [2][700/3517]	lr: 1.866e-03, eta: 8:46:00, time: 1.873, data_time: 0.051, memory: 32518, loss_cls: 0.1629, loss_bbox: 0.3154, d0.loss_cls: 0.2633, d0.loss_bbox: 0.4596, d1.loss_cls: 0.2412, d1.loss_bbox: 0.3365, d2.loss_cls: 0.2499, d2.loss_bbox: 0.3410, d3.loss_cls: 0.2396, d3.loss_bbox: 0.3617, d4.loss_cls: 0.1979, d4.loss_bbox: 0.3369, loss: 3.5059, grad_norm: 22.3620
2025-06-11 15:32:57,480 - mmdet - INFO - Epoch [2][750/3517]	lr: 1.866e-03, eta: 8:44:27, time: 1.872, data_time: 0.047, memory: 32518, loss_cls: 0.1553, loss_bbox: 0.3204, d0.loss_cls: 0.2622, d0.loss_bbox: 0.4679, d1.loss_cls: 0.2379, d1.loss_bbox: 0.3466, d2.loss_cls: 0.2429, d2.loss_bbox: 0.3514, d3.loss_cls: 0.2308, d3.loss_bbox: 0.3706, d4.loss_cls: 0.1873, d4.loss_bbox: 0.3428, loss: 3.5161, grad_norm: 18.4487
2025-06-11 15:34:31,329 - mmdet - INFO - Epoch [2][800/3517]	lr: 1.866e-03, eta: 8:42:55, time: 1.877, data_time: 0.050, memory: 32518, loss_cls: 0.1571, loss_bbox: 0.3326, d0.loss_cls: 0.2633, d0.loss_bbox: 0.4766, d1.loss_cls: 0.2414, d1.loss_bbox: 0.3453, d2.loss_cls: 0.2455, d2.loss_bbox: 0.3521, d3.loss_cls: 0.2332, d3.loss_bbox: 0.3708, d4.loss_cls: 0.1917, d4.loss_bbox: 0.3485, loss: 3.5581, grad_norm: 17.1228
2025-06-11 15:36:05,005 - mmdet - INFO - Epoch [2][850/3517]	lr: 1.866e-03, eta: 8:41:22, time: 1.874, data_time: 0.050, memory: 32518, loss_cls: 0.1541, loss_bbox: 0.3013, d0.loss_cls: 0.2616, d0.loss_bbox: 0.4491, d1.loss_cls: 0.2391, d1.loss_bbox: 0.3250, d2.loss_cls: 0.2462, d2.loss_bbox: 0.3325, d3.loss_cls: 0.2413, d3.loss_bbox: 0.3451, d4.loss_cls: 0.1913, d4.loss_bbox: 0.3176, loss: 3.4043, grad_norm: 20.4993
2025-06-11 15:37:38,626 - mmdet - INFO - Epoch [2][900/3517]	lr: 1.866e-03, eta: 8:39:49, time: 1.872, data_time: 0.056, memory: 32518, loss_cls: 0.1452, loss_bbox: 0.3209, d0.loss_cls: 0.2548, d0.loss_bbox: 0.4457, d1.loss_cls: 0.2227, d1.loss_bbox: 0.3288, d2.loss_cls: 0.2287, d2.loss_bbox: 0.3334, d3.loss_cls: 0.2198, d3.loss_bbox: 0.3442, d4.loss_cls: 0.1758, d4.loss_bbox: 0.3351, loss: 3.3550, grad_norm: 18.9069
2025-06-11 15:39:11,759 - mmdet - INFO - Epoch [2][950/3517]	lr: 1.866e-03, eta: 8:38:15, time: 1.863, data_time: 0.052, memory: 32518, loss_cls: 0.1516, loss_bbox: 0.3137, d0.loss_cls: 0.2533, d0.loss_bbox: 0.4561, d1.loss_cls: 0.2210, d1.loss_bbox: 0.3318, d2.loss_cls: 0.2268, d2.loss_bbox: 0.3436, d3.loss_cls: 0.2157, d3.loss_bbox: 0.3541, d4.loss_cls: 0.1812, d4.loss_bbox: 0.3378, loss: 3.3868, grad_norm: 19.3699
2025-06-11 15:40:44,724 - mmdet - INFO - Epoch [2][1000/3517]	lr: 1.866e-03, eta: 8:36:39, time: 1.859, data_time: 0.057, memory: 32518, loss_cls: 0.1448, loss_bbox: 0.3101, d0.loss_cls: 0.2471, d0.loss_bbox: 0.4351, d1.loss_cls: 0.2197, d1.loss_bbox: 0.3209, d2.loss_cls: 0.2258, d2.loss_bbox: 0.3259, d3.loss_cls: 0.2170, d3.loss_bbox: 0.3382, d4.loss_cls: 0.1764, d4.loss_bbox: 0.3225, loss: 3.2836, grad_norm: 15.3741
2025-06-11 15:42:18,730 - mmdet - INFO - Epoch [2][1050/3517]	lr: 1.866e-03, eta: 8:35:08, time: 1.880, data_time: 0.052, memory: 32518, loss_cls: 0.1511, loss_bbox: 0.3161, d0.loss_cls: 0.2539, d0.loss_bbox: 0.4435, d1.loss_cls: 0.2262, d1.loss_bbox: 0.3311, d2.loss_cls: 0.3097, d2.loss_bbox: 0.3443, d3.loss_cls: 0.2253, d3.loss_bbox: 0.3510, d4.loss_cls: 0.1788, d4.loss_bbox: 0.3387, loss: 3.4697, grad_norm: 25.8751
2025-06-11 15:43:52,601 - mmdet - INFO - Epoch [2][1100/3517]	lr: 1.866e-03, eta: 8:33:36, time: 1.877, data_time: 0.050, memory: 32518, loss_cls: 0.1502, loss_bbox: 0.3134, d0.loss_cls: 0.2458, d0.loss_bbox: 0.4455, d1.loss_cls: 0.2227, d1.loss_bbox: 0.3313, d2.loss_cls: 0.2355, d2.loss_bbox: 0.3327, d3.loss_cls: 0.2203, d3.loss_bbox: 0.3442, d4.loss_cls: 0.1783, d4.loss_bbox: 0.3266, loss: 3.3465, grad_norm: 17.4695
2025-06-11 15:45:26,597 - mmdet - INFO - Epoch [2][1150/3517]	lr: 1.866e-03, eta: 8:32:04, time: 1.880, data_time: 0.052, memory: 32518, loss_cls: 0.1552, loss_bbox: 0.3364, d0.loss_cls: 0.2478, d0.loss_bbox: 0.4510, d1.loss_cls: 0.2245, d1.loss_bbox: 0.3289, d2.loss_cls: 0.2313, d2.loss_bbox: 0.3327, d3.loss_cls: 0.2195, d3.loss_bbox: 0.3479, d4.loss_cls: 0.1859, d4.loss_bbox: 0.3350, loss: 3.3960, grad_norm: 17.7800
2025-06-11 15:47:00,794 - mmdet - INFO - Epoch [2][1200/3517]	lr: 1.866e-03, eta: 8:30:33, time: 1.884, data_time: 0.054, memory: 32518, loss_cls: 0.1484, loss_bbox: 0.3186, d0.loss_cls: 0.2524, d0.loss_bbox: 0.4427, d1.loss_cls: 0.2216, d1.loss_bbox: 0.3302, d2.loss_cls: 0.2239, d2.loss_bbox: 0.3357, d3.loss_cls: 0.2140, d3.loss_bbox: 0.3489, d4.loss_cls: 0.1790, d4.loss_bbox: 0.3325, loss: 3.3479, grad_norm: 17.5425
2025-06-11 15:48:34,408 - mmdet - INFO - Epoch [2][1250/3517]	lr: 1.866e-03, eta: 8:29:00, time: 1.872, data_time: 0.051, memory: 32518, loss_cls: 0.1484, loss_bbox: 0.3484, d0.loss_cls: 0.2505, d0.loss_bbox: 0.4423, d1.loss_cls: 0.2245, d1.loss_bbox: 0.3272, d2.loss_cls: 0.2295, d2.loss_bbox: 0.3311, d3.loss_cls: 0.2212, d3.loss_bbox: 0.3429, d4.loss_cls: 0.1765, d4.loss_bbox: 0.3446, loss: 3.3871, grad_norm: 16.7956
2025-06-11 15:50:07,550 - mmdet - INFO - Epoch [2][1300/3517]	lr: 1.866e-03, eta: 8:27:26, time: 1.863, data_time: 0.056, memory: 32518, loss_cls: 0.1526, loss_bbox: 0.3228, d0.loss_cls: 0.2460, d0.loss_bbox: 0.4454, d1.loss_cls: 0.2220, d1.loss_bbox: 0.3265, d2.loss_cls: 0.2293, d2.loss_bbox: 0.3300, d3.loss_cls: 0.2180, d3.loss_bbox: 0.3393, d4.loss_cls: 0.1809, d4.loss_bbox: 0.3263, loss: 3.3391, grad_norm: 17.9061
2025-06-11 15:51:41,831 - mmdet - INFO - Epoch [2][1350/3517]	lr: 1.866e-03, eta: 8:25:55, time: 1.886, data_time: 0.064, memory: 32518, loss_cls: 0.1433, loss_bbox: 0.3036, d0.loss_cls: 0.2484, d0.loss_bbox: 0.4383, d1.loss_cls: 0.2213, d1.loss_bbox: 0.3217, d2.loss_cls: 0.2260, d2.loss_bbox: 0.3245, d3.loss_cls: 0.2170, d3.loss_bbox: 0.3353, d4.loss_cls: 0.1736, d4.loss_bbox: 0.3191, loss: 3.2722, grad_norm: 17.0807
2025-06-11 15:53:19,003 - mmdet - INFO - Epoch [2][1400/3517]	lr: 1.866e-03, eta: 8:24:33, time: 1.943, data_time: 0.064, memory: 32518, loss_cls: 0.1459, loss_bbox: 0.3072, d0.loss_cls: 0.2544, d0.loss_bbox: 0.4621, d1.loss_cls: 0.2283, d1.loss_bbox: 0.3358, d2.loss_cls: 0.2331, d2.loss_bbox: 0.3392, d3.loss_cls: 0.2257, d3.loss_bbox: 0.3490, d4.loss_cls: 0.1777, d4.loss_bbox: 0.3299, loss: 3.3882, grad_norm: 20.1191
2025-06-11 15:54:52,461 - mmdet - INFO - Epoch [2][1450/3517]	lr: 1.866e-03, eta: 8:23:00, time: 1.869, data_time: 0.054, memory: 32518, loss_cls: 0.1439, loss_bbox: 0.2958, d0.loss_cls: 0.2450, d0.loss_bbox: 0.4553, d1.loss_cls: 0.2226, d1.loss_bbox: 0.3187, d2.loss_cls: 0.2266, d2.loss_bbox: 0.3190, d3.loss_cls: 0.2173, d3.loss_bbox: 0.3281, d4.loss_cls: 0.1738, d4.loss_bbox: 0.3181, loss: 3.2641, grad_norm: 19.7753
2025-06-11 15:56:25,272 - mmdet - INFO - Epoch [2][1500/3517]	lr: 1.866e-03, eta: 8:21:24, time: 1.856, data_time: 0.055, memory: 32518, loss_cls: 0.1526, loss_bbox: 0.3148, d0.loss_cls: 0.2549, d0.loss_bbox: 0.4642, d1.loss_cls: 0.2282, d1.loss_bbox: 0.3398, d2.loss_cls: 0.2309, d2.loss_bbox: 0.3497, d3.loss_cls: 0.2230, d3.loss_bbox: 0.3625, d4.loss_cls: 0.1797, d4.loss_bbox: 0.3415, loss: 3.4418, grad_norm: 18.6187
2025-06-11 15:57:58,359 - mmdet - INFO - Epoch [2][1550/3517]	lr: 1.866e-03, eta: 8:19:49, time: 1.862, data_time: 0.056, memory: 32518, loss_cls: 0.1554, loss_bbox: 0.3049, d0.loss_cls: 0.2475, d0.loss_bbox: 0.4434, d1.loss_cls: 0.2250, d1.loss_bbox: 0.3255, d2.loss_cls: 0.2309, d2.loss_bbox: 0.3271, d3.loss_cls: 0.2254, d3.loss_bbox: 0.3407, d4.loss_cls: 0.1851, d4.loss_bbox: 0.3269, loss: 3.3379, grad_norm: 20.9057
2025-06-11 15:59:31,103 - mmdet - INFO - Epoch [2][1600/3517]	lr: 1.866e-03, eta: 8:18:13, time: 1.855, data_time: 0.056, memory: 32518, loss_cls: 0.1518, loss_bbox: 0.3064, d0.loss_cls: 0.2579, d0.loss_bbox: 0.4556, d1.loss_cls: 0.2367, d1.loss_bbox: 0.3349, d2.loss_cls: 0.2417, d2.loss_bbox: 0.3386, d3.loss_cls: 0.2337, d3.loss_bbox: 0.3523, d4.loss_cls: 0.1864, d4.loss_bbox: 0.3285, loss: 3.4245, grad_norm: 16.4016
2025-06-11 16:01:04,037 - mmdet - INFO - Epoch [2][1650/3517]	lr: 1.866e-03, eta: 8:16:38, time: 1.859, data_time: 0.057, memory: 32518, loss_cls: 0.1472, loss_bbox: 0.2889, d0.loss_cls: 0.2414, d0.loss_bbox: 0.4316, d1.loss_cls: 0.2195, d1.loss_bbox: 0.3159, d2.loss_cls: 0.2268, d2.loss_bbox: 0.3178, d3.loss_cls: 0.2232, d3.loss_bbox: 0.3277, d4.loss_cls: 0.1870, d4.loss_bbox: 0.3070, loss: 3.2342, grad_norm: 16.2154
2025-06-11 16:02:37,457 - mmdet - INFO - Epoch [2][1700/3517]	lr: 1.866e-03, eta: 8:15:04, time: 1.868, data_time: 0.055, memory: 32518, loss_cls: 0.1481, loss_bbox: 0.3166, d0.loss_cls: 0.2479, d0.loss_bbox: 0.4489, d1.loss_cls: 0.2276, d1.loss_bbox: 0.3354, d2.loss_cls: 0.2335, d2.loss_bbox: 0.3344, d3.loss_cls: 0.2239, d3.loss_bbox: 0.3465, d4.loss_cls: 0.1844, d4.loss_bbox: 0.3308, loss: 3.3780, grad_norm: 17.3886
2025-06-11 16:04:10,736 - mmdet - INFO - Epoch [2][1750/3517]	lr: 1.866e-03, eta: 8:13:30, time: 1.866, data_time: 0.058, memory: 32518, loss_cls: 0.1471, loss_bbox: 0.3018, d0.loss_cls: 0.2482, d0.loss_bbox: 0.4454, d1.loss_cls: 0.2265, d1.loss_bbox: 0.3337, d2.loss_cls: 0.2303, d2.loss_bbox: 0.3408, d3.loss_cls: 0.2282, d3.loss_bbox: 0.3553, d4.loss_cls: 0.1853, d4.loss_bbox: 0.3278, loss: 3.3703, grad_norm: 16.8904
2025-06-11 16:05:44,742 - mmdet - INFO - Epoch [2][1800/3517]	lr: 1.866e-03, eta: 8:11:58, time: 1.880, data_time: 0.057, memory: 32518, loss_cls: 0.1436, loss_bbox: 0.3356, d0.loss_cls: 0.2388, d0.loss_bbox: 0.4313, d1.loss_cls: 0.2185, d1.loss_bbox: 0.3291, d2.loss_cls: 0.2229, d2.loss_bbox: 0.3382, d3.loss_cls: 0.2239, d3.loss_bbox: 0.3597, d4.loss_cls: 0.1775, d4.loss_bbox: 0.3439, loss: 3.3629, grad_norm: 18.8781
2025-06-11 16:07:24,832 - mmdet - INFO - Epoch [2][1850/3517]	lr: 1.866e-03, eta: 8:10:44, time: 2.002, data_time: 0.192, memory: 32518, loss_cls: 0.1418, loss_bbox: 0.3144, d0.loss_cls: 0.2423, d0.loss_bbox: 0.4327, d1.loss_cls: 0.2105, d1.loss_bbox: 0.3253, d2.loss_cls: 0.2154, d2.loss_bbox: 0.3309, d3.loss_cls: 0.2124, d3.loss_bbox: 0.3485, d4.loss_cls: 0.1677, d4.loss_bbox: 0.3280, loss: 3.2700, grad_norm: 22.2866
2025-06-11 16:09:42,589 - mmdet - INFO - Epoch [2][1900/3517]	lr: 1.866e-03, eta: 8:11:18, time: 2.755, data_time: 0.862, memory: 32518, loss_cls: 0.1424, loss_bbox: 0.3118, d0.loss_cls: 0.2433, d0.loss_bbox: 0.4400, d1.loss_cls: 0.2171, d1.loss_bbox: 0.3257, d2.loss_cls: 0.2211, d2.loss_bbox: 0.3323, d3.loss_cls: 0.2166, d3.loss_bbox: 0.3459, d4.loss_cls: 0.1684, d4.loss_bbox: 0.3261, loss: 3.2908, grad_norm: 36.1064
2025-06-11 16:11:21,396 - mmdet - INFO - Epoch [2][1950/3517]	lr: 1.866e-03, eta: 8:09:58, time: 1.976, data_time: 0.092, memory: 32518, loss_cls: 0.1428, loss_bbox: 0.3128, d0.loss_cls: 0.2438, d0.loss_bbox: 0.4292, d1.loss_cls: 0.2206, d1.loss_bbox: 0.3215, d2.loss_cls: 0.2261, d2.loss_bbox: 0.3260, d3.loss_cls: 0.2243, d3.loss_bbox: 0.3398, d4.loss_cls: 0.1708, d4.loss_bbox: 0.3288, loss: 3.2865, grad_norm: 23.2207
2025-06-11 16:12:55,817 - mmdet - INFO - Epoch [2][2000/3517]	lr: 1.866e-03, eta: 8:08:25, time: 1.888, data_time: 0.060, memory: 32518, loss_cls: 0.1292, loss_bbox: 0.2881, d0.loss_cls: 0.2369, d0.loss_bbox: 0.4226, d1.loss_cls: 0.2106, d1.loss_bbox: 0.3131, d2.loss_cls: 0.2120, d2.loss_bbox: 0.3148, d3.loss_cls: 0.2121, d3.loss_bbox: 0.3215, d4.loss_cls: 0.1553, d4.loss_bbox: 0.3064, loss: 3.1226, grad_norm: 18.4951
2025-06-11 16:14:29,898 - mmdet - INFO - Epoch [2][2050/3517]	lr: 1.866e-03, eta: 8:06:51, time: 1.882, data_time: 0.053, memory: 32518, loss_cls: 0.1345, loss_bbox: 0.3029, d0.loss_cls: 0.2609, d0.loss_bbox: 0.4583, d1.loss_cls: 0.2222, d1.loss_bbox: 0.3318, d2.loss_cls: 0.2260, d2.loss_bbox: 0.3347, d3.loss_cls: 0.2249, d3.loss_bbox: 0.3450, d4.loss_cls: 0.1687, d4.loss_bbox: 0.3369, loss: 3.3469, grad_norm: 26.8502
2025-06-11 16:16:03,972 - mmdet - INFO - Epoch [2][2100/3517]	lr: 1.866e-03, eta: 8:05:17, time: 1.881, data_time: 0.051, memory: 32518, loss_cls: 0.1501, loss_bbox: 0.2918, d0.loss_cls: 0.2558, d0.loss_bbox: 0.4375, d1.loss_cls: 0.2295, d1.loss_bbox: 0.3194, d2.loss_cls: 0.2319, d2.loss_bbox: 0.3185, d3.loss_cls: 0.2296, d3.loss_bbox: 0.3304, d4.loss_cls: 0.1822, d4.loss_bbox: 0.3108, loss: 3.2876, grad_norm: 18.7986
2025-06-11 16:17:37,708 - mmdet - INFO - Epoch [2][2150/3517]	lr: 1.866e-03, eta: 8:03:43, time: 1.875, data_time: 0.052, memory: 32518, loss_cls: 0.1471, loss_bbox: 0.2970, d0.loss_cls: 0.2508, d0.loss_bbox: 0.4402, d1.loss_cls: 0.2218, d1.loss_bbox: 0.3210, d2.loss_cls: 0.2305, d2.loss_bbox: 0.3242, d3.loss_cls: 0.2261, d3.loss_bbox: 0.3319, d4.loss_cls: 0.1810, d4.loss_bbox: 0.3187, loss: 3.2902, grad_norm: 20.1423
2025-06-11 16:19:10,680 - mmdet - INFO - Epoch [2][2200/3517]	lr: 1.866e-03, eta: 8:02:06, time: 1.859, data_time: 0.057, memory: 32518, loss_cls: 0.1388, loss_bbox: 0.3304, d0.loss_cls: 0.2516, d0.loss_bbox: 0.4515, d1.loss_cls: 0.2219, d1.loss_bbox: 0.3389, d2.loss_cls: 0.2251, d2.loss_bbox: 0.3432, d3.loss_cls: 0.2203, d3.loss_bbox: 0.3556, d4.loss_cls: 0.1674, d4.loss_bbox: 0.3434, loss: 3.3881, grad_norm: 18.3632
2025-06-11 16:20:44,352 - mmdet - INFO - Epoch [2][2250/3517]	lr: 1.866e-03, eta: 8:00:31, time: 1.873, data_time: 0.060, memory: 32518, loss_cls: 0.1514, loss_bbox: 0.3204, d0.loss_cls: 0.2476, d0.loss_bbox: 0.4350, d1.loss_cls: 0.2249, d1.loss_bbox: 0.3229, d2.loss_cls: 0.2288, d2.loss_bbox: 0.3286, d3.loss_cls: 0.2254, d3.loss_bbox: 0.3448, d4.loss_cls: 0.1760, d4.loss_bbox: 0.3359, loss: 3.3417, grad_norm: 22.9038
2025-06-11 16:22:18,063 - mmdet - INFO - Epoch [2][2300/3517]	lr: 1.866e-03, eta: 7:58:56, time: 1.874, data_time: 0.061, memory: 32518, loss_cls: 0.1424, loss_bbox: 0.2980, d0.loss_cls: 0.2517, d0.loss_bbox: 0.4321, d1.loss_cls: 0.2245, d1.loss_bbox: 0.3146, d2.loss_cls: 0.2284, d2.loss_bbox: 0.3147, d3.loss_cls: 0.2246, d3.loss_bbox: 0.3278, d4.loss_cls: 0.1714, d4.loss_bbox: 0.3106, loss: 3.2407, grad_norm: 18.5987
2025-06-11 16:23:52,339 - mmdet - INFO - Epoch [2][2350/3517]	lr: 1.866e-03, eta: 7:57:23, time: 1.886, data_time: 0.075, memory: 32518, loss_cls: 0.1331, loss_bbox: 0.2952, d0.loss_cls: 0.2436, d0.loss_bbox: 0.4299, d1.loss_cls: 0.2215, d1.loss_bbox: 0.3116, d2.loss_cls: 0.2287, d2.loss_bbox: 0.3084, d3.loss_cls: 0.2263, d3.loss_bbox: 0.3202, d4.loss_cls: 0.1670, d4.loss_bbox: 0.3090, loss: 3.1944, grad_norm: 16.2210
2025-06-11 16:25:26,146 - mmdet - INFO - Epoch [2][2400/3517]	lr: 1.866e-03, eta: 7:55:48, time: 1.876, data_time: 0.055, memory: 32518, loss_cls: 0.1439, loss_bbox: 0.3070, d0.loss_cls: 0.2532, d0.loss_bbox: 0.4345, d1.loss_cls: 0.2266, d1.loss_bbox: 0.3214, d2.loss_cls: 0.2287, d2.loss_bbox: 0.3227, d3.loss_cls: 0.2284, d3.loss_bbox: 0.3358, d4.loss_cls: 0.1770, d4.loss_bbox: 0.3116, loss: 3.2908, grad_norm: 55.0488
2025-06-11 16:27:00,946 - mmdet - INFO - Epoch [2][2450/3517]	lr: 1.866e-03, eta: 7:54:16, time: 1.896, data_time: 0.059, memory: 32518, loss_cls: 0.1402, loss_bbox: 0.3005, d0.loss_cls: 0.2467, d0.loss_bbox: 0.4329, d1.loss_cls: 0.2194, d1.loss_bbox: 0.3222, d2.loss_cls: 0.2255, d2.loss_bbox: 0.3229, d3.loss_cls: 0.2247, d3.loss_bbox: 0.3392, d4.loss_cls: 0.1742, d4.loss_bbox: 0.3146, loss: 3.2631, grad_norm: 53.4725
2025-06-11 16:28:35,421 - mmdet - INFO - Epoch [2][2500/3517]	lr: 1.866e-03, eta: 7:52:43, time: 1.889, data_time: 0.054, memory: 32518, loss_cls: 0.1353, loss_bbox: 0.3123, d0.loss_cls: 0.2428, d0.loss_bbox: 0.4286, d1.loss_cls: 0.2150, d1.loss_bbox: 0.3190, d2.loss_cls: 0.2198, d2.loss_bbox: 0.3162, d3.loss_cls: 0.2173, d3.loss_bbox: 0.3286, d4.loss_cls: 0.1650, d4.loss_bbox: 0.3156, loss: 3.2155, grad_norm: 17.6306
2025-06-11 16:30:09,490 - mmdet - INFO - Epoch [2][2550/3517]	lr: 1.866e-03, eta: 7:51:10, time: 1.881, data_time: 0.056, memory: 32518, loss_cls: 0.1407, loss_bbox: 0.2975, d0.loss_cls: 0.2422, d0.loss_bbox: 0.4255, d1.loss_cls: 0.2193, d1.loss_bbox: 0.3186, d2.loss_cls: 0.2235, d2.loss_bbox: 0.3153, d3.loss_cls: 0.2200, d3.loss_bbox: 0.3271, d4.loss_cls: 0.1699, d4.loss_bbox: 0.3102, loss: 3.2099, grad_norm: 15.9103
2025-06-11 16:31:43,647 - mmdet - INFO - Epoch [2][2600/3517]	lr: 1.866e-03, eta: 7:49:36, time: 1.883, data_time: 0.058, memory: 32518, loss_cls: 0.1404, loss_bbox: 0.3002, d0.loss_cls: 0.2396, d0.loss_bbox: 0.4303, d1.loss_cls: 0.2183, d1.loss_bbox: 0.3191, d2.loss_cls: 0.2233, d2.loss_bbox: 0.3197, d3.loss_cls: 0.2223, d3.loss_bbox: 0.3311, d4.loss_cls: 0.1737, d4.loss_bbox: 0.3135, loss: 3.2314, grad_norm: 14.8980
2025-06-11 16:33:17,043 - mmdet - INFO - Epoch [2][2650/3517]	lr: 1.866e-03, eta: 7:48:00, time: 1.868, data_time: 0.057, memory: 32518, loss_cls: 0.1430, loss_bbox: 0.3231, d0.loss_cls: 0.2371, d0.loss_bbox: 0.4212, d1.loss_cls: 0.2102, d1.loss_bbox: 0.3263, d2.loss_cls: 0.2109, d2.loss_bbox: 0.3326, d3.loss_cls: 0.2071, d3.loss_bbox: 0.3559, d4.loss_cls: 0.1657, d4.loss_bbox: 0.3414, loss: 3.2746, grad_norm: 25.3681
2025-06-11 16:34:50,370 - mmdet - INFO - Epoch [2][2700/3517]	lr: 1.866e-03, eta: 7:46:25, time: 1.867, data_time: 0.058, memory: 32518, loss_cls: 0.1359, loss_bbox: 0.3174, d0.loss_cls: 0.2379, d0.loss_bbox: 0.4284, d1.loss_cls: 0.2155, d1.loss_bbox: 0.3280, d2.loss_cls: 0.2158, d2.loss_bbox: 0.3296, d3.loss_cls: 0.2129, d3.loss_bbox: 0.3437, d4.loss_cls: 0.1665, d4.loss_bbox: 0.3300, loss: 3.2616, grad_norm: 17.7987
2025-06-11 16:36:23,865 - mmdet - INFO - Epoch [2][2750/3517]	lr: 1.866e-03, eta: 7:44:50, time: 1.870, data_time: 0.052, memory: 32518, loss_cls: 0.1389, loss_bbox: 0.3180, d0.loss_cls: 0.2348, d0.loss_bbox: 0.4374, d1.loss_cls: 0.2156, d1.loss_bbox: 0.3238, d2.loss_cls: 0.2182, d2.loss_bbox: 0.3226, d3.loss_cls: 0.2141, d3.loss_bbox: 0.3367, d4.loss_cls: 0.1697, d4.loss_bbox: 0.3311, loss: 3.2610, grad_norm: 19.3394
2025-06-11 16:37:57,569 - mmdet - INFO - Epoch [2][2800/3517]	lr: 1.866e-03, eta: 7:43:15, time: 1.874, data_time: 0.058, memory: 32518, loss_cls: 0.1317, loss_bbox: 0.3036, d0.loss_cls: 0.2298, d0.loss_bbox: 0.4252, d1.loss_cls: 0.2054, d1.loss_bbox: 0.3196, d2.loss_cls: 0.2079, d2.loss_bbox: 0.3184, d3.loss_cls: 0.2029, d3.loss_bbox: 0.3287, d4.loss_cls: 0.1567, d4.loss_bbox: 0.3142, loss: 3.1441, grad_norm: 14.3156
2025-06-11 16:39:31,867 - mmdet - INFO - Epoch [2][2850/3517]	lr: 1.866e-03, eta: 7:41:42, time: 1.886, data_time: 0.070, memory: 32518, loss_cls: 0.1315, loss_bbox: 0.2796, d0.loss_cls: 0.2339, d0.loss_bbox: 0.4095, d1.loss_cls: 0.2074, d1.loss_bbox: 0.3023, d2.loss_cls: 0.2063, d2.loss_bbox: 0.3035, d3.loss_cls: 0.2026, d3.loss_bbox: 0.3152, d4.loss_cls: 0.1614, d4.loss_bbox: 0.2958, loss: 3.0490, grad_norm: 13.5771
2025-06-11 16:41:05,695 - mmdet - INFO - Epoch [2][2900/3517]	lr: 1.866e-03, eta: 7:40:07, time: 1.877, data_time: 0.053, memory: 32518, loss_cls: 0.1408, loss_bbox: 0.2927, d0.loss_cls: 0.2397, d0.loss_bbox: 0.4195, d1.loss_cls: 0.2128, d1.loss_bbox: 0.3112, d2.loss_cls: 0.2157, d2.loss_bbox: 0.3126, d3.loss_cls: 0.2152, d3.loss_bbox: 0.3237, d4.loss_cls: 0.1740, d4.loss_bbox: 0.3088, loss: 3.1669, grad_norm: 14.9747
2025-06-11 16:42:38,916 - mmdet - INFO - Epoch [2][2950/3517]	lr: 1.866e-03, eta: 7:38:31, time: 1.864, data_time: 0.052, memory: 32518, loss_cls: 0.1492, loss_bbox: 0.3022, d0.loss_cls: 0.2383, d0.loss_bbox: 0.4218, d1.loss_cls: 0.2103, d1.loss_bbox: 0.3174, d2.loss_cls: 0.2161, d2.loss_bbox: 0.3206, d3.loss_cls: 0.2198, d3.loss_bbox: 0.3295, d4.loss_cls: 0.1888, d4.loss_bbox: 0.3172, loss: 3.2311, grad_norm: 18.4375
2025-06-11 16:44:12,316 - mmdet - INFO - Epoch [2][3000/3517]	lr: 1.866e-03, eta: 7:36:56, time: 1.868, data_time: 0.057, memory: 32518, loss_cls: 0.1396, loss_bbox: 0.2877, d0.loss_cls: 0.2388, d0.loss_bbox: 0.4163, d1.loss_cls: 0.2082, d1.loss_bbox: 0.3095, d2.loss_cls: 0.2123, d2.loss_bbox: 0.3124, d3.loss_cls: 0.2145, d3.loss_bbox: 0.3257, d4.loss_cls: 0.1713, d4.loss_bbox: 0.3098, loss: 3.1461, grad_norm: 18.0561
2025-06-11 16:45:46,551 - mmdet - INFO - Epoch [2][3050/3517]	lr: 1.866e-03, eta: 7:35:23, time: 1.885, data_time: 0.055, memory: 32518, loss_cls: 0.1286, loss_bbox: 0.2868, d0.loss_cls: 0.2312, d0.loss_bbox: 0.4117, d1.loss_cls: 0.2003, d1.loss_bbox: 0.3108, d2.loss_cls: 0.2041, d2.loss_bbox: 0.3065, d3.loss_cls: 0.2072, d3.loss_bbox: 0.3179, d4.loss_cls: 0.1593, d4.loss_bbox: 0.3024, loss: 3.0668, grad_norm: 14.9435
2025-06-11 16:47:20,299 - mmdet - INFO - Epoch [2][3100/3517]	lr: 1.866e-03, eta: 7:33:48, time: 1.875, data_time: 0.056, memory: 32518, loss_cls: 0.1393, loss_bbox: 0.2832, d0.loss_cls: 0.2382, d0.loss_bbox: 0.4246, d1.loss_cls: 0.2112, d1.loss_bbox: 0.3069, d2.loss_cls: 0.2112, d2.loss_bbox: 0.3061, d3.loss_cls: 0.2090, d3.loss_bbox: 0.3191, d4.loss_cls: 0.1677, d4.loss_bbox: 0.3053, loss: 3.1219, grad_norm: 22.6945
2025-06-11 16:48:53,681 - mmdet - INFO - Epoch [2][3150/3517]	lr: 1.866e-03, eta: 7:32:13, time: 1.868, data_time: 0.059, memory: 32518, loss_cls: 0.1349, loss_bbox: 0.2970, d0.loss_cls: 0.2343, d0.loss_bbox: 0.4179, d1.loss_cls: 0.2075, d1.loss_bbox: 0.3071, d2.loss_cls: 0.2115, d2.loss_bbox: 0.3119, d3.loss_cls: 0.2091, d3.loss_bbox: 0.3176, d4.loss_cls: 0.1619, d4.loss_bbox: 0.3103, loss: 3.1210, grad_norm: 18.5766
2025-06-11 16:50:27,981 - mmdet - INFO - Epoch [2][3200/3517]	lr: 1.866e-03, eta: 7:30:39, time: 1.886, data_time: 0.068, memory: 32518, loss_cls: 0.1531, loss_bbox: 0.3079, d0.loss_cls: 0.2384, d0.loss_bbox: 0.4254, d1.loss_cls: 0.2145, d1.loss_bbox: 0.3142, d2.loss_cls: 0.2174, d2.loss_bbox: 0.3140, d3.loss_cls: 0.2197, d3.loss_bbox: 0.3323, d4.loss_cls: 0.1844, d4.loss_bbox: 0.3201, loss: 3.2414, grad_norm: 22.1853
2025-06-11 16:52:01,713 - mmdet - INFO - Epoch [2][3250/3517]	lr: 1.866e-03, eta: 7:29:05, time: 1.875, data_time: 0.055, memory: 32518, loss_cls: 0.1488, loss_bbox: 0.3074, d0.loss_cls: 0.2431, d0.loss_bbox: 0.4269, d1.loss_cls: 0.2130, d1.loss_bbox: 0.3199, d2.loss_cls: 0.2140, d2.loss_bbox: 0.3244, d3.loss_cls: 0.2114, d3.loss_bbox: 0.3422, d4.loss_cls: 0.1764, d4.loss_bbox: 0.3225, loss: 3.2499, grad_norm: 17.3256
2025-06-11 16:53:34,721 - mmdet - INFO - Epoch [2][3300/3517]	lr: 1.866e-03, eta: 7:27:29, time: 1.860, data_time: 0.056, memory: 32518, loss_cls: 0.1558, loss_bbox: 0.3212, d0.loss_cls: 0.2439, d0.loss_bbox: 0.4260, d1.loss_cls: 0.2155, d1.loss_bbox: 0.3236, d2.loss_cls: 0.2145, d2.loss_bbox: 0.3266, d3.loss_cls: 0.2118, d3.loss_bbox: 0.3403, d4.loss_cls: 0.1832, d4.loss_bbox: 0.3382, loss: 3.3007, grad_norm: 18.0982
2025-06-11 16:55:07,923 - mmdet - INFO - Epoch [2][3350/3517]	lr: 1.866e-03, eta: 7:25:53, time: 1.864, data_time: 0.053, memory: 32518, loss_cls: 0.1421, loss_bbox: 0.3199, d0.loss_cls: 0.2365, d0.loss_bbox: 0.4195, d1.loss_cls: 0.2075, d1.loss_bbox: 0.3136, d2.loss_cls: 0.2070, d2.loss_bbox: 0.3157, d3.loss_cls: 0.2037, d3.loss_bbox: 0.3264, d4.loss_cls: 0.1739, d4.loss_bbox: 0.3211, loss: 3.1869, grad_norm: 14.8706
2025-06-11 16:56:41,709 - mmdet - INFO - Epoch [2][3400/3517]	lr: 1.866e-03, eta: 7:24:19, time: 1.876, data_time: 0.053, memory: 32518, loss_cls: 0.1363, loss_bbox: 0.2951, d0.loss_cls: 0.2345, d0.loss_bbox: 0.4185, d1.loss_cls: 0.2052, d1.loss_bbox: 0.3103, d2.loss_cls: 0.2033, d2.loss_bbox: 0.3121, d3.loss_cls: 0.1959, d3.loss_bbox: 0.3242, d4.loss_cls: 0.1621, d4.loss_bbox: 0.3047, loss: 3.1023, grad_norm: 14.9042
2025-06-11 16:58:15,366 - mmdet - INFO - Epoch [2][3450/3517]	lr: 1.866e-03, eta: 7:22:44, time: 1.873, data_time: 0.051, memory: 32518, loss_cls: 0.1399, loss_bbox: 0.2938, d0.loss_cls: 0.2369, d0.loss_bbox: 0.4142, d1.loss_cls: 0.2084, d1.loss_bbox: 0.3086, d2.loss_cls: 0.2107, d2.loss_bbox: 0.3075, d3.loss_cls: 0.2073, d3.loss_bbox: 0.3209, d4.loss_cls: 0.1747, d4.loss_bbox: 0.3067, loss: 3.1297, grad_norm: 17.0294
2025-06-11 16:59:51,960 - mmdet - INFO - Epoch [2][3500/3517]	lr: 1.866e-03, eta: 7:21:16, time: 1.932, data_time: 0.051, memory: 32518, loss_cls: 0.1386, loss_bbox: 0.3079, d0.loss_cls: 0.2339, d0.loss_bbox: 0.4321, d1.loss_cls: 0.2042, d1.loss_bbox: 0.3221, d2.loss_cls: 0.2067, d2.loss_bbox: 0.3213, d3.loss_cls: 0.2039, d3.loss_bbox: 0.3337, d4.loss_cls: 0.1658, d4.loss_bbox: 0.3225, loss: 3.1926, grad_norm: 17.6606
2025-06-11 17:00:23,900 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-06-11 17:29:21,669 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 17:29:21,669 - mmdet - INFO - Epoch(val) [2][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7214, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8479, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8810, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9005, pts_bbox_NuScenes/car_trans_err: 0.2238, pts_bbox_NuScenes/car_scale_err: 0.1539, pts_bbox_NuScenes/car_orient_err: 0.0795, pts_bbox_NuScenes/car_vel_err: 0.3588, pts_bbox_NuScenes/car_attr_err: 0.1866, pts_bbox_NuScenes/mATE: 0.3989, pts_bbox_NuScenes/mASE: 0.2870, pts_bbox_NuScenes/mAOE: 0.2902, pts_bbox_NuScenes/mAVE: 0.3462, pts_bbox_NuScenes/mAAE: 0.1774, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.3779, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5609, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6510, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.6955, pts_bbox_NuScenes/truck_trans_err: 0.3555, pts_bbox_NuScenes/truck_scale_err: 0.2325, pts_bbox_NuScenes/truck_orient_err: 0.1044, pts_bbox_NuScenes/truck_vel_err: 0.3331, pts_bbox_NuScenes/truck_attr_err: 0.1971, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0318, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1655, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3539, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4245, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.7139, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4604, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7922, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1105, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2936, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4262, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.6902, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8809, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9025, pts_bbox_NuScenes/bus_trans_err: 0.4172, pts_bbox_NuScenes/bus_scale_err: 0.2647, pts_bbox_NuScenes/bus_orient_err: 0.0674, pts_bbox_NuScenes/bus_vel_err: 0.6022, pts_bbox_NuScenes/bus_attr_err: 0.2508, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1274, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3542, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5638, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6506, pts_bbox_NuScenes/trailer_trans_err: 0.5540, pts_bbox_NuScenes/trailer_scale_err: 0.2887, pts_bbox_NuScenes/trailer_orient_err: 0.5048, pts_bbox_NuScenes/trailer_vel_err: 0.2127, pts_bbox_NuScenes/trailer_attr_err: 0.1764, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.4501, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6270, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.6892, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7223, pts_bbox_NuScenes/barrier_trans_err: 0.3831, pts_bbox_NuScenes/barrier_scale_err: 0.2873, pts_bbox_NuScenes/barrier_orient_err: 0.0926, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.5111, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7087, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7681, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7821, pts_bbox_NuScenes/motorcycle_trans_err: 0.3203, pts_bbox_NuScenes/motorcycle_scale_err: 0.2648, pts_bbox_NuScenes/motorcycle_orient_err: 0.2849, pts_bbox_NuScenes/motorcycle_vel_err: 0.5644, pts_bbox_NuScenes/motorcycle_attr_err: 0.1844, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.4135, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5497, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5680, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.5773, pts_bbox_NuScenes/bicycle_trans_err: 0.3393, pts_bbox_NuScenes/bicycle_scale_err: 0.2793, pts_bbox_NuScenes/bicycle_orient_err: 0.3306, pts_bbox_NuScenes/bicycle_vel_err: 0.3213, pts_bbox_NuScenes/bicycle_attr_err: 0.0127, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7128, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8035, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8428, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8599, pts_bbox_NuScenes/pedestrian_trans_err: 0.2684, pts_bbox_NuScenes/pedestrian_scale_err: 0.3042, pts_bbox_NuScenes/pedestrian_orient_err: 0.3553, pts_bbox_NuScenes/pedestrian_vel_err: 0.2666, pts_bbox_NuScenes/pedestrian_attr_err: 0.1175, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.5158, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.6899, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7325, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7659, pts_bbox_NuScenes/traffic_cone_trans_err: 0.4132, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3338, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6563, pts_bbox_NuScenes/mAP: 0.6124
2025-06-11 17:31:04,916 - mmdet - INFO - Epoch [3][50/3517]	lr: 1.501e-03, eta: 7:18:17, time: 1.985, data_time: 0.172, memory: 32518, loss_cls: 0.1382, loss_bbox: 0.3008, d0.loss_cls: 0.2317, d0.loss_bbox: 0.4235, d1.loss_cls: 0.2039, d1.loss_bbox: 0.3201, d2.loss_cls: 0.2063, d2.loss_bbox: 0.3187, d3.loss_cls: 0.1998, d3.loss_bbox: 0.3295, d4.loss_cls: 0.1659, d4.loss_bbox: 0.3205, loss: 3.1589, grad_norm: 17.2838
2025-06-11 17:32:38,635 - mmdet - INFO - Epoch [3][100/3517]	lr: 1.501e-03, eta: 7:16:43, time: 1.874, data_time: 0.064, memory: 32518, loss_cls: 0.1294, loss_bbox: 0.2840, d0.loss_cls: 0.2308, d0.loss_bbox: 0.4146, d1.loss_cls: 0.2034, d1.loss_bbox: 0.3050, d2.loss_cls: 0.2038, d2.loss_bbox: 0.3027, d3.loss_cls: 0.2011, d3.loss_bbox: 0.3133, d4.loss_cls: 0.1609, d4.loss_bbox: 0.2976, loss: 3.0464, grad_norm: 18.8959
2025-06-11 17:34:12,719 - mmdet - INFO - Epoch [3][150/3517]	lr: 1.501e-03, eta: 7:15:10, time: 1.882, data_time: 0.061, memory: 32518, loss_cls: 0.1317, loss_bbox: 0.2831, d0.loss_cls: 0.2268, d0.loss_bbox: 0.4137, d1.loss_cls: 0.2116, d1.loss_bbox: 0.3165, d2.loss_cls: 0.2168, d2.loss_bbox: 0.3079, d3.loss_cls: 0.2113, d3.loss_bbox: 0.3167, d4.loss_cls: 0.1630, d4.loss_bbox: 0.3008, loss: 3.0998, grad_norm: 24.1383
2025-06-11 17:35:46,265 - mmdet - INFO - Epoch [3][200/3517]	lr: 1.501e-03, eta: 7:13:35, time: 1.871, data_time: 0.061, memory: 32518, loss_cls: 0.1226, loss_bbox: 0.2690, d0.loss_cls: 0.2225, d0.loss_bbox: 0.3957, d1.loss_cls: 0.2011, d1.loss_bbox: 0.2982, d2.loss_cls: 0.2048, d2.loss_bbox: 0.2941, d3.loss_cls: 0.1964, d3.loss_bbox: 0.3033, d4.loss_cls: 0.1537, d4.loss_bbox: 0.2867, loss: 2.9482, grad_norm: 16.1328
2025-06-11 17:37:20,250 - mmdet - INFO - Epoch [3][250/3517]	lr: 1.501e-03, eta: 7:12:02, time: 1.880, data_time: 0.050, memory: 32518, loss_cls: 0.1313, loss_bbox: 0.2774, d0.loss_cls: 0.2352, d0.loss_bbox: 0.4101, d1.loss_cls: 0.2070, d1.loss_bbox: 0.3052, d2.loss_cls: 0.2131, d2.loss_bbox: 0.3044, d3.loss_cls: 0.2078, d3.loss_bbox: 0.3087, d4.loss_cls: 0.1604, d4.loss_bbox: 0.2923, loss: 3.0530, grad_norm: 18.5243
2025-06-11 17:38:53,926 - mmdet - INFO - Epoch [3][300/3517]	lr: 1.501e-03, eta: 7:10:28, time: 1.874, data_time: 0.050, memory: 32518, loss_cls: 0.1243, loss_bbox: 0.2681, d0.loss_cls: 0.2257, d0.loss_bbox: 0.3935, d1.loss_cls: 0.2011, d1.loss_bbox: 0.2924, d2.loss_cls: 0.2073, d2.loss_bbox: 0.2911, d3.loss_cls: 0.2009, d3.loss_bbox: 0.3010, d4.loss_cls: 0.1513, d4.loss_bbox: 0.2852, loss: 2.9420, grad_norm: 17.5385
2025-06-11 17:40:27,555 - mmdet - INFO - Epoch [3][350/3517]	lr: 1.501e-03, eta: 7:08:54, time: 1.873, data_time: 0.050, memory: 32518, loss_cls: 0.1180, loss_bbox: 0.2681, d0.loss_cls: 0.2193, d0.loss_bbox: 0.3874, d1.loss_cls: 0.1956, d1.loss_bbox: 0.2942, d2.loss_cls: 0.1990, d2.loss_bbox: 0.2938, d3.loss_cls: 0.1959, d3.loss_bbox: 0.3048, d4.loss_cls: 0.1441, d4.loss_bbox: 0.2874, loss: 2.9076, grad_norm: 14.8337
2025-06-11 17:42:00,762 - mmdet - INFO - Epoch [3][400/3517]	lr: 1.501e-03, eta: 7:07:19, time: 1.864, data_time: 0.052, memory: 32518, loss_cls: 0.1195, loss_bbox: 0.2712, d0.loss_cls: 0.2247, d0.loss_bbox: 0.3946, d1.loss_cls: 0.1958, d1.loss_bbox: 0.2922, d2.loss_cls: 0.1972, d2.loss_bbox: 0.2894, d3.loss_cls: 0.1885, d3.loss_bbox: 0.2989, d4.loss_cls: 0.1439, d4.loss_bbox: 0.2856, loss: 2.9014, grad_norm: 14.4015
2025-06-11 17:43:33,851 - mmdet - INFO - Epoch [3][450/3517]	lr: 1.501e-03, eta: 7:05:44, time: 1.862, data_time: 0.051, memory: 32518, loss_cls: 0.1243, loss_bbox: 0.2680, d0.loss_cls: 0.2265, d0.loss_bbox: 0.4092, d1.loss_cls: 0.1992, d1.loss_bbox: 0.2974, d2.loss_cls: 0.1997, d2.loss_bbox: 0.2945, d3.loss_cls: 0.1948, d3.loss_bbox: 0.3016, d4.loss_cls: 0.1483, d4.loss_bbox: 0.2860, loss: 2.9494, grad_norm: 73.0490
2025-06-11 17:45:06,721 - mmdet - INFO - Epoch [3][500/3517]	lr: 1.501e-03, eta: 7:04:08, time: 1.857, data_time: 0.049, memory: 32518, loss_cls: 0.1329, loss_bbox: 0.2889, d0.loss_cls: 0.2287, d0.loss_bbox: 0.4150, d1.loss_cls: 0.2022, d1.loss_bbox: 0.3061, d2.loss_cls: 0.2022, d2.loss_bbox: 0.3037, d3.loss_cls: 0.1974, d3.loss_bbox: 0.3125, d4.loss_cls: 0.1556, d4.loss_bbox: 0.2998, loss: 3.0450, grad_norm: 17.6606
2025-06-11 17:46:39,695 - mmdet - INFO - Epoch [3][550/3517]	lr: 1.501e-03, eta: 7:02:33, time: 1.859, data_time: 0.053, memory: 32518, loss_cls: 0.1288, loss_bbox: 0.2827, d0.loss_cls: 0.2275, d0.loss_bbox: 0.4016, d1.loss_cls: 0.2028, d1.loss_bbox: 0.2987, d2.loss_cls: 0.2052, d2.loss_bbox: 0.2935, d3.loss_cls: 0.1996, d3.loss_bbox: 0.3028, d4.loss_cls: 0.1556, d4.loss_bbox: 0.2898, loss: 2.9885, grad_norm: 16.8398
2025-06-11 17:48:13,104 - mmdet - INFO - Epoch [3][600/3517]	lr: 1.501e-03, eta: 7:00:59, time: 1.868, data_time: 0.052, memory: 32518, loss_cls: 0.1258, loss_bbox: 0.2753, d0.loss_cls: 0.2260, d0.loss_bbox: 0.4027, d1.loss_cls: 0.1988, d1.loss_bbox: 0.2944, d2.loss_cls: 0.2010, d2.loss_bbox: 0.2922, d3.loss_cls: 0.1932, d3.loss_bbox: 0.3036, d4.loss_cls: 0.1515, d4.loss_bbox: 0.2862, loss: 2.9507, grad_norm: 18.0595
2025-06-11 17:49:45,931 - mmdet - INFO - Epoch [3][650/3517]	lr: 1.501e-03, eta: 6:59:23, time: 1.857, data_time: 0.051, memory: 32518, loss_cls: 0.1276, loss_bbox: 0.2718, d0.loss_cls: 0.2269, d0.loss_bbox: 0.4000, d1.loss_cls: 0.2008, d1.loss_bbox: 0.2959, d2.loss_cls: 0.2009, d2.loss_bbox: 0.2900, d3.loss_cls: 0.1961, d3.loss_bbox: 0.2984, d4.loss_cls: 0.1517, d4.loss_bbox: 0.2843, loss: 2.9445, grad_norm: 18.4215
2025-06-11 17:51:19,084 - mmdet - INFO - Epoch [3][700/3517]	lr: 1.501e-03, eta: 6:57:48, time: 1.863, data_time: 0.054, memory: 32518, loss_cls: 0.1246, loss_bbox: 0.2713, d0.loss_cls: 0.2257, d0.loss_bbox: 0.3984, d1.loss_cls: 0.1914, d1.loss_bbox: 0.2947, d2.loss_cls: 0.1929, d2.loss_bbox: 0.2929, d3.loss_cls: 0.1890, d3.loss_bbox: 0.3002, d4.loss_cls: 0.1488, d4.loss_bbox: 0.2890, loss: 2.9190, grad_norm: 17.1636
2025-06-11 17:52:52,722 - mmdet - INFO - Epoch [3][750/3517]	lr: 1.501e-03, eta: 6:56:15, time: 1.873, data_time: 0.059, memory: 32518, loss_cls: 0.1264, loss_bbox: 0.2709, d0.loss_cls: 0.2300, d0.loss_bbox: 0.4055, d1.loss_cls: 0.2044, d1.loss_bbox: 0.2941, d2.loss_cls: 0.2059, d2.loss_bbox: 0.2973, d3.loss_cls: 0.2014, d3.loss_bbox: 0.3028, d4.loss_cls: 0.1519, d4.loss_bbox: 0.2926, loss: 2.9832, grad_norm: 24.6932
2025-06-11 17:54:26,207 - mmdet - INFO - Epoch [3][800/3517]	lr: 1.501e-03, eta: 6:54:40, time: 1.870, data_time: 0.059, memory: 32518, loss_cls: 0.1227, loss_bbox: 0.2630, d0.loss_cls: 0.2238, d0.loss_bbox: 0.4025, d1.loss_cls: 0.1944, d1.loss_bbox: 0.2892, d2.loss_cls: 0.1949, d2.loss_bbox: 0.2914, d3.loss_cls: 0.1897, d3.loss_bbox: 0.2964, d4.loss_cls: 0.1491, d4.loss_bbox: 0.2835, loss: 2.9006, grad_norm: 14.8304
2025-06-11 17:55:59,854 - mmdet - INFO - Epoch [3][850/3517]	lr: 1.501e-03, eta: 6:53:06, time: 1.873, data_time: 0.055, memory: 32518, loss_cls: 0.1279, loss_bbox: 0.2879, d0.loss_cls: 0.2326, d0.loss_bbox: 0.4098, d1.loss_cls: 0.2002, d1.loss_bbox: 0.3112, d2.loss_cls: 0.2025, d2.loss_bbox: 0.3172, d3.loss_cls: 0.1973, d3.loss_bbox: 0.3275, d4.loss_cls: 0.1506, d4.loss_bbox: 0.3030, loss: 3.0676, grad_norm: 27.5686
2025-06-11 17:57:33,379 - mmdet - INFO - Epoch [3][900/3517]	lr: 1.501e-03, eta: 6:51:32, time: 1.870, data_time: 0.058, memory: 32518, loss_cls: 0.1338, loss_bbox: 0.2849, d0.loss_cls: 0.2307, d0.loss_bbox: 0.3941, d1.loss_cls: 0.2096, d1.loss_bbox: 0.2930, d2.loss_cls: 0.2157, d2.loss_bbox: 0.2897, d3.loss_cls: 0.2093, d3.loss_bbox: 0.2964, d4.loss_cls: 0.1608, d4.loss_bbox: 0.2904, loss: 3.0085, grad_norm: 19.8539
2025-06-11 17:59:07,380 - mmdet - INFO - Epoch [3][950/3517]	lr: 1.501e-03, eta: 6:49:59, time: 1.880, data_time: 0.056, memory: 32518, loss_cls: 0.1267, loss_bbox: 0.2729, d0.loss_cls: 0.2234, d0.loss_bbox: 0.3976, d1.loss_cls: 0.1985, d1.loss_bbox: 0.3006, d2.loss_cls: 0.2010, d2.loss_bbox: 0.2981, d3.loss_cls: 0.2023, d3.loss_bbox: 0.3052, d4.loss_cls: 0.1576, d4.loss_bbox: 0.2901, loss: 2.9738, grad_norm: 15.1598
2025-06-11 18:00:41,198 - mmdet - INFO - Epoch [3][1000/3517]	lr: 1.501e-03, eta: 6:48:25, time: 1.876, data_time: 0.058, memory: 32518, loss_cls: 0.1402, loss_bbox: 0.2790, d0.loss_cls: 0.2455, d0.loss_bbox: 0.4226, d1.loss_cls: 0.2132, d1.loss_bbox: 0.3066, d2.loss_cls: 0.2135, d2.loss_bbox: 0.3031, d3.loss_cls: 0.2154, d3.loss_bbox: 0.3062, d4.loss_cls: 0.1689, d4.loss_bbox: 0.2953, loss: 3.1095, grad_norm: 19.7056
2025-06-11 18:02:15,353 - mmdet - INFO - Epoch [3][1050/3517]	lr: 1.501e-03, eta: 6:46:52, time: 1.883, data_time: 0.065, memory: 32518, loss_cls: 0.1375, loss_bbox: 0.2783, d0.loss_cls: 0.2316, d0.loss_bbox: 0.4103, d1.loss_cls: 0.2075, d1.loss_bbox: 0.3092, d2.loss_cls: 0.2096, d2.loss_bbox: 0.3113, d3.loss_cls: 0.2080, d3.loss_bbox: 0.3211, d4.loss_cls: 0.1707, d4.loss_bbox: 0.2957, loss: 3.0907, grad_norm: 41.6591
2025-06-11 18:03:49,239 - mmdet - INFO - Epoch [3][1100/3517]	lr: 1.501e-03, eta: 6:45:18, time: 1.878, data_time: 0.062, memory: 32518, loss_cls: 0.1406, loss_bbox: 0.2775, d0.loss_cls: 0.2303, d0.loss_bbox: 0.3990, d1.loss_cls: 0.2088, d1.loss_bbox: 0.2965, d2.loss_cls: 0.2157, d2.loss_bbox: 0.2962, d3.loss_cls: 0.2160, d3.loss_bbox: 0.3090, d4.loss_cls: 0.1746, d4.loss_bbox: 0.2990, loss: 3.0632, grad_norm: 21.1857
2025-06-11 18:05:23,246 - mmdet - INFO - Epoch [3][1150/3517]	lr: 1.501e-03, eta: 6:43:45, time: 1.880, data_time: 0.058, memory: 32518, loss_cls: 0.1312, loss_bbox: 0.2828, d0.loss_cls: 0.2222, d0.loss_bbox: 0.4080, d1.loss_cls: 0.1964, d1.loss_bbox: 0.3014, d2.loss_cls: 0.1993, d2.loss_bbox: 0.2937, d3.loss_cls: 0.1940, d3.loss_bbox: 0.2995, d4.loss_cls: 0.1561, d4.loss_bbox: 0.2935, loss: 2.9780, grad_norm: 14.5346
2025-06-11 18:06:57,691 - mmdet - INFO - Epoch [3][1200/3517]	lr: 1.501e-03, eta: 6:42:12, time: 1.889, data_time: 0.067, memory: 32518, loss_cls: 0.1260, loss_bbox: 0.2779, d0.loss_cls: 0.2209, d0.loss_bbox: 0.3981, d1.loss_cls: 0.1919, d1.loss_bbox: 0.2998, d2.loss_cls: 0.1935, d2.loss_bbox: 0.2983, d3.loss_cls: 0.1890, d3.loss_bbox: 0.3067, d4.loss_cls: 0.1507, d4.loss_bbox: 0.2914, loss: 2.9443, grad_norm: 23.1839
2025-06-11 18:08:31,442 - mmdet - INFO - Epoch [3][1250/3517]	lr: 1.501e-03, eta: 6:40:39, time: 1.875, data_time: 0.066, memory: 32518, loss_cls: 0.1247, loss_bbox: 0.2772, d0.loss_cls: 0.2244, d0.loss_bbox: 0.3972, d1.loss_cls: 0.2006, d1.loss_bbox: 0.2920, d2.loss_cls: 0.2025, d2.loss_bbox: 0.2904, d3.loss_cls: 0.1946, d3.loss_bbox: 0.2972, d4.loss_cls: 0.1532, d4.loss_bbox: 0.2874, loss: 2.9413, grad_norm: 16.6209
2025-06-11 18:10:05,226 - mmdet - INFO - Epoch [3][1300/3517]	lr: 1.501e-03, eta: 6:39:05, time: 1.876, data_time: 0.055, memory: 32518, loss_cls: 0.1344, loss_bbox: 0.2875, d0.loss_cls: 0.2298, d0.loss_bbox: 0.4077, d1.loss_cls: 0.2050, d1.loss_bbox: 0.3099, d2.loss_cls: 0.2108, d2.loss_bbox: 0.3068, d3.loss_cls: 0.2038, d3.loss_bbox: 0.3157, d4.loss_cls: 0.1614, d4.loss_bbox: 0.3049, loss: 3.0779, grad_norm: 17.0988
2025-06-11 18:11:39,071 - mmdet - INFO - Epoch [3][1350/3517]	lr: 1.501e-03, eta: 6:37:31, time: 1.877, data_time: 0.058, memory: 32518, loss_cls: 0.1281, loss_bbox: 0.2805, d0.loss_cls: 0.2295, d0.loss_bbox: 0.3996, d1.loss_cls: 0.2011, d1.loss_bbox: 0.2961, d2.loss_cls: 0.2040, d2.loss_bbox: 0.2957, d3.loss_cls: 0.1998, d3.loss_bbox: 0.3036, d4.loss_cls: 0.1559, d4.loss_bbox: 0.2898, loss: 2.9837, grad_norm: 20.1139
2025-06-11 18:13:16,114 - mmdet - INFO - Epoch [3][1400/3517]	lr: 1.501e-03, eta: 6:36:02, time: 1.941, data_time: 0.060, memory: 32518, loss_cls: 0.1295, loss_bbox: 0.2717, d0.loss_cls: 0.2300, d0.loss_bbox: 0.4100, d1.loss_cls: 0.2077, d1.loss_bbox: 0.2986, d2.loss_cls: 0.2117, d2.loss_bbox: 0.2973, d3.loss_cls: 0.2090, d3.loss_bbox: 0.3054, d4.loss_cls: 0.1637, d4.loss_bbox: 0.2862, loss: 3.0208, grad_norm: 20.7966
2025-06-11 18:14:50,068 - mmdet - INFO - Epoch [3][1450/3517]	lr: 1.501e-03, eta: 6:34:29, time: 1.879, data_time: 0.060, memory: 32518, loss_cls: 0.1279, loss_bbox: 0.2753, d0.loss_cls: 0.2231, d0.loss_bbox: 0.3981, d1.loss_cls: 0.1970, d1.loss_bbox: 0.3029, d2.loss_cls: 0.2027, d2.loss_bbox: 0.3053, d3.loss_cls: 0.1954, d3.loss_bbox: 0.3109, d4.loss_cls: 0.1559, d4.loss_bbox: 0.2927, loss: 2.9873, grad_norm: 16.9299
2025-06-11 18:16:24,281 - mmdet - INFO - Epoch [3][1500/3517]	lr: 1.501e-03, eta: 6:32:56, time: 1.884, data_time: 0.060, memory: 32518, loss_cls: 0.1209, loss_bbox: 0.2745, d0.loss_cls: 0.2225, d0.loss_bbox: 0.4011, d1.loss_cls: 0.1958, d1.loss_bbox: 0.2962, d2.loss_cls: 0.1987, d2.loss_bbox: 0.2958, d3.loss_cls: 0.1930, d3.loss_bbox: 0.3002, d4.loss_cls: 0.1525, d4.loss_bbox: 0.2918, loss: 2.9430, grad_norm: 20.1952
2025-06-11 18:17:58,061 - mmdet - INFO - Epoch [3][1550/3517]	lr: 1.501e-03, eta: 6:31:22, time: 1.876, data_time: 0.057, memory: 32518, loss_cls: 0.1233, loss_bbox: 0.2798, d0.loss_cls: 0.2244, d0.loss_bbox: 0.3967, d1.loss_cls: 0.2020, d1.loss_bbox: 0.2930, d2.loss_cls: 0.2041, d2.loss_bbox: 0.2971, d3.loss_cls: 0.1964, d3.loss_bbox: 0.3063, d4.loss_cls: 0.1513, d4.loss_bbox: 0.2929, loss: 2.9673, grad_norm: 16.7553
2025-06-11 18:19:32,027 - mmdet - INFO - Epoch [3][1600/3517]	lr: 1.501e-03, eta: 6:29:48, time: 1.879, data_time: 0.059, memory: 32518, loss_cls: 0.1329, loss_bbox: 0.2828, d0.loss_cls: 0.2266, d0.loss_bbox: 0.4197, d1.loss_cls: 0.2047, d1.loss_bbox: 0.3113, d2.loss_cls: 0.2089, d2.loss_bbox: 0.3188, d3.loss_cls: 0.2014, d3.loss_bbox: 0.3236, d4.loss_cls: 0.1594, d4.loss_bbox: 0.3043, loss: 3.0944, grad_norm: 23.3217
2025-06-11 18:21:05,473 - mmdet - INFO - Epoch [3][1650/3517]	lr: 1.501e-03, eta: 6:28:14, time: 1.869, data_time: 0.057, memory: 32518, loss_cls: 0.1313, loss_bbox: 0.2763, d0.loss_cls: 0.2292, d0.loss_bbox: 0.4058, d1.loss_cls: 0.2015, d1.loss_bbox: 0.3038, d2.loss_cls: 0.2056, d2.loss_bbox: 0.3033, d3.loss_cls: 0.1998, d3.loss_bbox: 0.3116, d4.loss_cls: 0.1590, d4.loss_bbox: 0.2937, loss: 3.0208, grad_norm: 14.8658
2025-06-11 18:22:39,081 - mmdet - INFO - Epoch [3][1700/3517]	lr: 1.501e-03, eta: 6:26:40, time: 1.872, data_time: 0.058, memory: 32518, loss_cls: 0.1249, loss_bbox: 0.2798, d0.loss_cls: 0.2227, d0.loss_bbox: 0.4138, d1.loss_cls: 0.1954, d1.loss_bbox: 0.3032, d2.loss_cls: 0.1963, d2.loss_bbox: 0.2989, d3.loss_cls: 0.1905, d3.loss_bbox: 0.3073, d4.loss_cls: 0.1521, d4.loss_bbox: 0.2931, loss: 2.9780, grad_norm: 15.3916
2025-06-11 18:24:13,205 - mmdet - INFO - Epoch [3][1750/3517]	lr: 1.501e-03, eta: 6:25:06, time: 1.882, data_time: 0.069, memory: 32518, loss_cls: 0.1282, loss_bbox: 0.2694, d0.loss_cls: 0.2327, d0.loss_bbox: 0.3970, d1.loss_cls: 0.1966, d1.loss_bbox: 0.2923, d2.loss_cls: 0.1997, d2.loss_bbox: 0.2907, d3.loss_cls: 0.1937, d3.loss_bbox: 0.2944, d4.loss_cls: 0.1504, d4.loss_bbox: 0.2845, loss: 2.9295, grad_norm: 18.6459
2025-06-11 18:25:47,347 - mmdet - INFO - Epoch [3][1800/3517]	lr: 1.501e-03, eta: 6:23:33, time: 1.883, data_time: 0.060, memory: 32518, loss_cls: 0.1244, loss_bbox: 0.2804, d0.loss_cls: 0.2235, d0.loss_bbox: 0.4099, d1.loss_cls: 0.1949, d1.loss_bbox: 0.3093, d2.loss_cls: 0.1985, d2.loss_bbox: 0.3078, d3.loss_cls: 0.1953, d3.loss_bbox: 0.3145, d4.loss_cls: 0.1532, d4.loss_bbox: 0.2982, loss: 3.0100, grad_norm: 17.4696
2025-06-11 18:27:21,136 - mmdet - INFO - Epoch [3][1850/3517]	lr: 1.501e-03, eta: 6:21:59, time: 1.876, data_time: 0.057, memory: 32518, loss_cls: 0.1195, loss_bbox: 0.2882, d0.loss_cls: 0.2231, d0.loss_bbox: 0.3892, d1.loss_cls: 0.1942, d1.loss_bbox: 0.2935, d2.loss_cls: 0.1939, d2.loss_bbox: 0.2952, d3.loss_cls: 0.1915, d3.loss_bbox: 0.3014, d4.loss_cls: 0.1513, d4.loss_bbox: 0.2940, loss: 2.9350, grad_norm: 15.6902
2025-06-11 18:28:54,786 - mmdet - INFO - Epoch [3][1900/3517]	lr: 1.501e-03, eta: 6:20:25, time: 1.873, data_time: 0.059, memory: 32518, loss_cls: 0.1113, loss_bbox: 0.2682, d0.loss_cls: 0.2111, d0.loss_bbox: 0.3918, d1.loss_cls: 0.1870, d1.loss_bbox: 0.2915, d2.loss_cls: 0.1886, d2.loss_bbox: 0.2867, d3.loss_cls: 0.1821, d3.loss_bbox: 0.2958, d4.loss_cls: 0.1376, d4.loss_bbox: 0.2799, loss: 2.8314, grad_norm: 17.6073
2025-06-11 18:30:29,041 - mmdet - INFO - Epoch [3][1950/3517]	lr: 1.501e-03, eta: 6:18:52, time: 1.885, data_time: 0.062, memory: 32518, loss_cls: 0.1266, loss_bbox: 0.2665, d0.loss_cls: 0.2253, d0.loss_bbox: 0.3977, d1.loss_cls: 0.2015, d1.loss_bbox: 0.2935, d2.loss_cls: 0.2056, d2.loss_bbox: 0.2871, d3.loss_cls: 0.2014, d3.loss_bbox: 0.2940, d4.loss_cls: 0.1544, d4.loss_bbox: 0.2802, loss: 2.9340, grad_norm: 19.0713
2025-06-11 18:32:02,563 - mmdet - INFO - Epoch [3][2000/3517]	lr: 1.501e-03, eta: 6:17:18, time: 1.870, data_time: 0.058, memory: 32518, loss_cls: 0.1195, loss_bbox: 0.2751, d0.loss_cls: 0.2280, d0.loss_bbox: 0.4127, d1.loss_cls: 0.2000, d1.loss_bbox: 0.3059, d2.loss_cls: 0.2028, d2.loss_bbox: 0.3022, d3.loss_cls: 0.1973, d3.loss_bbox: 0.3058, d4.loss_cls: 0.1463, d4.loss_bbox: 0.2893, loss: 2.9848, grad_norm: 15.5853
2025-06-11 18:33:36,242 - mmdet - INFO - Epoch [3][2050/3517]	lr: 1.501e-03, eta: 6:15:44, time: 1.874, data_time: 0.057, memory: 32518, loss_cls: 0.1206, loss_bbox: 0.2772, d0.loss_cls: 0.2217, d0.loss_bbox: 0.4035, d1.loss_cls: 0.1962, d1.loss_bbox: 0.3020, d2.loss_cls: 0.2006, d2.loss_bbox: 0.3017, d3.loss_cls: 0.1932, d3.loss_bbox: 0.3084, d4.loss_cls: 0.1489, d4.loss_bbox: 0.2879, loss: 2.9620, grad_norm: 24.7142
2025-06-11 18:35:10,106 - mmdet - INFO - Epoch [3][2100/3517]	lr: 1.501e-03, eta: 6:14:10, time: 1.877, data_time: 0.055, memory: 32518, loss_cls: 0.1156, loss_bbox: 0.2736, d0.loss_cls: 0.2262, d0.loss_bbox: 0.3973, d1.loss_cls: 0.1896, d1.loss_bbox: 0.2952, d2.loss_cls: 0.1940, d2.loss_bbox: 0.2913, d3.loss_cls: 0.1867, d3.loss_bbox: 0.2979, d4.loss_cls: 0.1414, d4.loss_bbox: 0.2865, loss: 2.8953, grad_norm: 14.1742
2025-06-11 18:36:44,245 - mmdet - INFO - Epoch [3][2150/3517]	lr: 1.501e-03, eta: 6:12:37, time: 1.883, data_time: 0.054, memory: 32518, loss_cls: 0.1210, loss_bbox: 0.2719, d0.loss_cls: 0.2253, d0.loss_bbox: 0.3989, d1.loss_cls: 0.1920, d1.loss_bbox: 0.2932, d2.loss_cls: 0.1940, d2.loss_bbox: 0.2880, d3.loss_cls: 0.1858, d3.loss_bbox: 0.2948, d4.loss_cls: 0.1434, d4.loss_bbox: 0.2813, loss: 2.8897, grad_norm: 15.7735
2025-06-11 18:38:18,385 - mmdet - INFO - Epoch [3][2200/3517]	lr: 1.501e-03, eta: 6:11:04, time: 1.883, data_time: 0.062, memory: 32518, loss_cls: 0.1277, loss_bbox: 0.2662, d0.loss_cls: 0.2193, d0.loss_bbox: 0.4005, d1.loss_cls: 0.1954, d1.loss_bbox: 0.2886, d2.loss_cls: 0.2004, d2.loss_bbox: 0.2814, d3.loss_cls: 0.1960, d3.loss_bbox: 0.2891, d4.loss_cls: 0.1569, d4.loss_bbox: 0.2787, loss: 2.9003, grad_norm: 13.5403
2025-06-11 18:39:52,518 - mmdet - INFO - Epoch [3][2250/3517]	lr: 1.501e-03, eta: 6:09:30, time: 1.883, data_time: 0.056, memory: 32518, loss_cls: 0.1217, loss_bbox: 0.2700, d0.loss_cls: 0.2220, d0.loss_bbox: 0.4009, d1.loss_cls: 0.1969, d1.loss_bbox: 0.2961, d2.loss_cls: 0.1969, d2.loss_bbox: 0.2918, d3.loss_cls: 0.1948, d3.loss_bbox: 0.2957, d4.loss_cls: 0.1465, d4.loss_bbox: 0.2834, loss: 2.9168, grad_norm: 19.4980
2025-06-11 18:41:26,767 - mmdet - INFO - Epoch [3][2300/3517]	lr: 1.501e-03, eta: 6:07:57, time: 1.885, data_time: 0.055, memory: 32518, loss_cls: 0.1146, loss_bbox: 0.2700, d0.loss_cls: 0.2183, d0.loss_bbox: 0.4011, d1.loss_cls: 0.1934, d1.loss_bbox: 0.2931, d2.loss_cls: 0.1922, d2.loss_bbox: 0.2894, d3.loss_cls: 0.1867, d3.loss_bbox: 0.2952, d4.loss_cls: 0.1392, d4.loss_bbox: 0.2832, loss: 2.8763, grad_norm: 13.7073
2025-06-11 18:43:00,680 - mmdet - INFO - Epoch [3][2350/3517]	lr: 1.501e-03, eta: 6:06:23, time: 1.878, data_time: 0.057, memory: 32518, loss_cls: 0.1213, loss_bbox: 0.2737, d0.loss_cls: 0.2268, d0.loss_bbox: 0.4044, d1.loss_cls: 0.1928, d1.loss_bbox: 0.3028, d2.loss_cls: 0.1939, d2.loss_bbox: 0.2988, d3.loss_cls: 0.1926, d3.loss_bbox: 0.3036, d4.loss_cls: 0.1486, d4.loss_bbox: 0.2890, loss: 2.9482, grad_norm: 17.7691
2025-06-11 18:44:46,188 - mmdet - INFO - Epoch [3][2400/3517]	lr: 1.501e-03, eta: 6:05:04, time: 2.110, data_time: 0.063, memory: 32518, loss_cls: 0.1200, loss_bbox: 0.2729, d0.loss_cls: 0.2222, d0.loss_bbox: 0.3928, d1.loss_cls: 0.1933, d1.loss_bbox: 0.2947, d2.loss_cls: 0.1957, d2.loss_bbox: 0.2910, d3.loss_cls: 0.1897, d3.loss_bbox: 0.2990, d4.loss_cls: 0.1509, d4.loss_bbox: 0.2851, loss: 2.9074, grad_norm: 20.2591
2025-06-11 18:46:19,010 - mmdet - INFO - Epoch [3][2450/3517]	lr: 1.501e-03, eta: 6:03:29, time: 1.856, data_time: 0.052, memory: 32518, loss_cls: 0.1286, loss_bbox: 0.2689, d0.loss_cls: 0.2314, d0.loss_bbox: 0.4015, d1.loss_cls: 0.2026, d1.loss_bbox: 0.2950, d2.loss_cls: 0.2062, d2.loss_bbox: 0.2886, d3.loss_cls: 0.2051, d3.loss_bbox: 0.2968, d4.loss_cls: 0.1593, d4.loss_bbox: 0.2853, loss: 2.9691, grad_norm: 19.5626
2025-06-11 18:47:51,457 - mmdet - INFO - Epoch [3][2500/3517]	lr: 1.501e-03, eta: 6:01:53, time: 1.849, data_time: 0.052, memory: 32518, loss_cls: 0.1252, loss_bbox: 0.2676, d0.loss_cls: 0.2254, d0.loss_bbox: 0.3995, d1.loss_cls: 0.2035, d1.loss_bbox: 0.2885, d2.loss_cls: 0.2062, d2.loss_bbox: 0.2849, d3.loss_cls: 0.2029, d3.loss_bbox: 0.2949, d4.loss_cls: 0.1663, d4.loss_bbox: 0.2822, loss: 2.9471, grad_norm: 18.7952
2025-06-11 18:49:24,632 - mmdet - INFO - Epoch [3][2550/3517]	lr: 1.501e-03, eta: 6:00:19, time: 1.864, data_time: 0.057, memory: 32518, loss_cls: 0.1202, loss_bbox: 0.2653, d0.loss_cls: 0.2246, d0.loss_bbox: 0.3965, d1.loss_cls: 0.1938, d1.loss_bbox: 0.2893, d2.loss_cls: 0.1923, d2.loss_bbox: 0.2853, d3.loss_cls: 0.1865, d3.loss_bbox: 0.2928, d4.loss_cls: 0.1517, d4.loss_bbox: 0.2816, loss: 2.8799, grad_norm: 13.0124
2025-06-11 18:50:57,322 - mmdet - INFO - Epoch [3][2600/3517]	lr: 1.501e-03, eta: 5:58:43, time: 1.854, data_time: 0.054, memory: 32518, loss_cls: 0.1214, loss_bbox: 0.2705, d0.loss_cls: 0.2165, d0.loss_bbox: 0.3918, d1.loss_cls: 0.1933, d1.loss_bbox: 0.2935, d2.loss_cls: 0.1946, d2.loss_bbox: 0.2935, d3.loss_cls: 0.1892, d3.loss_bbox: 0.3018, d4.loss_cls: 0.1485, d4.loss_bbox: 0.2917, loss: 2.9062, grad_norm: 16.2098
2025-06-11 18:52:29,584 - mmdet - INFO - Epoch [3][2650/3517]	lr: 1.501e-03, eta: 5:57:08, time: 1.845, data_time: 0.054, memory: 32518, loss_cls: 0.1195, loss_bbox: 0.2641, d0.loss_cls: 0.2185, d0.loss_bbox: 0.3868, d1.loss_cls: 0.1927, d1.loss_bbox: 0.2877, d2.loss_cls: 0.1926, d2.loss_bbox: 0.2820, d3.loss_cls: 0.1860, d3.loss_bbox: 0.2906, d4.loss_cls: 0.1475, d4.loss_bbox: 0.2748, loss: 2.8426, grad_norm: 13.4615
2025-06-11 18:54:01,776 - mmdet - INFO - Epoch [3][2700/3517]	lr: 1.501e-03, eta: 5:55:32, time: 1.844, data_time: 0.052, memory: 32518, loss_cls: 0.1210, loss_bbox: 0.2768, d0.loss_cls: 0.2185, d0.loss_bbox: 0.3983, d1.loss_cls: 0.1926, d1.loss_bbox: 0.2968, d2.loss_cls: 0.1893, d2.loss_bbox: 0.2978, d3.loss_cls: 0.1853, d3.loss_bbox: 0.3023, d4.loss_cls: 0.1469, d4.loss_bbox: 0.2867, loss: 2.9123, grad_norm: 20.8403
2025-06-11 18:55:35,247 - mmdet - INFO - Epoch [3][2750/3517]	lr: 1.501e-03, eta: 5:53:58, time: 1.869, data_time: 0.057, memory: 32518, loss_cls: 0.1253, loss_bbox: 0.2860, d0.loss_cls: 0.2204, d0.loss_bbox: 0.4059, d1.loss_cls: 0.1915, d1.loss_bbox: 0.3047, d2.loss_cls: 0.1932, d2.loss_bbox: 0.3049, d3.loss_cls: 0.1892, d3.loss_bbox: 0.3087, d4.loss_cls: 0.1551, d4.loss_bbox: 0.2938, loss: 2.9786, grad_norm: 16.7079
2025-06-11 18:57:08,897 - mmdet - INFO - Epoch [3][2800/3517]	lr: 1.501e-03, eta: 5:52:24, time: 1.873, data_time: 0.055, memory: 32518, loss_cls: 0.1263, loss_bbox: 0.2821, d0.loss_cls: 0.2244, d0.loss_bbox: 0.4134, d1.loss_cls: 0.1996, d1.loss_bbox: 0.3099, d2.loss_cls: 0.1998, d2.loss_bbox: 0.3031, d3.loss_cls: 0.1958, d3.loss_bbox: 0.3086, d4.loss_cls: 0.1579, d4.loss_bbox: 0.2962, loss: 3.0169, grad_norm: 13.5260
2025-06-11 18:58:43,139 - mmdet - INFO - Epoch [3][2850/3517]	lr: 1.501e-03, eta: 5:50:50, time: 1.885, data_time: 0.057, memory: 32518, loss_cls: 0.1255, loss_bbox: 0.2774, d0.loss_cls: 0.2309, d0.loss_bbox: 0.4105, d1.loss_cls: 0.2022, d1.loss_bbox: 0.3071, d2.loss_cls: 0.2050, d2.loss_bbox: 0.2989, d3.loss_cls: 0.1997, d3.loss_bbox: 0.3080, d4.loss_cls: 0.1557, d4.loss_bbox: 0.2918, loss: 3.0128, grad_norm: 12.0517
2025-06-11 19:00:16,570 - mmdet - INFO - Epoch [3][2900/3517]	lr: 1.501e-03, eta: 5:49:16, time: 1.869, data_time: 0.057, memory: 32518, loss_cls: 0.1228, loss_bbox: 0.2704, d0.loss_cls: 0.2311, d0.loss_bbox: 0.3956, d1.loss_cls: 0.1978, d1.loss_bbox: 0.2926, d2.loss_cls: 0.2028, d2.loss_bbox: 0.2836, d3.loss_cls: 0.2011, d3.loss_bbox: 0.2902, d4.loss_cls: 0.1611, d4.loss_bbox: 0.2802, loss: 2.9293, grad_norm: 18.2613
2025-06-11 19:01:50,103 - mmdet - INFO - Epoch [3][2950/3517]	lr: 1.501e-03, eta: 5:47:42, time: 1.871, data_time: 0.056, memory: 32518, loss_cls: 0.1202, loss_bbox: 0.2781, d0.loss_cls: 0.2246, d0.loss_bbox: 0.4082, d1.loss_cls: 0.1962, d1.loss_bbox: 0.2983, d2.loss_cls: 0.1974, d2.loss_bbox: 0.2911, d3.loss_cls: 0.1924, d3.loss_bbox: 0.2978, d4.loss_cls: 0.1511, d4.loss_bbox: 0.2873, loss: 2.9427, grad_norm: 25.8881
2025-06-11 19:03:24,806 - mmdet - INFO - Epoch [3][3000/3517]	lr: 1.501e-03, eta: 5:46:09, time: 1.894, data_time: 0.078, memory: 32518, loss_cls: 0.1196, loss_bbox: 0.2667, d0.loss_cls: 0.2222, d0.loss_bbox: 0.3910, d1.loss_cls: 0.1996, d1.loss_bbox: 0.2920, d2.loss_cls: 0.2025, d2.loss_bbox: 0.2873, d3.loss_cls: 0.1954, d3.loss_bbox: 0.2965, d4.loss_cls: 0.1470, d4.loss_bbox: 0.2814, loss: 2.9013, grad_norm: 17.3133
2025-06-11 19:04:58,237 - mmdet - INFO - Epoch [3][3050/3517]	lr: 1.501e-03, eta: 5:44:35, time: 1.869, data_time: 0.058, memory: 32518, loss_cls: 0.1250, loss_bbox: 0.2695, d0.loss_cls: 0.2267, d0.loss_bbox: 0.3952, d1.loss_cls: 0.2047, d1.loss_bbox: 0.2958, d2.loss_cls: 0.2086, d2.loss_bbox: 0.2864, d3.loss_cls: 0.2007, d3.loss_bbox: 0.2936, d4.loss_cls: 0.1562, d4.loss_bbox: 0.2843, loss: 2.9466, grad_norm: 19.3052
2025-06-11 19:06:32,280 - mmdet - INFO - Epoch [3][3100/3517]	lr: 1.501e-03, eta: 5:43:01, time: 1.881, data_time: 0.058, memory: 32518, loss_cls: 0.1242, loss_bbox: 0.2729, d0.loss_cls: 0.2319, d0.loss_bbox: 0.4079, d1.loss_cls: 0.1960, d1.loss_bbox: 0.3026, d2.loss_cls: 0.1985, d2.loss_bbox: 0.2945, d3.loss_cls: 0.1949, d3.loss_bbox: 0.3034, d4.loss_cls: 0.1522, d4.loss_bbox: 0.2852, loss: 2.9642, grad_norm: 19.0478
2025-06-11 19:08:05,842 - mmdet - INFO - Epoch [3][3150/3517]	lr: 1.501e-03, eta: 5:41:27, time: 1.871, data_time: 0.059, memory: 32518, loss_cls: 0.1266, loss_bbox: 0.2735, d0.loss_cls: 0.2304, d0.loss_bbox: 0.4117, d1.loss_cls: 0.1984, d1.loss_bbox: 0.3035, d2.loss_cls: 0.1999, d2.loss_bbox: 0.2975, d3.loss_cls: 0.1974, d3.loss_bbox: 0.3049, d4.loss_cls: 0.1572, d4.loss_bbox: 0.2874, loss: 2.9886, grad_norm: 16.3549
2025-06-11 19:09:39,614 - mmdet - INFO - Epoch [3][3200/3517]	lr: 1.501e-03, eta: 5:39:53, time: 1.875, data_time: 0.057, memory: 32518, loss_cls: 0.1251, loss_bbox: 0.2785, d0.loss_cls: 0.2333, d0.loss_bbox: 0.3969, d1.loss_cls: 0.2031, d1.loss_bbox: 0.3053, d2.loss_cls: 0.2048, d2.loss_bbox: 0.2998, d3.loss_cls: 0.1991, d3.loss_bbox: 0.3121, d4.loss_cls: 0.1552, d4.loss_bbox: 0.2957, loss: 3.0089, grad_norm: 19.4956
2025-06-11 19:11:12,992 - mmdet - INFO - Epoch [3][3250/3517]	lr: 1.501e-03, eta: 5:38:19, time: 1.867, data_time: 0.056, memory: 32518, loss_cls: 0.1186, loss_bbox: 0.2731, d0.loss_cls: 0.2268, d0.loss_bbox: 0.3945, d1.loss_cls: 0.2015, d1.loss_bbox: 0.2959, d2.loss_cls: 0.2040, d2.loss_bbox: 0.2900, d3.loss_cls: 0.1999, d3.loss_bbox: 0.2965, d4.loss_cls: 0.1474, d4.loss_bbox: 0.2848, loss: 2.9329, grad_norm: 19.3904
2025-06-11 19:12:46,906 - mmdet - INFO - Epoch [3][3300/3517]	lr: 1.501e-03, eta: 5:36:45, time: 1.878, data_time: 0.057, memory: 32518, loss_cls: 0.1310, loss_bbox: 0.2789, d0.loss_cls: 0.2395, d0.loss_bbox: 0.4141, d1.loss_cls: 0.2099, d1.loss_bbox: 0.3067, d2.loss_cls: 0.2117, d2.loss_bbox: 0.3015, d3.loss_cls: 0.2036, d3.loss_bbox: 0.3084, d4.loss_cls: 0.1593, d4.loss_bbox: 0.2976, loss: 3.0621, grad_norm: 20.7080
2025-06-11 19:14:20,613 - mmdet - INFO - Epoch [3][3350/3517]	lr: 1.501e-03, eta: 5:35:11, time: 1.874, data_time: 0.057, memory: 32518, loss_cls: 0.1162, loss_bbox: 0.2637, d0.loss_cls: 0.2268, d0.loss_bbox: 0.3983, d1.loss_cls: 0.1979, d1.loss_bbox: 0.2868, d2.loss_cls: 0.1961, d2.loss_bbox: 0.2812, d3.loss_cls: 0.1911, d3.loss_bbox: 0.2862, d4.loss_cls: 0.1456, d4.loss_bbox: 0.2746, loss: 2.8644, grad_norm: 14.5468
2025-06-11 19:15:54,309 - mmdet - INFO - Epoch [3][3400/3517]	lr: 1.501e-03, eta: 5:33:37, time: 1.874, data_time: 0.058, memory: 32518, loss_cls: 0.1244, loss_bbox: 0.2760, d0.loss_cls: 0.2265, d0.loss_bbox: 0.3940, d1.loss_cls: 0.2019, d1.loss_bbox: 0.2928, d2.loss_cls: 0.2022, d2.loss_bbox: 0.2908, d3.loss_cls: 0.1975, d3.loss_bbox: 0.2944, d4.loss_cls: 0.1532, d4.loss_bbox: 0.2809, loss: 2.9345, grad_norm: 15.1859
2025-06-11 19:17:27,640 - mmdet - INFO - Epoch [3][3450/3517]	lr: 1.501e-03, eta: 5:32:03, time: 1.867, data_time: 0.055, memory: 32518, loss_cls: 0.1234, loss_bbox: 0.2684, d0.loss_cls: 0.2312, d0.loss_bbox: 0.3858, d1.loss_cls: 0.2020, d1.loss_bbox: 0.2890, d2.loss_cls: 0.2008, d2.loss_bbox: 0.2846, d3.loss_cls: 0.1921, d3.loss_bbox: 0.2893, d4.loss_cls: 0.1532, d4.loss_bbox: 0.2761, loss: 2.8959, grad_norm: 15.6852
2025-06-11 19:19:01,663 - mmdet - INFO - Epoch [3][3500/3517]	lr: 1.501e-03, eta: 5:30:29, time: 1.880, data_time: 0.060, memory: 32518, loss_cls: 0.1204, loss_bbox: 0.2593, d0.loss_cls: 0.2227, d0.loss_bbox: 0.3902, d1.loss_cls: 0.1901, d1.loss_bbox: 0.2872, d2.loss_cls: 0.1907, d2.loss_bbox: 0.2804, d3.loss_cls: 0.1846, d3.loss_bbox: 0.2856, d4.loss_cls: 0.1473, d4.loss_bbox: 0.2731, loss: 2.8315, grad_norm: 19.3092
2025-06-11 19:19:34,110 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-06-11 19:46:01,954 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 19:46:01,955 - mmdet - INFO - Epoch(val) [3][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7636, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8635, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8936, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9095, pts_bbox_NuScenes/car_trans_err: 0.1967, pts_bbox_NuScenes/car_scale_err: 0.1523, pts_bbox_NuScenes/car_orient_err: 0.0605, pts_bbox_NuScenes/car_vel_err: 0.3463, pts_bbox_NuScenes/car_attr_err: 0.1789, pts_bbox_NuScenes/mATE: 0.3320, pts_bbox_NuScenes/mASE: 0.2757, pts_bbox_NuScenes/mAOE: 0.2896, pts_bbox_NuScenes/mAVE: 0.2957, pts_bbox_NuScenes/mAAE: 0.1808, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.3676, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5650, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6657, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7109, pts_bbox_NuScenes/truck_trans_err: 0.3715, pts_bbox_NuScenes/truck_scale_err: 0.2107, pts_bbox_NuScenes/truck_orient_err: 0.0793, pts_bbox_NuScenes/truck_vel_err: 0.2774, pts_bbox_NuScenes/truck_attr_err: 0.2085, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0538, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1928, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3646, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4389, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6592, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4538, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7980, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1105, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2948, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.3950, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7164, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8831, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9090, pts_bbox_NuScenes/bus_trans_err: 0.4179, pts_bbox_NuScenes/bus_scale_err: 0.2096, pts_bbox_NuScenes/bus_orient_err: 0.0552, pts_bbox_NuScenes/bus_vel_err: 0.5433, pts_bbox_NuScenes/bus_attr_err: 0.2429, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1356, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4274, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5609, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6384, pts_bbox_NuScenes/trailer_trans_err: 0.5295, pts_bbox_NuScenes/trailer_scale_err: 0.2392, pts_bbox_NuScenes/trailer_orient_err: 0.6346, pts_bbox_NuScenes/trailer_vel_err: 0.2188, pts_bbox_NuScenes/trailer_attr_err: 0.1863, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5559, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6703, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7262, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7521, pts_bbox_NuScenes/barrier_trans_err: 0.2842, pts_bbox_NuScenes/barrier_scale_err: 0.3011, pts_bbox_NuScenes/barrier_orient_err: 0.0780, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.5979, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7391, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7828, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7951, pts_bbox_NuScenes/motorcycle_trans_err: 0.2511, pts_bbox_NuScenes/motorcycle_scale_err: 0.2565, pts_bbox_NuScenes/motorcycle_orient_err: 0.2624, pts_bbox_NuScenes/motorcycle_vel_err: 0.3999, pts_bbox_NuScenes/motorcycle_attr_err: 0.2154, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5212, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5907, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6044, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6136, pts_bbox_NuScenes/bicycle_trans_err: 0.2201, pts_bbox_NuScenes/bicycle_scale_err: 0.2996, pts_bbox_NuScenes/bicycle_orient_err: 0.2945, pts_bbox_NuScenes/bicycle_vel_err: 0.2315, pts_bbox_NuScenes/bicycle_attr_err: 0.0083, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7479, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8242, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8569, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8723, pts_bbox_NuScenes/pedestrian_trans_err: 0.2113, pts_bbox_NuScenes/pedestrian_scale_err: 0.2994, pts_bbox_NuScenes/pedestrian_orient_err: 0.3439, pts_bbox_NuScenes/pedestrian_vel_err: 0.2382, pts_bbox_NuScenes/pedestrian_attr_err: 0.1116, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6776, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7279, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7580, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7904, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1790, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3346, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6834, pts_bbox_NuScenes/mAP: 0.6415
2025-06-11 19:47:45,743 - mmdet - INFO - Epoch [4][50/3517]	lr: 1.001e-03, eta: 5:27:58, time: 2.005, data_time: 0.186, memory: 32518, loss_cls: 0.1148, loss_bbox: 0.2568, d0.loss_cls: 0.2178, d0.loss_bbox: 0.3744, d1.loss_cls: 0.1893, d1.loss_bbox: 0.2813, d2.loss_cls: 0.1915, d2.loss_bbox: 0.2750, d3.loss_cls: 0.1849, d3.loss_bbox: 0.2794, d4.loss_cls: 0.1418, d4.loss_bbox: 0.2682, loss: 2.7752, grad_norm: 16.0775
2025-06-11 19:49:20,173 - mmdet - INFO - Epoch [4][100/3517]	lr: 1.001e-03, eta: 5:26:25, time: 1.889, data_time: 0.065, memory: 32518, loss_cls: 0.1069, loss_bbox: 0.2540, d0.loss_cls: 0.2119, d0.loss_bbox: 0.3800, d1.loss_cls: 0.1806, d1.loss_bbox: 0.2835, d2.loss_cls: 0.1820, d2.loss_bbox: 0.2741, d3.loss_cls: 0.1767, d3.loss_bbox: 0.2794, d4.loss_cls: 0.1334, d4.loss_bbox: 0.2667, loss: 2.7291, grad_norm: 14.4492
2025-06-11 19:50:54,284 - mmdet - INFO - Epoch [4][150/3517]	lr: 1.001e-03, eta: 5:24:52, time: 1.882, data_time: 0.062, memory: 32518, loss_cls: 0.1130, loss_bbox: 0.2570, d0.loss_cls: 0.2115, d0.loss_bbox: 0.3791, d1.loss_cls: 0.1870, d1.loss_bbox: 0.2849, d2.loss_cls: 0.1886, d2.loss_bbox: 0.2774, d3.loss_cls: 0.1856, d3.loss_bbox: 0.2790, d4.loss_cls: 0.1398, d4.loss_bbox: 0.2707, loss: 2.7735, grad_norm: 12.7743
2025-06-11 19:52:28,716 - mmdet - INFO - Epoch [4][200/3517]	lr: 1.001e-03, eta: 5:23:19, time: 1.889, data_time: 0.067, memory: 32518, loss_cls: 0.1122, loss_bbox: 0.2620, d0.loss_cls: 0.2103, d0.loss_bbox: 0.3823, d1.loss_cls: 0.1816, d1.loss_bbox: 0.2847, d2.loss_cls: 0.1814, d2.loss_bbox: 0.2759, d3.loss_cls: 0.1783, d3.loss_bbox: 0.2781, d4.loss_cls: 0.1453, d4.loss_bbox: 0.2698, loss: 2.7619, grad_norm: 12.8438
2025-06-11 19:54:02,797 - mmdet - INFO - Epoch [4][250/3517]	lr: 1.001e-03, eta: 5:21:46, time: 1.882, data_time: 0.065, memory: 32518, loss_cls: 0.1102, loss_bbox: 0.2518, d0.loss_cls: 0.2107, d0.loss_bbox: 0.3716, d1.loss_cls: 0.1829, d1.loss_bbox: 0.2758, d2.loss_cls: 0.1816, d2.loss_bbox: 0.2690, d3.loss_cls: 0.1751, d3.loss_bbox: 0.2707, d4.loss_cls: 0.1360, d4.loss_bbox: 0.2632, loss: 2.6987, grad_norm: 12.8007
2025-06-11 19:55:40,322 - mmdet - INFO - Epoch [4][300/3517]	lr: 1.001e-03, eta: 5:20:16, time: 1.950, data_time: 0.058, memory: 32518, loss_cls: 0.1106, loss_bbox: 0.2496, d0.loss_cls: 0.2087, d0.loss_bbox: 0.3717, d1.loss_cls: 0.1791, d1.loss_bbox: 0.2733, d2.loss_cls: 0.1798, d2.loss_bbox: 0.2655, d3.loss_cls: 0.1720, d3.loss_bbox: 0.2691, d4.loss_cls: 0.1355, d4.loss_bbox: 0.2591, loss: 2.6739, grad_norm: 13.9423
2025-06-11 19:58:34,939 - mmdet - INFO - Epoch [4][350/3517]	lr: 1.001e-03, eta: 5:19:58, time: 3.492, data_time: 1.607, memory: 32518, loss_cls: 0.1186, loss_bbox: 0.2590, d0.loss_cls: 0.2162, d0.loss_bbox: 0.3880, d1.loss_cls: 0.1841, d1.loss_bbox: 0.2875, d2.loss_cls: 0.1863, d2.loss_bbox: 0.2789, d3.loss_cls: 0.1806, d3.loss_bbox: 0.2806, d4.loss_cls: 0.1437, d4.loss_bbox: 0.2718, loss: 2.7953, grad_norm: 16.1230
2025-06-11 20:00:09,615 - mmdet - INFO - Epoch [4][400/3517]	lr: 1.001e-03, eta: 5:18:24, time: 1.893, data_time: 0.056, memory: 32518, loss_cls: 0.1134, loss_bbox: 0.2558, d0.loss_cls: 0.2144, d0.loss_bbox: 0.3837, d1.loss_cls: 0.1821, d1.loss_bbox: 0.2856, d2.loss_cls: 0.1817, d2.loss_bbox: 0.2762, d3.loss_cls: 0.1747, d3.loss_bbox: 0.2766, d4.loss_cls: 0.1350, d4.loss_bbox: 0.2678, loss: 2.7469, grad_norm: 16.6856
2025-06-11 20:01:44,044 - mmdet - INFO - Epoch [4][450/3517]	lr: 1.001e-03, eta: 5:16:50, time: 1.889, data_time: 0.063, memory: 32518, loss_cls: 0.1119, loss_bbox: 0.2616, d0.loss_cls: 0.2096, d0.loss_bbox: 0.3797, d1.loss_cls: 0.1819, d1.loss_bbox: 0.2856, d2.loss_cls: 0.1819, d2.loss_bbox: 0.2805, d3.loss_cls: 0.1757, d3.loss_bbox: 0.2831, d4.loss_cls: 0.1376, d4.loss_bbox: 0.2710, loss: 2.7600, grad_norm: 15.2640
2025-06-11 20:03:31,920 - mmdet - INFO - Epoch [4][500/3517]	lr: 1.001e-03, eta: 5:15:29, time: 2.158, data_time: 0.253, memory: 32518, loss_cls: 0.1083, loss_bbox: 0.2518, d0.loss_cls: 0.2084, d0.loss_bbox: 0.3793, d1.loss_cls: 0.1739, d1.loss_bbox: 0.2804, d2.loss_cls: 0.1748, d2.loss_bbox: 0.2722, d3.loss_cls: 0.1679, d3.loss_bbox: 0.2767, d4.loss_cls: 0.1334, d4.loss_bbox: 0.2621, loss: 2.6893, grad_norm: 16.4813
2025-06-11 20:05:06,763 - mmdet - INFO - Epoch [4][550/3517]	lr: 1.001e-03, eta: 5:13:55, time: 1.897, data_time: 0.060, memory: 32518, loss_cls: 0.1101, loss_bbox: 0.2522, d0.loss_cls: 0.2105, d0.loss_bbox: 0.3707, d1.loss_cls: 0.1800, d1.loss_bbox: 0.2765, d2.loss_cls: 0.1792, d2.loss_bbox: 0.2709, d3.loss_cls: 0.1755, d3.loss_bbox: 0.2728, d4.loss_cls: 0.1350, d4.loss_bbox: 0.2649, loss: 2.6984, grad_norm: 13.3165
2025-06-11 20:06:41,340 - mmdet - INFO - Epoch [4][600/3517]	lr: 1.001e-03, eta: 5:12:21, time: 1.891, data_time: 0.060, memory: 32518, loss_cls: 0.1117, loss_bbox: 0.2580, d0.loss_cls: 0.2105, d0.loss_bbox: 0.3760, d1.loss_cls: 0.1841, d1.loss_bbox: 0.2826, d2.loss_cls: 0.1837, d2.loss_bbox: 0.2762, d3.loss_cls: 0.1792, d3.loss_bbox: 0.2784, d4.loss_cls: 0.1376, d4.loss_bbox: 0.2675, loss: 2.7455, grad_norm: 18.3574
2025-06-11 20:08:16,355 - mmdet - INFO - Epoch [4][650/3517]	lr: 1.001e-03, eta: 5:10:48, time: 1.900, data_time: 0.060, memory: 32518, loss_cls: 0.1127, loss_bbox: 0.2536, d0.loss_cls: 0.2121, d0.loss_bbox: 0.3730, d1.loss_cls: 0.1835, d1.loss_bbox: 0.2784, d2.loss_cls: 0.1839, d2.loss_bbox: 0.2716, d3.loss_cls: 0.1789, d3.loss_bbox: 0.2749, d4.loss_cls: 0.1354, d4.loss_bbox: 0.2646, loss: 2.7226, grad_norm: 13.7820
2025-06-11 20:09:56,225 - mmdet - INFO - Epoch [4][700/3517]	lr: 1.001e-03, eta: 5:09:19, time: 1.997, data_time: 0.167, memory: 32518, loss_cls: 0.1067, loss_bbox: 0.2560, d0.loss_cls: 0.2098, d0.loss_bbox: 0.3786, d1.loss_cls: 0.1792, d1.loss_bbox: 0.2808, d2.loss_cls: 0.1788, d2.loss_bbox: 0.2729, d3.loss_cls: 0.1749, d3.loss_bbox: 0.2759, d4.loss_cls: 0.1296, d4.loss_bbox: 0.2654, loss: 2.7086, grad_norm: 12.5731
2025-06-11 20:11:30,620 - mmdet - INFO - Epoch [4][750/3517]	lr: 1.001e-03, eta: 5:07:45, time: 1.888, data_time: 0.049, memory: 32518, loss_cls: 0.1056, loss_bbox: 0.2388, d0.loss_cls: 0.2043, d0.loss_bbox: 0.3623, d1.loss_cls: 0.1757, d1.loss_bbox: 0.2647, d2.loss_cls: 0.1757, d2.loss_bbox: 0.2572, d3.loss_cls: 0.1709, d3.loss_bbox: 0.2594, d4.loss_cls: 0.1261, d4.loss_bbox: 0.2512, loss: 2.5919, grad_norm: 13.9437
2025-06-11 20:13:04,154 - mmdet - INFO - Epoch [4][800/3517]	lr: 1.001e-03, eta: 5:06:10, time: 1.871, data_time: 0.054, memory: 32518, loss_cls: 0.1072, loss_bbox: 0.2508, d0.loss_cls: 0.2086, d0.loss_bbox: 0.3747, d1.loss_cls: 0.1778, d1.loss_bbox: 0.2798, d2.loss_cls: 0.1800, d2.loss_bbox: 0.2695, d3.loss_cls: 0.1721, d3.loss_bbox: 0.2720, d4.loss_cls: 0.1282, d4.loss_bbox: 0.2639, loss: 2.6846, grad_norm: 18.0893
2025-06-11 20:14:37,528 - mmdet - INFO - Epoch [4][850/3517]	lr: 1.001e-03, eta: 5:04:35, time: 1.868, data_time: 0.057, memory: 32518, loss_cls: 0.1071, loss_bbox: 0.2461, d0.loss_cls: 0.2066, d0.loss_bbox: 0.3741, d1.loss_cls: 0.1743, d1.loss_bbox: 0.2780, d2.loss_cls: 0.1755, d2.loss_bbox: 0.2695, d3.loss_cls: 0.1694, d3.loss_bbox: 0.2720, d4.loss_cls: 0.1298, d4.loss_bbox: 0.2594, loss: 2.6618, grad_norm: 15.1259
2025-06-11 20:16:11,189 - mmdet - INFO - Epoch [4][900/3517]	lr: 1.001e-03, eta: 5:03:00, time: 1.873, data_time: 0.057, memory: 32518, loss_cls: 0.1111, loss_bbox: 0.2506, d0.loss_cls: 0.2189, d0.loss_bbox: 0.3792, d1.loss_cls: 0.1862, d1.loss_bbox: 0.2775, d2.loss_cls: 0.1855, d2.loss_bbox: 0.2679, d3.loss_cls: 0.1810, d3.loss_bbox: 0.2696, d4.loss_cls: 0.1380, d4.loss_bbox: 0.2600, loss: 2.7256, grad_norm: 22.1343
2025-06-11 20:17:45,384 - mmdet - INFO - Epoch [4][950/3517]	lr: 1.001e-03, eta: 5:01:26, time: 1.884, data_time: 0.055, memory: 32518, loss_cls: 0.1071, loss_bbox: 0.2460, d0.loss_cls: 0.2101, d0.loss_bbox: 0.3700, d1.loss_cls: 0.1775, d1.loss_bbox: 0.2710, d2.loss_cls: 0.1772, d2.loss_bbox: 0.2652, d3.loss_cls: 0.1711, d3.loss_bbox: 0.2673, d4.loss_cls: 0.1299, d4.loss_bbox: 0.2574, loss: 2.6499, grad_norm: 18.8659
2025-06-11 20:19:18,938 - mmdet - INFO - Epoch [4][1000/3517]	lr: 1.001e-03, eta: 4:59:51, time: 1.871, data_time: 0.055, memory: 32518, loss_cls: 0.1098, loss_bbox: 0.2527, d0.loss_cls: 0.2053, d0.loss_bbox: 0.3699, d1.loss_cls: 0.1772, d1.loss_bbox: 0.2777, d2.loss_cls: 0.1776, d2.loss_bbox: 0.2752, d3.loss_cls: 0.1733, d3.loss_bbox: 0.2788, d4.loss_cls: 0.1306, d4.loss_bbox: 0.2662, loss: 2.6943, grad_norm: 27.8883
2025-06-11 20:20:52,667 - mmdet - INFO - Epoch [4][1050/3517]	lr: 1.001e-03, eta: 4:58:17, time: 1.875, data_time: 0.055, memory: 32518, loss_cls: 0.1036, loss_bbox: 0.2574, d0.loss_cls: 0.2020, d0.loss_bbox: 0.3749, d1.loss_cls: 0.1730, d1.loss_bbox: 0.2829, d2.loss_cls: 0.1743, d2.loss_bbox: 0.2756, d3.loss_cls: 0.1700, d3.loss_bbox: 0.2770, d4.loss_cls: 0.1264, d4.loss_bbox: 0.2680, loss: 2.6852, grad_norm: 15.9847
2025-06-11 20:22:39,217 - mmdet - INFO - Epoch [4][1100/3517]	lr: 1.001e-03, eta: 4:56:53, time: 2.131, data_time: 0.188, memory: 32518, loss_cls: 0.1115, loss_bbox: 0.2539, d0.loss_cls: 0.2116, d0.loss_bbox: 0.3702, d1.loss_cls: 0.1806, d1.loss_bbox: 0.2769, d2.loss_cls: 0.1793, d2.loss_bbox: 0.2697, d3.loss_cls: 0.1761, d3.loss_bbox: 0.2705, d4.loss_cls: 0.1358, d4.loss_bbox: 0.2616, loss: 2.6977, grad_norm: 15.4529
2025-06-11 20:24:12,274 - mmdet - INFO - Epoch [4][1150/3517]	lr: 1.001e-03, eta: 4:55:18, time: 1.861, data_time: 0.054, memory: 32518, loss_cls: 0.1118, loss_bbox: 0.2498, d0.loss_cls: 0.2144, d0.loss_bbox: 0.3746, d1.loss_cls: 0.1848, d1.loss_bbox: 0.2729, d2.loss_cls: 0.1840, d2.loss_bbox: 0.2674, d3.loss_cls: 0.1767, d3.loss_bbox: 0.2698, d4.loss_cls: 0.1324, d4.loss_bbox: 0.2596, loss: 2.6983, grad_norm: 19.2243
2025-06-11 20:25:46,295 - mmdet - INFO - Epoch [4][1200/3517]	lr: 1.001e-03, eta: 4:53:43, time: 1.880, data_time: 0.055, memory: 32518, loss_cls: 0.1074, loss_bbox: 0.2503, d0.loss_cls: 0.2067, d0.loss_bbox: 0.3740, d1.loss_cls: 0.1770, d1.loss_bbox: 0.2773, d2.loss_cls: 0.1756, d2.loss_bbox: 0.2721, d3.loss_cls: 0.1702, d3.loss_bbox: 0.2728, d4.loss_cls: 0.1279, d4.loss_bbox: 0.2619, loss: 2.6732, grad_norm: 17.5517
2025-06-11 20:27:20,233 - mmdet - INFO - Epoch [4][1250/3517]	lr: 1.001e-03, eta: 4:52:09, time: 1.879, data_time: 0.060, memory: 32518, loss_cls: 0.1097, loss_bbox: 0.2480, d0.loss_cls: 0.2022, d0.loss_bbox: 0.3678, d1.loss_cls: 0.1766, d1.loss_bbox: 0.2760, d2.loss_cls: 0.1749, d2.loss_bbox: 0.2712, d3.loss_cls: 0.1714, d3.loss_bbox: 0.2715, d4.loss_cls: 0.1303, d4.loss_bbox: 0.2592, loss: 2.6587, grad_norm: 14.7951
2025-06-11 20:28:54,241 - mmdet - INFO - Epoch [4][1300/3517]	lr: 1.001e-03, eta: 4:50:34, time: 1.880, data_time: 0.060, memory: 32518, loss_cls: 0.1115, loss_bbox: 0.2496, d0.loss_cls: 0.2107, d0.loss_bbox: 0.3770, d1.loss_cls: 0.1823, d1.loss_bbox: 0.2738, d2.loss_cls: 0.1822, d2.loss_bbox: 0.2665, d3.loss_cls: 0.1758, d3.loss_bbox: 0.2658, d4.loss_cls: 0.1332, d4.loss_bbox: 0.2582, loss: 2.6868, grad_norm: 22.6072
2025-06-11 20:30:28,177 - mmdet - INFO - Epoch [4][1350/3517]	lr: 1.001e-03, eta: 4:49:00, time: 1.879, data_time: 0.059, memory: 32518, loss_cls: 0.1106, loss_bbox: 0.2520, d0.loss_cls: 0.2079, d0.loss_bbox: 0.3746, d1.loss_cls: 0.1808, d1.loss_bbox: 0.2716, d2.loss_cls: 0.1792, d2.loss_bbox: 0.2655, d3.loss_cls: 0.1736, d3.loss_bbox: 0.2704, d4.loss_cls: 0.1362, d4.loss_bbox: 0.2623, loss: 2.6846, grad_norm: 22.5967
2025-06-11 20:32:02,030 - mmdet - INFO - Epoch [4][1400/3517]	lr: 1.001e-03, eta: 4:47:25, time: 1.877, data_time: 0.062, memory: 32518, loss_cls: 0.1121, loss_bbox: 0.2481, d0.loss_cls: 0.2043, d0.loss_bbox: 0.3721, d1.loss_cls: 0.1758, d1.loss_bbox: 0.2746, d2.loss_cls: 0.1762, d2.loss_bbox: 0.2691, d3.loss_cls: 0.1716, d3.loss_bbox: 0.2699, d4.loss_cls: 0.1350, d4.loss_bbox: 0.2606, loss: 2.6693, grad_norm: 19.4430
2025-06-11 20:33:35,984 - mmdet - INFO - Epoch [4][1450/3517]	lr: 1.001e-03, eta: 4:45:51, time: 1.879, data_time: 0.059, memory: 32518, loss_cls: 0.1059, loss_bbox: 0.2447, d0.loss_cls: 0.1995, d0.loss_bbox: 0.3715, d1.loss_cls: 0.1690, d1.loss_bbox: 0.2731, d2.loss_cls: 0.1684, d2.loss_bbox: 0.2660, d3.loss_cls: 0.1632, d3.loss_bbox: 0.2688, d4.loss_cls: 0.1269, d4.loss_bbox: 0.2564, loss: 2.6134, grad_norm: 15.9229
2025-06-11 20:35:09,644 - mmdet - INFO - Epoch [4][1500/3517]	lr: 1.001e-03, eta: 4:44:16, time: 1.873, data_time: 0.052, memory: 32518, loss_cls: 0.1133, loss_bbox: 0.2570, d0.loss_cls: 0.2104, d0.loss_bbox: 0.3804, d1.loss_cls: 0.1790, d1.loss_bbox: 0.2834, d2.loss_cls: 0.1775, d2.loss_bbox: 0.2757, d3.loss_cls: 0.1734, d3.loss_bbox: 0.2764, d4.loss_cls: 0.1389, d4.loss_bbox: 0.2654, loss: 2.7307, grad_norm: 18.9110
2025-06-11 20:36:43,887 - mmdet - INFO - Epoch [4][1550/3517]	lr: 1.001e-03, eta: 4:42:42, time: 1.885, data_time: 0.058, memory: 32518, loss_cls: 0.1062, loss_bbox: 0.2468, d0.loss_cls: 0.2102, d0.loss_bbox: 0.3710, d1.loss_cls: 0.1785, d1.loss_bbox: 0.2725, d2.loss_cls: 0.1770, d2.loss_bbox: 0.2636, d3.loss_cls: 0.1700, d3.loss_bbox: 0.2638, d4.loss_cls: 0.1272, d4.loss_bbox: 0.2553, loss: 2.6423, grad_norm: 16.9226
2025-06-11 20:38:18,063 - mmdet - INFO - Epoch [4][1600/3517]	lr: 1.001e-03, eta: 4:41:08, time: 1.884, data_time: 0.060, memory: 32518, loss_cls: 0.1043, loss_bbox: 0.2447, d0.loss_cls: 0.1998, d0.loss_bbox: 0.3681, d1.loss_cls: 0.1753, d1.loss_bbox: 0.2702, d2.loss_cls: 0.1727, d2.loss_bbox: 0.2629, d3.loss_cls: 0.1676, d3.loss_bbox: 0.2642, d4.loss_cls: 0.1256, d4.loss_bbox: 0.2548, loss: 2.6101, grad_norm: 22.3405
2025-06-11 20:39:52,226 - mmdet - INFO - Epoch [4][1650/3517]	lr: 1.001e-03, eta: 4:39:33, time: 1.883, data_time: 0.056, memory: 32518, loss_cls: 0.1079, loss_bbox: 0.2431, d0.loss_cls: 0.2105, d0.loss_bbox: 0.3680, d1.loss_cls: 0.1815, d1.loss_bbox: 0.2725, d2.loss_cls: 0.1812, d2.loss_bbox: 0.2633, d3.loss_cls: 0.1739, d3.loss_bbox: 0.2640, d4.loss_cls: 0.1309, d4.loss_bbox: 0.2532, loss: 2.6501, grad_norm: 18.1566
2025-06-11 20:41:26,353 - mmdet - INFO - Epoch [4][1700/3517]	lr: 1.001e-03, eta: 4:37:59, time: 1.883, data_time: 0.058, memory: 32518, loss_cls: 0.1110, loss_bbox: 0.2511, d0.loss_cls: 0.2019, d0.loss_bbox: 0.3701, d1.loss_cls: 0.1779, d1.loss_bbox: 0.2744, d2.loss_cls: 0.1783, d2.loss_bbox: 0.2653, d3.loss_cls: 0.1717, d3.loss_bbox: 0.2685, d4.loss_cls: 0.1341, d4.loss_bbox: 0.2602, loss: 2.6645, grad_norm: 14.2944
2025-06-11 20:42:59,882 - mmdet - INFO - Epoch [4][1750/3517]	lr: 1.001e-03, eta: 4:36:24, time: 1.870, data_time: 0.059, memory: 32518, loss_cls: 0.1158, loss_bbox: 0.2695, d0.loss_cls: 0.2118, d0.loss_bbox: 0.3950, d1.loss_cls: 0.1888, d1.loss_bbox: 0.2985, d2.loss_cls: 0.1845, d2.loss_bbox: 0.2865, d3.loss_cls: 0.1791, d3.loss_bbox: 0.2881, d4.loss_cls: 0.1407, d4.loss_bbox: 0.2793, loss: 2.8376, grad_norm: 15.8769
2025-06-11 20:44:33,394 - mmdet - INFO - Epoch [4][1800/3517]	lr: 1.001e-03, eta: 4:34:50, time: 1.870, data_time: 0.059, memory: 32518, loss_cls: 0.1066, loss_bbox: 0.2444, d0.loss_cls: 0.2040, d0.loss_bbox: 0.3681, d1.loss_cls: 0.1777, d1.loss_bbox: 0.2722, d2.loss_cls: 0.1746, d2.loss_bbox: 0.2658, d3.loss_cls: 0.1679, d3.loss_bbox: 0.2674, d4.loss_cls: 0.1289, d4.loss_bbox: 0.2568, loss: 2.6343, grad_norm: 15.7661
2025-06-11 20:46:08,013 - mmdet - INFO - Epoch [4][1850/3517]	lr: 1.001e-03, eta: 4:33:16, time: 1.892, data_time: 0.069, memory: 32518, loss_cls: 0.1050, loss_bbox: 0.2454, d0.loss_cls: 0.2079, d0.loss_bbox: 0.3683, d1.loss_cls: 0.1804, d1.loss_bbox: 0.2706, d2.loss_cls: 0.1815, d2.loss_bbox: 0.2641, d3.loss_cls: 0.1748, d3.loss_bbox: 0.2649, d4.loss_cls: 0.1318, d4.loss_bbox: 0.2545, loss: 2.6492, grad_norm: 20.4342
2025-06-11 20:47:41,626 - mmdet - INFO - Epoch [4][1900/3517]	lr: 1.001e-03, eta: 4:31:41, time: 1.872, data_time: 0.056, memory: 32518, loss_cls: 0.1132, loss_bbox: 0.2517, d0.loss_cls: 0.2103, d0.loss_bbox: 0.3844, d1.loss_cls: 0.1833, d1.loss_bbox: 0.2785, d2.loss_cls: 0.1815, d2.loss_bbox: 0.2698, d3.loss_cls: 0.1750, d3.loss_bbox: 0.2718, d4.loss_cls: 0.1369, d4.loss_bbox: 0.2640, loss: 2.7203, grad_norm: 51.7734
2025-06-11 20:49:16,330 - mmdet - INFO - Epoch [4][1950/3517]	lr: 1.001e-03, eta: 4:30:07, time: 1.894, data_time: 0.060, memory: 32518, loss_cls: 0.1103, loss_bbox: 0.2551, d0.loss_cls: 0.2090, d0.loss_bbox: 0.3793, d1.loss_cls: 0.1822, d1.loss_bbox: 0.2821, d2.loss_cls: 0.1793, d2.loss_bbox: 0.2767, d3.loss_cls: 0.1721, d3.loss_bbox: 0.2783, d4.loss_cls: 0.1335, d4.loss_bbox: 0.2662, loss: 2.7240, grad_norm: 65.4437
2025-06-11 20:50:53,973 - mmdet - INFO - Epoch [4][2000/3517]	lr: 1.001e-03, eta: 4:28:35, time: 1.953, data_time: 0.054, memory: 32518, loss_cls: 0.1081, loss_bbox: 0.2498, d0.loss_cls: 0.2053, d0.loss_bbox: 0.3750, d1.loss_cls: 0.1766, d1.loss_bbox: 0.2763, d2.loss_cls: 0.1752, d2.loss_bbox: 0.2708, d3.loss_cls: 0.1677, d3.loss_bbox: 0.2732, d4.loss_cls: 0.1288, d4.loss_bbox: 0.2635, loss: 2.6702, grad_norm: 28.4358
2025-06-11 20:52:29,533 - mmdet - INFO - Epoch [4][2050/3517]	lr: 1.001e-03, eta: 4:27:02, time: 1.911, data_time: 0.081, memory: 32518, loss_cls: 0.1065, loss_bbox: 0.2542, d0.loss_cls: 0.2048, d0.loss_bbox: 0.3791, d1.loss_cls: 0.1752, d1.loss_bbox: 0.2793, d2.loss_cls: 0.1747, d2.loss_bbox: 0.2710, d3.loss_cls: 0.1694, d3.loss_bbox: 0.2737, d4.loss_cls: 0.1292, d4.loss_bbox: 0.2660, loss: 2.6832, grad_norm: 14.5839
2025-06-11 20:54:03,729 - mmdet - INFO - Epoch [4][2100/3517]	lr: 1.001e-03, eta: 4:25:28, time: 1.884, data_time: 0.055, memory: 32518, loss_cls: 0.1002, loss_bbox: 0.2513, d0.loss_cls: 0.2021, d0.loss_bbox: 0.3687, d1.loss_cls: 0.1703, d1.loss_bbox: 0.2708, d2.loss_cls: 0.1662, d2.loss_bbox: 0.2636, d3.loss_cls: 0.1597, d3.loss_bbox: 0.2648, d4.loss_cls: 0.1213, d4.loss_bbox: 0.2568, loss: 2.5958, grad_norm: 20.6868
2025-06-11 20:55:37,428 - mmdet - INFO - Epoch [4][2150/3517]	lr: 1.001e-03, eta: 4:23:53, time: 1.874, data_time: 0.051, memory: 32518, loss_cls: 0.1071, loss_bbox: 0.2534, d0.loss_cls: 0.2072, d0.loss_bbox: 0.3743, d1.loss_cls: 0.1832, d1.loss_bbox: 0.2785, d2.loss_cls: 0.1808, d2.loss_bbox: 0.2686, d3.loss_cls: 0.1745, d3.loss_bbox: 0.2702, d4.loss_cls: 0.1321, d4.loss_bbox: 0.2620, loss: 2.6919, grad_norm: 18.7537
2025-06-11 20:57:11,704 - mmdet - INFO - Epoch [4][2200/3517]	lr: 1.001e-03, eta: 4:22:19, time: 1.885, data_time: 0.066, memory: 32518, loss_cls: 0.1047, loss_bbox: 0.2481, d0.loss_cls: 0.2037, d0.loss_bbox: 0.3763, d1.loss_cls: 0.1759, d1.loss_bbox: 0.2758, d2.loss_cls: 0.1732, d2.loss_bbox: 0.2675, d3.loss_cls: 0.1639, d3.loss_bbox: 0.2674, d4.loss_cls: 0.1248, d4.loss_bbox: 0.2598, loss: 2.6410, grad_norm: 26.4682
2025-06-11 20:58:45,234 - mmdet - INFO - Epoch [4][2250/3517]	lr: 1.001e-03, eta: 4:20:44, time: 1.871, data_time: 0.058, memory: 32518, loss_cls: 0.1044, loss_bbox: 0.2565, d0.loss_cls: 0.2049, d0.loss_bbox: 0.3743, d1.loss_cls: 0.1747, d1.loss_bbox: 0.2809, d2.loss_cls: 0.1726, d2.loss_bbox: 0.2731, d3.loss_cls: 0.1646, d3.loss_bbox: 0.2731, d4.loss_cls: 0.1281, d4.loss_bbox: 0.2659, loss: 2.6730, grad_norm: 14.8227
2025-06-11 21:00:19,310 - mmdet - INFO - Epoch [4][2300/3517]	lr: 1.001e-03, eta: 4:19:10, time: 1.882, data_time: 0.059, memory: 32518, loss_cls: 0.1040, loss_bbox: 0.2526, d0.loss_cls: 0.2047, d0.loss_bbox: 0.3830, d1.loss_cls: 0.1773, d1.loss_bbox: 0.2843, d2.loss_cls: 0.1765, d2.loss_bbox: 0.2730, d3.loss_cls: 0.1708, d3.loss_bbox: 0.2747, d4.loss_cls: 0.1263, d4.loss_bbox: 0.2632, loss: 2.6904, grad_norm: 16.9025
2025-06-11 21:01:52,709 - mmdet - INFO - Epoch [4][2350/3517]	lr: 1.001e-03, eta: 4:17:35, time: 1.868, data_time: 0.053, memory: 32518, loss_cls: 0.1020, loss_bbox: 0.2481, d0.loss_cls: 0.2000, d0.loss_bbox: 0.3576, d1.loss_cls: 0.1737, d1.loss_bbox: 0.2671, d2.loss_cls: 0.1720, d2.loss_bbox: 0.2610, d3.loss_cls: 0.1630, d3.loss_bbox: 0.2645, d4.loss_cls: 0.1229, d4.loss_bbox: 0.2563, loss: 2.5884, grad_norm: 18.7744
2025-06-11 21:03:26,257 - mmdet - INFO - Epoch [4][2400/3517]	lr: 1.001e-03, eta: 4:16:00, time: 1.871, data_time: 0.055, memory: 32518, loss_cls: 0.1082, loss_bbox: 0.2557, d0.loss_cls: 0.2029, d0.loss_bbox: 0.3743, d1.loss_cls: 0.1748, d1.loss_bbox: 0.2786, d2.loss_cls: 0.1727, d2.loss_bbox: 0.2698, d3.loss_cls: 0.1663, d3.loss_bbox: 0.2708, d4.loss_cls: 0.1294, d4.loss_bbox: 0.2622, loss: 2.6659, grad_norm: 17.6592
2025-06-11 21:04:59,966 - mmdet - INFO - Epoch [4][2450/3517]	lr: 1.001e-03, eta: 4:14:26, time: 1.874, data_time: 0.054, memory: 32518, loss_cls: 0.1051, loss_bbox: 0.2495, d0.loss_cls: 0.2050, d0.loss_bbox: 0.3755, d1.loss_cls: 0.1735, d1.loss_bbox: 0.2807, d2.loss_cls: 0.1697, d2.loss_bbox: 0.2729, d3.loss_cls: 0.1632, d3.loss_bbox: 0.2713, d4.loss_cls: 0.1273, d4.loss_bbox: 0.2639, loss: 2.6576, grad_norm: 18.4398
2025-06-11 21:06:33,408 - mmdet - INFO - Epoch [4][2500/3517]	lr: 1.001e-03, eta: 4:12:51, time: 1.869, data_time: 0.053, memory: 32518, loss_cls: 0.1084, loss_bbox: 0.2503, d0.loss_cls: 0.2080, d0.loss_bbox: 0.3720, d1.loss_cls: 0.1760, d1.loss_bbox: 0.2768, d2.loss_cls: 0.1734, d2.loss_bbox: 0.2693, d3.loss_cls: 0.1651, d3.loss_bbox: 0.2708, d4.loss_cls: 0.1301, d4.loss_bbox: 0.2636, loss: 2.6638, grad_norm: 13.0892
2025-06-11 21:08:07,165 - mmdet - INFO - Epoch [4][2550/3517]	lr: 1.001e-03, eta: 4:11:17, time: 1.875, data_time: 0.059, memory: 32518, loss_cls: 0.1065, loss_bbox: 0.2477, d0.loss_cls: 0.2050, d0.loss_bbox: 0.3720, d1.loss_cls: 0.1764, d1.loss_bbox: 0.2746, d2.loss_cls: 0.1734, d2.loss_bbox: 0.2659, d3.loss_cls: 0.1657, d3.loss_bbox: 0.2673, d4.loss_cls: 0.1297, d4.loss_bbox: 0.2596, loss: 2.6437, grad_norm: 18.4017
2025-06-11 21:09:41,598 - mmdet - INFO - Epoch [4][2600/3517]	lr: 1.001e-03, eta: 4:09:43, time: 1.889, data_time: 0.064, memory: 32518, loss_cls: 0.1049, loss_bbox: 0.2494, d0.loss_cls: 0.2094, d0.loss_bbox: 0.3697, d1.loss_cls: 0.1787, d1.loss_bbox: 0.2737, d2.loss_cls: 0.1711, d2.loss_bbox: 0.2709, d3.loss_cls: 0.1639, d3.loss_bbox: 0.2708, d4.loss_cls: 0.1261, d4.loss_bbox: 0.2609, loss: 2.6494, grad_norm: 18.3891
2025-06-11 21:11:15,909 - mmdet - INFO - Epoch [4][2650/3517]	lr: 1.001e-03, eta: 4:08:08, time: 1.886, data_time: 0.055, memory: 32518, loss_cls: 0.1124, loss_bbox: 0.2532, d0.loss_cls: 0.2138, d0.loss_bbox: 0.3829, d1.loss_cls: 0.1905, d1.loss_bbox: 0.2839, d2.loss_cls: 0.1916, d2.loss_bbox: 0.2764, d3.loss_cls: 0.1835, d3.loss_bbox: 0.2793, d4.loss_cls: 0.1368, d4.loss_bbox: 0.2640, loss: 2.7681, grad_norm: 16.9373
2025-06-11 21:12:50,657 - mmdet - INFO - Epoch [4][2700/3517]	lr: 1.001e-03, eta: 4:06:35, time: 1.895, data_time: 0.056, memory: 32518, loss_cls: 0.1055, loss_bbox: 0.2403, d0.loss_cls: 0.2043, d0.loss_bbox: 0.3702, d1.loss_cls: 0.1765, d1.loss_bbox: 0.2714, d2.loss_cls: 0.1777, d2.loss_bbox: 0.2659, d3.loss_cls: 0.1722, d3.loss_bbox: 0.2720, d4.loss_cls: 0.1331, d4.loss_bbox: 0.2550, loss: 2.6440, grad_norm: 15.8172
2025-06-11 21:14:27,141 - mmdet - INFO - Epoch [4][2750/3517]	lr: 1.001e-03, eta: 4:05:02, time: 1.930, data_time: 0.066, memory: 32518, loss_cls: 0.1060, loss_bbox: 0.2424, d0.loss_cls: 0.2011, d0.loss_bbox: 0.3615, d1.loss_cls: 0.1722, d1.loss_bbox: 0.2704, d2.loss_cls: 0.1711, d2.loss_bbox: 0.2658, d3.loss_cls: 0.1638, d3.loss_bbox: 0.2679, d4.loss_cls: 0.1291, d4.loss_bbox: 0.2536, loss: 2.6049, grad_norm: 15.7530
2025-06-11 21:16:03,106 - mmdet - INFO - Epoch [4][2800/3517]	lr: 1.001e-03, eta: 4:03:28, time: 1.919, data_time: 0.069, memory: 32518, loss_cls: 0.1114, loss_bbox: 0.2583, d0.loss_cls: 0.2063, d0.loss_bbox: 0.3797, d1.loss_cls: 0.1764, d1.loss_bbox: 0.2878, d2.loss_cls: 0.1752, d2.loss_bbox: 0.2791, d3.loss_cls: 0.1681, d3.loss_bbox: 0.2819, d4.loss_cls: 0.1340, d4.loss_bbox: 0.2693, loss: 2.7274, grad_norm: 19.1850
2025-06-11 21:17:37,995 - mmdet - INFO - Epoch [4][2850/3517]	lr: 1.001e-03, eta: 4:01:55, time: 1.898, data_time: 0.069, memory: 32518, loss_cls: 0.1129, loss_bbox: 0.2546, d0.loss_cls: 0.2087, d0.loss_bbox: 0.3831, d1.loss_cls: 0.1778, d1.loss_bbox: 0.2831, d2.loss_cls: 0.1741, d2.loss_bbox: 0.2760, d3.loss_cls: 0.1683, d3.loss_bbox: 0.2784, d4.loss_cls: 0.1356, d4.loss_bbox: 0.2665, loss: 2.7191, grad_norm: 19.1782
2025-06-11 21:19:12,021 - mmdet - INFO - Epoch [4][2900/3517]	lr: 1.001e-03, eta: 4:00:20, time: 1.881, data_time: 0.054, memory: 32518, loss_cls: 0.1141, loss_bbox: 0.2571, d0.loss_cls: 0.2112, d0.loss_bbox: 0.3780, d1.loss_cls: 0.1827, d1.loss_bbox: 0.2828, d2.loss_cls: 0.1795, d2.loss_bbox: 0.2762, d3.loss_cls: 0.1691, d3.loss_bbox: 0.2794, d4.loss_cls: 0.1375, d4.loss_bbox: 0.2670, loss: 2.7346, grad_norm: 32.5860
2025-06-11 21:20:46,265 - mmdet - INFO - Epoch [4][2950/3517]	lr: 1.001e-03, eta: 3:58:46, time: 1.885, data_time: 0.058, memory: 32518, loss_cls: 0.1064, loss_bbox: 0.2465, d0.loss_cls: 0.2026, d0.loss_bbox: 0.3734, d1.loss_cls: 0.1736, d1.loss_bbox: 0.2733, d2.loss_cls: 0.1701, d2.loss_bbox: 0.2651, d3.loss_cls: 0.1605, d3.loss_bbox: 0.2651, d4.loss_cls: 0.1264, d4.loss_bbox: 0.2540, loss: 2.6170, grad_norm: 19.0783
2025-06-11 21:22:19,358 - mmdet - INFO - Epoch [4][3000/3517]	lr: 1.001e-03, eta: 3:57:11, time: 1.862, data_time: 0.049, memory: 32518, loss_cls: 0.1130, loss_bbox: 0.2518, d0.loss_cls: 0.2074, d0.loss_bbox: 0.3728, d1.loss_cls: 0.1783, d1.loss_bbox: 0.2769, d2.loss_cls: 0.1762, d2.loss_bbox: 0.2691, d3.loss_cls: 0.1676, d3.loss_bbox: 0.2687, d4.loss_cls: 0.1372, d4.loss_bbox: 0.2612, loss: 2.6801, grad_norm: 22.5970
2025-06-11 21:23:52,711 - mmdet - INFO - Epoch [4][3050/3517]	lr: 1.001e-03, eta: 3:55:36, time: 1.867, data_time: 0.050, memory: 32518, loss_cls: 0.1079, loss_bbox: 0.2447, d0.loss_cls: 0.2038, d0.loss_bbox: 0.3650, d1.loss_cls: 0.1734, d1.loss_bbox: 0.2715, d2.loss_cls: 0.1704, d2.loss_bbox: 0.2644, d3.loss_cls: 0.1608, d3.loss_bbox: 0.2648, d4.loss_cls: 0.1286, d4.loss_bbox: 0.2548, loss: 2.6100, grad_norm: 13.2127
2025-06-11 21:25:27,054 - mmdet - INFO - Epoch [4][3100/3517]	lr: 1.001e-03, eta: 3:54:02, time: 1.887, data_time: 0.060, memory: 32518, loss_cls: 0.1059, loss_bbox: 0.2435, d0.loss_cls: 0.2028, d0.loss_bbox: 0.3620, d1.loss_cls: 0.1741, d1.loss_bbox: 0.2692, d2.loss_cls: 0.1712, d2.loss_bbox: 0.2645, d3.loss_cls: 0.1626, d3.loss_bbox: 0.2639, d4.loss_cls: 0.1281, d4.loss_bbox: 0.2545, loss: 2.6022, grad_norm: 12.5226
2025-06-11 21:27:01,189 - mmdet - INFO - Epoch [4][3150/3517]	lr: 1.001e-03, eta: 3:52:28, time: 1.883, data_time: 0.058, memory: 32518, loss_cls: 0.1093, loss_bbox: 0.2542, d0.loss_cls: 0.2074, d0.loss_bbox: 0.3802, d1.loss_cls: 0.1787, d1.loss_bbox: 0.2820, d2.loss_cls: 0.1765, d2.loss_bbox: 0.2749, d3.loss_cls: 0.1651, d3.loss_bbox: 0.2759, d4.loss_cls: 0.1296, d4.loss_bbox: 0.2653, loss: 2.6991, grad_norm: 37.2295
2025-06-11 21:28:35,620 - mmdet - INFO - Epoch [4][3200/3517]	lr: 1.001e-03, eta: 3:50:54, time: 1.889, data_time: 0.061, memory: 32518, loss_cls: 0.1116, loss_bbox: 0.2552, d0.loss_cls: 0.2058, d0.loss_bbox: 0.3745, d1.loss_cls: 0.1792, d1.loss_bbox: 0.2795, d2.loss_cls: 0.1735, d2.loss_bbox: 0.2722, d3.loss_cls: 0.1678, d3.loss_bbox: 0.2735, d4.loss_cls: 0.1343, d4.loss_bbox: 0.2654, loss: 2.6924, grad_norm: 17.0555
2025-06-11 21:30:10,199 - mmdet - INFO - Epoch [4][3250/3517]	lr: 1.001e-03, eta: 3:49:20, time: 1.892, data_time: 0.062, memory: 32518, loss_cls: 0.1127, loss_bbox: 0.2585, d0.loss_cls: 0.2044, d0.loss_bbox: 0.3818, d1.loss_cls: 0.1750, d1.loss_bbox: 0.2865, d2.loss_cls: 0.1754, d2.loss_bbox: 0.2758, d3.loss_cls: 0.1638, d3.loss_bbox: 0.2775, d4.loss_cls: 0.1322, d4.loss_bbox: 0.2686, loss: 2.7122, grad_norm: 25.1986
2025-06-11 21:31:44,442 - mmdet - INFO - Epoch [4][3300/3517]	lr: 1.001e-03, eta: 3:47:45, time: 1.885, data_time: 0.061, memory: 32518, loss_cls: 0.1032, loss_bbox: 0.2418, d0.loss_cls: 0.2061, d0.loss_bbox: 0.3656, d1.loss_cls: 0.1772, d1.loss_bbox: 0.2697, d2.loss_cls: 0.1731, d2.loss_bbox: 0.2631, d3.loss_cls: 0.1625, d3.loss_bbox: 0.2645, d4.loss_cls: 0.1257, d4.loss_bbox: 0.2521, loss: 2.6048, grad_norm: 20.2874
2025-06-11 21:33:18,785 - mmdet - INFO - Epoch [4][3350/3517]	lr: 1.001e-03, eta: 3:46:11, time: 1.887, data_time: 0.058, memory: 32518, loss_cls: 0.1054, loss_bbox: 0.2422, d0.loss_cls: 0.2088, d0.loss_bbox: 0.3679, d1.loss_cls: 0.1732, d1.loss_bbox: 0.2710, d2.loss_cls: 0.1709, d2.loss_bbox: 0.2621, d3.loss_cls: 0.1626, d3.loss_bbox: 0.2618, d4.loss_cls: 0.1275, d4.loss_bbox: 0.2525, loss: 2.6056, grad_norm: 16.7370
2025-06-11 21:34:53,644 - mmdet - INFO - Epoch [4][3400/3517]	lr: 1.001e-03, eta: 3:44:37, time: 1.897, data_time: 0.065, memory: 32518, loss_cls: 0.1047, loss_bbox: 0.2538, d0.loss_cls: 0.2072, d0.loss_bbox: 0.3793, d1.loss_cls: 0.1792, d1.loss_bbox: 0.2790, d2.loss_cls: 0.1753, d2.loss_bbox: 0.2714, d3.loss_cls: 0.1647, d3.loss_bbox: 0.2725, d4.loss_cls: 0.1277, d4.loss_bbox: 0.2635, loss: 2.6782, grad_norm: 12.1316
2025-06-11 21:36:31,418 - mmdet - INFO - Epoch [4][3450/3517]	lr: 1.001e-03, eta: 3:43:05, time: 1.955, data_time: 0.074, memory: 32518, loss_cls: 0.1115, loss_bbox: 0.2622, d0.loss_cls: 0.2119, d0.loss_bbox: 0.3862, d1.loss_cls: 0.1823, d1.loss_bbox: 0.2861, d2.loss_cls: 0.1800, d2.loss_bbox: 0.2795, d3.loss_cls: 0.1683, d3.loss_bbox: 0.2787, d4.loss_cls: 0.1301, d4.loss_bbox: 0.2701, loss: 2.7470, grad_norm: 25.0451
2025-06-11 21:38:08,634 - mmdet - INFO - Epoch [4][3500/3517]	lr: 1.001e-03, eta: 3:41:32, time: 1.944, data_time: 0.068, memory: 32518, loss_cls: 0.1031, loss_bbox: 0.2484, d0.loss_cls: 0.2041, d0.loss_bbox: 0.3741, d1.loss_cls: 0.1783, d1.loss_bbox: 0.2747, d2.loss_cls: 0.1700, d2.loss_bbox: 0.2672, d3.loss_cls: 0.1638, d3.loss_bbox: 0.2657, d4.loss_cls: 0.1247, d4.loss_bbox: 0.2564, loss: 2.6304, grad_norm: 13.9819
2025-06-11 21:38:40,926 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-06-11 22:01:26,186 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 22:01:26,186 - mmdet - INFO - Epoch(val) [4][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7788, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8682, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8982, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9158, pts_bbox_NuScenes/car_trans_err: 0.1841, pts_bbox_NuScenes/car_scale_err: 0.1484, pts_bbox_NuScenes/car_orient_err: 0.0544, pts_bbox_NuScenes/car_vel_err: 0.3038, pts_bbox_NuScenes/car_attr_err: 0.1849, pts_bbox_NuScenes/mATE: 0.3142, pts_bbox_NuScenes/mASE: 0.2667, pts_bbox_NuScenes/mAOE: 0.2728, pts_bbox_NuScenes/mAVE: 0.2984, pts_bbox_NuScenes/mAAE: 0.1882, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4047, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5917, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6903, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7312, pts_bbox_NuScenes/truck_trans_err: 0.3473, pts_bbox_NuScenes/truck_scale_err: 0.1943, pts_bbox_NuScenes/truck_orient_err: 0.0679, pts_bbox_NuScenes/truck_vel_err: 0.2899, pts_bbox_NuScenes/truck_attr_err: 0.2111, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0440, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1937, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3976, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4811, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6987, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4342, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7914, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1123, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2991, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4562, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7206, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8904, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9210, pts_bbox_NuScenes/bus_trans_err: 0.3671, pts_bbox_NuScenes/bus_scale_err: 0.2128, pts_bbox_NuScenes/bus_orient_err: 0.0407, pts_bbox_NuScenes/bus_vel_err: 0.5434, pts_bbox_NuScenes/bus_attr_err: 0.2896, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1424, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3927, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5837, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6699, pts_bbox_NuScenes/trailer_trans_err: 0.5157, pts_bbox_NuScenes/trailer_scale_err: 0.2327, pts_bbox_NuScenes/trailer_orient_err: 0.4862, pts_bbox_NuScenes/trailer_vel_err: 0.2115, pts_bbox_NuScenes/trailer_attr_err: 0.1774, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5474, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6532, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7148, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7371, pts_bbox_NuScenes/barrier_trans_err: 0.2478, pts_bbox_NuScenes/barrier_scale_err: 0.2984, pts_bbox_NuScenes/barrier_orient_err: 0.0749, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6024, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7488, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7871, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7958, pts_bbox_NuScenes/motorcycle_trans_err: 0.2455, pts_bbox_NuScenes/motorcycle_scale_err: 0.2502, pts_bbox_NuScenes/motorcycle_orient_err: 0.2521, pts_bbox_NuScenes/motorcycle_vel_err: 0.4894, pts_bbox_NuScenes/motorcycle_attr_err: 0.2146, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5242, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5813, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5977, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6079, pts_bbox_NuScenes/bicycle_trans_err: 0.1982, pts_bbox_NuScenes/bicycle_scale_err: 0.2736, pts_bbox_NuScenes/bicycle_orient_err: 0.3371, pts_bbox_NuScenes/bicycle_vel_err: 0.2090, pts_bbox_NuScenes/bicycle_attr_err: 0.0133, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7735, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8277, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8568, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8736, pts_bbox_NuScenes/pedestrian_trans_err: 0.1740, pts_bbox_NuScenes/pedestrian_scale_err: 0.2918, pts_bbox_NuScenes/pedestrian_orient_err: 0.3507, pts_bbox_NuScenes/pedestrian_vel_err: 0.2280, pts_bbox_NuScenes/pedestrian_attr_err: 0.1152, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6785, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7286, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7665, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7961, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1641, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3302, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6906, pts_bbox_NuScenes/mAP: 0.6493
2025-06-11 22:03:11,293 - mmdet - INFO - Epoch [5][50/3517]	lr: 5.015e-04, eta: 3:39:13, time: 2.026, data_time: 0.210, memory: 32518, loss_cls: 0.1050, loss_bbox: 0.2483, d0.loss_cls: 0.1979, d0.loss_bbox: 0.3639, d1.loss_cls: 0.1715, d1.loss_bbox: 0.2735, d2.loss_cls: 0.1629, d2.loss_bbox: 0.2646, d3.loss_cls: 0.1542, d3.loss_bbox: 0.2639, d4.loss_cls: 0.1256, d4.loss_bbox: 0.2574, loss: 2.5885, grad_norm: 16.4263
2025-06-11 22:04:45,646 - mmdet - INFO - Epoch [5][100/3517]	lr: 5.015e-04, eta: 3:37:39, time: 1.887, data_time: 0.058, memory: 32518, loss_cls: 0.1082, loss_bbox: 0.2595, d0.loss_cls: 0.1971, d0.loss_bbox: 0.3824, d1.loss_cls: 0.1704, d1.loss_bbox: 0.2862, d2.loss_cls: 0.1648, d2.loss_bbox: 0.2762, d3.loss_cls: 0.1576, d3.loss_bbox: 0.2753, d4.loss_cls: 0.1319, d4.loss_bbox: 0.2667, loss: 2.6763, grad_norm: 12.9923
2025-06-11 22:06:19,625 - mmdet - INFO - Epoch [5][150/3517]	lr: 5.015e-04, eta: 3:36:05, time: 1.880, data_time: 0.056, memory: 32518, loss_cls: 0.1011, loss_bbox: 0.2477, d0.loss_cls: 0.1952, d0.loss_bbox: 0.3577, d1.loss_cls: 0.1644, d1.loss_bbox: 0.2717, d2.loss_cls: 0.1604, d2.loss_bbox: 0.2629, d3.loss_cls: 0.1507, d3.loss_bbox: 0.2636, d4.loss_cls: 0.1209, d4.loss_bbox: 0.2566, loss: 2.5530, grad_norm: 17.1132
2025-06-11 22:07:52,982 - mmdet - INFO - Epoch [5][200/3517]	lr: 5.015e-04, eta: 3:34:31, time: 1.867, data_time: 0.057, memory: 32518, loss_cls: 0.0945, loss_bbox: 0.2384, d0.loss_cls: 0.1912, d0.loss_bbox: 0.3525, d1.loss_cls: 0.1615, d1.loss_bbox: 0.2658, d2.loss_cls: 0.1565, d2.loss_bbox: 0.2567, d3.loss_cls: 0.1481, d3.loss_bbox: 0.2567, d4.loss_cls: 0.1141, d4.loss_bbox: 0.2492, loss: 2.4853, grad_norm: 18.5109
2025-06-11 22:09:26,091 - mmdet - INFO - Epoch [5][250/3517]	lr: 5.015e-04, eta: 3:32:56, time: 1.862, data_time: 0.057, memory: 32518, loss_cls: 0.0951, loss_bbox: 0.2434, d0.loss_cls: 0.1977, d0.loss_bbox: 0.3582, d1.loss_cls: 0.1633, d1.loss_bbox: 0.2703, d2.loss_cls: 0.1577, d2.loss_bbox: 0.2614, d3.loss_cls: 0.1487, d3.loss_bbox: 0.2607, d4.loss_cls: 0.1128, d4.loss_bbox: 0.2534, loss: 2.5227, grad_norm: 16.4067
2025-06-11 22:10:59,864 - mmdet - INFO - Epoch [5][300/3517]	lr: 5.015e-04, eta: 3:31:22, time: 1.875, data_time: 0.057, memory: 32518, loss_cls: 0.0984, loss_bbox: 0.2389, d0.loss_cls: 0.1921, d0.loss_bbox: 0.3617, d1.loss_cls: 0.1649, d1.loss_bbox: 0.2669, d2.loss_cls: 0.1598, d2.loss_bbox: 0.2581, d3.loss_cls: 0.1503, d3.loss_bbox: 0.2584, d4.loss_cls: 0.1172, d4.loss_bbox: 0.2488, loss: 2.5154, grad_norm: 18.3282
2025-06-11 22:12:34,064 - mmdet - INFO - Epoch [5][350/3517]	lr: 5.015e-04, eta: 3:29:47, time: 1.884, data_time: 0.065, memory: 32518, loss_cls: 0.0957, loss_bbox: 0.2416, d0.loss_cls: 0.1942, d0.loss_bbox: 0.3619, d1.loss_cls: 0.1655, d1.loss_bbox: 0.2715, d2.loss_cls: 0.1584, d2.loss_bbox: 0.2619, d3.loss_cls: 0.1484, d3.loss_bbox: 0.2613, d4.loss_cls: 0.1141, d4.loss_bbox: 0.2541, loss: 2.5287, grad_norm: 15.7893
2025-06-11 22:14:08,717 - mmdet - INFO - Epoch [5][400/3517]	lr: 5.015e-04, eta: 3:28:13, time: 1.893, data_time: 0.067, memory: 32518, loss_cls: 0.0918, loss_bbox: 0.2392, d0.loss_cls: 0.1894, d0.loss_bbox: 0.3543, d1.loss_cls: 0.1595, d1.loss_bbox: 0.2659, d2.loss_cls: 0.1542, d2.loss_bbox: 0.2556, d3.loss_cls: 0.1439, d3.loss_bbox: 0.2549, d4.loss_cls: 0.1108, d4.loss_bbox: 0.2486, loss: 2.4680, grad_norm: 13.8503
2025-06-11 22:15:43,946 - mmdet - INFO - Epoch [5][450/3517]	lr: 5.015e-04, eta: 3:26:40, time: 1.905, data_time: 0.083, memory: 32518, loss_cls: 0.0982, loss_bbox: 0.2397, d0.loss_cls: 0.1919, d0.loss_bbox: 0.3668, d1.loss_cls: 0.1646, d1.loss_bbox: 0.2706, d2.loss_cls: 0.1565, d2.loss_bbox: 0.2609, d3.loss_cls: 0.1459, d3.loss_bbox: 0.2608, d4.loss_cls: 0.1156, d4.loss_bbox: 0.2527, loss: 2.5242, grad_norm: 17.2082
2025-06-11 22:17:18,166 - mmdet - INFO - Epoch [5][500/3517]	lr: 5.015e-04, eta: 3:25:06, time: 1.884, data_time: 0.064, memory: 32518, loss_cls: 0.0958, loss_bbox: 0.2298, d0.loss_cls: 0.1913, d0.loss_bbox: 0.3525, d1.loss_cls: 0.1648, d1.loss_bbox: 0.2602, d2.loss_cls: 0.1568, d2.loss_bbox: 0.2522, d3.loss_cls: 0.1462, d3.loss_bbox: 0.2512, d4.loss_cls: 0.1130, d4.loss_bbox: 0.2443, loss: 2.4582, grad_norm: 22.0101
2025-06-11 22:18:52,560 - mmdet - INFO - Epoch [5][550/3517]	lr: 5.015e-04, eta: 3:23:32, time: 1.888, data_time: 0.066, memory: 32518, loss_cls: 0.1006, loss_bbox: 0.2411, d0.loss_cls: 0.1967, d0.loss_bbox: 0.3638, d1.loss_cls: 0.1675, d1.loss_bbox: 0.2690, d2.loss_cls: 0.1591, d2.loss_bbox: 0.2602, d3.loss_cls: 0.1500, d3.loss_bbox: 0.2586, d4.loss_cls: 0.1174, d4.loss_bbox: 0.2513, loss: 2.5353, grad_norm: 12.9524
2025-06-11 22:20:38,429 - mmdet - INFO - Epoch [5][600/3517]	lr: 5.015e-04, eta: 3:22:03, time: 2.117, data_time: 0.069, memory: 32518, loss_cls: 0.0985, loss_bbox: 0.2419, d0.loss_cls: 0.1907, d0.loss_bbox: 0.3613, d1.loss_cls: 0.1634, d1.loss_bbox: 0.2700, d2.loss_cls: 0.1575, d2.loss_bbox: 0.2613, d3.loss_cls: 0.1475, d3.loss_bbox: 0.2612, d4.loss_cls: 0.1171, d4.loss_bbox: 0.2513, loss: 2.5217, grad_norm: 17.3274
2025-06-11 22:22:13,061 - mmdet - INFO - Epoch [5][650/3517]	lr: 5.015e-04, eta: 3:20:28, time: 1.893, data_time: 0.064, memory: 32518, loss_cls: 0.0931, loss_bbox: 0.2332, d0.loss_cls: 0.1903, d0.loss_bbox: 0.3544, d1.loss_cls: 0.1600, d1.loss_bbox: 0.2622, d2.loss_cls: 0.1529, d2.loss_bbox: 0.2518, d3.loss_cls: 0.1443, d3.loss_bbox: 0.2514, d4.loss_cls: 0.1113, d4.loss_bbox: 0.2448, loss: 2.4497, grad_norm: 12.8163
2025-06-11 22:23:47,164 - mmdet - INFO - Epoch [5][700/3517]	lr: 5.015e-04, eta: 3:18:54, time: 1.882, data_time: 0.063, memory: 32518, loss_cls: 0.0905, loss_bbox: 0.2252, d0.loss_cls: 0.1916, d0.loss_bbox: 0.3444, d1.loss_cls: 0.1603, d1.loss_bbox: 0.2527, d2.loss_cls: 0.1553, d2.loss_bbox: 0.2443, d3.loss_cls: 0.1464, d3.loss_bbox: 0.2433, d4.loss_cls: 0.1106, d4.loss_bbox: 0.2348, loss: 2.3995, grad_norm: 16.8194
2025-06-11 22:25:21,080 - mmdet - INFO - Epoch [5][750/3517]	lr: 5.015e-04, eta: 3:17:20, time: 1.878, data_time: 0.062, memory: 32518, loss_cls: 0.0999, loss_bbox: 0.2397, d0.loss_cls: 0.1941, d0.loss_bbox: 0.3646, d1.loss_cls: 0.1637, d1.loss_bbox: 0.2702, d2.loss_cls: 0.1592, d2.loss_bbox: 0.2579, d3.loss_cls: 0.1477, d3.loss_bbox: 0.2584, d4.loss_cls: 0.1179, d4.loss_bbox: 0.2506, loss: 2.5241, grad_norm: 18.8339
2025-06-11 22:26:55,091 - mmdet - INFO - Epoch [5][800/3517]	lr: 5.015e-04, eta: 3:15:46, time: 1.880, data_time: 0.065, memory: 32518, loss_cls: 0.0957, loss_bbox: 0.2306, d0.loss_cls: 0.1895, d0.loss_bbox: 0.3556, d1.loss_cls: 0.1588, d1.loss_bbox: 0.2620, d2.loss_cls: 0.1532, d2.loss_bbox: 0.2500, d3.loss_cls: 0.1428, d3.loss_bbox: 0.2506, d4.loss_cls: 0.1120, d4.loss_bbox: 0.2423, loss: 2.4432, grad_norm: 15.0909
2025-06-11 22:28:29,232 - mmdet - INFO - Epoch [5][850/3517]	lr: 5.015e-04, eta: 3:14:11, time: 1.883, data_time: 0.062, memory: 32518, loss_cls: 0.1005, loss_bbox: 0.2392, d0.loss_cls: 0.1928, d0.loss_bbox: 0.3558, d1.loss_cls: 0.1647, d1.loss_bbox: 0.2665, d2.loss_cls: 0.1582, d2.loss_bbox: 0.2577, d3.loss_cls: 0.1485, d3.loss_bbox: 0.2576, d4.loss_cls: 0.1183, d4.loss_bbox: 0.2483, loss: 2.5082, grad_norm: 36.3970
2025-06-11 22:30:03,410 - mmdet - INFO - Epoch [5][900/3517]	lr: 5.015e-04, eta: 3:12:37, time: 1.884, data_time: 0.065, memory: 32518, loss_cls: 0.0956, loss_bbox: 0.2377, d0.loss_cls: 0.1926, d0.loss_bbox: 0.3537, d1.loss_cls: 0.1650, d1.loss_bbox: 0.2631, d2.loss_cls: 0.1562, d2.loss_bbox: 0.2551, d3.loss_cls: 0.1470, d3.loss_bbox: 0.2551, d4.loss_cls: 0.1152, d4.loss_bbox: 0.2467, loss: 2.4829, grad_norm: 13.7901
2025-06-11 22:31:36,920 - mmdet - INFO - Epoch [5][950/3517]	lr: 5.015e-04, eta: 3:11:03, time: 1.870, data_time: 0.057, memory: 32518, loss_cls: 0.0940, loss_bbox: 0.2378, d0.loss_cls: 0.1928, d0.loss_bbox: 0.3584, d1.loss_cls: 0.1604, d1.loss_bbox: 0.2655, d2.loss_cls: 0.1525, d2.loss_bbox: 0.2558, d3.loss_cls: 0.1442, d3.loss_bbox: 0.2552, d4.loss_cls: 0.1137, d4.loss_bbox: 0.2460, loss: 2.4762, grad_norm: 13.7296
2025-06-11 22:33:11,486 - mmdet - INFO - Epoch [5][1000/3517]	lr: 5.015e-04, eta: 3:09:29, time: 1.891, data_time: 0.069, memory: 32518, loss_cls: 0.0946, loss_bbox: 0.2335, d0.loss_cls: 0.1923, d0.loss_bbox: 0.3488, d1.loss_cls: 0.1595, d1.loss_bbox: 0.2611, d2.loss_cls: 0.1532, d2.loss_bbox: 0.2525, d3.loss_cls: 0.1437, d3.loss_bbox: 0.2517, d4.loss_cls: 0.1142, d4.loss_bbox: 0.2436, loss: 2.4488, grad_norm: 18.8562
2025-06-11 22:34:45,474 - mmdet - INFO - Epoch [5][1050/3517]	lr: 5.015e-04, eta: 3:07:54, time: 1.880, data_time: 0.061, memory: 32518, loss_cls: 0.0958, loss_bbox: 0.2316, d0.loss_cls: 0.1897, d0.loss_bbox: 0.3489, d1.loss_cls: 0.1626, d1.loss_bbox: 0.2564, d2.loss_cls: 0.1531, d2.loss_bbox: 0.2503, d3.loss_cls: 0.1428, d3.loss_bbox: 0.2491, d4.loss_cls: 0.1126, d4.loss_bbox: 0.2418, loss: 2.4347, grad_norm: 19.6545
2025-06-11 22:36:19,543 - mmdet - INFO - Epoch [5][1100/3517]	lr: 5.015e-04, eta: 3:06:20, time: 1.881, data_time: 0.065, memory: 32518, loss_cls: 0.0929, loss_bbox: 0.2339, d0.loss_cls: 0.1884, d0.loss_bbox: 0.3524, d1.loss_cls: 0.1597, d1.loss_bbox: 0.2610, d2.loss_cls: 0.1500, d2.loss_bbox: 0.2536, d3.loss_cls: 0.1396, d3.loss_bbox: 0.2529, d4.loss_cls: 0.1114, d4.loss_bbox: 0.2446, loss: 2.4403, grad_norm: 34.3603
2025-06-11 22:37:53,321 - mmdet - INFO - Epoch [5][1150/3517]	lr: 5.015e-04, eta: 3:04:46, time: 1.876, data_time: 0.058, memory: 32518, loss_cls: 0.0954, loss_bbox: 0.2388, d0.loss_cls: 0.1878, d0.loss_bbox: 0.3589, d1.loss_cls: 0.1591, d1.loss_bbox: 0.2666, d2.loss_cls: 0.1520, d2.loss_bbox: 0.2583, d3.loss_cls: 0.1441, d3.loss_bbox: 0.2570, d4.loss_cls: 0.1136, d4.loss_bbox: 0.2484, loss: 2.4799, grad_norm: 12.0823
2025-06-11 22:39:27,303 - mmdet - INFO - Epoch [5][1200/3517]	lr: 5.015e-04, eta: 3:03:11, time: 1.880, data_time: 0.059, memory: 32518, loss_cls: 0.0956, loss_bbox: 0.2345, d0.loss_cls: 0.1902, d0.loss_bbox: 0.3496, d1.loss_cls: 0.1566, d1.loss_bbox: 0.2618, d2.loss_cls: 0.1481, d2.loss_bbox: 0.2549, d3.loss_cls: 0.1393, d3.loss_bbox: 0.2535, d4.loss_cls: 0.1109, d4.loss_bbox: 0.2438, loss: 2.4387, grad_norm: 11.7612
2025-06-11 22:41:01,246 - mmdet - INFO - Epoch [5][1250/3517]	lr: 5.015e-04, eta: 3:01:37, time: 1.879, data_time: 0.058, memory: 32518, loss_cls: 0.0958, loss_bbox: 0.2370, d0.loss_cls: 0.1873, d0.loss_bbox: 0.3561, d1.loss_cls: 0.1589, d1.loss_bbox: 0.2663, d2.loss_cls: 0.1515, d2.loss_bbox: 0.2568, d3.loss_cls: 0.1424, d3.loss_bbox: 0.2560, d4.loss_cls: 0.1125, d4.loss_bbox: 0.2480, loss: 2.4687, grad_norm: 100.1300
2025-06-11 22:42:35,086 - mmdet - INFO - Epoch [5][1300/3517]	lr: 5.015e-04, eta: 3:00:03, time: 1.877, data_time: 0.063, memory: 32518, loss_cls: 0.0903, loss_bbox: 0.2331, d0.loss_cls: 0.1915, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1618, d1.loss_bbox: 0.2607, d2.loss_cls: 0.1550, d2.loss_bbox: 0.2488, d3.loss_cls: 0.1439, d3.loss_bbox: 0.2486, d4.loss_cls: 0.1075, d4.loss_bbox: 0.2422, loss: 2.4351, grad_norm: 13.0103
2025-06-11 22:44:08,773 - mmdet - INFO - Epoch [5][1350/3517]	lr: 5.015e-04, eta: 2:58:28, time: 1.874, data_time: 0.063, memory: 32518, loss_cls: 0.0960, loss_bbox: 0.2335, d0.loss_cls: 0.1868, d0.loss_bbox: 0.3572, d1.loss_cls: 0.1603, d1.loss_bbox: 0.2628, d2.loss_cls: 0.1541, d2.loss_bbox: 0.2531, d3.loss_cls: 0.1440, d3.loss_bbox: 0.2531, d4.loss_cls: 0.1133, d4.loss_bbox: 0.2444, loss: 2.4587, grad_norm: 30.7850
2025-06-11 22:45:42,533 - mmdet - INFO - Epoch [5][1400/3517]	lr: 5.015e-04, eta: 2:56:54, time: 1.875, data_time: 0.063, memory: 32518, loss_cls: 0.0974, loss_bbox: 0.2379, d0.loss_cls: 0.1947, d0.loss_bbox: 0.3594, d1.loss_cls: 0.1664, d1.loss_bbox: 0.2657, d2.loss_cls: 0.1565, d2.loss_bbox: 0.2554, d3.loss_cls: 0.1482, d3.loss_bbox: 0.2549, d4.loss_cls: 0.1187, d4.loss_bbox: 0.2456, loss: 2.5009, grad_norm: 14.9907
2025-06-11 22:47:16,367 - mmdet - INFO - Epoch [5][1450/3517]	lr: 5.015e-04, eta: 2:55:20, time: 1.877, data_time: 0.066, memory: 32518, loss_cls: 0.0890, loss_bbox: 0.2288, d0.loss_cls: 0.1874, d0.loss_bbox: 0.3472, d1.loss_cls: 0.1593, d1.loss_bbox: 0.2553, d2.loss_cls: 0.1525, d2.loss_bbox: 0.2461, d3.loss_cls: 0.1410, d3.loss_bbox: 0.2450, d4.loss_cls: 0.1071, d4.loss_bbox: 0.2365, loss: 2.3953, grad_norm: 15.5465
2025-06-11 22:48:50,878 - mmdet - INFO - Epoch [5][1500/3517]	lr: 5.015e-04, eta: 2:53:46, time: 1.890, data_time: 0.064, memory: 32518, loss_cls: 0.0969, loss_bbox: 0.2325, d0.loss_cls: 0.1905, d0.loss_bbox: 0.3553, d1.loss_cls: 0.1608, d1.loss_bbox: 0.2625, d2.loss_cls: 0.1512, d2.loss_bbox: 0.2532, d3.loss_cls: 0.1425, d3.loss_bbox: 0.2538, d4.loss_cls: 0.1132, d4.loss_bbox: 0.2428, loss: 2.4554, grad_norm: 13.0365
2025-06-11 22:50:24,832 - mmdet - INFO - Epoch [5][1550/3517]	lr: 5.015e-04, eta: 2:52:11, time: 1.879, data_time: 0.065, memory: 32518, loss_cls: 0.0933, loss_bbox: 0.2270, d0.loss_cls: 0.1896, d0.loss_bbox: 0.3467, d1.loss_cls: 0.1636, d1.loss_bbox: 0.2528, d2.loss_cls: 0.1540, d2.loss_bbox: 0.2449, d3.loss_cls: 0.1461, d3.loss_bbox: 0.2432, d4.loss_cls: 0.1113, d4.loss_bbox: 0.2358, loss: 2.4083, grad_norm: 20.7644
2025-06-11 22:51:59,402 - mmdet - INFO - Epoch [5][1600/3517]	lr: 5.015e-04, eta: 2:50:37, time: 1.891, data_time: 0.062, memory: 32518, loss_cls: 0.0900, loss_bbox: 0.2347, d0.loss_cls: 0.1926, d0.loss_bbox: 0.3549, d1.loss_cls: 0.1631, d1.loss_bbox: 0.2626, d2.loss_cls: 0.1547, d2.loss_bbox: 0.2526, d3.loss_cls: 0.1442, d3.loss_bbox: 0.2525, d4.loss_cls: 0.1099, d4.loss_bbox: 0.2435, loss: 2.4554, grad_norm: 13.5341
2025-06-11 22:53:33,837 - mmdet - INFO - Epoch [5][1650/3517]	lr: 5.015e-04, eta: 2:49:03, time: 1.889, data_time: 0.058, memory: 32518, loss_cls: 0.0971, loss_bbox: 0.2351, d0.loss_cls: 0.1930, d0.loss_bbox: 0.3613, d1.loss_cls: 0.1668, d1.loss_bbox: 0.2680, d2.loss_cls: 0.1593, d2.loss_bbox: 0.2560, d3.loss_cls: 0.1515, d3.loss_bbox: 0.2546, d4.loss_cls: 0.1162, d4.loss_bbox: 0.2454, loss: 2.5044, grad_norm: 17.5725
2025-06-11 22:55:08,073 - mmdet - INFO - Epoch [5][1700/3517]	lr: 5.015e-04, eta: 2:47:29, time: 1.885, data_time: 0.062, memory: 32518, loss_cls: 0.0931, loss_bbox: 0.2292, d0.loss_cls: 0.1896, d0.loss_bbox: 0.3493, d1.loss_cls: 0.1595, d1.loss_bbox: 0.2579, d2.loss_cls: 0.1524, d2.loss_bbox: 0.2469, d3.loss_cls: 0.1444, d3.loss_bbox: 0.2461, d4.loss_cls: 0.1114, d4.loss_bbox: 0.2380, loss: 2.4178, grad_norm: 17.9849
2025-06-11 22:56:44,696 - mmdet - INFO - Epoch [5][1750/3517]	lr: 5.015e-04, eta: 2:45:55, time: 1.932, data_time: 0.056, memory: 32518, loss_cls: 0.0964, loss_bbox: 0.2310, d0.loss_cls: 0.1940, d0.loss_bbox: 0.3519, d1.loss_cls: 0.1615, d1.loss_bbox: 0.2578, d2.loss_cls: 0.1537, d2.loss_bbox: 0.2456, d3.loss_cls: 0.1439, d3.loss_bbox: 0.2473, d4.loss_cls: 0.1162, d4.loss_bbox: 0.2390, loss: 2.4383, grad_norm: 12.9296
2025-06-11 22:58:18,356 - mmdet - INFO - Epoch [5][1800/3517]	lr: 5.015e-04, eta: 2:44:21, time: 1.873, data_time: 0.058, memory: 32518, loss_cls: 0.0968, loss_bbox: 0.2242, d0.loss_cls: 0.1872, d0.loss_bbox: 0.3445, d1.loss_cls: 0.1626, d1.loss_bbox: 0.2500, d2.loss_cls: 0.1539, d2.loss_bbox: 0.2440, d3.loss_cls: 0.1454, d3.loss_bbox: 0.2425, d4.loss_cls: 0.1124, d4.loss_bbox: 0.2341, loss: 2.3977, grad_norm: 14.8390
2025-06-11 22:59:51,502 - mmdet - INFO - Epoch [5][1850/3517]	lr: 5.015e-04, eta: 2:42:47, time: 1.863, data_time: 0.056, memory: 32518, loss_cls: 0.0932, loss_bbox: 0.2277, d0.loss_cls: 0.1902, d0.loss_bbox: 0.3586, d1.loss_cls: 0.1615, d1.loss_bbox: 0.2605, d2.loss_cls: 0.1548, d2.loss_bbox: 0.2485, d3.loss_cls: 0.1445, d3.loss_bbox: 0.2485, d4.loss_cls: 0.1085, d4.loss_bbox: 0.2384, loss: 2.4349, grad_norm: 15.6932
2025-06-11 23:01:25,426 - mmdet - INFO - Epoch [5][1900/3517]	lr: 5.015e-04, eta: 2:41:12, time: 1.878, data_time: 0.053, memory: 32518, loss_cls: 0.0929, loss_bbox: 0.2342, d0.loss_cls: 0.1893, d0.loss_bbox: 0.3550, d1.loss_cls: 0.1599, d1.loss_bbox: 0.2605, d2.loss_cls: 0.1536, d2.loss_bbox: 0.2508, d3.loss_cls: 0.1416, d3.loss_bbox: 0.2514, d4.loss_cls: 0.1079, d4.loss_bbox: 0.2449, loss: 2.4422, grad_norm: 15.5214
2025-06-11 23:02:59,511 - mmdet - INFO - Epoch [5][1950/3517]	lr: 5.015e-04, eta: 2:39:38, time: 1.882, data_time: 0.059, memory: 32518, loss_cls: 0.0934, loss_bbox: 0.2271, d0.loss_cls: 0.1916, d0.loss_bbox: 0.3424, d1.loss_cls: 0.1568, d1.loss_bbox: 0.2532, d2.loss_cls: 0.1479, d2.loss_bbox: 0.2460, d3.loss_cls: 0.1383, d3.loss_bbox: 0.2453, d4.loss_cls: 0.1093, d4.loss_bbox: 0.2376, loss: 2.3890, grad_norm: 15.0258
2025-06-11 23:04:33,505 - mmdet - INFO - Epoch [5][2000/3517]	lr: 5.015e-04, eta: 2:38:04, time: 1.880, data_time: 0.058, memory: 32518, loss_cls: 0.0980, loss_bbox: 0.2323, d0.loss_cls: 0.1857, d0.loss_bbox: 0.3589, d1.loss_cls: 0.1589, d1.loss_bbox: 0.2613, d2.loss_cls: 0.1528, d2.loss_bbox: 0.2511, d3.loss_cls: 0.1451, d3.loss_bbox: 0.2496, d4.loss_cls: 0.1167, d4.loss_bbox: 0.2418, loss: 2.4520, grad_norm: 12.6165
2025-06-11 23:06:07,683 - mmdet - INFO - Epoch [5][2050/3517]	lr: 5.015e-04, eta: 2:36:30, time: 1.884, data_time: 0.057, memory: 32518, loss_cls: 0.0952, loss_bbox: 0.2317, d0.loss_cls: 0.1893, d0.loss_bbox: 0.3495, d1.loss_cls: 0.1625, d1.loss_bbox: 0.2565, d2.loss_cls: 0.1530, d2.loss_bbox: 0.2490, d3.loss_cls: 0.1430, d3.loss_bbox: 0.2459, d4.loss_cls: 0.1118, d4.loss_bbox: 0.2399, loss: 2.4274, grad_norm: 14.1602
2025-06-11 23:07:41,591 - mmdet - INFO - Epoch [5][2100/3517]	lr: 5.015e-04, eta: 2:34:55, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0888, loss_bbox: 0.2269, d0.loss_cls: 0.1857, d0.loss_bbox: 0.3463, d1.loss_cls: 0.1545, d1.loss_bbox: 0.2533, d2.loss_cls: 0.1459, d2.loss_bbox: 0.2444, d3.loss_cls: 0.1371, d3.loss_bbox: 0.2436, d4.loss_cls: 0.1075, d4.loss_bbox: 0.2355, loss: 2.3695, grad_norm: 11.5999
2025-06-11 23:09:15,763 - mmdet - INFO - Epoch [5][2150/3517]	lr: 5.015e-04, eta: 2:33:21, time: 1.883, data_time: 0.056, memory: 32518, loss_cls: 0.0984, loss_bbox: 0.2324, d0.loss_cls: 0.1896, d0.loss_bbox: 0.3505, d1.loss_cls: 0.1607, d1.loss_bbox: 0.2601, d2.loss_cls: 0.1537, d2.loss_bbox: 0.2507, d3.loss_cls: 0.1446, d3.loss_bbox: 0.2498, d4.loss_cls: 0.1154, d4.loss_bbox: 0.2423, loss: 2.4483, grad_norm: 17.8292
2025-06-11 23:10:50,047 - mmdet - INFO - Epoch [5][2200/3517]	lr: 5.015e-04, eta: 2:31:47, time: 1.886, data_time: 0.058, memory: 32518, loss_cls: 0.0940, loss_bbox: 0.2333, d0.loss_cls: 0.1903, d0.loss_bbox: 0.3475, d1.loss_cls: 0.1599, d1.loss_bbox: 0.2590, d2.loss_cls: 0.1515, d2.loss_bbox: 0.2484, d3.loss_cls: 0.1415, d3.loss_bbox: 0.2486, d4.loss_cls: 0.1096, d4.loss_bbox: 0.2421, loss: 2.4257, grad_norm: 22.7863
2025-06-11 23:12:23,632 - mmdet - INFO - Epoch [5][2250/3517]	lr: 5.015e-04, eta: 2:30:12, time: 1.872, data_time: 0.056, memory: 32518, loss_cls: 0.0901, loss_bbox: 0.2296, d0.loss_cls: 0.1798, d0.loss_bbox: 0.3414, d1.loss_cls: 0.1541, d1.loss_bbox: 0.2553, d2.loss_cls: 0.1446, d2.loss_bbox: 0.2485, d3.loss_cls: 0.1351, d3.loss_bbox: 0.2463, d4.loss_cls: 0.1074, d4.loss_bbox: 0.2377, loss: 2.3698, grad_norm: 16.9822
2025-06-11 23:14:01,301 - mmdet - INFO - Epoch [5][2300/3517]	lr: 5.015e-04, eta: 2:28:39, time: 1.953, data_time: 0.059, memory: 32518, loss_cls: 0.0938, loss_bbox: 0.2355, d0.loss_cls: 0.1859, d0.loss_bbox: 0.3574, d1.loss_cls: 0.1576, d1.loss_bbox: 0.2634, d2.loss_cls: 0.1493, d2.loss_bbox: 0.2554, d3.loss_cls: 0.1393, d3.loss_bbox: 0.2536, d4.loss_cls: 0.1120, d4.loss_bbox: 0.2453, loss: 2.4486, grad_norm: 13.3825
2025-06-11 23:15:34,894 - mmdet - INFO - Epoch [5][2350/3517]	lr: 5.015e-04, eta: 2:27:05, time: 1.872, data_time: 0.057, memory: 32518, loss_cls: 0.0852, loss_bbox: 0.2235, d0.loss_cls: 0.1824, d0.loss_bbox: 0.3488, d1.loss_cls: 0.1546, d1.loss_bbox: 0.2519, d2.loss_cls: 0.1441, d2.loss_bbox: 0.2438, d3.loss_cls: 0.1335, d3.loss_bbox: 0.2419, d4.loss_cls: 0.1032, d4.loss_bbox: 0.2337, loss: 2.3467, grad_norm: 19.8398
2025-06-11 23:17:09,726 - mmdet - INFO - Epoch [5][2400/3517]	lr: 5.015e-04, eta: 2:25:31, time: 1.897, data_time: 0.062, memory: 32518, loss_cls: 0.0968, loss_bbox: 0.2229, d0.loss_cls: 0.1863, d0.loss_bbox: 0.3436, d1.loss_cls: 0.1627, d1.loss_bbox: 0.2520, d2.loss_cls: 0.1565, d2.loss_bbox: 0.2425, d3.loss_cls: 0.1441, d3.loss_bbox: 0.2436, d4.loss_cls: 0.1131, d4.loss_bbox: 0.2340, loss: 2.3980, grad_norm: 26.9480
2025-06-11 23:18:43,817 - mmdet - INFO - Epoch [5][2450/3517]	lr: 5.015e-04, eta: 2:23:57, time: 1.882, data_time: 0.055, memory: 32518, loss_cls: 0.0870, loss_bbox: 0.2229, d0.loss_cls: 0.1832, d0.loss_bbox: 0.3411, d1.loss_cls: 0.1520, d1.loss_bbox: 0.2482, d2.loss_cls: 0.1422, d2.loss_bbox: 0.2392, d3.loss_cls: 0.1304, d3.loss_bbox: 0.2409, d4.loss_cls: 0.1027, d4.loss_bbox: 0.2314, loss: 2.3212, grad_norm: 18.8513
2025-06-11 23:20:18,753 - mmdet - INFO - Epoch [5][2500/3517]	lr: 5.015e-04, eta: 2:22:23, time: 1.899, data_time: 0.057, memory: 32518, loss_cls: 0.0949, loss_bbox: 0.2336, d0.loss_cls: 0.1944, d0.loss_bbox: 0.3511, d1.loss_cls: 0.1618, d1.loss_bbox: 0.2607, d2.loss_cls: 0.1508, d2.loss_bbox: 0.2509, d3.loss_cls: 0.1402, d3.loss_bbox: 0.2509, d4.loss_cls: 0.1092, d4.loss_bbox: 0.2434, loss: 2.4418, grad_norm: 14.0154
2025-06-11 23:21:52,558 - mmdet - INFO - Epoch [5][2550/3517]	lr: 5.015e-04, eta: 2:20:48, time: 1.876, data_time: 0.050, memory: 32518, loss_cls: 0.0953, loss_bbox: 0.2361, d0.loss_cls: 0.1942, d0.loss_bbox: 0.3547, d1.loss_cls: 0.1648, d1.loss_bbox: 0.2639, d2.loss_cls: 0.1572, d2.loss_bbox: 0.2536, d3.loss_cls: 0.1451, d3.loss_bbox: 0.2514, d4.loss_cls: 0.1179, d4.loss_bbox: 0.2435, loss: 2.4778, grad_norm: 18.4950
2025-06-11 23:23:27,047 - mmdet - INFO - Epoch [5][2600/3517]	lr: 5.015e-04, eta: 2:19:14, time: 1.890, data_time: 0.057, memory: 32518, loss_cls: 0.0953, loss_bbox: 0.2325, d0.loss_cls: 0.1860, d0.loss_bbox: 0.3443, d1.loss_cls: 0.1570, d1.loss_bbox: 0.2591, d2.loss_cls: 0.1449, d2.loss_bbox: 0.2513, d3.loss_cls: 0.1373, d3.loss_bbox: 0.2513, d4.loss_cls: 0.1127, d4.loss_bbox: 0.2420, loss: 2.4136, grad_norm: 24.0616
2025-06-11 23:25:01,396 - mmdet - INFO - Epoch [5][2650/3517]	lr: 5.015e-04, eta: 2:17:40, time: 1.887, data_time: 0.057, memory: 32518, loss_cls: 0.0982, loss_bbox: 0.2421, d0.loss_cls: 0.1880, d0.loss_bbox: 0.3658, d1.loss_cls: 0.1599, d1.loss_bbox: 0.2734, d2.loss_cls: 0.1499, d2.loss_bbox: 0.2641, d3.loss_cls: 0.1403, d3.loss_bbox: 0.2623, d4.loss_cls: 0.1154, d4.loss_bbox: 0.2514, loss: 2.5109, grad_norm: 30.9901
2025-06-11 23:26:35,095 - mmdet - INFO - Epoch [5][2700/3517]	lr: 5.015e-04, eta: 2:16:06, time: 1.874, data_time: 0.058, memory: 32518, loss_cls: 0.0922, loss_bbox: 0.2379, d0.loss_cls: 0.1880, d0.loss_bbox: 0.3549, d1.loss_cls: 0.1570, d1.loss_bbox: 0.2647, d2.loss_cls: 0.1473, d2.loss_bbox: 0.2538, d3.loss_cls: 0.1368, d3.loss_bbox: 0.2539, d4.loss_cls: 0.1094, d4.loss_bbox: 0.2447, loss: 2.4406, grad_norm: 15.1290
2025-06-11 23:28:09,080 - mmdet - INFO - Epoch [5][2750/3517]	lr: 5.015e-04, eta: 2:14:31, time: 1.880, data_time: 0.063, memory: 32518, loss_cls: 0.0948, loss_bbox: 0.2357, d0.loss_cls: 0.1931, d0.loss_bbox: 0.3552, d1.loss_cls: 0.1596, d1.loss_bbox: 0.2649, d2.loss_cls: 0.1493, d2.loss_bbox: 0.2541, d3.loss_cls: 0.1378, d3.loss_bbox: 0.2548, d4.loss_cls: 0.1127, d4.loss_bbox: 0.2446, loss: 2.4567, grad_norm: 16.8297
2025-06-11 23:29:43,004 - mmdet - INFO - Epoch [5][2800/3517]	lr: 5.015e-04, eta: 2:12:57, time: 1.878, data_time: 0.058, memory: 32518, loss_cls: 0.0953, loss_bbox: 0.2312, d0.loss_cls: 0.1893, d0.loss_bbox: 0.3516, d1.loss_cls: 0.1597, d1.loss_bbox: 0.2580, d2.loss_cls: 0.1503, d2.loss_bbox: 0.2490, d3.loss_cls: 0.1391, d3.loss_bbox: 0.2484, d4.loss_cls: 0.1128, d4.loss_bbox: 0.2387, loss: 2.4233, grad_norm: 18.5641
2025-06-11 23:31:16,965 - mmdet - INFO - Epoch [5][2850/3517]	lr: 5.015e-04, eta: 2:11:23, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0924, loss_bbox: 0.2373, d0.loss_cls: 0.1829, d0.loss_bbox: 0.3607, d1.loss_cls: 0.1567, d1.loss_bbox: 0.2655, d2.loss_cls: 0.1478, d2.loss_bbox: 0.2556, d3.loss_cls: 0.1386, d3.loss_bbox: 0.2550, d4.loss_cls: 0.1129, d4.loss_bbox: 0.2472, loss: 2.4524, grad_norm: 15.5587
2025-06-11 23:32:50,392 - mmdet - INFO - Epoch [5][2900/3517]	lr: 5.015e-04, eta: 2:09:48, time: 1.869, data_time: 0.058, memory: 32518, loss_cls: 0.0948, loss_bbox: 0.2353, d0.loss_cls: 0.1913, d0.loss_bbox: 0.3497, d1.loss_cls: 0.1626, d1.loss_bbox: 0.2636, d2.loss_cls: 0.1512, d2.loss_bbox: 0.2530, d3.loss_cls: 0.1429, d3.loss_bbox: 0.2533, d4.loss_cls: 0.1114, d4.loss_bbox: 0.2439, loss: 2.4531, grad_norm: 15.8719
2025-06-11 23:34:24,316 - mmdet - INFO - Epoch [5][2950/3517]	lr: 5.015e-04, eta: 2:08:14, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0934, loss_bbox: 0.2327, d0.loss_cls: 0.1916, d0.loss_bbox: 0.3585, d1.loss_cls: 0.1586, d1.loss_bbox: 0.2628, d2.loss_cls: 0.1484, d2.loss_bbox: 0.2515, d3.loss_cls: 0.1371, d3.loss_bbox: 0.2512, d4.loss_cls: 0.1112, d4.loss_bbox: 0.2421, loss: 2.4389, grad_norm: 15.4379
2025-06-11 23:35:58,382 - mmdet - INFO - Epoch [5][3000/3517]	lr: 5.015e-04, eta: 2:06:40, time: 1.881, data_time: 0.063, memory: 32518, loss_cls: 0.0873, loss_bbox: 0.2299, d0.loss_cls: 0.1856, d0.loss_bbox: 0.3474, d1.loss_cls: 0.1528, d1.loss_bbox: 0.2574, d2.loss_cls: 0.1409, d2.loss_bbox: 0.2489, d3.loss_cls: 0.1327, d3.loss_bbox: 0.2462, d4.loss_cls: 0.1045, d4.loss_bbox: 0.2394, loss: 2.3731, grad_norm: 11.5282
2025-06-11 23:37:32,340 - mmdet - INFO - Epoch [5][3050/3517]	lr: 5.015e-04, eta: 2:05:06, time: 1.879, data_time: 0.065, memory: 32518, loss_cls: 0.0945, loss_bbox: 0.2413, d0.loss_cls: 0.1878, d0.loss_bbox: 0.3588, d1.loss_cls: 0.1617, d1.loss_bbox: 0.2690, d2.loss_cls: 0.1508, d2.loss_bbox: 0.2598, d3.loss_cls: 0.1395, d3.loss_bbox: 0.2596, d4.loss_cls: 0.1126, d4.loss_bbox: 0.2499, loss: 2.4853, grad_norm: 12.2050
2025-06-11 23:39:06,609 - mmdet - INFO - Epoch [5][3100/3517]	lr: 5.015e-04, eta: 2:03:31, time: 1.885, data_time: 0.064, memory: 32518, loss_cls: 0.0875, loss_bbox: 0.2284, d0.loss_cls: 0.1832, d0.loss_bbox: 0.3452, d1.loss_cls: 0.1539, d1.loss_bbox: 0.2564, d2.loss_cls: 0.1436, d2.loss_bbox: 0.2463, d3.loss_cls: 0.1319, d3.loss_bbox: 0.2468, d4.loss_cls: 0.1066, d4.loss_bbox: 0.2377, loss: 2.3674, grad_norm: 17.0833
2025-06-11 23:40:40,652 - mmdet - INFO - Epoch [5][3150/3517]	lr: 5.015e-04, eta: 2:01:57, time: 1.881, data_time: 0.064, memory: 32518, loss_cls: 0.0916, loss_bbox: 0.2368, d0.loss_cls: 0.1915, d0.loss_bbox: 0.3529, d1.loss_cls: 0.1586, d1.loss_bbox: 0.2647, d2.loss_cls: 0.1476, d2.loss_bbox: 0.2535, d3.loss_cls: 0.1371, d3.loss_bbox: 0.2532, d4.loss_cls: 0.1084, d4.loss_bbox: 0.2446, loss: 2.4405, grad_norm: 18.3529
2025-06-11 23:42:15,296 - mmdet - INFO - Epoch [5][3200/3517]	lr: 5.015e-04, eta: 2:00:23, time: 1.893, data_time: 0.064, memory: 32518, loss_cls: 0.0866, loss_bbox: 0.2280, d0.loss_cls: 0.1808, d0.loss_bbox: 0.3496, d1.loss_cls: 0.1520, d1.loss_bbox: 0.2593, d2.loss_cls: 0.1422, d2.loss_bbox: 0.2493, d3.loss_cls: 0.1315, d3.loss_bbox: 0.2479, d4.loss_cls: 0.1042, d4.loss_bbox: 0.2377, loss: 2.3691, grad_norm: 18.4361
2025-06-11 23:43:50,115 - mmdet - INFO - Epoch [5][3250/3517]	lr: 5.015e-04, eta: 1:58:49, time: 1.896, data_time: 0.066, memory: 32518, loss_cls: 0.0915, loss_bbox: 0.2314, d0.loss_cls: 0.1860, d0.loss_bbox: 0.3561, d1.loss_cls: 0.1541, d1.loss_bbox: 0.2644, d2.loss_cls: 0.1445, d2.loss_bbox: 0.2537, d3.loss_cls: 0.1373, d3.loss_bbox: 0.2504, d4.loss_cls: 0.1086, d4.loss_bbox: 0.2416, loss: 2.4195, grad_norm: 17.0941
2025-06-11 23:45:24,811 - mmdet - INFO - Epoch [5][3300/3517]	lr: 5.015e-04, eta: 1:57:15, time: 1.894, data_time: 0.067, memory: 32518, loss_cls: 0.0915, loss_bbox: 0.2379, d0.loss_cls: 0.1841, d0.loss_bbox: 0.3519, d1.loss_cls: 0.1546, d1.loss_bbox: 0.2634, d2.loss_cls: 0.1434, d2.loss_bbox: 0.2561, d3.loss_cls: 0.1342, d3.loss_bbox: 0.2568, d4.loss_cls: 0.1103, d4.loss_bbox: 0.2459, loss: 2.4302, grad_norm: 35.5419
2025-06-11 23:46:59,483 - mmdet - INFO - Epoch [5][3350/3517]	lr: 5.015e-04, eta: 1:55:41, time: 1.893, data_time: 0.067, memory: 32518, loss_cls: 0.0872, loss_bbox: 0.2312, d0.loss_cls: 0.1772, d0.loss_bbox: 0.3450, d1.loss_cls: 0.1527, d1.loss_bbox: 0.2564, d2.loss_cls: 0.1422, d2.loss_bbox: 0.2493, d3.loss_cls: 0.1306, d3.loss_bbox: 0.2482, d4.loss_cls: 0.1045, d4.loss_bbox: 0.2401, loss: 2.3646, grad_norm: 25.9267
2025-06-11 23:48:33,503 - mmdet - INFO - Epoch [5][3400/3517]	lr: 5.015e-04, eta: 1:54:07, time: 1.880, data_time: 0.059, memory: 32518, loss_cls: 0.0860, loss_bbox: 0.2290, d0.loss_cls: 0.1840, d0.loss_bbox: 0.3457, d1.loss_cls: 0.1563, d1.loss_bbox: 0.2561, d2.loss_cls: 0.1442, d2.loss_bbox: 0.2453, d3.loss_cls: 0.1325, d3.loss_bbox: 0.2467, d4.loss_cls: 0.1036, d4.loss_bbox: 0.2376, loss: 2.3671, grad_norm: 14.6563
2025-06-11 23:50:10,755 - mmdet - INFO - Epoch [5][3450/3517]	lr: 5.015e-04, eta: 1:52:33, time: 1.945, data_time: 0.065, memory: 32518, loss_cls: 0.0925, loss_bbox: 0.2337, d0.loss_cls: 0.1858, d0.loss_bbox: 0.3516, d1.loss_cls: 0.1557, d1.loss_bbox: 0.2627, d2.loss_cls: 0.1440, d2.loss_bbox: 0.2529, d3.loss_cls: 0.1340, d3.loss_bbox: 0.2525, d4.loss_cls: 0.1099, d4.loss_bbox: 0.2426, loss: 2.4180, grad_norm: 11.2505
2025-06-11 23:51:44,749 - mmdet - INFO - Epoch [5][3500/3517]	lr: 5.015e-04, eta: 1:50:59, time: 1.880, data_time: 0.059, memory: 32518, loss_cls: 0.0902, loss_bbox: 0.2263, d0.loss_cls: 0.1846, d0.loss_bbox: 0.3448, d1.loss_cls: 0.1568, d1.loss_bbox: 0.2527, d2.loss_cls: 0.1439, d2.loss_bbox: 0.2448, d3.loss_cls: 0.1342, d3.loss_bbox: 0.2429, d4.loss_cls: 0.1051, d4.loss_bbox: 0.2353, loss: 2.3616, grad_norm: 13.1907
2025-06-11 23:52:16,861 - mmdet - INFO - Saving checkpoint at 5 epochs
2025-06-12 00:15:04,822 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-12 00:15:04,823 - mmdet - INFO - Epoch(val) [5][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7867, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8774, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9064, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9207, pts_bbox_NuScenes/car_trans_err: 0.1853, pts_bbox_NuScenes/car_scale_err: 0.1497, pts_bbox_NuScenes/car_orient_err: 0.0484, pts_bbox_NuScenes/car_vel_err: 0.3170, pts_bbox_NuScenes/car_attr_err: 0.1767, pts_bbox_NuScenes/mATE: 0.2994, pts_bbox_NuScenes/mASE: 0.2592, pts_bbox_NuScenes/mAOE: 0.2733, pts_bbox_NuScenes/mAVE: 0.2889, pts_bbox_NuScenes/mAAE: 0.1848, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4257, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6116, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7118, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7485, pts_bbox_NuScenes/truck_trans_err: 0.3356, pts_bbox_NuScenes/truck_scale_err: 0.1896, pts_bbox_NuScenes/truck_orient_err: 0.0593, pts_bbox_NuScenes/truck_vel_err: 0.2803, pts_bbox_NuScenes/truck_attr_err: 0.2132, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0543, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2060, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4071, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4841, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6657, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4339, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7957, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1148, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3034, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5141, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7410, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8977, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9232, pts_bbox_NuScenes/bus_trans_err: 0.3414, pts_bbox_NuScenes/bus_scale_err: 0.1874, pts_bbox_NuScenes/bus_orient_err: 0.0367, pts_bbox_NuScenes/bus_vel_err: 0.4560, pts_bbox_NuScenes/bus_attr_err: 0.2646, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1779, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4322, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5983, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6862, pts_bbox_NuScenes/trailer_trans_err: 0.4884, pts_bbox_NuScenes/trailer_scale_err: 0.2141, pts_bbox_NuScenes/trailer_orient_err: 0.5945, pts_bbox_NuScenes/trailer_vel_err: 0.2388, pts_bbox_NuScenes/trailer_attr_err: 0.1755, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5745, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6790, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7277, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7451, pts_bbox_NuScenes/barrier_trans_err: 0.2236, pts_bbox_NuScenes/barrier_scale_err: 0.2890, pts_bbox_NuScenes/barrier_orient_err: 0.0763, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6105, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7610, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7969, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8061, pts_bbox_NuScenes/motorcycle_trans_err: 0.2475, pts_bbox_NuScenes/motorcycle_scale_err: 0.2399, pts_bbox_NuScenes/motorcycle_orient_err: 0.2334, pts_bbox_NuScenes/motorcycle_vel_err: 0.4877, pts_bbox_NuScenes/motorcycle_attr_err: 0.2276, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5428, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5940, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6060, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6149, pts_bbox_NuScenes/bicycle_trans_err: 0.1895, pts_bbox_NuScenes/bicycle_scale_err: 0.2703, pts_bbox_NuScenes/bicycle_orient_err: 0.2939, pts_bbox_NuScenes/bicycle_vel_err: 0.1965, pts_bbox_NuScenes/bicycle_attr_err: 0.0128, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7983, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8487, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8720, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8854, pts_bbox_NuScenes/pedestrian_trans_err: 0.1631, pts_bbox_NuScenes/pedestrian_scale_err: 0.2917, pts_bbox_NuScenes/pedestrian_orient_err: 0.3215, pts_bbox_NuScenes/pedestrian_vel_err: 0.2204, pts_bbox_NuScenes/pedestrian_attr_err: 0.1049, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7123, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7561, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7826, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8043, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1535, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3263, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7023, pts_bbox_NuScenes/mAP: 0.6657
2025-06-12 00:16:48,497 - mmdet - INFO - Epoch [6][50/3517]	lr: 1.358e-04, eta: 1:48:47, time: 1.997, data_time: 0.175, memory: 32518, loss_cls: 0.0882, loss_bbox: 0.2243, d0.loss_cls: 0.1861, d0.loss_bbox: 0.3442, d1.loss_cls: 0.1519, d1.loss_bbox: 0.2542, d2.loss_cls: 0.1387, d2.loss_bbox: 0.2436, d3.loss_cls: 0.1301, d3.loss_bbox: 0.2414, d4.loss_cls: 0.1046, d4.loss_bbox: 0.2348, loss: 2.3421, grad_norm: 12.3174
2025-06-12 00:18:22,464 - mmdet - INFO - Epoch [6][100/3517]	lr: 1.358e-04, eta: 1:47:13, time: 1.879, data_time: 0.055, memory: 32518, loss_cls: 0.0901, loss_bbox: 0.2209, d0.loss_cls: 0.1872, d0.loss_bbox: 0.3400, d1.loss_cls: 0.1550, d1.loss_bbox: 0.2522, d2.loss_cls: 0.1424, d2.loss_bbox: 0.2410, d3.loss_cls: 0.1304, d3.loss_bbox: 0.2400, d4.loss_cls: 0.1053, d4.loss_bbox: 0.2309, loss: 2.3352, grad_norm: 13.6164
2025-06-12 00:19:56,350 - mmdet - INFO - Epoch [6][150/3517]	lr: 1.358e-04, eta: 1:45:39, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0867, loss_bbox: 0.2190, d0.loss_cls: 0.1796, d0.loss_bbox: 0.3373, d1.loss_cls: 0.1498, d1.loss_bbox: 0.2507, d2.loss_cls: 0.1384, d2.loss_bbox: 0.2391, d3.loss_cls: 0.1251, d3.loss_bbox: 0.2373, d4.loss_cls: 0.1022, d4.loss_bbox: 0.2294, loss: 2.2945, grad_norm: 19.5978
2025-06-12 00:21:30,214 - mmdet - INFO - Epoch [6][200/3517]	lr: 1.358e-04, eta: 1:44:05, time: 1.877, data_time: 0.052, memory: 32518, loss_cls: 0.0906, loss_bbox: 0.2271, d0.loss_cls: 0.1855, d0.loss_bbox: 0.3511, d1.loss_cls: 0.1527, d1.loss_bbox: 0.2589, d2.loss_cls: 0.1411, d2.loss_bbox: 0.2482, d3.loss_cls: 0.1282, d3.loss_bbox: 0.2468, d4.loss_cls: 0.1063, d4.loss_bbox: 0.2376, loss: 2.3740, grad_norm: 20.3231
2025-06-12 00:23:03,226 - mmdet - INFO - Epoch [6][250/3517]	lr: 1.358e-04, eta: 1:42:30, time: 1.860, data_time: 0.057, memory: 32518, loss_cls: 0.0885, loss_bbox: 0.2270, d0.loss_cls: 0.1815, d0.loss_bbox: 0.3451, d1.loss_cls: 0.1515, d1.loss_bbox: 0.2559, d2.loss_cls: 0.1371, d2.loss_bbox: 0.2451, d3.loss_cls: 0.1253, d3.loss_bbox: 0.2433, d4.loss_cls: 0.1037, d4.loss_bbox: 0.2368, loss: 2.3407, grad_norm: 10.6953
2025-06-12 00:24:36,183 - mmdet - INFO - Epoch [6][300/3517]	lr: 1.358e-04, eta: 1:40:56, time: 1.859, data_time: 0.050, memory: 32518, loss_cls: 0.0834, loss_bbox: 0.2188, d0.loss_cls: 0.1796, d0.loss_bbox: 0.3384, d1.loss_cls: 0.1476, d1.loss_bbox: 0.2514, d2.loss_cls: 0.1362, d2.loss_bbox: 0.2397, d3.loss_cls: 0.1206, d3.loss_bbox: 0.2375, d4.loss_cls: 0.0996, d4.loss_bbox: 0.2284, loss: 2.2813, grad_norm: 15.3406
2025-06-12 00:26:10,007 - mmdet - INFO - Epoch [6][350/3517]	lr: 1.358e-04, eta: 1:39:22, time: 1.876, data_time: 0.058, memory: 32518, loss_cls: 0.0904, loss_bbox: 0.2228, d0.loss_cls: 0.1814, d0.loss_bbox: 0.3407, d1.loss_cls: 0.1513, d1.loss_bbox: 0.2535, d2.loss_cls: 0.1383, d2.loss_bbox: 0.2413, d3.loss_cls: 0.1251, d3.loss_bbox: 0.2391, d4.loss_cls: 0.1056, d4.loss_bbox: 0.2336, loss: 2.3231, grad_norm: 15.0787
2025-06-12 00:27:44,535 - mmdet - INFO - Epoch [6][400/3517]	lr: 1.358e-04, eta: 1:37:48, time: 1.891, data_time: 0.069, memory: 32518, loss_cls: 0.0834, loss_bbox: 0.2175, d0.loss_cls: 0.1757, d0.loss_bbox: 0.3341, d1.loss_cls: 0.1473, d1.loss_bbox: 0.2459, d2.loss_cls: 0.1333, d2.loss_bbox: 0.2355, d3.loss_cls: 0.1166, d3.loss_bbox: 0.2330, d4.loss_cls: 0.0982, d4.loss_bbox: 0.2278, loss: 2.2483, grad_norm: 18.6261
2025-06-12 00:29:18,718 - mmdet - INFO - Epoch [6][450/3517]	lr: 1.358e-04, eta: 1:36:14, time: 1.884, data_time: 0.065, memory: 32518, loss_cls: 0.0919, loss_bbox: 0.2331, d0.loss_cls: 0.1815, d0.loss_bbox: 0.3480, d1.loss_cls: 0.1542, d1.loss_bbox: 0.2588, d2.loss_cls: 0.1415, d2.loss_bbox: 0.2494, d3.loss_cls: 0.1240, d3.loss_bbox: 0.2481, d4.loss_cls: 0.1068, d4.loss_bbox: 0.2421, loss: 2.3794, grad_norm: 23.8621
2025-06-12 00:30:52,879 - mmdet - INFO - Epoch [6][500/3517]	lr: 1.358e-04, eta: 1:34:40, time: 1.883, data_time: 0.061, memory: 32518, loss_cls: 0.0856, loss_bbox: 0.2227, d0.loss_cls: 0.1744, d0.loss_bbox: 0.3356, d1.loss_cls: 0.1457, d1.loss_bbox: 0.2509, d2.loss_cls: 0.1334, d2.loss_bbox: 0.2394, d3.loss_cls: 0.1161, d3.loss_bbox: 0.2380, d4.loss_cls: 0.0995, d4.loss_bbox: 0.2320, loss: 2.2734, grad_norm: 12.5507
2025-06-12 00:32:26,306 - mmdet - INFO - Epoch [6][550/3517]	lr: 1.358e-04, eta: 1:33:05, time: 1.869, data_time: 0.064, memory: 32518, loss_cls: 0.0876, loss_bbox: 0.2198, d0.loss_cls: 0.1769, d0.loss_bbox: 0.3425, d1.loss_cls: 0.1482, d1.loss_bbox: 0.2533, d2.loss_cls: 0.1373, d2.loss_bbox: 0.2392, d3.loss_cls: 0.1182, d3.loss_bbox: 0.2376, d4.loss_cls: 0.1016, d4.loss_bbox: 0.2309, loss: 2.2932, grad_norm: 13.0029
2025-06-12 00:33:59,697 - mmdet - INFO - Epoch [6][600/3517]	lr: 1.358e-04, eta: 1:31:31, time: 1.868, data_time: 0.055, memory: 32518, loss_cls: 0.0886, loss_bbox: 0.2194, d0.loss_cls: 0.1766, d0.loss_bbox: 0.3344, d1.loss_cls: 0.1488, d1.loss_bbox: 0.2494, d2.loss_cls: 0.1366, d2.loss_bbox: 0.2386, d3.loss_cls: 0.1188, d3.loss_bbox: 0.2360, d4.loss_cls: 0.1016, d4.loss_bbox: 0.2294, loss: 2.2784, grad_norm: 15.1716
2025-06-12 00:35:34,006 - mmdet - INFO - Epoch [6][650/3517]	lr: 1.358e-04, eta: 1:29:57, time: 1.886, data_time: 0.059, memory: 32518, loss_cls: 0.0865, loss_bbox: 0.2248, d0.loss_cls: 0.1814, d0.loss_bbox: 0.3429, d1.loss_cls: 0.1537, d1.loss_bbox: 0.2530, d2.loss_cls: 0.1416, d2.loss_bbox: 0.2437, d3.loss_cls: 0.1222, d3.loss_bbox: 0.2408, d4.loss_cls: 0.1023, d4.loss_bbox: 0.2344, loss: 2.3272, grad_norm: 21.0838
2025-06-12 00:37:08,787 - mmdet - INFO - Epoch [6][700/3517]	lr: 1.358e-04, eta: 1:28:23, time: 1.896, data_time: 0.058, memory: 32518, loss_cls: 0.0841, loss_bbox: 0.2237, d0.loss_cls: 0.1725, d0.loss_bbox: 0.3316, d1.loss_cls: 0.1438, d1.loss_bbox: 0.2498, d2.loss_cls: 0.1314, d2.loss_bbox: 0.2416, d3.loss_cls: 0.1148, d3.loss_bbox: 0.2389, d4.loss_cls: 0.0970, d4.loss_bbox: 0.2325, loss: 2.2618, grad_norm: 13.9575
2025-06-12 00:38:42,311 - mmdet - INFO - Epoch [6][750/3517]	lr: 1.358e-04, eta: 1:26:49, time: 1.870, data_time: 0.056, memory: 32518, loss_cls: 0.0849, loss_bbox: 0.2197, d0.loss_cls: 0.1753, d0.loss_bbox: 0.3344, d1.loss_cls: 0.1452, d1.loss_bbox: 0.2488, d2.loss_cls: 0.1331, d2.loss_bbox: 0.2366, d3.loss_cls: 0.1134, d3.loss_bbox: 0.2362, d4.loss_cls: 0.0976, d4.loss_bbox: 0.2314, loss: 2.2566, grad_norm: 27.7270
2025-06-12 00:40:15,911 - mmdet - INFO - Epoch [6][800/3517]	lr: 1.358e-04, eta: 1:25:14, time: 1.872, data_time: 0.064, memory: 32518, loss_cls: 0.0884, loss_bbox: 0.2218, d0.loss_cls: 0.1760, d0.loss_bbox: 0.3427, d1.loss_cls: 0.1465, d1.loss_bbox: 0.2523, d2.loss_cls: 0.1342, d2.loss_bbox: 0.2406, d3.loss_cls: 0.1173, d3.loss_bbox: 0.2392, d4.loss_cls: 0.1011, d4.loss_bbox: 0.2323, loss: 2.2924, grad_norm: 17.0535
2025-06-12 00:41:49,384 - mmdet - INFO - Epoch [6][850/3517]	lr: 1.358e-04, eta: 1:23:40, time: 1.869, data_time: 0.060, memory: 32518, loss_cls: 0.0814, loss_bbox: 0.2207, d0.loss_cls: 0.1728, d0.loss_bbox: 0.3331, d1.loss_cls: 0.1430, d1.loss_bbox: 0.2493, d2.loss_cls: 0.1284, d2.loss_bbox: 0.2387, d3.loss_cls: 0.1101, d3.loss_bbox: 0.2374, d4.loss_cls: 0.0960, d4.loss_bbox: 0.2308, loss: 2.2418, grad_norm: 14.3952
2025-06-12 00:43:25,308 - mmdet - INFO - Epoch [6][900/3517]	lr: 1.358e-04, eta: 1:22:06, time: 1.918, data_time: 0.068, memory: 32518, loss_cls: 0.0837, loss_bbox: 0.2197, d0.loss_cls: 0.1802, d0.loss_bbox: 0.3379, d1.loss_cls: 0.1484, d1.loss_bbox: 0.2497, d2.loss_cls: 0.1350, d2.loss_bbox: 0.2378, d3.loss_cls: 0.1152, d3.loss_bbox: 0.2367, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2300, loss: 2.2719, grad_norm: 11.4578
2025-06-12 00:45:10,229 - mmdet - INFO - Epoch [6][950/3517]	lr: 1.358e-04, eta: 1:20:34, time: 2.098, data_time: 0.082, memory: 32518, loss_cls: 0.0869, loss_bbox: 0.2193, d0.loss_cls: 0.1802, d0.loss_bbox: 0.3349, d1.loss_cls: 0.1532, d1.loss_bbox: 0.2488, d2.loss_cls: 0.1388, d2.loss_bbox: 0.2368, d3.loss_cls: 0.1174, d3.loss_bbox: 0.2356, d4.loss_cls: 0.1018, d4.loss_bbox: 0.2287, loss: 2.2824, grad_norm: 11.0192
2025-06-12 00:46:44,456 - mmdet - INFO - Epoch [6][1000/3517]	lr: 1.358e-04, eta: 1:19:00, time: 1.885, data_time: 0.068, memory: 32518, loss_cls: 0.0828, loss_bbox: 0.2159, d0.loss_cls: 0.1722, d0.loss_bbox: 0.3215, d1.loss_cls: 0.1441, d1.loss_bbox: 0.2415, d2.loss_cls: 0.1295, d2.loss_bbox: 0.2323, d3.loss_cls: 0.1118, d3.loss_bbox: 0.2295, d4.loss_cls: 0.0973, d4.loss_bbox: 0.2238, loss: 2.2023, grad_norm: 17.5133
2025-06-12 00:48:19,112 - mmdet - INFO - Epoch [6][1050/3517]	lr: 1.358e-04, eta: 1:17:25, time: 1.893, data_time: 0.073, memory: 32518, loss_cls: 0.0862, loss_bbox: 0.2207, d0.loss_cls: 0.1776, d0.loss_bbox: 0.3347, d1.loss_cls: 0.1474, d1.loss_bbox: 0.2480, d2.loss_cls: 0.1339, d2.loss_bbox: 0.2380, d3.loss_cls: 0.1166, d3.loss_bbox: 0.2359, d4.loss_cls: 0.1003, d4.loss_bbox: 0.2301, loss: 2.2693, grad_norm: 11.5548
2025-06-12 00:49:52,564 - mmdet - INFO - Epoch [6][1100/3517]	lr: 1.358e-04, eta: 1:15:51, time: 1.869, data_time: 0.054, memory: 32518, loss_cls: 0.0857, loss_bbox: 0.2148, d0.loss_cls: 0.1750, d0.loss_bbox: 0.3280, d1.loss_cls: 0.1444, d1.loss_bbox: 0.2441, d2.loss_cls: 0.1339, d2.loss_bbox: 0.2341, d3.loss_cls: 0.1150, d3.loss_bbox: 0.2323, d4.loss_cls: 0.1001, d4.loss_bbox: 0.2246, loss: 2.2320, grad_norm: 12.6707
2025-06-12 00:51:25,778 - mmdet - INFO - Epoch [6][1150/3517]	lr: 1.358e-04, eta: 1:14:17, time: 1.864, data_time: 0.051, memory: 32518, loss_cls: 0.0865, loss_bbox: 0.2187, d0.loss_cls: 0.1782, d0.loss_bbox: 0.3321, d1.loss_cls: 0.1498, d1.loss_bbox: 0.2478, d2.loss_cls: 0.1363, d2.loss_bbox: 0.2374, d3.loss_cls: 0.1159, d3.loss_bbox: 0.2357, d4.loss_cls: 0.1004, d4.loss_bbox: 0.2283, loss: 2.2671, grad_norm: 14.4400
2025-06-12 00:52:59,203 - mmdet - INFO - Epoch [6][1200/3517]	lr: 1.358e-04, eta: 1:12:43, time: 1.868, data_time: 0.060, memory: 32518, loss_cls: 0.0850, loss_bbox: 0.2229, d0.loss_cls: 0.1740, d0.loss_bbox: 0.3407, d1.loss_cls: 0.1459, d1.loss_bbox: 0.2510, d2.loss_cls: 0.1327, d2.loss_bbox: 0.2397, d3.loss_cls: 0.1128, d3.loss_bbox: 0.2379, d4.loss_cls: 0.0981, d4.loss_bbox: 0.2324, loss: 2.2731, grad_norm: 14.1316
2025-06-12 00:54:32,326 - mmdet - INFO - Epoch [6][1250/3517]	lr: 1.358e-04, eta: 1:11:08, time: 1.862, data_time: 0.060, memory: 32518, loss_cls: 0.0880, loss_bbox: 0.2240, d0.loss_cls: 0.1790, d0.loss_bbox: 0.3454, d1.loss_cls: 0.1491, d1.loss_bbox: 0.2548, d2.loss_cls: 0.1352, d2.loss_bbox: 0.2435, d3.loss_cls: 0.1149, d3.loss_bbox: 0.2416, d4.loss_cls: 0.1002, d4.loss_bbox: 0.2347, loss: 2.3104, grad_norm: 27.9252
2025-06-12 00:57:16,165 - mmdet - INFO - Epoch [6][1300/3517]	lr: 1.358e-04, eta: 1:09:42, time: 3.277, data_time: 0.147, memory: 32518, loss_cls: 0.0860, loss_bbox: 0.2228, d0.loss_cls: 0.1757, d0.loss_bbox: 0.3347, d1.loss_cls: 0.1475, d1.loss_bbox: 0.2503, d2.loss_cls: 0.1348, d2.loss_bbox: 0.2415, d3.loss_cls: 0.1142, d3.loss_bbox: 0.2407, d4.loss_cls: 0.0991, d4.loss_bbox: 0.2324, loss: 2.2797, grad_norm: 10.5422
2025-06-12 00:59:00,928 - mmdet - INFO - Epoch [6][1350/3517]	lr: 1.358e-04, eta: 1:08:09, time: 2.095, data_time: 0.063, memory: 32518, loss_cls: 0.0816, loss_bbox: 0.2154, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3338, d1.loss_cls: 0.1439, d1.loss_bbox: 0.2446, d2.loss_cls: 0.1296, d2.loss_bbox: 0.2342, d3.loss_cls: 0.1106, d3.loss_bbox: 0.2312, d4.loss_cls: 0.0943, d4.loss_bbox: 0.2266, loss: 2.2195, grad_norm: 11.5032
2025-06-12 01:00:34,572 - mmdet - INFO - Epoch [6][1400/3517]	lr: 1.358e-04, eta: 1:06:35, time: 1.873, data_time: 0.068, memory: 32518, loss_cls: 0.0891, loss_bbox: 0.2169, d0.loss_cls: 0.1766, d0.loss_bbox: 0.3341, d1.loss_cls: 0.1484, d1.loss_bbox: 0.2479, d2.loss_cls: 0.1364, d2.loss_bbox: 0.2368, d3.loss_cls: 0.1148, d3.loss_bbox: 0.2360, d4.loss_cls: 0.1003, d4.loss_bbox: 0.2284, loss: 2.2659, grad_norm: 78.2465
2025-06-12 01:02:09,090 - mmdet - INFO - Epoch [6][1450/3517]	lr: 1.358e-04, eta: 1:05:01, time: 1.890, data_time: 0.062, memory: 32518, loss_cls: 0.0858, loss_bbox: 0.2183, d0.loss_cls: 0.1781, d0.loss_bbox: 0.3420, d1.loss_cls: 0.1515, d1.loss_bbox: 0.2489, d2.loss_cls: 0.1358, d2.loss_bbox: 0.2391, d3.loss_cls: 0.1155, d3.loss_bbox: 0.2366, d4.loss_cls: 0.0989, d4.loss_bbox: 0.2302, loss: 2.2807, grad_norm: 10.6280
2025-06-12 01:03:44,427 - mmdet - INFO - Epoch [6][1500/3517]	lr: 1.358e-04, eta: 1:03:26, time: 1.907, data_time: 0.074, memory: 32518, loss_cls: 0.0866, loss_bbox: 0.2238, d0.loss_cls: 0.1811, d0.loss_bbox: 0.3403, d1.loss_cls: 0.1484, d1.loss_bbox: 0.2505, d2.loss_cls: 0.1347, d2.loss_bbox: 0.2405, d3.loss_cls: 0.1166, d3.loss_bbox: 0.2365, d4.loss_cls: 0.0993, d4.loss_bbox: 0.2323, loss: 2.2905, grad_norm: 12.9613
2025-06-12 01:05:19,079 - mmdet - INFO - Epoch [6][1550/3517]	lr: 1.358e-04, eta: 1:01:52, time: 1.893, data_time: 0.065, memory: 32518, loss_cls: 0.0847, loss_bbox: 0.2217, d0.loss_cls: 0.1732, d0.loss_bbox: 0.3401, d1.loss_cls: 0.1478, d1.loss_bbox: 0.2524, d2.loss_cls: 0.1334, d2.loss_bbox: 0.2419, d3.loss_cls: 0.1131, d3.loss_bbox: 0.2396, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2320, loss: 2.2770, grad_norm: 47.2760
2025-06-12 01:06:56,369 - mmdet - INFO - Epoch [6][1600/3517]	lr: 1.358e-04, eta: 1:00:18, time: 1.946, data_time: 0.060, memory: 32518, loss_cls: 0.0844, loss_bbox: 0.2178, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3356, d1.loss_cls: 0.1446, d1.loss_bbox: 0.2476, d2.loss_cls: 0.1315, d2.loss_bbox: 0.2381, d3.loss_cls: 0.1113, d3.loss_bbox: 0.2348, d4.loss_cls: 0.0974, d4.loss_bbox: 0.2286, loss: 2.2455, grad_norm: 15.2590
2025-06-12 01:09:10,556 - mmdet - INFO - Epoch [6][1650/3517]	lr: 1.358e-04, eta: 0:58:47, time: 2.684, data_time: 0.355, memory: 32518, loss_cls: 0.0852, loss_bbox: 0.2167, d0.loss_cls: 0.1792, d0.loss_bbox: 0.3320, d1.loss_cls: 0.1489, d1.loss_bbox: 0.2444, d2.loss_cls: 0.1352, d2.loss_bbox: 0.2346, d3.loss_cls: 0.1154, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0977, d4.loss_bbox: 0.2267, loss: 2.2489, grad_norm: 15.5834
2025-06-12 01:11:26,705 - mmdet - INFO - Epoch [6][1700/3517]	lr: 1.358e-04, eta: 0:57:17, time: 2.723, data_time: 0.856, memory: 32518, loss_cls: 0.0845, loss_bbox: 0.2221, d0.loss_cls: 0.1791, d0.loss_bbox: 0.3353, d1.loss_cls: 0.1504, d1.loss_bbox: 0.2509, d2.loss_cls: 0.1329, d2.loss_bbox: 0.2412, d3.loss_cls: 0.1123, d3.loss_bbox: 0.2382, d4.loss_cls: 0.0979, d4.loss_bbox: 0.2319, loss: 2.2767, grad_norm: 41.6448
2025-06-12 01:13:53,642 - mmdet - INFO - Epoch [6][1750/3517]	lr: 1.358e-04, eta: 0:55:47, time: 2.939, data_time: 1.135, memory: 32518, loss_cls: 0.0872, loss_bbox: 0.2235, d0.loss_cls: 0.1780, d0.loss_bbox: 0.3394, d1.loss_cls: 0.1489, d1.loss_bbox: 0.2532, d2.loss_cls: 0.1333, d2.loss_bbox: 0.2407, d3.loss_cls: 0.1152, d3.loss_bbox: 0.2386, d4.loss_cls: 0.0994, d4.loss_bbox: 0.2333, loss: 2.2906, grad_norm: 36.9686
2025-06-12 01:16:16,139 - mmdet - INFO - Epoch [6][1800/3517]	lr: 1.358e-04, eta: 0:54:16, time: 2.850, data_time: 1.065, memory: 32518, loss_cls: 0.0856, loss_bbox: 0.2265, d0.loss_cls: 0.1793, d0.loss_bbox: 0.3411, d1.loss_cls: 0.1495, d1.loss_bbox: 0.2561, d2.loss_cls: 0.1362, d2.loss_bbox: 0.2433, d3.loss_cls: 0.1163, d3.loss_bbox: 0.2417, d4.loss_cls: 0.0993, d4.loss_bbox: 0.2361, loss: 2.3111, grad_norm: 43.8074
2025-06-12 01:18:54,711 - mmdet - INFO - Epoch [6][1850/3517]	lr: 1.358e-04, eta: 0:52:47, time: 3.171, data_time: 0.893, memory: 32518, loss_cls: 0.0855, loss_bbox: 0.2185, d0.loss_cls: 0.1723, d0.loss_bbox: 0.3366, d1.loss_cls: 0.1415, d1.loss_bbox: 0.2487, d2.loss_cls: 0.1290, d2.loss_bbox: 0.2380, d3.loss_cls: 0.1101, d3.loss_bbox: 0.2363, d4.loss_cls: 0.0958, d4.loss_bbox: 0.2286, loss: 2.2409, grad_norm: 15.1586
2025-06-12 01:21:24,045 - mmdet - INFO - Epoch [6][1900/3517]	lr: 1.358e-04, eta: 0:51:17, time: 2.987, data_time: 0.166, memory: 32518, loss_cls: 0.0813, loss_bbox: 0.2193, d0.loss_cls: 0.1792, d0.loss_bbox: 0.3328, d1.loss_cls: 0.1454, d1.loss_bbox: 0.2465, d2.loss_cls: 0.1330, d2.loss_bbox: 0.2341, d3.loss_cls: 0.1111, d3.loss_bbox: 0.2333, d4.loss_cls: 0.0953, d4.loss_bbox: 0.2276, loss: 2.2389, grad_norm: 14.4184
2025-06-12 01:23:06,223 - mmdet - INFO - Epoch [6][1950/3517]	lr: 1.358e-04, eta: 0:49:42, time: 2.044, data_time: 0.173, memory: 32518, loss_cls: 0.0864, loss_bbox: 0.2241, d0.loss_cls: 0.1779, d0.loss_bbox: 0.3435, d1.loss_cls: 0.1496, d1.loss_bbox: 0.2550, d2.loss_cls: 0.1358, d2.loss_bbox: 0.2416, d3.loss_cls: 0.1159, d3.loss_bbox: 0.2407, d4.loss_cls: 0.0998, d4.loss_bbox: 0.2348, loss: 2.3050, grad_norm: 10.1161
2025-06-12 01:24:55,500 - mmdet - INFO - Epoch [6][2000/3517]	lr: 1.358e-04, eta: 0:48:08, time: 2.185, data_time: 0.337, memory: 32518, loss_cls: 0.0855, loss_bbox: 0.2235, d0.loss_cls: 0.1755, d0.loss_bbox: 0.3371, d1.loss_cls: 0.1445, d1.loss_bbox: 0.2519, d2.loss_cls: 0.1295, d2.loss_bbox: 0.2417, d3.loss_cls: 0.1133, d3.loss_bbox: 0.2393, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2331, loss: 2.2721, grad_norm: 15.6594
2025-06-12 01:26:29,136 - mmdet - INFO - Epoch [6][2050/3517]	lr: 1.358e-04, eta: 0:46:33, time: 1.873, data_time: 0.066, memory: 32518, loss_cls: 0.0876, loss_bbox: 0.2203, d0.loss_cls: 0.1767, d0.loss_bbox: 0.3352, d1.loss_cls: 0.1497, d1.loss_bbox: 0.2485, d2.loss_cls: 0.1366, d2.loss_bbox: 0.2377, d3.loss_cls: 0.1181, d3.loss_bbox: 0.2353, d4.loss_cls: 0.1028, d4.loss_bbox: 0.2300, loss: 2.2785, grad_norm: 18.1021
2025-06-12 01:28:02,458 - mmdet - INFO - Epoch [6][2100/3517]	lr: 1.358e-04, eta: 0:44:57, time: 1.866, data_time: 0.065, memory: 32518, loss_cls: 0.0838, loss_bbox: 0.2263, d0.loss_cls: 0.1788, d0.loss_bbox: 0.3394, d1.loss_cls: 0.1460, d1.loss_bbox: 0.2542, d2.loss_cls: 0.1323, d2.loss_bbox: 0.2441, d3.loss_cls: 0.1124, d3.loss_bbox: 0.2430, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2347, loss: 2.2929, grad_norm: 10.7544
2025-06-12 01:29:43,325 - mmdet - INFO - Epoch [6][2150/3517]	lr: 1.358e-04, eta: 0:43:22, time: 2.017, data_time: 0.226, memory: 32518, loss_cls: 0.0847, loss_bbox: 0.2228, d0.loss_cls: 0.1809, d0.loss_bbox: 0.3406, d1.loss_cls: 0.1483, d1.loss_bbox: 0.2510, d2.loss_cls: 0.1332, d2.loss_bbox: 0.2409, d3.loss_cls: 0.1133, d3.loss_bbox: 0.2395, d4.loss_cls: 0.0987, d4.loss_bbox: 0.2321, loss: 2.2860, grad_norm: 12.7297
2025-06-12 01:31:17,686 - mmdet - INFO - Epoch [6][2200/3517]	lr: 1.358e-04, eta: 0:41:47, time: 1.887, data_time: 0.083, memory: 32518, loss_cls: 0.0801, loss_bbox: 0.2196, d0.loss_cls: 0.1744, d0.loss_bbox: 0.3339, d1.loss_cls: 0.1445, d1.loss_bbox: 0.2485, d2.loss_cls: 0.1279, d2.loss_bbox: 0.2379, d3.loss_cls: 0.1073, d3.loss_bbox: 0.2362, d4.loss_cls: 0.0937, d4.loss_bbox: 0.2293, loss: 2.2333, grad_norm: 75.4536
2025-06-12 01:32:53,615 - mmdet - INFO - Epoch [6][2250/3517]	lr: 1.358e-04, eta: 0:40:12, time: 1.918, data_time: 0.069, memory: 32518, loss_cls: 0.0839, loss_bbox: 0.2186, d0.loss_cls: 0.1716, d0.loss_bbox: 0.3365, d1.loss_cls: 0.1400, d1.loss_bbox: 0.2481, d2.loss_cls: 0.1270, d2.loss_bbox: 0.2372, d3.loss_cls: 0.1091, d3.loss_bbox: 0.2352, d4.loss_cls: 0.0974, d4.loss_bbox: 0.2291, loss: 2.2337, grad_norm: 16.9773
2025-06-12 01:34:28,685 - mmdet - INFO - Epoch [6][2300/3517]	lr: 1.358e-04, eta: 0:38:37, time: 1.902, data_time: 0.061, memory: 32518, loss_cls: 0.0891, loss_bbox: 0.2259, d0.loss_cls: 0.1795, d0.loss_bbox: 0.3401, d1.loss_cls: 0.1486, d1.loss_bbox: 0.2554, d2.loss_cls: 0.1362, d2.loss_bbox: 0.2448, d3.loss_cls: 0.1176, d3.loss_bbox: 0.2426, d4.loss_cls: 0.1018, d4.loss_bbox: 0.2363, loss: 2.3180, grad_norm: 11.9906
2025-06-12 01:36:04,133 - mmdet - INFO - Epoch [6][2350/3517]	lr: 1.358e-04, eta: 0:37:02, time: 1.909, data_time: 0.061, memory: 32518, loss_cls: 0.0842, loss_bbox: 0.2207, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3314, d1.loss_cls: 0.1438, d1.loss_bbox: 0.2483, d2.loss_cls: 0.1292, d2.loss_bbox: 0.2370, d3.loss_cls: 0.1103, d3.loss_bbox: 0.2348, d4.loss_cls: 0.0964, d4.loss_bbox: 0.2287, loss: 2.2409, grad_norm: 24.4934
2025-06-12 01:37:39,691 - mmdet - INFO - Epoch [6][2400/3517]	lr: 1.358e-04, eta: 0:35:26, time: 1.911, data_time: 0.069, memory: 32518, loss_cls: 0.0829, loss_bbox: 0.2229, d0.loss_cls: 0.1775, d0.loss_bbox: 0.3406, d1.loss_cls: 0.1459, d1.loss_bbox: 0.2520, d2.loss_cls: 0.1337, d2.loss_bbox: 0.2419, d3.loss_cls: 0.1131, d3.loss_bbox: 0.2400, d4.loss_cls: 0.0976, d4.loss_bbox: 0.2321, loss: 2.2801, grad_norm: 11.8376
2025-06-12 01:39:15,319 - mmdet - INFO - Epoch [6][2450/3517]	lr: 1.358e-04, eta: 0:33:51, time: 1.913, data_time: 0.069, memory: 32518, loss_cls: 0.0820, loss_bbox: 0.2168, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3263, d1.loss_cls: 0.1394, d1.loss_bbox: 0.2431, d2.loss_cls: 0.1281, d2.loss_bbox: 0.2330, d3.loss_cls: 0.1066, d3.loss_bbox: 0.2325, d4.loss_cls: 0.0937, d4.loss_bbox: 0.2267, loss: 2.1981, grad_norm: 14.8858
2025-06-12 01:40:50,065 - mmdet - INFO - Epoch [6][2500/3517]	lr: 1.358e-04, eta: 0:32:16, time: 1.895, data_time: 0.066, memory: 32518, loss_cls: 0.0854, loss_bbox: 0.2270, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3482, d1.loss_cls: 0.1462, d1.loss_bbox: 0.2579, d2.loss_cls: 0.1331, d2.loss_bbox: 0.2446, d3.loss_cls: 0.1113, d3.loss_bbox: 0.2440, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2367, loss: 2.3079, grad_norm: 11.2970
2025-06-12 01:42:24,948 - mmdet - INFO - Epoch [6][2550/3517]	lr: 1.358e-04, eta: 0:30:41, time: 1.898, data_time: 0.065, memory: 32518, loss_cls: 0.0844, loss_bbox: 0.2207, d0.loss_cls: 0.1780, d0.loss_bbox: 0.3377, d1.loss_cls: 0.1456, d1.loss_bbox: 0.2510, d2.loss_cls: 0.1320, d2.loss_bbox: 0.2406, d3.loss_cls: 0.1113, d3.loss_bbox: 0.2386, d4.loss_cls: 0.0972, d4.loss_bbox: 0.2308, loss: 2.2679, grad_norm: 16.7288
2025-06-12 01:43:58,586 - mmdet - INFO - Epoch [6][2600/3517]	lr: 1.358e-04, eta: 0:29:06, time: 1.873, data_time: 0.048, memory: 32518, loss_cls: 0.0817, loss_bbox: 0.2167, d0.loss_cls: 0.1724, d0.loss_bbox: 0.3311, d1.loss_cls: 0.1425, d1.loss_bbox: 0.2446, d2.loss_cls: 0.1271, d2.loss_bbox: 0.2343, d3.loss_cls: 0.1089, d3.loss_bbox: 0.2321, d4.loss_cls: 0.0959, d4.loss_bbox: 0.2256, loss: 2.2129, grad_norm: 40.7980
2025-06-12 01:45:31,464 - mmdet - INFO - Epoch [6][2650/3517]	lr: 1.358e-04, eta: 0:27:30, time: 1.858, data_time: 0.049, memory: 32518, loss_cls: 0.0849, loss_bbox: 0.2198, d0.loss_cls: 0.1793, d0.loss_bbox: 0.3351, d1.loss_cls: 0.1489, d1.loss_bbox: 0.2502, d2.loss_cls: 0.1348, d2.loss_bbox: 0.2376, d3.loss_cls: 0.1150, d3.loss_bbox: 0.2371, d4.loss_cls: 0.0988, d4.loss_bbox: 0.2313, loss: 2.2728, grad_norm: 14.0146
2025-06-12 01:47:04,079 - mmdet - INFO - Epoch [6][2700/3517]	lr: 1.358e-04, eta: 0:25:55, time: 1.852, data_time: 0.048, memory: 32518, loss_cls: 0.0777, loss_bbox: 0.2160, d0.loss_cls: 0.1704, d0.loss_bbox: 0.3314, d1.loss_cls: 0.1407, d1.loss_bbox: 0.2427, d2.loss_cls: 0.1242, d2.loss_bbox: 0.2329, d3.loss_cls: 0.1055, d3.loss_bbox: 0.2310, d4.loss_cls: 0.0911, d4.loss_bbox: 0.2254, loss: 2.1891, grad_norm: 26.2885
2025-06-12 01:48:37,479 - mmdet - INFO - Epoch [6][2750/3517]	lr: 1.358e-04, eta: 0:24:20, time: 1.868, data_time: 0.048, memory: 32518, loss_cls: 0.0873, loss_bbox: 0.2279, d0.loss_cls: 0.1774, d0.loss_bbox: 0.3440, d1.loss_cls: 0.1489, d1.loss_bbox: 0.2571, d2.loss_cls: 0.1350, d2.loss_bbox: 0.2456, d3.loss_cls: 0.1153, d3.loss_bbox: 0.2443, d4.loss_cls: 0.0999, d4.loss_bbox: 0.2388, loss: 2.3216, grad_norm: 41.3862
2025-06-12 01:50:11,474 - mmdet - INFO - Epoch [6][2800/3517]	lr: 1.358e-04, eta: 0:22:44, time: 1.880, data_time: 0.059, memory: 32518, loss_cls: 0.0828, loss_bbox: 0.2268, d0.loss_cls: 0.1732, d0.loss_bbox: 0.3438, d1.loss_cls: 0.1444, d1.loss_bbox: 0.2567, d2.loss_cls: 0.1310, d2.loss_bbox: 0.2445, d3.loss_cls: 0.1099, d3.loss_bbox: 0.2432, d4.loss_cls: 0.0959, d4.loss_bbox: 0.2361, loss: 2.2882, grad_norm: 165.1740
2025-06-12 01:51:45,041 - mmdet - INFO - Epoch [6][2850/3517]	lr: 1.358e-04, eta: 0:21:09, time: 1.871, data_time: 0.061, memory: 32518, loss_cls: 0.0793, loss_bbox: 0.2215, d0.loss_cls: 0.1749, d0.loss_bbox: 0.3426, d1.loss_cls: 0.1447, d1.loss_bbox: 0.2513, d2.loss_cls: 0.1316, d2.loss_bbox: 0.2407, d3.loss_cls: 0.1098, d3.loss_bbox: 0.2389, d4.loss_cls: 0.0933, d4.loss_bbox: 0.2318, loss: 2.2604, grad_norm: 14.2905
2025-06-12 01:53:19,478 - mmdet - INFO - Epoch [6][2900/3517]	lr: 1.358e-04, eta: 0:19:34, time: 1.889, data_time: 0.073, memory: 32518, loss_cls: 0.0800, loss_bbox: 0.2113, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3302, d1.loss_cls: 0.1425, d1.loss_bbox: 0.2424, d2.loss_cls: 0.1294, d2.loss_bbox: 0.2299, d3.loss_cls: 0.1088, d3.loss_bbox: 0.2289, d4.loss_cls: 0.0940, d4.loss_bbox: 0.2210, loss: 2.1914, grad_norm: 11.7359
2025-06-12 01:54:53,879 - mmdet - INFO - Epoch [6][2950/3517]	lr: 1.358e-04, eta: 0:17:59, time: 1.888, data_time: 0.068, memory: 32518, loss_cls: 0.0876, loss_bbox: 0.2227, d0.loss_cls: 0.1711, d0.loss_bbox: 0.3396, d1.loss_cls: 0.1451, d1.loss_bbox: 0.2534, d2.loss_cls: 0.1332, d2.loss_bbox: 0.2402, d3.loss_cls: 0.1126, d3.loss_bbox: 0.2391, d4.loss_cls: 0.0996, d4.loss_bbox: 0.2325, loss: 2.2768, grad_norm: 15.7170
2025-06-12 01:56:27,582 - mmdet - INFO - Epoch [6][3000/3517]	lr: 1.358e-04, eta: 0:16:24, time: 1.874, data_time: 0.058, memory: 32518, loss_cls: 0.0862, loss_bbox: 0.2216, d0.loss_cls: 0.1812, d0.loss_bbox: 0.3309, d1.loss_cls: 0.1487, d1.loss_bbox: 0.2482, d2.loss_cls: 0.1345, d2.loss_bbox: 0.2372, d3.loss_cls: 0.1117, d3.loss_bbox: 0.2366, d4.loss_cls: 0.0985, d4.loss_bbox: 0.2303, loss: 2.2654, grad_norm: 19.8544
2025-06-12 01:58:01,336 - mmdet - INFO - Epoch [6][3050/3517]	lr: 1.358e-04, eta: 0:14:48, time: 1.875, data_time: 0.059, memory: 32518, loss_cls: 0.0848, loss_bbox: 0.2239, d0.loss_cls: 0.1786, d0.loss_bbox: 0.3368, d1.loss_cls: 0.1457, d1.loss_bbox: 0.2532, d2.loss_cls: 0.1301, d2.loss_bbox: 0.2443, d3.loss_cls: 0.1101, d3.loss_bbox: 0.2413, d4.loss_cls: 0.0969, d4.loss_bbox: 0.2337, loss: 2.2795, grad_norm: 12.8468
2025-06-12 01:59:34,917 - mmdet - INFO - Epoch [6][3100/3517]	lr: 1.358e-04, eta: 0:13:13, time: 1.872, data_time: 0.062, memory: 32518, loss_cls: 0.0832, loss_bbox: 0.2254, d0.loss_cls: 0.1769, d0.loss_bbox: 0.3391, d1.loss_cls: 0.1441, d1.loss_bbox: 0.2545, d2.loss_cls: 0.1299, d2.loss_bbox: 0.2437, d3.loss_cls: 0.1081, d3.loss_bbox: 0.2430, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2351, loss: 2.2782, grad_norm: 24.1798
2025-06-12 02:01:08,286 - mmdet - INFO - Epoch [6][3150/3517]	lr: 1.358e-04, eta: 0:11:38, time: 1.867, data_time: 0.051, memory: 32518, loss_cls: 0.0854, loss_bbox: 0.2203, d0.loss_cls: 0.1746, d0.loss_bbox: 0.3295, d1.loss_cls: 0.1450, d1.loss_bbox: 0.2481, d2.loss_cls: 0.1331, d2.loss_bbox: 0.2371, d3.loss_cls: 0.1131, d3.loss_bbox: 0.2347, d4.loss_cls: 0.0990, d4.loss_bbox: 0.2288, loss: 2.2486, grad_norm: 11.0075
2025-06-12 02:02:42,030 - mmdet - INFO - Epoch [6][3200/3517]	lr: 1.358e-04, eta: 0:10:03, time: 1.875, data_time: 0.063, memory: 32518, loss_cls: 0.0871, loss_bbox: 0.2247, d0.loss_cls: 0.1756, d0.loss_bbox: 0.3391, d1.loss_cls: 0.1473, d1.loss_bbox: 0.2537, d2.loss_cls: 0.1322, d2.loss_bbox: 0.2436, d3.loss_cls: 0.1138, d3.loss_bbox: 0.2414, d4.loss_cls: 0.0986, d4.loss_bbox: 0.2355, loss: 2.2926, grad_norm: 12.2992
2025-06-12 02:04:16,582 - mmdet - INFO - Epoch [6][3250/3517]	lr: 1.358e-04, eta: 0:08:28, time: 1.891, data_time: 0.066, memory: 32518, loss_cls: 0.0843, loss_bbox: 0.2232, d0.loss_cls: 0.1782, d0.loss_bbox: 0.3354, d1.loss_cls: 0.1465, d1.loss_bbox: 0.2513, d2.loss_cls: 0.1316, d2.loss_bbox: 0.2421, d3.loss_cls: 0.1117, d3.loss_bbox: 0.2399, d4.loss_cls: 0.0988, d4.loss_bbox: 0.2319, loss: 2.2750, grad_norm: 12.3865
2025-06-12 02:05:53,177 - mmdet - INFO - Epoch [6][3300/3517]	lr: 1.358e-04, eta: 0:06:52, time: 1.932, data_time: 0.067, memory: 32518, loss_cls: 0.0830, loss_bbox: 0.2148, d0.loss_cls: 0.1758, d0.loss_bbox: 0.3292, d1.loss_cls: 0.1467, d1.loss_bbox: 0.2439, d2.loss_cls: 0.1309, d2.loss_bbox: 0.2346, d3.loss_cls: 0.1100, d3.loss_bbox: 0.2321, d4.loss_cls: 0.0952, d4.loss_bbox: 0.2258, loss: 2.2221, grad_norm: 12.0599
2025-06-12 02:07:29,907 - mmdet - INFO - Epoch [6][3350/3517]	lr: 1.358e-04, eta: 0:05:17, time: 1.935, data_time: 0.070, memory: 32518, loss_cls: 0.0881, loss_bbox: 0.2219, d0.loss_cls: 0.1802, d0.loss_bbox: 0.3369, d1.loss_cls: 0.1472, d1.loss_bbox: 0.2521, d2.loss_cls: 0.1317, d2.loss_bbox: 0.2429, d3.loss_cls: 0.1127, d3.loss_bbox: 0.2406, d4.loss_cls: 0.1004, d4.loss_bbox: 0.2313, loss: 2.2861, grad_norm: 13.1070
2025-06-12 02:09:05,948 - mmdet - INFO - Epoch [6][3400/3517]	lr: 1.358e-04, eta: 0:03:42, time: 1.921, data_time: 0.063, memory: 32518, loss_cls: 0.0848, loss_bbox: 0.2152, d0.loss_cls: 0.1703, d0.loss_bbox: 0.3266, d1.loss_cls: 0.1430, d1.loss_bbox: 0.2440, d2.loss_cls: 0.1285, d2.loss_bbox: 0.2352, d3.loss_cls: 0.1101, d3.loss_bbox: 0.2316, d4.loss_cls: 0.0973, d4.loss_bbox: 0.2247, loss: 2.2112, grad_norm: 14.7156
2025-06-12 02:10:40,451 - mmdet - INFO - Epoch [6][3450/3517]	lr: 1.358e-04, eta: 0:02:07, time: 1.890, data_time: 0.063, memory: 32518, loss_cls: 0.0861, loss_bbox: 0.2168, d0.loss_cls: 0.1754, d0.loss_bbox: 0.3348, d1.loss_cls: 0.1481, d1.loss_bbox: 0.2457, d2.loss_cls: 0.1327, d2.loss_bbox: 0.2355, d3.loss_cls: 0.1125, d3.loss_bbox: 0.2326, d4.loss_cls: 0.0984, d4.loss_bbox: 0.2266, loss: 2.2453, grad_norm: 11.1110
2025-06-12 02:12:16,072 - mmdet - INFO - Epoch [6][3500/3517]	lr: 1.358e-04, eta: 0:00:32, time: 1.912, data_time: 0.067, memory: 32518, loss_cls: 0.0866, loss_bbox: 0.2255, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3463, d1.loss_cls: 0.1444, d1.loss_bbox: 0.2558, d2.loss_cls: 0.1300, d2.loss_bbox: 0.2447, d3.loss_cls: 0.1110, d3.loss_bbox: 0.2412, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2365, loss: 2.2966, grad_norm: 14.7370
2025-06-12 02:12:48,329 - mmdet - INFO - Saving checkpoint at 6 epochs
2025-06-12 02:37:37,338 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-12 02:37:37,338 - mmdet - INFO - Epoch(val) [6][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7856, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8767, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9052, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9194, pts_bbox_NuScenes/car_trans_err: 0.1801, pts_bbox_NuScenes/car_scale_err: 0.1490, pts_bbox_NuScenes/car_orient_err: 0.0477, pts_bbox_NuScenes/car_vel_err: 0.2887, pts_bbox_NuScenes/car_attr_err: 0.1807, pts_bbox_NuScenes/mATE: 0.2915, pts_bbox_NuScenes/mASE: 0.2612, pts_bbox_NuScenes/mAOE: 0.2656, pts_bbox_NuScenes/mAVE: 0.2831, pts_bbox_NuScenes/mAAE: 0.1887, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4147, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6100, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7071, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7446, pts_bbox_NuScenes/truck_trans_err: 0.3381, pts_bbox_NuScenes/truck_scale_err: 0.1923, pts_bbox_NuScenes/truck_orient_err: 0.0561, pts_bbox_NuScenes/truck_vel_err: 0.2809, pts_bbox_NuScenes/truck_attr_err: 0.2175, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0585, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2016, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4075, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4806, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6576, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4334, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8078, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1154, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3050, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5150, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7414, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8959, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9234, pts_bbox_NuScenes/bus_trans_err: 0.3336, pts_bbox_NuScenes/bus_scale_err: 0.1903, pts_bbox_NuScenes/bus_orient_err: 0.0309, pts_bbox_NuScenes/bus_vel_err: 0.4672, pts_bbox_NuScenes/bus_attr_err: 0.2786, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1644, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4373, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5874, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6650, pts_bbox_NuScenes/trailer_trans_err: 0.4925, pts_bbox_NuScenes/trailer_scale_err: 0.2253, pts_bbox_NuScenes/trailer_orient_err: 0.5038, pts_bbox_NuScenes/trailer_vel_err: 0.2242, pts_bbox_NuScenes/trailer_attr_err: 0.1756, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5778, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6763, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7262, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7429, pts_bbox_NuScenes/barrier_trans_err: 0.2202, pts_bbox_NuScenes/barrier_scale_err: 0.2853, pts_bbox_NuScenes/barrier_orient_err: 0.0751, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6246, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7629, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.8023, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8099, pts_bbox_NuScenes/motorcycle_trans_err: 0.2235, pts_bbox_NuScenes/motorcycle_scale_err: 0.2478, pts_bbox_NuScenes/motorcycle_orient_err: 0.2305, pts_bbox_NuScenes/motorcycle_vel_err: 0.4584, pts_bbox_NuScenes/motorcycle_attr_err: 0.2373, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5435, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5912, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6041, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6112, pts_bbox_NuScenes/bicycle_trans_err: 0.1747, pts_bbox_NuScenes/bicycle_scale_err: 0.2727, pts_bbox_NuScenes/bicycle_orient_err: 0.3173, pts_bbox_NuScenes/bicycle_vel_err: 0.2063, pts_bbox_NuScenes/bicycle_attr_err: 0.0076, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8014, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8481, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8716, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8853, pts_bbox_NuScenes/pedestrian_trans_err: 0.1549, pts_bbox_NuScenes/pedestrian_scale_err: 0.2927, pts_bbox_NuScenes/pedestrian_orient_err: 0.3212, pts_bbox_NuScenes/pedestrian_vel_err: 0.2235, pts_bbox_NuScenes/pedestrian_attr_err: 0.1073, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7152, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7571, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7826, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8071, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1395, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3236, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7033, pts_bbox_NuScenes/mAP: 0.6646
