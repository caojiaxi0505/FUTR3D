2025-06-10 22:42:33,681 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0+cu116
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0+cu116
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+unknown
spconv2.0: True
------------------------------------------------------------

2025-06-10 22:42:34,392 - mmdet - INFO - 分布式训练: True
2025-06-10 22:42:35,100 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['points', 'img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/fuse_4095'
load_from = 'pretrained/hedres_forced.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_grid_mask=True,
    freeze_backbone=True,
    img_backbone=dict(
        type='ResNet',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN2d', requires_grad=False),
        norm_eval=True,
        style='caffe',
        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),
        stage_with_dcn=(False, False, True, True)),
    img_neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_output',
        num_outs=4,
        relu_before_extra_convs=True),
    pts_voxel_layer=dict(
        max_num_points=-1,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(-1, -1),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(
        type='DynamicVFE',
        in_channels=5,
        feat_channels=[64, 128],
        with_distance=False,
        with_cluster_center=True,
        with_voxel_center=True,
        voxel_size=[0.075, 0.075, 0.2],
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_middle_encoder=dict(
        type='HEDNet',
        in_channels=128,
        sparse_shape=[41, 1440, 1440],
        model_cfg=dict(
            FEATURE_DIM=128,
            NUM_LAYERS=2,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDE=[1, 2, 2],
            DOWN_KERNEL_SIZE=[3, 3, 3])),
    pts_backbone=dict(
        type='CascadeDEDBackbone',
        in_channels=256,
        model_cfg=dict(
            USE_SECONDMAMBA=False,
            FEATURE_DIM=256,
            NUM_LAYERS=4,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDES=[1, 2, 2])),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        dss_date_version='0511',
        dss_drop_prob=0.3,
        dss_mamba_version='DSSMamba_Huge_EP2',
        dss_num_layers=2,
        dss_use_morton=True,
        dss_use_conv=True,
        dss_use_xy=True,
        dss_use_rope=True,
        dss_stack=True,
        dss_strong_cls=True,
        anchor_size=3,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='FUTR3DAttention',
                            use_lidar=True,
                            use_camera=True,
                            use_radar=False,
                            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
db_sampler = dict(
    data_root='data/nuscenes/',
    info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
    rate=1.0,
    prepare=dict(
        filter_by_difficulty=[-1],
        filter_by_min_points=dict(
            car=5,
            truck=5,
            bus=5,
            trailer=5,
            construction_vehicle=5,
            traffic_cone=5,
            barrier=5,
            motorcycle=5,
            bicycle=5,
            pedestrian=5)),
    classes=[
        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
    ],
    sample_groups=dict(
        car=2,
        truck=3,
        construction_vehicle=7,
        bus=4,
        trailer=6,
        barrier=2,
        motorcycle=6,
        bicycle=6,
        pedestrian=2,
        traffic_cone=2),
    points_loader=dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk')))
find_unused_parameters = True
runner = dict(type='EpochBasedRunner', max_epochs=6)
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    paramwise_cfg=dict(
        custom_keys=dict(
            img_backbone=dict(lr_mult=0.1),
            img_neck=dict(lr_mult=0.1),
            pts_middle_encoder=dict(lr_mult=0.1),
            pts_backbone=dict(lr_mult=0.1),
            pts_neck=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
gpu_ids = range(0, 2)

2025-06-10 22:42:35,101 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-06-10 22:42:37,203 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-06-10 22:42:37,468 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2025-06-10 22:42:37,559 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,560 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,560 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,561 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,561 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,561 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,562 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,562 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,565 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,567 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,569 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,571 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,573 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,576 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,578 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,580 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,582 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,584 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,586 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,588 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,590 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,593 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,595 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,597 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,599 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,601 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,603 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,606 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,608 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,610 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,619 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,628 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,636 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-06-10 22:42:37,658 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_voxel_encoder.vfe_layers.0.0.weight - torch.Size([64, 11]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.0.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.0.weight - torch.Size([16, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.0.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.0.weight - torch.Size([32, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.3.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.0.weight - torch.Size([64, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.0.weight - torch.Size([128, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.3.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.1.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer1.2.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

img_backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.1.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.2.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer2.3.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

img_backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.0.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.1.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.1.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.2.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.2.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.3.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.3.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.3.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.4.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.4.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.4.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.5.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.5.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.5.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.6.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.6.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.6.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.6.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.6.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.7.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.7.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.7.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.7.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.7.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.8.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.8.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.8.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.8.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.8.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.9.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.9.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.9.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.9.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.9.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.10.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.10.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.10.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.10.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.10.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.11.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.11.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.11.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.11.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.11.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.12.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.12.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.12.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.12.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.12.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.13.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.13.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.13.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.13.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.13.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.14.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.14.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.14.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.14.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.14.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.15.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.15.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.15.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.15.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.15.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.16.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.16.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.16.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.16.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.16.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.17.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.17.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.17.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.17.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.17.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.18.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.18.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.18.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.18.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.18.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.19.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.19.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.19.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.19.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.19.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.20.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.20.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.20.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.20.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.20.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.21.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.21.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.21.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.21.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.21.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.22.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.22.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer3.22.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer3.22.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

img_backbone.layer3.22.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.0.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.1.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.1.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.2.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  

img_backbone.layer4.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

img_backbone.layer4.2.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

img_backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-06-10 22:42:37,680 - mmdet - INFO - Model:
FUTR3D(
  (grid_mask): GridMask()
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=-1, max_voxels=(-1, -1), deterministic=True)
  (pts_voxel_encoder): DynamicVFE(
    (scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
    (vfe_layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=11, out_features=64, bias=False)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (vfe_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=False)
    (cluster_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
  )
  (pts_middle_encoder): HEDNet(
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SubMConv3d(128, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (3): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv2): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv3): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[1, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (layers): ModuleList(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (4): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU()
    )
  )
  (pts_backbone): CascadeDEDBackbone(
    (layers): ModuleList(
      (0): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (2): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (3): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=24, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=512, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (1): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (2): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (3): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (4): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (5): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
)
2025-06-10 22:44:30,549 - mmdet - INFO - load checkpoint from local path: pretrained/hedres_forced.pth
2025-06-10 22:44:48,069 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.code_weights, pts_bbox_head.query_embedding.weight, pts_bbox_head.aux_head.shared_conv.conv.weight, pts_bbox_head.aux_head.shared_conv.bn.weight, pts_bbox_head.aux_head.shared_conv.bn.bias, pts_bbox_head.aux_head.shared_conv.bn.running_mean, pts_bbox_head.aux_head.shared_conv.bn.running_var, pts_bbox_head.aux_head.shared_conv.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.1.weight, pts_bbox_head.aux_head.task_heads.0.reg.1.bias, pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.height.1.weight, pts_bbox_head.aux_head.task_heads.0.height.1.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.dim.1.weight, pts_bbox_head.aux_head.task_heads.0.dim.1.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.rot.1.weight, pts_bbox_head.aux_head.task_heads.0.rot.1.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.vel.1.weight, pts_bbox_head.aux_head.task_heads.0.vel.1.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.reg.1.weight, pts_bbox_head.aux_head.task_heads.1.reg.1.bias, pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.height.1.weight, pts_bbox_head.aux_head.task_heads.1.height.1.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.dim.1.weight, pts_bbox_head.aux_head.task_heads.1.dim.1.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.rot.1.weight, pts_bbox_head.aux_head.task_heads.1.rot.1.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.vel.1.weight, pts_bbox_head.aux_head.task_heads.1.vel.1.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.reg.1.weight, pts_bbox_head.aux_head.task_heads.2.reg.1.bias, pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.height.1.weight, pts_bbox_head.aux_head.task_heads.2.height.1.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.dim.1.weight, pts_bbox_head.aux_head.task_heads.2.dim.1.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.rot.1.weight, pts_bbox_head.aux_head.task_heads.2.rot.1.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.vel.1.weight, pts_bbox_head.aux_head.task_heads.2.vel.1.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.reg.1.weight, pts_bbox_head.aux_head.task_heads.3.reg.1.bias, pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.height.1.weight, pts_bbox_head.aux_head.task_heads.3.height.1.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.dim.1.weight, pts_bbox_head.aux_head.task_heads.3.dim.1.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.rot.1.weight, pts_bbox_head.aux_head.task_heads.3.rot.1.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.vel.1.weight, pts_bbox_head.aux_head.task_heads.3.vel.1.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.reg.1.weight, pts_bbox_head.aux_head.task_heads.4.reg.1.bias, pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.height.1.weight, pts_bbox_head.aux_head.task_heads.4.height.1.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.dim.1.weight, pts_bbox_head.aux_head.task_heads.4.dim.1.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.rot.1.weight, pts_bbox_head.aux_head.task_heads.4.rot.1.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.vel.1.weight, pts_bbox_head.aux_head.task_heads.4.vel.1.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.reg.1.weight, pts_bbox_head.aux_head.task_heads.5.reg.1.bias, pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.height.1.weight, pts_bbox_head.aux_head.task_heads.5.height.1.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.dim.1.weight, pts_bbox_head.aux_head.task_heads.5.dim.1.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.rot.1.weight, pts_bbox_head.aux_head.task_heads.5.rot.1.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.vel.1.weight, pts_bbox_head.aux_head.task_heads.5.vel.1.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.sin_cached, pts_bbox_head.cls_branches.0.0.weight, pts_bbox_head.cls_branches.0.0.bias, pts_bbox_head.cls_branches.0.1.weight, pts_bbox_head.cls_branches.0.1.bias, pts_bbox_head.cls_branches.0.3.weight, pts_bbox_head.cls_branches.0.3.bias, pts_bbox_head.cls_branches.0.4.weight, pts_bbox_head.cls_branches.0.4.bias, pts_bbox_head.cls_branches.0.6.weight, pts_bbox_head.cls_branches.0.6.bias, pts_bbox_head.cls_branches.1.0.weight, pts_bbox_head.cls_branches.1.0.bias, pts_bbox_head.cls_branches.1.1.weight, pts_bbox_head.cls_branches.1.1.bias, pts_bbox_head.cls_branches.1.3.weight, pts_bbox_head.cls_branches.1.3.bias, pts_bbox_head.cls_branches.1.4.weight, pts_bbox_head.cls_branches.1.4.bias, pts_bbox_head.cls_branches.1.6.weight, pts_bbox_head.cls_branches.1.6.bias, pts_bbox_head.cls_branches.2.0.weight, pts_bbox_head.cls_branches.2.0.bias, pts_bbox_head.cls_branches.2.1.weight, pts_bbox_head.cls_branches.2.1.bias, pts_bbox_head.cls_branches.2.3.weight, pts_bbox_head.cls_branches.2.3.bias, pts_bbox_head.cls_branches.2.4.weight, pts_bbox_head.cls_branches.2.4.bias, pts_bbox_head.cls_branches.2.6.weight, pts_bbox_head.cls_branches.2.6.bias, pts_bbox_head.cls_branches.3.0.weight, pts_bbox_head.cls_branches.3.0.bias, pts_bbox_head.cls_branches.3.1.weight, pts_bbox_head.cls_branches.3.1.bias, pts_bbox_head.cls_branches.3.3.weight, pts_bbox_head.cls_branches.3.3.bias, pts_bbox_head.cls_branches.3.4.weight, pts_bbox_head.cls_branches.3.4.bias, pts_bbox_head.cls_branches.3.6.weight, pts_bbox_head.cls_branches.3.6.bias, pts_bbox_head.cls_branches.4.0.weight, pts_bbox_head.cls_branches.4.0.bias, pts_bbox_head.cls_branches.4.1.weight, pts_bbox_head.cls_branches.4.1.bias, pts_bbox_head.cls_branches.4.3.weight, pts_bbox_head.cls_branches.4.3.bias, pts_bbox_head.cls_branches.4.4.weight, pts_bbox_head.cls_branches.4.4.bias, pts_bbox_head.cls_branches.4.6.weight, pts_bbox_head.cls_branches.4.6.bias, pts_bbox_head.cls_branches.5.0.weight, pts_bbox_head.cls_branches.5.0.bias, pts_bbox_head.cls_branches.5.1.weight, pts_bbox_head.cls_branches.5.1.bias, pts_bbox_head.cls_branches.5.3.weight, pts_bbox_head.cls_branches.5.3.bias, pts_bbox_head.cls_branches.5.4.weight, pts_bbox_head.cls_branches.5.4.bias, pts_bbox_head.cls_branches.5.6.weight, pts_bbox_head.cls_branches.5.6.bias

missing keys in source state_dict: pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias

2025-06-10 22:44:48,081 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/fuse_4095
2025-06-10 22:44:48,082 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-06-10 22:44:48,082 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-06-10 22:44:48,083 - mmdet - INFO - Checkpoints will be saved to /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4/fuse_4095 by HardDiskBackend.
2025-06-10 22:46:49,213 - mmdet - INFO - Epoch [1][50/3517]	lr: 7.973e-05, eta: 13:59:11, time: 2.392, data_time: 0.229, memory: 30457, loss_cls: 0.9958, loss_bbox: 1.4258, d0.loss_cls: 0.9928, d0.loss_bbox: 1.4918, d1.loss_cls: 1.0150, d1.loss_bbox: 1.4541, d2.loss_cls: 0.9269, d2.loss_bbox: 1.4119, d3.loss_cls: 0.9165, d3.loss_bbox: 1.4228, d4.loss_cls: 0.9230, d4.loss_bbox: 1.3910, loss: 14.3674, grad_norm: 11.0934
2025-06-10 22:48:32,661 - mmdet - INFO - Epoch [1][100/3517]	lr: 9.307e-05, eta: 13:00:37, time: 2.069, data_time: 0.189, memory: 30826, loss_cls: 0.7171, loss_bbox: 1.1216, d0.loss_cls: 0.8163, d0.loss_bbox: 1.2651, d1.loss_cls: 0.7498, d1.loss_bbox: 1.1861, d2.loss_cls: 0.7238, d2.loss_bbox: 1.1520, d3.loss_cls: 0.7196, d3.loss_bbox: 1.1430, d4.loss_cls: 0.7065, d4.loss_bbox: 1.1247, loss: 11.4256, grad_norm: 7.9693
2025-06-10 22:50:06,581 - mmdet - INFO - Epoch [1][150/3517]	lr: 1.064e-04, eta: 12:17:51, time: 1.879, data_time: 0.062, memory: 30826, loss_cls: 0.6121, loss_bbox: 1.0525, d0.loss_cls: 0.7319, d0.loss_bbox: 1.2141, d1.loss_cls: 0.6594, d1.loss_bbox: 1.1226, d2.loss_cls: 0.6459, d2.loss_bbox: 1.0892, d3.loss_cls: 0.6344, d3.loss_bbox: 1.0751, d4.loss_cls: 0.6058, d4.loss_bbox: 1.0663, loss: 10.5092, grad_norm: 7.3354
2025-06-10 22:51:40,506 - mmdet - INFO - Epoch [1][200/3517]	lr: 1.197e-04, eta: 11:55:40, time: 1.878, data_time: 0.059, memory: 30895, loss_cls: 0.5305, loss_bbox: 0.9927, d0.loss_cls: 0.6618, d0.loss_bbox: 1.1469, d1.loss_cls: 0.5885, d1.loss_bbox: 1.0564, d2.loss_cls: 0.5809, d2.loss_bbox: 1.0169, d3.loss_cls: 0.5644, d3.loss_bbox: 1.0112, d4.loss_cls: 0.5289, d4.loss_bbox: 1.0017, loss: 9.6809, grad_norm: 7.1086
2025-06-10 22:53:14,534 - mmdet - INFO - Epoch [1][250/3517]	lr: 1.331e-04, eta: 11:41:53, time: 1.881, data_time: 0.061, memory: 30895, loss_cls: 0.5004, loss_bbox: 0.9985, d0.loss_cls: 0.6470, d0.loss_bbox: 1.1567, d1.loss_cls: 0.5628, d1.loss_bbox: 1.0596, d2.loss_cls: 0.5542, d2.loss_bbox: 1.0155, d3.loss_cls: 0.5346, d3.loss_bbox: 1.0161, d4.loss_cls: 0.4985, d4.loss_bbox: 1.0094, loss: 9.5532, grad_norm: 7.7281
2025-06-10 22:54:48,050 - mmdet - INFO - Epoch [1][300/3517]	lr: 1.464e-04, eta: 11:31:33, time: 1.870, data_time: 0.058, memory: 31070, loss_cls: 0.4378, loss_bbox: 0.9445, d0.loss_cls: 0.5828, d0.loss_bbox: 1.1151, d1.loss_cls: 0.4942, d1.loss_bbox: 1.0028, d2.loss_cls: 0.4798, d2.loss_bbox: 0.9627, d3.loss_cls: 0.4665, d3.loss_bbox: 0.9527, d4.loss_cls: 0.4340, d4.loss_bbox: 0.9464, loss: 8.8193, grad_norm: 7.9585
2025-06-10 22:56:22,167 - mmdet - INFO - Epoch [1][350/3517]	lr: 1.597e-04, eta: 11:24:21, time: 1.882, data_time: 0.059, memory: 31070, loss_cls: 0.4083, loss_bbox: 0.9202, d0.loss_cls: 0.5565, d0.loss_bbox: 1.1086, d1.loss_cls: 0.4576, d1.loss_bbox: 0.9891, d2.loss_cls: 0.4441, d2.loss_bbox: 0.9422, d3.loss_cls: 0.4322, d3.loss_bbox: 0.9282, d4.loss_cls: 0.4069, d4.loss_bbox: 0.9199, loss: 8.5138, grad_norm: 8.4877
2025-06-10 22:57:56,517 - mmdet - INFO - Epoch [1][400/3517]	lr: 1.731e-04, eta: 11:18:44, time: 1.887, data_time: 0.054, memory: 31244, loss_cls: 0.3779, loss_bbox: 0.8676, d0.loss_cls: 0.5270, d0.loss_bbox: 1.0891, d1.loss_cls: 0.4161, d1.loss_bbox: 0.9553, d2.loss_cls: 0.4020, d2.loss_bbox: 0.9028, d3.loss_cls: 0.3889, d3.loss_bbox: 0.8840, d4.loss_cls: 0.3786, d4.loss_bbox: 0.8654, loss: 8.0548, grad_norm: 9.3705
2025-06-10 22:59:36,849 - mmdet - INFO - Epoch [1][450/3517]	lr: 1.864e-04, eta: 11:18:37, time: 2.007, data_time: 0.058, memory: 31244, loss_cls: 0.3350, loss_bbox: 0.8584, d0.loss_cls: 0.5279, d0.loss_bbox: 1.0734, d1.loss_cls: 0.3556, d1.loss_bbox: 0.9316, d2.loss_cls: 0.3405, d2.loss_bbox: 0.8745, d3.loss_cls: 0.3296, d3.loss_bbox: 0.8557, d4.loss_cls: 0.3292, d4.loss_bbox: 0.8490, loss: 7.6604, grad_norm: 10.3234
2025-06-10 23:01:10,246 - mmdet - INFO - Epoch [1][500/3517]	lr: 1.997e-04, eta: 11:13:25, time: 1.868, data_time: 0.067, memory: 31244, loss_cls: 0.2809, loss_bbox: 0.8018, d0.loss_cls: 0.4921, d0.loss_bbox: 1.0521, d1.loss_cls: 0.3109, d1.loss_bbox: 0.8528, d2.loss_cls: 0.2899, d2.loss_bbox: 0.7894, d3.loss_cls: 0.2747, d3.loss_bbox: 0.7806, d4.loss_cls: 0.2746, d4.loss_bbox: 0.7794, loss: 6.9792, grad_norm: 12.3201
2025-06-10 23:02:44,529 - mmdet - INFO - Epoch [1][550/3517]	lr: 2.000e-04, eta: 11:09:25, time: 1.886, data_time: 0.073, memory: 31264, loss_cls: 0.2492, loss_bbox: 0.6949, d0.loss_cls: 0.4636, d0.loss_bbox: 1.0280, d1.loss_cls: 0.2984, d1.loss_bbox: 0.7262, d2.loss_cls: 0.2589, d2.loss_bbox: 0.6709, d3.loss_cls: 0.2451, d3.loss_bbox: 0.6679, d4.loss_cls: 0.2475, d4.loss_bbox: 0.6727, loss: 6.2233, grad_norm: 13.3419
2025-06-10 23:04:18,277 - mmdet - INFO - Epoch [1][600/3517]	lr: 2.000e-04, eta: 11:05:32, time: 1.875, data_time: 0.063, memory: 31547, loss_cls: 0.2227, loss_bbox: 0.5873, d0.loss_cls: 0.4185, d0.loss_bbox: 0.9664, d1.loss_cls: 0.3001, d1.loss_bbox: 0.5616, d2.loss_cls: 0.2423, d2.loss_bbox: 0.5346, d3.loss_cls: 0.2216, d3.loss_bbox: 0.5440, d4.loss_cls: 0.2171, d4.loss_bbox: 0.5588, loss: 5.3749, grad_norm: 18.5863
2025-06-10 23:05:51,879 - mmdet - INFO - Epoch [1][650/3517]	lr: 2.000e-04, eta: 11:01:55, time: 1.872, data_time: 0.058, memory: 31547, loss_cls: 0.1943, loss_bbox: 0.5210, d0.loss_cls: 0.3861, d0.loss_bbox: 0.8977, d1.loss_cls: 0.2715, d1.loss_bbox: 0.4782, d2.loss_cls: 0.2136, d2.loss_bbox: 0.4662, d3.loss_cls: 0.1931, d3.loss_bbox: 0.4849, d4.loss_cls: 0.1879, d4.loss_bbox: 0.4992, loss: 4.7935, grad_norm: 23.3274
2025-06-10 23:07:25,175 - mmdet - INFO - Epoch [1][700/3517]	lr: 2.000e-04, eta: 10:58:28, time: 1.866, data_time: 0.057, memory: 31547, loss_cls: 0.1877, loss_bbox: 0.4528, d0.loss_cls: 0.3125, d0.loss_bbox: 0.7592, d1.loss_cls: 0.2524, d1.loss_bbox: 0.4221, d2.loss_cls: 0.2023, d2.loss_bbox: 0.4129, d3.loss_cls: 0.1843, d3.loss_bbox: 0.4276, d4.loss_cls: 0.1857, d4.loss_bbox: 0.4365, loss: 4.2360, grad_norm: 16.5275
2025-06-10 23:08:58,875 - mmdet - INFO - Epoch [1][750/3517]	lr: 2.000e-04, eta: 10:55:26, time: 1.874, data_time: 0.054, memory: 31547, loss_cls: 0.1641, loss_bbox: 0.4113, d0.loss_cls: 0.2515, d0.loss_bbox: 0.6017, d1.loss_cls: 0.2154, d1.loss_bbox: 0.3820, d2.loss_cls: 0.1748, d2.loss_bbox: 0.3735, d3.loss_cls: 0.1616, d3.loss_bbox: 0.3840, d4.loss_cls: 0.1592, d4.loss_bbox: 0.3966, loss: 3.6756, grad_norm: 23.8731
2025-06-10 23:10:32,261 - mmdet - INFO - Epoch [1][800/3517]	lr: 2.000e-04, eta: 10:52:27, time: 1.868, data_time: 0.054, memory: 31547, loss_cls: 0.1540, loss_bbox: 0.3901, d0.loss_cls: 0.2395, d0.loss_bbox: 0.5159, d1.loss_cls: 0.1946, d1.loss_bbox: 0.3587, d2.loss_cls: 0.1614, d2.loss_bbox: 0.3479, d3.loss_cls: 0.1494, d3.loss_bbox: 0.3579, d4.loss_cls: 0.1512, d4.loss_bbox: 0.3705, loss: 3.3910, grad_norm: 26.1241
2025-06-10 23:12:05,749 - mmdet - INFO - Epoch [1][850/3517]	lr: 2.000e-04, eta: 10:49:41, time: 1.870, data_time: 0.055, memory: 31547, loss_cls: 0.1475, loss_bbox: 0.3729, d0.loss_cls: 0.2401, d0.loss_bbox: 0.5061, d1.loss_cls: 0.1877, d1.loss_bbox: 0.3586, d2.loss_cls: 0.1584, d2.loss_bbox: 0.3449, d3.loss_cls: 0.1473, d3.loss_bbox: 0.3533, d4.loss_cls: 0.1449, d4.loss_bbox: 0.3616, loss: 3.3231, grad_norm: 127.5758
2025-06-10 23:13:39,071 - mmdet - INFO - Epoch [1][900/3517]	lr: 2.000e-04, eta: 10:46:59, time: 1.866, data_time: 0.055, memory: 31547, loss_cls: 0.1442, loss_bbox: 0.3590, d0.loss_cls: 0.2286, d0.loss_bbox: 0.4822, d1.loss_cls: 0.1801, d1.loss_bbox: 0.3386, d2.loss_cls: 0.1521, d2.loss_bbox: 0.3317, d3.loss_cls: 0.1437, d3.loss_bbox: 0.3406, d4.loss_cls: 0.1413, d4.loss_bbox: 0.3478, loss: 3.1902, grad_norm: 27.0857
2025-06-10 23:15:12,859 - mmdet - INFO - Epoch [1][950/3517]	lr: 2.000e-04, eta: 10:44:35, time: 1.876, data_time: 0.058, memory: 31547, loss_cls: 0.1372, loss_bbox: 0.3552, d0.loss_cls: 0.2226, d0.loss_bbox: 0.4756, d1.loss_cls: 0.1742, d1.loss_bbox: 0.3404, d2.loss_cls: 0.1442, d2.loss_bbox: 0.3284, d3.loss_cls: 0.1354, d3.loss_bbox: 0.3360, d4.loss_cls: 0.1348, d4.loss_bbox: 0.3431, loss: 3.1272, grad_norm: 30.2056
2025-06-10 23:16:45,878 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-10 23:16:45,879 - mmdet - INFO - Epoch [1][1000/3517]	lr: 2.000e-04, eta: 10:42:00, time: 1.860, data_time: 0.057, memory: 31547, loss_cls: 0.1293, loss_bbox: 0.3407, d0.loss_cls: 0.2156, d0.loss_bbox: 0.4489, d1.loss_cls: 0.1632, d1.loss_bbox: 0.3261, d2.loss_cls: 0.1384, d2.loss_bbox: 0.3162, d3.loss_cls: 0.1295, d3.loss_bbox: 0.3227, d4.loss_cls: 0.1283, d4.loss_bbox: 0.3296, loss: 2.9885, grad_norm: 30.7364
2025-06-10 23:18:20,040 - mmdet - INFO - Epoch [1][1050/3517]	lr: 2.000e-04, eta: 10:39:52, time: 1.883, data_time: 0.060, memory: 31547, loss_cls: 0.1286, loss_bbox: 0.3636, d0.loss_cls: 0.2171, d0.loss_bbox: 0.4631, d1.loss_cls: 0.1627, d1.loss_bbox: 0.3305, d2.loss_cls: 0.1409, d2.loss_bbox: 0.3202, d3.loss_cls: 0.1302, d3.loss_bbox: 0.3325, d4.loss_cls: 0.1276, d4.loss_bbox: 0.3460, loss: 3.0630, grad_norm: 24.8813
2025-06-10 23:19:54,833 - mmdet - INFO - Epoch [1][1100/3517]	lr: 2.000e-04, eta: 10:37:59, time: 1.896, data_time: 0.071, memory: 31547, loss_cls: 0.1177, loss_bbox: 0.3352, d0.loss_cls: 0.2066, d0.loss_bbox: 0.4327, d1.loss_cls: 0.1511, d1.loss_bbox: 0.3123, d2.loss_cls: 0.1235, d2.loss_bbox: 0.3036, d3.loss_cls: 0.1194, d3.loss_bbox: 0.3101, d4.loss_cls: 0.1161, d4.loss_bbox: 0.3197, loss: 2.8480, grad_norm: 25.2045
2025-06-10 23:21:28,726 - mmdet - INFO - Epoch [1][1150/3517]	lr: 2.000e-04, eta: 10:35:53, time: 1.878, data_time: 0.055, memory: 31547, loss_cls: 0.1247, loss_bbox: 0.3448, d0.loss_cls: 0.2081, d0.loss_bbox: 0.4366, d1.loss_cls: 0.1545, d1.loss_bbox: 0.3196, d2.loss_cls: 0.1335, d2.loss_bbox: 0.3105, d3.loss_cls: 0.1259, d3.loss_bbox: 0.3199, d4.loss_cls: 0.1225, d4.loss_bbox: 0.3298, loss: 2.9306, grad_norm: 26.9879
2025-06-10 23:23:02,750 - mmdet - INFO - Epoch [1][1200/3517]	lr: 2.000e-04, eta: 10:33:51, time: 1.881, data_time: 0.058, memory: 31547, loss_cls: 0.1167, loss_bbox: 0.3367, d0.loss_cls: 0.2094, d0.loss_bbox: 0.4392, d1.loss_cls: 0.1542, d1.loss_bbox: 0.3222, d2.loss_cls: 0.1291, d2.loss_bbox: 0.3108, d3.loss_cls: 0.1188, d3.loss_bbox: 0.3165, d4.loss_cls: 0.1164, d4.loss_bbox: 0.3240, loss: 2.8940, grad_norm: 24.5044
2025-06-10 23:24:36,546 - mmdet - INFO - Epoch [1][1250/3517]	lr: 2.000e-04, eta: 10:31:47, time: 1.876, data_time: 0.056, memory: 31547, loss_cls: 0.1269, loss_bbox: 0.3304, d0.loss_cls: 0.2215, d0.loss_bbox: 0.4557, d1.loss_cls: 0.1655, d1.loss_bbox: 0.3198, d2.loss_cls: 0.1348, d2.loss_bbox: 0.3101, d3.loss_cls: 0.1264, d3.loss_bbox: 0.3163, d4.loss_cls: 0.1264, d4.loss_bbox: 0.3211, loss: 2.9549, grad_norm: 27.9444
2025-06-10 23:26:10,858 - mmdet - INFO - Epoch [1][1300/3517]	lr: 2.000e-04, eta: 10:29:54, time: 1.886, data_time: 0.057, memory: 32518, loss_cls: 0.1258, loss_bbox: 0.3168, d0.loss_cls: 0.2120, d0.loss_bbox: 0.4340, d1.loss_cls: 0.1612, d1.loss_bbox: 0.3132, d2.loss_cls: 0.1324, d2.loss_bbox: 0.3002, d3.loss_cls: 0.1244, d3.loss_bbox: 0.3042, d4.loss_cls: 0.1256, d4.loss_bbox: 0.3059, loss: 2.8556, grad_norm: 23.9093
2025-06-10 23:27:45,018 - mmdet - INFO - Epoch [1][1350/3517]	lr: 2.000e-04, eta: 10:28:00, time: 1.883, data_time: 0.059, memory: 32518, loss_cls: 0.1174, loss_bbox: 0.3339, d0.loss_cls: 0.2104, d0.loss_bbox: 0.4295, d1.loss_cls: 0.1577, d1.loss_bbox: 0.3133, d2.loss_cls: 0.1326, d2.loss_bbox: 0.3069, d3.loss_cls: 0.1204, d3.loss_bbox: 0.3141, d4.loss_cls: 0.1174, d4.loss_bbox: 0.3212, loss: 2.8748, grad_norm: 25.7552
2025-06-10 23:29:18,398 - mmdet - INFO - Epoch [1][1400/3517]	lr: 2.000e-04, eta: 10:25:57, time: 1.868, data_time: 0.055, memory: 32518, loss_cls: 0.1082, loss_bbox: 0.3240, d0.loss_cls: 0.2033, d0.loss_bbox: 0.4201, d1.loss_cls: 0.1452, d1.loss_bbox: 0.3083, d2.loss_cls: 0.1209, d2.loss_bbox: 0.2974, d3.loss_cls: 0.1125, d3.loss_bbox: 0.3048, d4.loss_cls: 0.1082, d4.loss_bbox: 0.3118, loss: 2.7647, grad_norm: 24.8449
2025-06-10 23:30:52,369 - mmdet - INFO - Epoch [1][1450/3517]	lr: 2.000e-04, eta: 10:24:03, time: 1.879, data_time: 0.052, memory: 32518, loss_cls: 0.1187, loss_bbox: 0.3121, d0.loss_cls: 0.2001, d0.loss_bbox: 0.4051, d1.loss_cls: 0.1430, d1.loss_bbox: 0.2981, d2.loss_cls: 0.1237, d2.loss_bbox: 0.2892, d3.loss_cls: 0.1169, d3.loss_bbox: 0.2957, d4.loss_cls: 0.1171, d4.loss_bbox: 0.3022, loss: 2.7218, grad_norm: 21.0237
2025-06-10 23:32:25,897 - mmdet - INFO - Epoch [1][1500/3517]	lr: 2.000e-04, eta: 10:22:05, time: 1.871, data_time: 0.054, memory: 32518, loss_cls: 0.1097, loss_bbox: 0.2983, d0.loss_cls: 0.2038, d0.loss_bbox: 0.3925, d1.loss_cls: 0.1410, d1.loss_bbox: 0.2883, d2.loss_cls: 0.1182, d2.loss_bbox: 0.2792, d3.loss_cls: 0.1089, d3.loss_bbox: 0.2849, d4.loss_cls: 0.1089, d4.loss_bbox: 0.2892, loss: 2.6228, grad_norm: 100.6409
2025-06-10 23:33:59,373 - mmdet - INFO - Epoch [1][1550/3517]	lr: 2.000e-04, eta: 10:20:08, time: 1.869, data_time: 0.050, memory: 32518, loss_cls: 0.1168, loss_bbox: 0.3087, d0.loss_cls: 0.2061, d0.loss_bbox: 0.4153, d1.loss_cls: 0.1476, d1.loss_bbox: 0.3003, d2.loss_cls: 0.1245, d2.loss_bbox: 0.2892, d3.loss_cls: 0.1178, d3.loss_bbox: 0.2942, d4.loss_cls: 0.1161, d4.loss_bbox: 0.2994, loss: 2.7359, grad_norm: 37.4285
2025-06-10 23:35:31,931 - mmdet - INFO - Epoch [1][1600/3517]	lr: 2.000e-04, eta: 10:18:01, time: 1.851, data_time: 0.055, memory: 32518, loss_cls: 0.1121, loss_bbox: 0.3089, d0.loss_cls: 0.2111, d0.loss_bbox: 0.4224, d1.loss_cls: 0.1506, d1.loss_bbox: 0.2938, d2.loss_cls: 0.1235, d2.loss_bbox: 0.2833, d3.loss_cls: 0.1131, d3.loss_bbox: 0.2886, d4.loss_cls: 0.1104, d4.loss_bbox: 0.2966, loss: 2.7143, grad_norm: 42.5289
2025-06-10 23:37:04,636 - mmdet - INFO - Epoch [1][1650/3517]	lr: 2.000e-04, eta: 10:15:58, time: 1.854, data_time: 0.052, memory: 32518, loss_cls: 0.1065, loss_bbox: 0.3066, d0.loss_cls: 0.2009, d0.loss_bbox: 0.4095, d1.loss_cls: 0.1436, d1.loss_bbox: 0.2940, d2.loss_cls: 0.1184, d2.loss_bbox: 0.2815, d3.loss_cls: 0.1101, d3.loss_bbox: 0.2875, d4.loss_cls: 0.1063, d4.loss_bbox: 0.2947, loss: 2.6598, grad_norm: 48.2071
2025-06-10 23:38:37,404 - mmdet - INFO - Epoch [1][1700/3517]	lr: 2.000e-04, eta: 10:13:58, time: 1.855, data_time: 0.057, memory: 32518, loss_cls: 0.1056, loss_bbox: 0.3023, d0.loss_cls: 0.2012, d0.loss_bbox: 0.4096, d1.loss_cls: 0.1423, d1.loss_bbox: 0.2942, d2.loss_cls: 0.1176, d2.loss_bbox: 0.2798, d3.loss_cls: 0.1069, d3.loss_bbox: 0.2838, d4.loss_cls: 0.1038, d4.loss_bbox: 0.2901, loss: 2.6372, grad_norm: 48.7634
2025-06-10 23:40:10,779 - mmdet - INFO - Epoch [1][1750/3517]	lr: 2.000e-04, eta: 10:12:06, time: 1.867, data_time: 0.053, memory: 32518, loss_cls: 0.1039, loss_bbox: 0.3025, d0.loss_cls: 0.1941, d0.loss_bbox: 0.3965, d1.loss_cls: 0.1374, d1.loss_bbox: 0.2868, d2.loss_cls: 0.1162, d2.loss_bbox: 0.2758, d3.loss_cls: 0.1062, d3.loss_bbox: 0.2820, d4.loss_cls: 0.1035, d4.loss_bbox: 0.2893, loss: 2.5941, grad_norm: 24.6426
2025-06-10 23:41:44,803 - mmdet - INFO - Epoch [1][1800/3517]	lr: 2.000e-04, eta: 10:10:21, time: 1.881, data_time: 0.054, memory: 32518, loss_cls: 0.1057, loss_bbox: 0.2973, d0.loss_cls: 0.1919, d0.loss_bbox: 0.3860, d1.loss_cls: 0.1316, d1.loss_bbox: 0.2860, d2.loss_cls: 0.1134, d2.loss_bbox: 0.2756, d3.loss_cls: 0.1060, d3.loss_bbox: 0.2816, d4.loss_cls: 0.1044, d4.loss_bbox: 0.2877, loss: 2.5672, grad_norm: 26.5623
2025-06-10 23:43:19,079 - mmdet - INFO - Epoch [1][1850/3517]	lr: 2.000e-04, eta: 10:08:40, time: 1.885, data_time: 0.052, memory: 32518, loss_cls: 0.1031, loss_bbox: 0.2962, d0.loss_cls: 0.1895, d0.loss_bbox: 0.3737, d1.loss_cls: 0.1343, d1.loss_bbox: 0.2790, d2.loss_cls: 0.1098, d2.loss_bbox: 0.2732, d3.loss_cls: 0.1033, d3.loss_bbox: 0.2765, d4.loss_cls: 0.1018, d4.loss_bbox: 0.2845, loss: 2.5250, grad_norm: 26.1900
2025-06-10 23:44:53,130 - mmdet - INFO - Epoch [1][1900/3517]	lr: 2.000e-04, eta: 10:06:57, time: 1.881, data_time: 0.054, memory: 32518, loss_cls: 0.1082, loss_bbox: 0.3063, d0.loss_cls: 0.2005, d0.loss_bbox: 0.3895, d1.loss_cls: 0.1442, d1.loss_bbox: 0.2892, d2.loss_cls: 0.1192, d2.loss_bbox: 0.2796, d3.loss_cls: 0.1093, d3.loss_bbox: 0.2866, d4.loss_cls: 0.1077, d4.loss_bbox: 0.2938, loss: 2.6341, grad_norm: 23.1804
2025-06-10 23:46:27,077 - mmdet - INFO - Epoch [1][1950/3517]	lr: 2.000e-04, eta: 10:05:14, time: 1.879, data_time: 0.052, memory: 32518, loss_cls: 0.1052, loss_bbox: 0.2985, d0.loss_cls: 0.2013, d0.loss_bbox: 0.3988, d1.loss_cls: 0.1363, d1.loss_bbox: 0.2967, d2.loss_cls: 0.1137, d2.loss_bbox: 0.2825, d3.loss_cls: 0.1058, d3.loss_bbox: 0.2855, d4.loss_cls: 0.1028, d4.loss_bbox: 0.2905, loss: 2.6175, grad_norm: 38.3338
2025-06-10 23:48:00,742 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-10 23:48:00,742 - mmdet - INFO - Epoch [1][2000/3517]	lr: 2.000e-04, eta: 10:03:28, time: 1.873, data_time: 0.051, memory: 32518, loss_cls: 0.0986, loss_bbox: 0.3003, d0.loss_cls: 0.1891, d0.loss_bbox: 0.3900, d1.loss_cls: 0.1285, d1.loss_bbox: 0.2844, d2.loss_cls: 0.1072, d2.loss_bbox: 0.2746, d3.loss_cls: 0.0983, d3.loss_bbox: 0.2819, d4.loss_cls: 0.0970, d4.loss_bbox: 0.2885, loss: 2.5384, grad_norm: 37.1660
2025-06-10 23:49:35,432 - mmdet - INFO - Epoch [1][2050/3517]	lr: 2.000e-04, eta: 10:01:53, time: 1.894, data_time: 0.059, memory: 32518, loss_cls: 0.1074, loss_bbox: 0.2975, d0.loss_cls: 0.1974, d0.loss_bbox: 0.3888, d1.loss_cls: 0.1365, d1.loss_bbox: 0.2908, d2.loss_cls: 0.1157, d2.loss_bbox: 0.2810, d3.loss_cls: 0.1076, d3.loss_bbox: 0.2858, d4.loss_cls: 0.1066, d4.loss_bbox: 0.2898, loss: 2.6050, grad_norm: 42.3192
2025-06-10 23:51:09,226 - mmdet - INFO - Epoch [1][2100/3517]	lr: 2.000e-04, eta: 10:00:09, time: 1.876, data_time: 0.053, memory: 32518, loss_cls: 0.1102, loss_bbox: 0.3002, d0.loss_cls: 0.1984, d0.loss_bbox: 0.4006, d1.loss_cls: 0.1393, d1.loss_bbox: 0.2944, d2.loss_cls: 0.1197, d2.loss_bbox: 0.2786, d3.loss_cls: 0.1121, d3.loss_bbox: 0.2817, d4.loss_cls: 0.1102, d4.loss_bbox: 0.2879, loss: 2.6332, grad_norm: 34.8324
2025-06-10 23:52:43,405 - mmdet - INFO - Epoch [1][2150/3517]	lr: 2.000e-04, eta: 9:58:29, time: 1.884, data_time: 0.052, memory: 32518, loss_cls: 0.1036, loss_bbox: 0.2937, d0.loss_cls: 0.1942, d0.loss_bbox: 0.3863, d1.loss_cls: 0.1326, d1.loss_bbox: 0.2881, d2.loss_cls: 0.1102, d2.loss_bbox: 0.2767, d3.loss_cls: 0.1032, d3.loss_bbox: 0.2806, d4.loss_cls: 0.1020, d4.loss_bbox: 0.2843, loss: 2.5553, grad_norm: 22.8971
2025-06-10 23:54:17,746 - mmdet - INFO - Epoch [1][2200/3517]	lr: 2.000e-04, eta: 9:56:51, time: 1.887, data_time: 0.052, memory: 32518, loss_cls: 0.0959, loss_bbox: 0.2909, d0.loss_cls: 0.1930, d0.loss_bbox: 0.3813, d1.loss_cls: 0.1270, d1.loss_bbox: 0.2840, d2.loss_cls: 0.1089, d2.loss_bbox: 0.2712, d3.loss_cls: 0.1003, d3.loss_bbox: 0.2744, d4.loss_cls: 0.0965, d4.loss_bbox: 0.2807, loss: 2.5041, grad_norm: 21.4806
2025-06-10 23:55:52,004 - mmdet - INFO - Epoch [1][2250/3517]	lr: 2.000e-04, eta: 9:55:12, time: 1.885, data_time: 0.052, memory: 32518, loss_cls: 0.1003, loss_bbox: 0.2891, d0.loss_cls: 0.1904, d0.loss_bbox: 0.3733, d1.loss_cls: 0.1307, d1.loss_bbox: 0.2782, d2.loss_cls: 0.1099, d2.loss_bbox: 0.2678, d3.loss_cls: 0.1020, d3.loss_bbox: 0.2724, d4.loss_cls: 0.0999, d4.loss_bbox: 0.2786, loss: 2.4926, grad_norm: 38.0876
2025-06-10 23:57:29,279 - mmdet - INFO - Epoch [1][2300/3517]	lr: 2.000e-04, eta: 9:53:59, time: 1.945, data_time: 0.051, memory: 32518, loss_cls: 0.0999, loss_bbox: 0.2933, d0.loss_cls: 0.1871, d0.loss_bbox: 0.3822, d1.loss_cls: 0.1271, d1.loss_bbox: 0.2845, d2.loss_cls: 0.1074, d2.loss_bbox: 0.2719, d3.loss_cls: 0.1000, d3.loss_bbox: 0.2764, d4.loss_cls: 0.0990, d4.loss_bbox: 0.2820, loss: 2.5108, grad_norm: 33.4015
2025-06-10 23:59:03,635 - mmdet - INFO - Epoch [1][2350/3517]	lr: 2.000e-04, eta: 9:52:20, time: 1.887, data_time: 0.057, memory: 32518, loss_cls: 0.1039, loss_bbox: 0.2837, d0.loss_cls: 0.2010, d0.loss_bbox: 0.3872, d1.loss_cls: 0.1395, d1.loss_bbox: 0.2792, d2.loss_cls: 0.1163, d2.loss_bbox: 0.2645, d3.loss_cls: 0.1064, d3.loss_bbox: 0.2692, d4.loss_cls: 0.1040, d4.loss_bbox: 0.2731, loss: 2.5280, grad_norm: 40.2234
2025-06-11 00:00:40,812 - mmdet - INFO - Epoch [1][2400/3517]	lr: 2.000e-04, eta: 9:51:04, time: 1.944, data_time: 0.063, memory: 32518, loss_cls: 0.0993, loss_bbox: 0.2984, d0.loss_cls: 0.1945, d0.loss_bbox: 0.3912, d1.loss_cls: 0.1415, d1.loss_bbox: 0.2863, d2.loss_cls: 0.1127, d2.loss_bbox: 0.2737, d3.loss_cls: 0.1014, d3.loss_bbox: 0.2807, d4.loss_cls: 0.1001, d4.loss_bbox: 0.2871, loss: 2.5670, grad_norm: 32.6467
2025-06-11 00:02:14,887 - mmdet - INFO - Epoch [1][2450/3517]	lr: 2.000e-04, eta: 9:49:24, time: 1.881, data_time: 0.054, memory: 32518, loss_cls: 0.1055, loss_bbox: 0.2911, d0.loss_cls: 0.1977, d0.loss_bbox: 0.3840, d1.loss_cls: 0.1382, d1.loss_bbox: 0.2919, d2.loss_cls: 0.1167, d2.loss_bbox: 0.2784, d3.loss_cls: 0.1074, d3.loss_bbox: 0.2802, d4.loss_cls: 0.1032, d4.loss_bbox: 0.2838, loss: 2.5779, grad_norm: 37.1140
2025-06-11 00:03:48,250 - mmdet - INFO - Epoch [1][2500/3517]	lr: 2.000e-04, eta: 9:47:38, time: 1.867, data_time: 0.054, memory: 32518, loss_cls: 0.0974, loss_bbox: 0.2868, d0.loss_cls: 0.1914, d0.loss_bbox: 0.3752, d1.loss_cls: 0.1307, d1.loss_bbox: 0.2849, d2.loss_cls: 0.1102, d2.loss_bbox: 0.2700, d3.loss_cls: 0.1011, d3.loss_bbox: 0.2710, d4.loss_cls: 0.0973, d4.loss_bbox: 0.2755, loss: 2.4915, grad_norm: 28.4941
2025-06-11 00:05:21,802 - mmdet - INFO - Epoch [1][2550/3517]	lr: 2.000e-04, eta: 9:45:55, time: 1.871, data_time: 0.055, memory: 32518, loss_cls: 0.1030, loss_bbox: 0.2979, d0.loss_cls: 0.1915, d0.loss_bbox: 0.3918, d1.loss_cls: 0.1322, d1.loss_bbox: 0.2960, d2.loss_cls: 0.1132, d2.loss_bbox: 0.2801, d3.loss_cls: 0.1034, d3.loss_bbox: 0.2847, d4.loss_cls: 0.1027, d4.loss_bbox: 0.2887, loss: 2.5852, grad_norm: 406.0225
2025-06-11 00:06:56,281 - mmdet - INFO - Epoch [1][2600/3517]	lr: 2.000e-04, eta: 9:44:18, time: 1.889, data_time: 0.075, memory: 32518, loss_cls: 0.0977, loss_bbox: 0.2859, d0.loss_cls: 0.1979, d0.loss_bbox: 0.3794, d1.loss_cls: 0.1377, d1.loss_bbox: 0.2843, d2.loss_cls: 0.1103, d2.loss_bbox: 0.2702, d3.loss_cls: 0.0998, d3.loss_bbox: 0.2729, d4.loss_cls: 0.0978, d4.loss_bbox: 0.2758, loss: 2.5097, grad_norm: 28.9858
2025-06-11 00:08:30,328 - mmdet - INFO - Epoch [1][2650/3517]	lr: 2.000e-04, eta: 9:42:39, time: 1.881, data_time: 0.056, memory: 32518, loss_cls: 0.0968, loss_bbox: 0.2871, d0.loss_cls: 0.1929, d0.loss_bbox: 0.3725, d1.loss_cls: 0.1315, d1.loss_bbox: 0.2765, d2.loss_cls: 0.1110, d2.loss_bbox: 0.2646, d3.loss_cls: 0.1007, d3.loss_bbox: 0.2687, d4.loss_cls: 0.0973, d4.loss_bbox: 0.2749, loss: 2.4745, grad_norm: 63.0646
2025-06-11 00:10:04,321 - mmdet - INFO - Epoch [1][2700/3517]	lr: 2.000e-04, eta: 9:40:59, time: 1.880, data_time: 0.058, memory: 32518, loss_cls: 0.0997, loss_bbox: 0.2871, d0.loss_cls: 0.1913, d0.loss_bbox: 0.3703, d1.loss_cls: 0.1326, d1.loss_bbox: 0.2792, d2.loss_cls: 0.1096, d2.loss_bbox: 0.2664, d3.loss_cls: 0.1007, d3.loss_bbox: 0.2694, d4.loss_cls: 0.0989, d4.loss_bbox: 0.2757, loss: 2.4809, grad_norm: 19.3851
2025-06-11 00:11:37,601 - mmdet - INFO - Epoch [1][2750/3517]	lr: 2.000e-04, eta: 9:39:14, time: 1.866, data_time: 0.056, memory: 32518, loss_cls: 0.0971, loss_bbox: 0.2836, d0.loss_cls: 0.1919, d0.loss_bbox: 0.3742, d1.loss_cls: 0.1288, d1.loss_bbox: 0.2827, d2.loss_cls: 0.1094, d2.loss_bbox: 0.2685, d3.loss_cls: 0.1001, d3.loss_bbox: 0.2707, d4.loss_cls: 0.0971, d4.loss_bbox: 0.2754, loss: 2.4795, grad_norm: 33.7148
2025-06-11 00:13:12,193 - mmdet - INFO - Epoch [1][2800/3517]	lr: 2.000e-04, eta: 9:37:39, time: 1.892, data_time: 0.070, memory: 32518, loss_cls: 0.0927, loss_bbox: 0.2888, d0.loss_cls: 0.1847, d0.loss_bbox: 0.3691, d1.loss_cls: 0.1213, d1.loss_bbox: 0.2798, d2.loss_cls: 0.1031, d2.loss_bbox: 0.2671, d3.loss_cls: 0.0957, d3.loss_bbox: 0.2704, d4.loss_cls: 0.0925, d4.loss_bbox: 0.2774, loss: 2.4424, grad_norm: 18.2091
2025-06-11 00:14:45,746 - mmdet - INFO - Epoch [1][2850/3517]	lr: 2.000e-04, eta: 9:35:57, time: 1.871, data_time: 0.056, memory: 32518, loss_cls: 0.0972, loss_bbox: 0.2796, d0.loss_cls: 0.1874, d0.loss_bbox: 0.3747, d1.loss_cls: 0.1260, d1.loss_bbox: 0.2799, d2.loss_cls: 0.1070, d2.loss_bbox: 0.2659, d3.loss_cls: 0.0986, d3.loss_bbox: 0.2689, d4.loss_cls: 0.0970, d4.loss_bbox: 0.2715, loss: 2.4538, grad_norm: 47.0063
2025-06-11 00:17:10,935 - mmdet - INFO - Epoch [1][2900/3517]	lr: 2.000e-04, eta: 9:39:40, time: 2.904, data_time: 1.088, memory: 32518, loss_cls: 0.0968, loss_bbox: 0.2854, d0.loss_cls: 0.1888, d0.loss_bbox: 0.3768, d1.loss_cls: 0.1303, d1.loss_bbox: 0.2817, d2.loss_cls: 0.1076, d2.loss_bbox: 0.2694, d3.loss_cls: 0.0981, d3.loss_bbox: 0.2725, d4.loss_cls: 0.0969, d4.loss_bbox: 0.2768, loss: 2.4812, grad_norm: 21.9861
2025-06-11 00:18:45,435 - mmdet - INFO - Epoch [1][2950/3517]	lr: 2.000e-04, eta: 9:37:58, time: 1.890, data_time: 0.081, memory: 32518, loss_cls: 0.0975, loss_bbox: 0.2721, d0.loss_cls: 0.1848, d0.loss_bbox: 0.3672, d1.loss_cls: 0.1286, d1.loss_bbox: 0.2760, d2.loss_cls: 0.1076, d2.loss_bbox: 0.2603, d3.loss_cls: 0.0989, d3.loss_bbox: 0.2629, d4.loss_cls: 0.0977, d4.loss_bbox: 0.2635, loss: 2.4172, grad_norm: 38.7743
2025-06-11 00:20:18,602 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 00:20:18,602 - mmdet - INFO - Epoch [1][3000/3517]	lr: 2.000e-04, eta: 9:36:08, time: 1.863, data_time: 0.052, memory: 32518, loss_cls: 0.0915, loss_bbox: 0.2702, d0.loss_cls: 0.1842, d0.loss_bbox: 0.3695, d1.loss_cls: 0.1260, d1.loss_bbox: 0.2726, d2.loss_cls: 0.1060, d2.loss_bbox: 0.2595, d3.loss_cls: 0.0963, d3.loss_bbox: 0.2627, d4.loss_cls: 0.0930, d4.loss_bbox: 0.2635, loss: 2.3949, grad_norm: 19.7189
2025-06-11 00:21:51,823 - mmdet - INFO - Epoch [1][3050/3517]	lr: 2.000e-04, eta: 9:34:19, time: 1.864, data_time: 0.063, memory: 32518, loss_cls: 0.0976, loss_bbox: 0.2884, d0.loss_cls: 0.1870, d0.loss_bbox: 0.3776, d1.loss_cls: 0.1292, d1.loss_bbox: 0.2838, d2.loss_cls: 0.1101, d2.loss_bbox: 0.2708, d3.loss_cls: 0.1028, d3.loss_bbox: 0.2731, d4.loss_cls: 0.0983, d4.loss_bbox: 0.2786, loss: 2.4972, grad_norm: 62.2052
2025-06-11 00:23:25,293 - mmdet - INFO - Epoch [1][3100/3517]	lr: 2.000e-04, eta: 9:32:32, time: 1.869, data_time: 0.057, memory: 32518, loss_cls: 0.0891, loss_bbox: 0.2796, d0.loss_cls: 0.1788, d0.loss_bbox: 0.3675, d1.loss_cls: 0.1196, d1.loss_bbox: 0.2773, d2.loss_cls: 0.1013, d2.loss_bbox: 0.2622, d3.loss_cls: 0.0917, d3.loss_bbox: 0.2661, d4.loss_cls: 0.0892, d4.loss_bbox: 0.2708, loss: 2.3932, grad_norm: 22.8376
2025-06-11 00:24:57,908 - mmdet - INFO - Epoch [1][3150/3517]	lr: 2.000e-04, eta: 9:30:41, time: 1.852, data_time: 0.057, memory: 32518, loss_cls: 0.0958, loss_bbox: 0.2878, d0.loss_cls: 0.1871, d0.loss_bbox: 0.3752, d1.loss_cls: 0.1296, d1.loss_bbox: 0.2867, d2.loss_cls: 0.1092, d2.loss_bbox: 0.2725, d3.loss_cls: 0.0980, d3.loss_bbox: 0.2744, d4.loss_cls: 0.0967, d4.loss_bbox: 0.2788, loss: 2.4918, grad_norm: 41.6089
2025-06-11 00:26:30,672 - mmdet - INFO - Epoch [1][3200/3517]	lr: 2.000e-04, eta: 9:28:51, time: 1.855, data_time: 0.057, memory: 32518, loss_cls: 0.0941, loss_bbox: 0.2791, d0.loss_cls: 0.1873, d0.loss_bbox: 0.3748, d1.loss_cls: 0.1262, d1.loss_bbox: 0.2828, d2.loss_cls: 0.1075, d2.loss_bbox: 0.2650, d3.loss_cls: 0.0975, d3.loss_bbox: 0.2679, d4.loss_cls: 0.0954, d4.loss_bbox: 0.2708, loss: 2.4485, grad_norm: 21.1903
2025-06-11 00:28:03,298 - mmdet - INFO - Epoch [1][3250/3517]	lr: 2.000e-04, eta: 9:27:01, time: 1.853, data_time: 0.052, memory: 32518, loss_cls: 0.0981, loss_bbox: 0.2857, d0.loss_cls: 0.1886, d0.loss_bbox: 0.3773, d1.loss_cls: 0.1295, d1.loss_bbox: 0.2829, d2.loss_cls: 0.1068, d2.loss_bbox: 0.2691, d3.loss_cls: 0.1008, d3.loss_bbox: 0.2722, d4.loss_cls: 0.0985, d4.loss_bbox: 0.2769, loss: 2.4863, grad_norm: 27.3356
2025-06-11 00:29:36,656 - mmdet - INFO - Epoch [1][3300/3517]	lr: 2.000e-04, eta: 9:25:15, time: 1.867, data_time: 0.054, memory: 32518, loss_cls: 0.0949, loss_bbox: 0.2888, d0.loss_cls: 0.1854, d0.loss_bbox: 0.3841, d1.loss_cls: 0.1276, d1.loss_bbox: 0.2897, d2.loss_cls: 0.1080, d2.loss_bbox: 0.2741, d3.loss_cls: 0.0975, d3.loss_bbox: 0.2767, d4.loss_cls: 0.0950, d4.loss_bbox: 0.2808, loss: 2.5026, grad_norm: 53.3510
2025-06-11 00:31:09,553 - mmdet - INFO - Epoch [1][3350/3517]	lr: 2.000e-04, eta: 9:23:27, time: 1.858, data_time: 0.053, memory: 32518, loss_cls: 0.0990, loss_bbox: 0.2865, d0.loss_cls: 0.1856, d0.loss_bbox: 0.3770, d1.loss_cls: 0.1301, d1.loss_bbox: 0.2878, d2.loss_cls: 0.1104, d2.loss_bbox: 0.2738, d3.loss_cls: 0.0998, d3.loss_bbox: 0.2771, d4.loss_cls: 0.0983, d4.loss_bbox: 0.2789, loss: 2.5042, grad_norm: 32.8276
2025-06-11 00:32:42,716 - mmdet - INFO - Epoch [1][3400/3517]	lr: 2.000e-04, eta: 9:21:41, time: 1.863, data_time: 0.053, memory: 32518, loss_cls: 0.0897, loss_bbox: 0.2767, d0.loss_cls: 0.1908, d0.loss_bbox: 0.3758, d1.loss_cls: 0.1251, d1.loss_bbox: 0.2821, d2.loss_cls: 0.1053, d2.loss_bbox: 0.2648, d3.loss_cls: 0.0933, d3.loss_bbox: 0.2669, d4.loss_cls: 0.0918, d4.loss_bbox: 0.2681, loss: 2.4302, grad_norm: 23.5747
2025-06-11 00:34:16,379 - mmdet - INFO - Epoch [1][3450/3517]	lr: 2.000e-04, eta: 9:19:58, time: 1.873, data_time: 0.051, memory: 32518, loss_cls: 0.0961, loss_bbox: 0.2770, d0.loss_cls: 0.1927, d0.loss_bbox: 0.3777, d1.loss_cls: 0.1346, d1.loss_bbox: 0.2796, d2.loss_cls: 0.1091, d2.loss_bbox: 0.2639, d3.loss_cls: 0.0995, d3.loss_bbox: 0.2657, d4.loss_cls: 0.0964, d4.loss_bbox: 0.2683, loss: 2.4604, grad_norm: 107.2465
2025-06-11 00:35:50,271 - mmdet - INFO - Epoch [1][3500/3517]	lr: 2.000e-04, eta: 9:18:17, time: 1.878, data_time: 0.054, memory: 32518, loss_cls: 0.0996, loss_bbox: 0.2819, d0.loss_cls: 0.1929, d0.loss_bbox: 0.3819, d1.loss_cls: 0.1343, d1.loss_bbox: 0.2800, d2.loss_cls: 0.1123, d2.loss_bbox: 0.2648, d3.loss_cls: 0.1024, d3.loss_bbox: 0.2677, d4.loss_cls: 0.0993, d4.loss_bbox: 0.2711, loss: 2.4882, grad_norm: 99.1743
2025-06-11 00:36:22,020 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-06-11 01:03:00,928 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 01:03:00,928 - mmdet - INFO - Epoch(val) [1][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.5650, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8625, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9058, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9214, pts_bbox_NuScenes/car_trans_err: 0.3401, pts_bbox_NuScenes/car_scale_err: 0.1549, pts_bbox_NuScenes/car_orient_err: 0.0674, pts_bbox_NuScenes/car_vel_err: 0.4960, pts_bbox_NuScenes/car_attr_err: 0.1809, pts_bbox_NuScenes/mATE: 0.3933, pts_bbox_NuScenes/mASE: 0.2726, pts_bbox_NuScenes/mAOE: 0.2709, pts_bbox_NuScenes/mAVE: 0.4529, pts_bbox_NuScenes/mAAE: 0.1856, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.2975, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6118, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7248, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7654, pts_bbox_NuScenes/truck_trans_err: 0.4606, pts_bbox_NuScenes/truck_scale_err: 0.2142, pts_bbox_NuScenes/truck_orient_err: 0.0986, pts_bbox_NuScenes/truck_vel_err: 0.4789, pts_bbox_NuScenes/truck_attr_err: 0.2167, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0226, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1664, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3722, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4502, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.7596, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4532, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7743, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1291, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3181, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.3338, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7093, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8797, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9147, pts_bbox_NuScenes/bus_trans_err: 0.4605, pts_bbox_NuScenes/bus_scale_err: 0.2080, pts_bbox_NuScenes/bus_orient_err: 0.0595, pts_bbox_NuScenes/bus_vel_err: 0.7964, pts_bbox_NuScenes/bus_attr_err: 0.2822, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0860, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3663, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5777, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6615, pts_bbox_NuScenes/trailer_trans_err: 0.6188, pts_bbox_NuScenes/trailer_scale_err: 0.2382, pts_bbox_NuScenes/trailer_orient_err: 0.4330, pts_bbox_NuScenes/trailer_vel_err: 0.4366, pts_bbox_NuScenes/trailer_attr_err: 0.1391, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5452, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.6699, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7264, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7482, pts_bbox_NuScenes/barrier_trans_err: 0.2998, pts_bbox_NuScenes/barrier_scale_err: 0.2866, pts_bbox_NuScenes/barrier_orient_err: 0.0898, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.4508, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.6947, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7743, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7843, pts_bbox_NuScenes/motorcycle_trans_err: 0.3476, pts_bbox_NuScenes/motorcycle_scale_err: 0.2531, pts_bbox_NuScenes/motorcycle_orient_err: 0.2429, pts_bbox_NuScenes/motorcycle_vel_err: 0.7528, pts_bbox_NuScenes/motorcycle_attr_err: 0.2194, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.4852, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5665, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5794, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.5900, pts_bbox_NuScenes/bicycle_trans_err: 0.2516, pts_bbox_NuScenes/bicycle_scale_err: 0.2778, pts_bbox_NuScenes/bicycle_orient_err: 0.3393, pts_bbox_NuScenes/bicycle_vel_err: 0.2593, pts_bbox_NuScenes/bicycle_attr_err: 0.0046, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7746, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8395, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8670, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8806, pts_bbox_NuScenes/pedestrian_trans_err: 0.1884, pts_bbox_NuScenes/pedestrian_scale_err: 0.3032, pts_bbox_NuScenes/pedestrian_orient_err: 0.3336, pts_bbox_NuScenes/pedestrian_vel_err: 0.2742, pts_bbox_NuScenes/pedestrian_attr_err: 0.1235, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6772, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7374, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7734, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8042, pts_bbox_NuScenes/traffic_cone_trans_err: 0.2062, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3370, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6570, pts_bbox_NuScenes/mAP: 0.6291
2025-06-11 01:04:44,532 - mmdet - INFO - Epoch [2][50/3517]	lr: 1.866e-04, eta: 9:13:49, time: 1.980, data_time: 0.172, memory: 32518, loss_cls: 0.0950, loss_bbox: 0.2677, d0.loss_cls: 0.1929, d0.loss_bbox: 0.3697, d1.loss_cls: 0.1305, d1.loss_bbox: 0.2723, d2.loss_cls: 0.1090, d2.loss_bbox: 0.2572, d3.loss_cls: 0.0975, d3.loss_bbox: 0.2580, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2611, loss: 2.4060, grad_norm: 19.4372
2025-06-11 01:06:18,145 - mmdet - INFO - Epoch [2][100/3517]	lr: 1.866e-04, eta: 9:12:09, time: 1.872, data_time: 0.057, memory: 32518, loss_cls: 0.0965, loss_bbox: 0.2782, d0.loss_cls: 0.1819, d0.loss_bbox: 0.3715, d1.loss_cls: 0.1281, d1.loss_bbox: 0.2781, d2.loss_cls: 0.1078, d2.loss_bbox: 0.2643, d3.loss_cls: 0.0982, d3.loss_bbox: 0.2662, d4.loss_cls: 0.0967, d4.loss_bbox: 0.2689, loss: 2.4363, grad_norm: 32.5669
2025-06-11 01:07:52,107 - mmdet - INFO - Epoch [2][150/3517]	lr: 1.866e-04, eta: 9:10:30, time: 1.879, data_time: 0.064, memory: 32518, loss_cls: 0.0958, loss_bbox: 0.2712, d0.loss_cls: 0.1879, d0.loss_bbox: 0.3678, d1.loss_cls: 0.1304, d1.loss_bbox: 0.2727, d2.loss_cls: 0.1064, d2.loss_bbox: 0.2594, d3.loss_cls: 0.0977, d3.loss_bbox: 0.2621, d4.loss_cls: 0.0961, d4.loss_bbox: 0.2638, loss: 2.4114, grad_norm: 23.3306
2025-06-11 01:09:25,933 - mmdet - INFO - Epoch [2][200/3517]	lr: 1.866e-04, eta: 9:08:51, time: 1.877, data_time: 0.060, memory: 32518, loss_cls: 0.0941, loss_bbox: 0.2731, d0.loss_cls: 0.1886, d0.loss_bbox: 0.3691, d1.loss_cls: 0.1281, d1.loss_bbox: 0.2791, d2.loss_cls: 0.1033, d2.loss_bbox: 0.2622, d3.loss_cls: 0.0950, d3.loss_bbox: 0.2637, d4.loss_cls: 0.0941, d4.loss_bbox: 0.2653, loss: 2.4155, grad_norm: 45.6974
2025-06-11 01:10:59,870 - mmdet - INFO - Epoch [2][250/3517]	lr: 1.866e-04, eta: 9:07:13, time: 1.879, data_time: 0.061, memory: 32518, loss_cls: 0.0874, loss_bbox: 0.2701, d0.loss_cls: 0.1822, d0.loss_bbox: 0.3606, d1.loss_cls: 0.1178, d1.loss_bbox: 0.2703, d2.loss_cls: 0.0982, d2.loss_bbox: 0.2553, d3.loss_cls: 0.0885, d3.loss_bbox: 0.2598, d4.loss_cls: 0.0868, d4.loss_bbox: 0.2618, loss: 2.3388, grad_norm: 65.7834
2025-06-11 01:12:33,952 - mmdet - INFO - Epoch [2][300/3517]	lr: 1.866e-04, eta: 9:05:36, time: 1.882, data_time: 0.061, memory: 32518, loss_cls: 0.0920, loss_bbox: 0.2603, d0.loss_cls: 0.1867, d0.loss_bbox: 0.3700, d1.loss_cls: 0.1257, d1.loss_bbox: 0.2705, d2.loss_cls: 0.1022, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0940, d3.loss_bbox: 0.2545, d4.loss_cls: 0.0920, d4.loss_bbox: 0.2549, loss: 2.3583, grad_norm: 39.0539
2025-06-11 01:14:08,048 - mmdet - INFO - Epoch [2][350/3517]	lr: 1.866e-04, eta: 9:03:58, time: 1.882, data_time: 0.060, memory: 32518, loss_cls: 0.0895, loss_bbox: 0.2578, d0.loss_cls: 0.1862, d0.loss_bbox: 0.3595, d1.loss_cls: 0.1218, d1.loss_bbox: 0.2685, d2.loss_cls: 0.1010, d2.loss_bbox: 0.2509, d3.loss_cls: 0.0914, d3.loss_bbox: 0.2524, d4.loss_cls: 0.0904, d4.loss_bbox: 0.2510, loss: 2.3204, grad_norm: 25.5843
2025-06-11 01:15:42,669 - mmdet - INFO - Epoch [2][400/3517]	lr: 1.866e-04, eta: 9:02:23, time: 1.892, data_time: 0.060, memory: 32518, loss_cls: 0.0916, loss_bbox: 0.2646, d0.loss_cls: 0.1819, d0.loss_bbox: 0.3604, d1.loss_cls: 0.1214, d1.loss_bbox: 0.2687, d2.loss_cls: 0.1003, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0934, d3.loss_bbox: 0.2572, d4.loss_cls: 0.0924, d4.loss_bbox: 0.2580, loss: 2.3451, grad_norm: 110.0169
2025-06-11 01:17:20,329 - mmdet - INFO - Epoch [2][450/3517]	lr: 1.866e-04, eta: 9:01:01, time: 1.953, data_time: 0.065, memory: 32518, loss_cls: 0.0934, loss_bbox: 0.2534, d0.loss_cls: 0.1884, d0.loss_bbox: 0.3512, d1.loss_cls: 0.1251, d1.loss_bbox: 0.2630, d2.loss_cls: 0.1061, d2.loss_bbox: 0.2490, d3.loss_cls: 0.0953, d3.loss_bbox: 0.2502, d4.loss_cls: 0.0936, d4.loss_bbox: 0.2482, loss: 2.3170, grad_norm: 27.6707
2025-06-11 01:18:54,668 - mmdet - INFO - Epoch [2][500/3517]	lr: 1.866e-04, eta: 8:59:25, time: 1.887, data_time: 0.059, memory: 32518, loss_cls: 0.0859, loss_bbox: 0.2499, d0.loss_cls: 0.1834, d0.loss_bbox: 0.3554, d1.loss_cls: 0.1219, d1.loss_bbox: 0.2617, d2.loss_cls: 0.0999, d2.loss_bbox: 0.2449, d3.loss_cls: 0.0879, d3.loss_bbox: 0.2470, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2445, loss: 2.2680, grad_norm: 255.8687
2025-06-11 01:20:29,273 - mmdet - INFO - Epoch [2][550/3517]	lr: 1.866e-04, eta: 8:57:50, time: 1.892, data_time: 0.059, memory: 32518, loss_cls: 0.0893, loss_bbox: 0.2629, d0.loss_cls: 0.1810, d0.loss_bbox: 0.3618, d1.loss_cls: 0.1237, d1.loss_bbox: 0.2673, d2.loss_cls: 0.1028, d2.loss_bbox: 0.2520, d3.loss_cls: 0.0918, d3.loss_bbox: 0.2563, d4.loss_cls: 0.0893, d4.loss_bbox: 0.2549, loss: 2.3331, grad_norm: 26.3722
2025-06-11 01:22:03,537 - mmdet - INFO - Epoch [2][600/3517]	lr: 1.866e-04, eta: 8:56:13, time: 1.885, data_time: 0.056, memory: 32518, loss_cls: 0.0868, loss_bbox: 0.2557, d0.loss_cls: 0.1773, d0.loss_bbox: 0.3548, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2667, d2.loss_cls: 0.0994, d2.loss_bbox: 0.2506, d3.loss_cls: 0.0890, d3.loss_bbox: 0.2533, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2497, loss: 2.2886, grad_norm: 20.7978
2025-06-11 01:23:37,467 - mmdet - INFO - Epoch [2][650/3517]	lr: 1.866e-04, eta: 8:54:35, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0919, loss_bbox: 0.2561, d0.loss_cls: 0.1820, d0.loss_bbox: 0.3615, d1.loss_cls: 0.1227, d1.loss_bbox: 0.2697, d2.loss_cls: 0.1029, d2.loss_bbox: 0.2532, d3.loss_cls: 0.0945, d3.loss_bbox: 0.2544, d4.loss_cls: 0.0927, d4.loss_bbox: 0.2510, loss: 2.3326, grad_norm: 24.6597
2025-06-11 01:25:11,413 - mmdet - INFO - Epoch [2][700/3517]	lr: 1.866e-04, eta: 8:52:58, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0921, loss_bbox: 0.2572, d0.loss_cls: 0.1794, d0.loss_bbox: 0.3561, d1.loss_cls: 0.1223, d1.loss_bbox: 0.2667, d2.loss_cls: 0.1052, d2.loss_bbox: 0.2522, d3.loss_cls: 0.0959, d3.loss_bbox: 0.2553, d4.loss_cls: 0.0934, d4.loss_bbox: 0.2511, loss: 2.3269, grad_norm: 34.3434
2025-06-11 01:26:45,440 - mmdet - INFO - Epoch [2][750/3517]	lr: 1.866e-04, eta: 8:51:20, time: 1.881, data_time: 0.061, memory: 32518, loss_cls: 0.0869, loss_bbox: 0.2570, d0.loss_cls: 0.1835, d0.loss_bbox: 0.3613, d1.loss_cls: 0.1238, d1.loss_bbox: 0.2672, d2.loss_cls: 0.0993, d2.loss_bbox: 0.2543, d3.loss_cls: 0.0901, d3.loss_bbox: 0.2559, d4.loss_cls: 0.0874, d4.loss_bbox: 0.2515, loss: 2.3180, grad_norm: 53.9878
2025-06-11 01:28:19,585 - mmdet - INFO - Epoch [2][800/3517]	lr: 1.866e-04, eta: 8:49:44, time: 1.883, data_time: 0.059, memory: 32518, loss_cls: 0.0923, loss_bbox: 0.2590, d0.loss_cls: 0.1922, d0.loss_bbox: 0.3740, d1.loss_cls: 0.1304, d1.loss_bbox: 0.2769, d2.loss_cls: 0.1074, d2.loss_bbox: 0.2588, d3.loss_cls: 0.0964, d3.loss_bbox: 0.2577, d4.loss_cls: 0.0934, d4.loss_bbox: 0.2540, loss: 2.3925, grad_norm: 32.0004
2025-06-11 01:29:53,266 - mmdet - INFO - Epoch [2][850/3517]	lr: 1.866e-04, eta: 8:48:05, time: 1.874, data_time: 0.057, memory: 32518, loss_cls: 0.0863, loss_bbox: 0.2504, d0.loss_cls: 0.1834, d0.loss_bbox: 0.3570, d1.loss_cls: 0.1226, d1.loss_bbox: 0.2625, d2.loss_cls: 0.0999, d2.loss_bbox: 0.2477, d3.loss_cls: 0.0912, d3.loss_bbox: 0.2501, d4.loss_cls: 0.0878, d4.loss_bbox: 0.2454, loss: 2.2842, grad_norm: 36.0950
2025-06-11 01:31:26,657 - mmdet - INFO - Epoch [2][900/3517]	lr: 1.866e-04, eta: 8:46:26, time: 1.868, data_time: 0.058, memory: 32518, loss_cls: 0.0934, loss_bbox: 0.2484, d0.loss_cls: 0.1884, d0.loss_bbox: 0.3615, d1.loss_cls: 0.1350, d1.loss_bbox: 0.2636, d2.loss_cls: 0.1095, d2.loss_bbox: 0.2478, d3.loss_cls: 0.0963, d3.loss_bbox: 0.2489, d4.loss_cls: 0.0951, d4.loss_bbox: 0.2438, loss: 2.3317, grad_norm: 26.4329
2025-06-11 01:32:59,847 - mmdet - INFO - Epoch [2][950/3517]	lr: 1.866e-04, eta: 8:44:45, time: 1.864, data_time: 0.056, memory: 32518, loss_cls: 0.0812, loss_bbox: 0.2588, d0.loss_cls: 0.1845, d0.loss_bbox: 0.3615, d1.loss_cls: 0.1209, d1.loss_bbox: 0.2682, d2.loss_cls: 0.0954, d2.loss_bbox: 0.2520, d3.loss_cls: 0.0846, d3.loss_bbox: 0.2546, d4.loss_cls: 0.0820, d4.loss_bbox: 0.2505, loss: 2.2942, grad_norm: 20.3287
2025-06-11 01:34:33,142 - mmdet - INFO - Epoch [2][1000/3517]	lr: 1.866e-04, eta: 8:43:06, time: 1.866, data_time: 0.067, memory: 32518, loss_cls: 0.0876, loss_bbox: 0.2575, d0.loss_cls: 0.1927, d0.loss_bbox: 0.3603, d1.loss_cls: 0.1300, d1.loss_bbox: 0.2667, d2.loss_cls: 0.1035, d2.loss_bbox: 0.2509, d3.loss_cls: 0.0909, d3.loss_bbox: 0.2546, d4.loss_cls: 0.0882, d4.loss_bbox: 0.2518, loss: 2.3349, grad_norm: 45.3388
2025-06-11 01:36:06,221 - mmdet - INFO - Epoch [2][1050/3517]	lr: 1.866e-04, eta: 8:41:26, time: 1.862, data_time: 0.052, memory: 32518, loss_cls: 0.0906, loss_bbox: 0.2573, d0.loss_cls: 0.1916, d0.loss_bbox: 0.3714, d1.loss_cls: 0.1292, d1.loss_bbox: 0.2745, d2.loss_cls: 0.1083, d2.loss_bbox: 0.2544, d3.loss_cls: 0.0939, d3.loss_bbox: 0.2577, d4.loss_cls: 0.0914, d4.loss_bbox: 0.2508, loss: 2.3712, grad_norm: 30.6802
2025-06-11 01:37:39,005 - mmdet - INFO - Epoch [2][1100/3517]	lr: 1.866e-04, eta: 8:39:45, time: 1.856, data_time: 0.052, memory: 32518, loss_cls: 0.0853, loss_bbox: 0.2471, d0.loss_cls: 0.1784, d0.loss_bbox: 0.3551, d1.loss_cls: 0.1223, d1.loss_bbox: 0.2650, d2.loss_cls: 0.1011, d2.loss_bbox: 0.2463, d3.loss_cls: 0.0908, d3.loss_bbox: 0.2480, d4.loss_cls: 0.0875, d4.loss_bbox: 0.2419, loss: 2.2688, grad_norm: 27.3907
2025-06-11 01:39:12,206 - mmdet - INFO - Epoch [2][1150/3517]	lr: 1.866e-04, eta: 8:38:05, time: 1.864, data_time: 0.053, memory: 32518, loss_cls: 0.0896, loss_bbox: 0.2622, d0.loss_cls: 0.1838, d0.loss_bbox: 0.3637, d1.loss_cls: 0.1228, d1.loss_bbox: 0.2690, d2.loss_cls: 0.1047, d2.loss_bbox: 0.2551, d3.loss_cls: 0.0943, d3.loss_bbox: 0.2567, d4.loss_cls: 0.0921, d4.loss_bbox: 0.2535, loss: 2.3475, grad_norm: 23.8239
2025-06-11 01:40:45,923 - mmdet - INFO - Epoch [2][1200/3517]	lr: 1.866e-04, eta: 8:36:28, time: 1.874, data_time: 0.055, memory: 32518, loss_cls: 0.0863, loss_bbox: 0.2554, d0.loss_cls: 0.1849, d0.loss_bbox: 0.3606, d1.loss_cls: 0.1196, d1.loss_bbox: 0.2724, d2.loss_cls: 0.1003, d2.loss_bbox: 0.2543, d3.loss_cls: 0.0903, d3.loss_bbox: 0.2542, d4.loss_cls: 0.0869, d4.loss_bbox: 0.2495, loss: 2.3147, grad_norm: 24.6592
2025-06-11 01:42:19,093 - mmdet - INFO - Epoch [2][1250/3517]	lr: 1.866e-04, eta: 8:34:48, time: 1.863, data_time: 0.053, memory: 32518, loss_cls: 0.0903, loss_bbox: 0.2537, d0.loss_cls: 0.1859, d0.loss_bbox: 0.3593, d1.loss_cls: 0.1253, d1.loss_bbox: 0.2693, d2.loss_cls: 0.1044, d2.loss_bbox: 0.2533, d3.loss_cls: 0.0940, d3.loss_bbox: 0.2546, d4.loss_cls: 0.0917, d4.loss_bbox: 0.2489, loss: 2.3306, grad_norm: 23.4315
2025-06-11 01:43:52,588 - mmdet - INFO - Epoch [2][1300/3517]	lr: 1.866e-04, eta: 8:33:10, time: 1.870, data_time: 0.054, memory: 32518, loss_cls: 0.0891, loss_bbox: 0.2588, d0.loss_cls: 0.1833, d0.loss_bbox: 0.3614, d1.loss_cls: 0.1205, d1.loss_bbox: 0.2713, d2.loss_cls: 0.1023, d2.loss_bbox: 0.2554, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2587, d4.loss_cls: 0.0888, d4.loss_bbox: 0.2530, loss: 2.3336, grad_norm: 22.9182
2025-06-11 01:45:26,198 - mmdet - INFO - Epoch [2][1350/3517]	lr: 1.866e-04, eta: 8:31:32, time: 1.872, data_time: 0.055, memory: 32518, loss_cls: 0.0838, loss_bbox: 0.2511, d0.loss_cls: 0.1783, d0.loss_bbox: 0.3509, d1.loss_cls: 0.1155, d1.loss_bbox: 0.2652, d2.loss_cls: 0.0980, d2.loss_bbox: 0.2503, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2548, d4.loss_cls: 0.0846, d4.loss_bbox: 0.2465, loss: 2.2650, grad_norm: 27.5382
2025-06-11 01:46:59,857 - mmdet - INFO - Epoch [2][1400/3517]	lr: 1.866e-04, eta: 8:29:55, time: 1.873, data_time: 0.055, memory: 32518, loss_cls: 0.0869, loss_bbox: 0.2518, d0.loss_cls: 0.1811, d0.loss_bbox: 0.3590, d1.loss_cls: 0.1210, d1.loss_bbox: 0.2691, d2.loss_cls: 0.1028, d2.loss_bbox: 0.2516, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2547, d4.loss_cls: 0.0893, d4.loss_bbox: 0.2461, loss: 2.3043, grad_norm: 29.6980
2025-06-11 01:48:34,114 - mmdet - INFO - Epoch [2][1450/3517]	lr: 1.866e-04, eta: 8:28:20, time: 1.885, data_time: 0.058, memory: 32518, loss_cls: 0.0822, loss_bbox: 0.2474, d0.loss_cls: 0.1780, d0.loss_bbox: 0.3578, d1.loss_cls: 0.1182, d1.loss_bbox: 0.2657, d2.loss_cls: 0.0985, d2.loss_bbox: 0.2476, d3.loss_cls: 0.0872, d3.loss_bbox: 0.2493, d4.loss_cls: 0.0848, d4.loss_bbox: 0.2415, loss: 2.2581, grad_norm: 78.7446
2025-06-11 01:50:07,394 - mmdet - INFO - Epoch [2][1500/3517]	lr: 1.866e-04, eta: 8:26:41, time: 1.866, data_time: 0.055, memory: 32518, loss_cls: 0.0939, loss_bbox: 0.2472, d0.loss_cls: 0.1869, d0.loss_bbox: 0.3602, d1.loss_cls: 0.1291, d1.loss_bbox: 0.2718, d2.loss_cls: 0.1081, d2.loss_bbox: 0.2542, d3.loss_cls: 0.0989, d3.loss_bbox: 0.2551, d4.loss_cls: 0.0961, d4.loss_bbox: 0.2428, loss: 2.3445, grad_norm: 25.5553
2025-06-11 01:51:40,504 - mmdet - INFO - Epoch [2][1550/3517]	lr: 1.866e-04, eta: 8:25:02, time: 1.862, data_time: 0.050, memory: 32518, loss_cls: 0.0876, loss_bbox: 0.2463, d0.loss_cls: 0.1790, d0.loss_bbox: 0.3529, d1.loss_cls: 0.1223, d1.loss_bbox: 0.2724, d2.loss_cls: 0.1008, d2.loss_bbox: 0.2560, d3.loss_cls: 0.0910, d3.loss_bbox: 0.2573, d4.loss_cls: 0.0896, d4.loss_bbox: 0.2442, loss: 2.2991, grad_norm: 22.4605
2025-06-11 01:53:13,530 - mmdet - INFO - Epoch [2][1600/3517]	lr: 1.866e-04, eta: 8:23:23, time: 1.860, data_time: 0.054, memory: 32518, loss_cls: 0.0916, loss_bbox: 0.2494, d0.loss_cls: 0.1854, d0.loss_bbox: 0.3589, d1.loss_cls: 0.1217, d1.loss_bbox: 0.2762, d2.loss_cls: 0.1039, d2.loss_bbox: 0.2570, d3.loss_cls: 0.0938, d3.loss_bbox: 0.2569, d4.loss_cls: 0.0927, d4.loss_bbox: 0.2464, loss: 2.3338, grad_norm: 54.9662
2025-06-11 01:54:46,663 - mmdet - INFO - Epoch [2][1650/3517]	lr: 1.866e-04, eta: 8:21:45, time: 1.863, data_time: 0.049, memory: 32518, loss_cls: 0.0818, loss_bbox: 0.2363, d0.loss_cls: 0.1695, d0.loss_bbox: 0.3426, d1.loss_cls: 0.1152, d1.loss_bbox: 0.2592, d2.loss_cls: 0.0967, d2.loss_bbox: 0.2438, d3.loss_cls: 0.0856, d3.loss_bbox: 0.2465, d4.loss_cls: 0.0838, d4.loss_bbox: 0.2345, loss: 2.1956, grad_norm: 20.3163
2025-06-11 01:56:20,991 - mmdet - INFO - Epoch [2][1700/3517]	lr: 1.866e-04, eta: 8:20:10, time: 1.887, data_time: 0.055, memory: 32518, loss_cls: 0.0893, loss_bbox: 0.2456, d0.loss_cls: 0.1860, d0.loss_bbox: 0.3577, d1.loss_cls: 0.1206, d1.loss_bbox: 0.2720, d2.loss_cls: 0.1018, d2.loss_bbox: 0.2552, d3.loss_cls: 0.0931, d3.loss_bbox: 0.2550, d4.loss_cls: 0.0917, d4.loss_bbox: 0.2434, loss: 2.3113, grad_norm: 30.9773
2025-06-11 01:57:53,798 - mmdet - INFO - Epoch [2][1750/3517]	lr: 1.866e-04, eta: 8:18:30, time: 1.856, data_time: 0.052, memory: 32518, loss_cls: 0.0819, loss_bbox: 0.2364, d0.loss_cls: 0.1740, d0.loss_bbox: 0.3561, d1.loss_cls: 0.1147, d1.loss_bbox: 0.2643, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2483, d3.loss_cls: 0.0861, d3.loss_bbox: 0.2481, d4.loss_cls: 0.0837, d4.loss_bbox: 0.2346, loss: 2.2235, grad_norm: 35.8186
2025-06-11 01:59:26,526 - mmdet - INFO - Epoch [2][1800/3517]	lr: 1.866e-04, eta: 8:16:51, time: 1.855, data_time: 0.054, memory: 32518, loss_cls: 0.0838, loss_bbox: 0.2384, d0.loss_cls: 0.1785, d0.loss_bbox: 0.3547, d1.loss_cls: 0.1195, d1.loss_bbox: 0.2658, d2.loss_cls: 0.0990, d2.loss_bbox: 0.2524, d3.loss_cls: 0.0867, d3.loss_bbox: 0.2547, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2387, loss: 2.2579, grad_norm: 30.7702
2025-06-11 02:00:59,359 - mmdet - INFO - Epoch [2][1850/3517]	lr: 1.866e-04, eta: 8:15:12, time: 1.857, data_time: 0.049, memory: 32518, loss_cls: 0.0855, loss_bbox: 0.2424, d0.loss_cls: 0.1783, d0.loss_bbox: 0.3546, d1.loss_cls: 0.1216, d1.loss_bbox: 0.2698, d2.loss_cls: 0.1005, d2.loss_bbox: 0.2530, d3.loss_cls: 0.0899, d3.loss_bbox: 0.2538, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2410, loss: 2.2785, grad_norm: 25.3170
2025-06-11 02:02:32,088 - mmdet - INFO - Epoch [2][1900/3517]	lr: 1.866e-04, eta: 8:13:32, time: 1.855, data_time: 0.052, memory: 32518, loss_cls: 0.0825, loss_bbox: 0.2460, d0.loss_cls: 0.1788, d0.loss_bbox: 0.3608, d1.loss_cls: 0.1178, d1.loss_bbox: 0.2783, d2.loss_cls: 0.0985, d2.loss_bbox: 0.2611, d3.loss_cls: 0.0873, d3.loss_bbox: 0.2627, d4.loss_cls: 0.0843, d4.loss_bbox: 0.2454, loss: 2.3035, grad_norm: 31.6987
2025-06-11 02:04:21,141 - mmdet - INFO - Epoch [2][1950/3517]	lr: 1.866e-04, eta: 8:12:40, time: 2.181, data_time: 0.388, memory: 32518, loss_cls: 0.0795, loss_bbox: 0.2317, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3507, d1.loss_cls: 0.1148, d1.loss_bbox: 0.2614, d2.loss_cls: 0.0951, d2.loss_bbox: 0.2443, d3.loss_cls: 0.0840, d3.loss_bbox: 0.2442, d4.loss_cls: 0.0815, d4.loss_bbox: 0.2305, loss: 2.1913, grad_norm: 27.9946
2025-06-11 02:05:53,631 - mmdet - INFO - Epoch [2][2000/3517]	lr: 1.866e-04, eta: 8:11:00, time: 1.850, data_time: 0.054, memory: 32518, loss_cls: 0.0769, loss_bbox: 0.2288, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3462, d1.loss_cls: 0.1162, d1.loss_bbox: 0.2590, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2400, d3.loss_cls: 0.0816, d3.loss_bbox: 0.2401, d4.loss_cls: 0.0793, d4.loss_bbox: 0.2271, loss: 2.1657, grad_norm: 65.0239
2025-06-11 02:07:26,419 - mmdet - INFO - Epoch [2][2050/3517]	lr: 1.866e-04, eta: 8:09:20, time: 1.856, data_time: 0.056, memory: 32518, loss_cls: 0.0828, loss_bbox: 0.2371, d0.loss_cls: 0.1741, d0.loss_bbox: 0.3515, d1.loss_cls: 0.1156, d1.loss_bbox: 0.2647, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2487, d3.loss_cls: 0.0870, d3.loss_bbox: 0.2485, d4.loss_cls: 0.0844, d4.loss_bbox: 0.2353, loss: 2.2233, grad_norm: 297.0600
2025-06-11 02:08:59,034 - mmdet - INFO - Epoch [2][2100/3517]	lr: 1.866e-04, eta: 8:07:41, time: 1.852, data_time: 0.051, memory: 32518, loss_cls: 0.0890, loss_bbox: 0.2376, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3491, d1.loss_cls: 0.1213, d1.loss_bbox: 0.2633, d2.loss_cls: 0.1029, d2.loss_bbox: 0.2488, d3.loss_cls: 0.0925, d3.loss_bbox: 0.2499, d4.loss_cls: 0.0906, d4.loss_bbox: 0.2362, loss: 2.2574, grad_norm: 31.2547
2025-06-11 02:10:31,585 - mmdet - INFO - Epoch [2][2150/3517]	lr: 1.866e-04, eta: 8:06:01, time: 1.851, data_time: 0.053, memory: 32518, loss_cls: 0.0848, loss_bbox: 0.2325, d0.loss_cls: 0.1746, d0.loss_bbox: 0.3511, d1.loss_cls: 0.1163, d1.loss_bbox: 0.2616, d2.loss_cls: 0.0980, d2.loss_bbox: 0.2450, d3.loss_cls: 0.0875, d3.loss_bbox: 0.2451, d4.loss_cls: 0.0860, d4.loss_bbox: 0.2309, loss: 2.2135, grad_norm: 31.6520
2025-06-11 02:12:04,046 - mmdet - INFO - Epoch [2][2200/3517]	lr: 1.866e-04, eta: 8:04:21, time: 1.849, data_time: 0.053, memory: 32518, loss_cls: 0.0794, loss_bbox: 0.2422, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3574, d1.loss_cls: 0.1125, d1.loss_bbox: 0.2676, d2.loss_cls: 0.0928, d2.loss_bbox: 0.2538, d3.loss_cls: 0.0825, d3.loss_bbox: 0.2554, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2405, loss: 2.2385, grad_norm: 25.2389
2025-06-11 02:13:36,652 - mmdet - INFO - Epoch [2][2250/3517]	lr: 1.866e-04, eta: 8:02:42, time: 1.852, data_time: 0.056, memory: 32518, loss_cls: 0.0901, loss_bbox: 0.2420, d0.loss_cls: 0.1865, d0.loss_bbox: 0.3570, d1.loss_cls: 0.1243, d1.loss_bbox: 0.2706, d2.loss_cls: 0.1043, d2.loss_bbox: 0.2540, d3.loss_cls: 0.0935, d3.loss_bbox: 0.2553, d4.loss_cls: 0.0922, d4.loss_bbox: 0.2400, loss: 2.3099, grad_norm: 69.2938
2025-06-11 02:15:09,269 - mmdet - INFO - Epoch [2][2300/3517]	lr: 1.866e-04, eta: 8:01:02, time: 1.852, data_time: 0.051, memory: 32518, loss_cls: 0.0863, loss_bbox: 0.2331, d0.loss_cls: 0.1878, d0.loss_bbox: 0.3506, d1.loss_cls: 0.1209, d1.loss_bbox: 0.2634, d2.loss_cls: 0.1025, d2.loss_bbox: 0.2464, d3.loss_cls: 0.0908, d3.loss_bbox: 0.2467, d4.loss_cls: 0.0881, d4.loss_bbox: 0.2327, loss: 2.2495, grad_norm: 28.7214
2025-06-11 02:16:41,637 - mmdet - INFO - Epoch [2][2350/3517]	lr: 1.866e-04, eta: 7:59:23, time: 1.847, data_time: 0.050, memory: 32518, loss_cls: 0.0776, loss_bbox: 0.2248, d0.loss_cls: 0.1804, d0.loss_bbox: 0.3459, d1.loss_cls: 0.1202, d1.loss_bbox: 0.2568, d2.loss_cls: 0.0952, d2.loss_bbox: 0.2402, d3.loss_cls: 0.0845, d3.loss_bbox: 0.2380, d4.loss_cls: 0.0809, d4.loss_bbox: 0.2244, loss: 2.1688, grad_norm: 38.6100
2025-06-11 02:18:14,463 - mmdet - INFO - Epoch [2][2400/3517]	lr: 1.866e-04, eta: 7:57:44, time: 1.857, data_time: 0.053, memory: 32518, loss_cls: 0.0865, loss_bbox: 0.2287, d0.loss_cls: 0.1834, d0.loss_bbox: 0.3542, d1.loss_cls: 0.1267, d1.loss_bbox: 0.2624, d2.loss_cls: 0.1014, d2.loss_bbox: 0.2435, d3.loss_cls: 0.0901, d3.loss_bbox: 0.2429, d4.loss_cls: 0.0871, d4.loss_bbox: 0.2285, loss: 2.2353, grad_norm: 25.8723
2025-06-11 02:19:47,494 - mmdet - INFO - Epoch [2][2450/3517]	lr: 1.866e-04, eta: 7:56:06, time: 1.861, data_time: 0.053, memory: 32518, loss_cls: 0.0897, loss_bbox: 0.2340, d0.loss_cls: 0.1825, d0.loss_bbox: 0.3530, d1.loss_cls: 0.1256, d1.loss_bbox: 0.2618, d2.loss_cls: 0.1063, d2.loss_bbox: 0.2434, d3.loss_cls: 0.0958, d3.loss_bbox: 0.2455, d4.loss_cls: 0.0927, d4.loss_bbox: 0.2316, loss: 2.2619, grad_norm: 29.2906
2025-06-11 02:21:20,603 - mmdet - INFO - Epoch [2][2500/3517]	lr: 1.866e-04, eta: 7:54:29, time: 1.862, data_time: 0.053, memory: 32518, loss_cls: 0.0835, loss_bbox: 0.2312, d0.loss_cls: 0.1778, d0.loss_bbox: 0.3504, d1.loss_cls: 0.1190, d1.loss_bbox: 0.2591, d2.loss_cls: 0.0979, d2.loss_bbox: 0.2418, d3.loss_cls: 0.0873, d3.loss_bbox: 0.2422, d4.loss_cls: 0.0846, d4.loss_bbox: 0.2307, loss: 2.2054, grad_norm: 19.0258
2025-06-11 02:22:53,801 - mmdet - INFO - Epoch [2][2550/3517]	lr: 1.866e-04, eta: 7:52:52, time: 1.864, data_time: 0.056, memory: 32518, loss_cls: 0.0867, loss_bbox: 0.2358, d0.loss_cls: 0.1819, d0.loss_bbox: 0.3586, d1.loss_cls: 0.1239, d1.loss_bbox: 0.2634, d2.loss_cls: 0.1016, d2.loss_bbox: 0.2462, d3.loss_cls: 0.0911, d3.loss_bbox: 0.2483, d4.loss_cls: 0.0888, d4.loss_bbox: 0.2330, loss: 2.2592, grad_norm: 24.2514
2025-06-11 02:24:26,828 - mmdet - INFO - Epoch [2][2600/3517]	lr: 1.866e-04, eta: 7:51:14, time: 1.861, data_time: 0.055, memory: 32518, loss_cls: 0.0824, loss_bbox: 0.2342, d0.loss_cls: 0.1763, d0.loss_bbox: 0.3549, d1.loss_cls: 0.1252, d1.loss_bbox: 0.2645, d2.loss_cls: 0.0999, d2.loss_bbox: 0.2446, d3.loss_cls: 0.0881, d3.loss_bbox: 0.2449, d4.loss_cls: 0.0861, d4.loss_bbox: 0.2310, loss: 2.2321, grad_norm: 32.5759
2025-06-11 02:25:58,622 - mmdet - INFO - Epoch [2][2650/3517]	lr: 1.866e-04, eta: 7:49:33, time: 1.836, data_time: 0.050, memory: 32518, loss_cls: 0.0801, loss_bbox: 0.2281, d0.loss_cls: 0.1721, d0.loss_bbox: 0.3381, d1.loss_cls: 0.1189, d1.loss_bbox: 0.2552, d2.loss_cls: 0.0922, d2.loss_bbox: 0.2380, d3.loss_cls: 0.0823, d3.loss_bbox: 0.2377, d4.loss_cls: 0.0809, d4.loss_bbox: 0.2258, loss: 2.1493, grad_norm: 31.4957
2025-06-11 02:27:30,348 - mmdet - INFO - Epoch [2][2700/3517]	lr: 1.866e-04, eta: 7:47:53, time: 1.835, data_time: 0.050, memory: 32518, loss_cls: 0.0821, loss_bbox: 0.2281, d0.loss_cls: 0.1766, d0.loss_bbox: 0.3490, d1.loss_cls: 0.1180, d1.loss_bbox: 0.2592, d2.loss_cls: 0.0971, d2.loss_bbox: 0.2423, d3.loss_cls: 0.0858, d3.loss_bbox: 0.2419, d4.loss_cls: 0.0846, d4.loss_bbox: 0.2278, loss: 2.1925, grad_norm: 16.4713
2025-06-11 02:29:02,329 - mmdet - INFO - Epoch [2][2750/3517]	lr: 1.866e-04, eta: 7:46:13, time: 1.840, data_time: 0.051, memory: 32518, loss_cls: 0.0822, loss_bbox: 0.2283, d0.loss_cls: 0.1774, d0.loss_bbox: 0.3543, d1.loss_cls: 0.1188, d1.loss_bbox: 0.2609, d2.loss_cls: 0.0976, d2.loss_bbox: 0.2413, d3.loss_cls: 0.0867, d3.loss_bbox: 0.2412, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2281, loss: 2.2004, grad_norm: 156.5416
2025-06-11 02:30:35,339 - mmdet - INFO - Epoch [2][2800/3517]	lr: 1.866e-04, eta: 7:44:36, time: 1.860, data_time: 0.055, memory: 32518, loss_cls: 0.0842, loss_bbox: 0.2325, d0.loss_cls: 0.1742, d0.loss_bbox: 0.3526, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2640, d2.loss_cls: 0.0985, d2.loss_bbox: 0.2457, d3.loss_cls: 0.0881, d3.loss_bbox: 0.2469, d4.loss_cls: 0.0861, d4.loss_bbox: 0.2317, loss: 2.2218, grad_norm: 18.0440
2025-06-11 02:32:09,861 - mmdet - INFO - Epoch [2][2850/3517]	lr: 1.866e-04, eta: 7:43:02, time: 1.891, data_time: 0.055, memory: 32518, loss_cls: 0.0739, loss_bbox: 0.2263, d0.loss_cls: 0.1726, d0.loss_bbox: 0.3431, d1.loss_cls: 0.1097, d1.loss_bbox: 0.2559, d2.loss_cls: 0.0893, d2.loss_bbox: 0.2404, d3.loss_cls: 0.0781, d3.loss_bbox: 0.2412, d4.loss_cls: 0.0750, d4.loss_bbox: 0.2257, loss: 2.1312, grad_norm: 27.5411
2025-06-11 02:33:44,152 - mmdet - INFO - Epoch [2][2900/3517]	lr: 1.866e-04, eta: 7:41:28, time: 1.886, data_time: 0.059, memory: 32518, loss_cls: 0.0856, loss_bbox: 0.2328, d0.loss_cls: 0.1761, d0.loss_bbox: 0.3505, d1.loss_cls: 0.1186, d1.loss_bbox: 0.2648, d2.loss_cls: 0.1012, d2.loss_bbox: 0.2448, d3.loss_cls: 0.0890, d3.loss_bbox: 0.2457, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2319, loss: 2.2281, grad_norm: 24.5834
2025-06-11 02:35:17,990 - mmdet - INFO - Epoch [2][2950/3517]	lr: 1.866e-04, eta: 7:39:53, time: 1.877, data_time: 0.055, memory: 32518, loss_cls: 0.0781, loss_bbox: 0.2285, d0.loss_cls: 0.1750, d0.loss_bbox: 0.3489, d1.loss_cls: 0.1133, d1.loss_bbox: 0.2559, d2.loss_cls: 0.0930, d2.loss_bbox: 0.2382, d3.loss_cls: 0.0833, d3.loss_bbox: 0.2389, d4.loss_cls: 0.0813, d4.loss_bbox: 0.2241, loss: 2.1585, grad_norm: 23.3164
2025-06-11 02:36:51,612 - mmdet - INFO - Epoch [2][3000/3517]	lr: 1.866e-04, eta: 7:38:17, time: 1.872, data_time: 0.053, memory: 32518, loss_cls: 0.0813, loss_bbox: 0.2315, d0.loss_cls: 0.1774, d0.loss_bbox: 0.3487, d1.loss_cls: 0.1198, d1.loss_bbox: 0.2644, d2.loss_cls: 0.0964, d2.loss_bbox: 0.2454, d3.loss_cls: 0.0856, d3.loss_bbox: 0.2443, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2285, loss: 2.2069, grad_norm: 40.1418
2025-06-11 02:38:28,765 - mmdet - INFO - Epoch [2][3050/3517]	lr: 1.866e-04, eta: 7:36:49, time: 1.943, data_time: 0.057, memory: 32518, loss_cls: 0.0775, loss_bbox: 0.2268, d0.loss_cls: 0.1734, d0.loss_bbox: 0.3452, d1.loss_cls: 0.1151, d1.loss_bbox: 0.2586, d2.loss_cls: 0.0920, d2.loss_bbox: 0.2406, d3.loss_cls: 0.0812, d3.loss_bbox: 0.2405, d4.loss_cls: 0.0788, d4.loss_bbox: 0.2258, loss: 2.1554, grad_norm: 368.4451
2025-06-11 02:40:02,470 - mmdet - INFO - Epoch [2][3100/3517]	lr: 1.866e-04, eta: 7:35:14, time: 1.874, data_time: 0.059, memory: 32518, loss_cls: 0.0800, loss_bbox: 0.2279, d0.loss_cls: 0.1766, d0.loss_bbox: 0.3471, d1.loss_cls: 0.1150, d1.loss_bbox: 0.2600, d2.loss_cls: 0.0948, d2.loss_bbox: 0.2413, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2409, d4.loss_cls: 0.0811, d4.loss_bbox: 0.2268, loss: 2.1751, grad_norm: 33.9071
2025-06-11 02:41:36,204 - mmdet - INFO - Epoch [2][3150/3517]	lr: 1.866e-04, eta: 7:33:38, time: 1.875, data_time: 0.057, memory: 32518, loss_cls: 0.0820, loss_bbox: 0.2288, d0.loss_cls: 0.1801, d0.loss_bbox: 0.3473, d1.loss_cls: 0.1178, d1.loss_bbox: 0.2606, d2.loss_cls: 0.0980, d2.loss_bbox: 0.2405, d3.loss_cls: 0.0885, d3.loss_bbox: 0.2397, d4.loss_cls: 0.0847, d4.loss_bbox: 0.2272, loss: 2.1952, grad_norm: 33.8628
2025-06-11 02:43:10,235 - mmdet - INFO - Epoch [2][3200/3517]	lr: 1.866e-04, eta: 7:32:03, time: 1.881, data_time: 0.053, memory: 32518, loss_cls: 0.0843, loss_bbox: 0.2312, d0.loss_cls: 0.1791, d0.loss_bbox: 0.3504, d1.loss_cls: 0.1186, d1.loss_bbox: 0.2606, d2.loss_cls: 0.0976, d2.loss_bbox: 0.2424, d3.loss_cls: 0.0882, d3.loss_bbox: 0.2432, d4.loss_cls: 0.0856, d4.loss_bbox: 0.2303, loss: 2.2113, grad_norm: 55.3750
2025-06-11 02:44:44,164 - mmdet - INFO - Epoch [2][3250/3517]	lr: 1.866e-04, eta: 7:30:28, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0789, loss_bbox: 0.2248, d0.loss_cls: 0.1822, d0.loss_bbox: 0.3475, d1.loss_cls: 0.1126, d1.loss_bbox: 0.2536, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2361, d3.loss_cls: 0.0822, d3.loss_bbox: 0.2362, d4.loss_cls: 0.0801, d4.loss_bbox: 0.2235, loss: 2.1518, grad_norm: 15.7264
2025-06-11 02:46:18,269 - mmdet - INFO - Epoch [2][3300/3517]	lr: 1.866e-04, eta: 7:28:54, time: 1.882, data_time: 0.058, memory: 32518, loss_cls: 0.0817, loss_bbox: 0.2261, d0.loss_cls: 0.1816, d0.loss_bbox: 0.3462, d1.loss_cls: 0.1183, d1.loss_bbox: 0.2558, d2.loss_cls: 0.0978, d2.loss_bbox: 0.2375, d3.loss_cls: 0.0863, d3.loss_bbox: 0.2375, d4.loss_cls: 0.0838, d4.loss_bbox: 0.2245, loss: 2.1770, grad_norm: 25.4570
2025-06-11 02:47:52,512 - mmdet - INFO - Epoch [2][3350/3517]	lr: 1.866e-04, eta: 7:27:19, time: 1.885, data_time: 0.053, memory: 32518, loss_cls: 0.0768, loss_bbox: 0.2218, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3401, d1.loss_cls: 0.1132, d1.loss_bbox: 0.2524, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2341, d3.loss_cls: 0.0811, d3.loss_bbox: 0.2333, d4.loss_cls: 0.0788, d4.loss_bbox: 0.2213, loss: 2.1202, grad_norm: 24.9880
2025-06-11 02:49:26,204 - mmdet - INFO - Epoch [2][3400/3517]	lr: 1.866e-04, eta: 7:25:44, time: 1.874, data_time: 0.059, memory: 32518, loss_cls: 0.0827, loss_bbox: 0.2291, d0.loss_cls: 0.1776, d0.loss_bbox: 0.3521, d1.loss_cls: 0.1139, d1.loss_bbox: 0.2607, d2.loss_cls: 0.0959, d2.loss_bbox: 0.2403, d3.loss_cls: 0.0864, d3.loss_bbox: 0.2395, d4.loss_cls: 0.0838, d4.loss_bbox: 0.2268, loss: 2.1889, grad_norm: 18.6261
2025-06-11 02:50:59,483 - mmdet - INFO - Epoch [2][3450/3517]	lr: 1.866e-04, eta: 7:24:08, time: 1.866, data_time: 0.054, memory: 32518, loss_cls: 0.0778, loss_bbox: 0.2277, d0.loss_cls: 0.1764, d0.loss_bbox: 0.3510, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2586, d2.loss_cls: 0.0931, d2.loss_bbox: 0.2413, d3.loss_cls: 0.0827, d3.loss_bbox: 0.2394, d4.loss_cls: 0.0803, d4.loss_bbox: 0.2269, loss: 2.1690, grad_norm: 16.7568
2025-06-11 02:52:34,108 - mmdet - INFO - Epoch [2][3500/3517]	lr: 1.866e-04, eta: 7:22:34, time: 1.892, data_time: 0.060, memory: 32518, loss_cls: 0.0844, loss_bbox: 0.2325, d0.loss_cls: 0.1803, d0.loss_bbox: 0.3585, d1.loss_cls: 0.1199, d1.loss_bbox: 0.2670, d2.loss_cls: 0.1012, d2.loss_bbox: 0.2453, d3.loss_cls: 0.0897, d3.loss_bbox: 0.2445, d4.loss_cls: 0.0872, d4.loss_bbox: 0.2311, loss: 2.2416, grad_norm: 19.8731
2025-06-11 02:53:06,174 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-06-11 03:18:53,128 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 03:18:53,128 - mmdet - INFO - Epoch(val) [2][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7833, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8786, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9076, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9224, pts_bbox_NuScenes/car_trans_err: 0.1898, pts_bbox_NuScenes/car_scale_err: 0.1569, pts_bbox_NuScenes/car_orient_err: 0.0471, pts_bbox_NuScenes/car_vel_err: 0.3279, pts_bbox_NuScenes/car_attr_err: 0.1815, pts_bbox_NuScenes/mATE: 0.2982, pts_bbox_NuScenes/mASE: 0.2735, pts_bbox_NuScenes/mAOE: 0.2750, pts_bbox_NuScenes/mAVE: 0.3145, pts_bbox_NuScenes/mAAE: 0.1833, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4085, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5998, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6970, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7465, pts_bbox_NuScenes/truck_trans_err: 0.3384, pts_bbox_NuScenes/truck_scale_err: 0.2066, pts_bbox_NuScenes/truck_orient_err: 0.0644, pts_bbox_NuScenes/truck_vel_err: 0.3475, pts_bbox_NuScenes/truck_attr_err: 0.1989, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0487, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2011, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4053, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4768, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6610, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4506, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8245, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1147, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2830, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5049, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7363, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8927, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9223, pts_bbox_NuScenes/bus_trans_err: 0.3555, pts_bbox_NuScenes/bus_scale_err: 0.2247, pts_bbox_NuScenes/bus_orient_err: 0.0481, pts_bbox_NuScenes/bus_vel_err: 0.5306, pts_bbox_NuScenes/bus_attr_err: 0.2951, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1835, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4354, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5838, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6711, pts_bbox_NuScenes/trailer_trans_err: 0.4786, pts_bbox_NuScenes/trailer_scale_err: 0.2508, pts_bbox_NuScenes/trailer_orient_err: 0.5569, pts_bbox_NuScenes/trailer_vel_err: 0.2802, pts_bbox_NuScenes/trailer_attr_err: 0.1703, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.6009, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7066, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7610, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7790, pts_bbox_NuScenes/barrier_trans_err: 0.2295, pts_bbox_NuScenes/barrier_scale_err: 0.2893, pts_bbox_NuScenes/barrier_orient_err: 0.0606, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6245, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7622, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7953, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8037, pts_bbox_NuScenes/motorcycle_trans_err: 0.2232, pts_bbox_NuScenes/motorcycle_scale_err: 0.2560, pts_bbox_NuScenes/motorcycle_orient_err: 0.2164, pts_bbox_NuScenes/motorcycle_vel_err: 0.4384, pts_bbox_NuScenes/motorcycle_attr_err: 0.2191, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5347, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5863, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6014, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6125, pts_bbox_NuScenes/bicycle_trans_err: 0.1801, pts_bbox_NuScenes/bicycle_scale_err: 0.2702, pts_bbox_NuScenes/bicycle_orient_err: 0.3127, pts_bbox_NuScenes/bicycle_vel_err: 0.2315, pts_bbox_NuScenes/bicycle_attr_err: 0.0038, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7989, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8532, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8779, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8926, pts_bbox_NuScenes/pedestrian_trans_err: 0.1628, pts_bbox_NuScenes/pedestrian_scale_err: 0.3007, pts_bbox_NuScenes/pedestrian_orient_err: 0.3445, pts_bbox_NuScenes/pedestrian_vel_err: 0.2455, pts_bbox_NuScenes/pedestrian_attr_err: 0.1149, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7099, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7598, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7914, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8166, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1627, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3298, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6990, pts_bbox_NuScenes/mAP: 0.6669
2025-06-11 03:20:36,172 - mmdet - INFO - Epoch [3][50/3517]	lr: 1.501e-04, eta: 7:19:35, time: 1.991, data_time: 0.174, memory: 32518, loss_cls: 0.0789, loss_bbox: 0.2246, d0.loss_cls: 0.1756, d0.loss_bbox: 0.3425, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2545, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2378, d3.loss_cls: 0.0824, d3.loss_bbox: 0.2378, d4.loss_cls: 0.0806, d4.loss_bbox: 0.2240, loss: 2.1472, grad_norm: 19.9352
2025-06-11 03:22:09,357 - mmdet - INFO - Epoch [3][100/3517]	lr: 1.501e-04, eta: 7:17:59, time: 1.864, data_time: 0.052, memory: 32518, loss_cls: 0.0811, loss_bbox: 0.2202, d0.loss_cls: 0.1813, d0.loss_bbox: 0.3466, d1.loss_cls: 0.1161, d1.loss_bbox: 0.2559, d2.loss_cls: 0.0987, d2.loss_bbox: 0.2351, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2336, d4.loss_cls: 0.0830, d4.loss_bbox: 0.2207, loss: 2.1584, grad_norm: 18.7378
2025-06-11 03:23:42,877 - mmdet - INFO - Epoch [3][150/3517]	lr: 1.501e-04, eta: 7:16:24, time: 1.870, data_time: 0.050, memory: 32518, loss_cls: 0.0802, loss_bbox: 0.2189, d0.loss_cls: 0.1742, d0.loss_bbox: 0.3414, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2547, d2.loss_cls: 0.0974, d2.loss_bbox: 0.2320, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2311, d4.loss_cls: 0.0817, d4.loss_bbox: 0.2192, loss: 2.1299, grad_norm: 31.6219
2025-06-11 03:25:16,043 - mmdet - INFO - Epoch [3][200/3517]	lr: 1.501e-04, eta: 7:14:48, time: 1.863, data_time: 0.052, memory: 32518, loss_cls: 0.0761, loss_bbox: 0.2215, d0.loss_cls: 0.1715, d0.loss_bbox: 0.3410, d1.loss_cls: 0.1136, d1.loss_bbox: 0.2531, d2.loss_cls: 0.0933, d2.loss_bbox: 0.2331, d3.loss_cls: 0.0816, d3.loss_bbox: 0.2313, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2210, loss: 2.1150, grad_norm: 18.5935
2025-06-11 03:26:50,087 - mmdet - INFO - Epoch [3][250/3517]	lr: 1.501e-04, eta: 7:13:14, time: 1.881, data_time: 0.052, memory: 32518, loss_cls: 0.0829, loss_bbox: 0.2305, d0.loss_cls: 0.1775, d0.loss_bbox: 0.3483, d1.loss_cls: 0.1188, d1.loss_bbox: 0.2649, d2.loss_cls: 0.0970, d2.loss_bbox: 0.2426, d3.loss_cls: 0.0890, d3.loss_bbox: 0.2410, d4.loss_cls: 0.0848, d4.loss_bbox: 0.2296, loss: 2.2069, grad_norm: 20.4811
2025-06-11 03:28:23,510 - mmdet - INFO - Epoch [3][300/3517]	lr: 1.501e-04, eta: 7:11:39, time: 1.868, data_time: 0.055, memory: 32518, loss_cls: 0.0790, loss_bbox: 0.2163, d0.loss_cls: 0.1731, d0.loss_bbox: 0.3337, d1.loss_cls: 0.1110, d1.loss_bbox: 0.2474, d2.loss_cls: 0.0943, d2.loss_bbox: 0.2297, d3.loss_cls: 0.0832, d3.loss_bbox: 0.2282, d4.loss_cls: 0.0815, d4.loss_bbox: 0.2156, loss: 2.0929, grad_norm: 20.3895
2025-06-11 03:29:55,957 - mmdet - INFO - Epoch [3][350/3517]	lr: 1.501e-04, eta: 7:10:02, time: 1.849, data_time: 0.048, memory: 32518, loss_cls: 0.0773, loss_bbox: 0.2190, d0.loss_cls: 0.1686, d0.loss_bbox: 0.3369, d1.loss_cls: 0.1136, d1.loss_bbox: 0.2540, d2.loss_cls: 0.0913, d2.loss_bbox: 0.2340, d3.loss_cls: 0.0809, d3.loss_bbox: 0.2305, d4.loss_cls: 0.0788, d4.loss_bbox: 0.2193, loss: 2.1041, grad_norm: 28.1109
2025-06-11 03:31:28,937 - mmdet - INFO - Epoch [3][400/3517]	lr: 1.501e-04, eta: 7:08:26, time: 1.860, data_time: 0.049, memory: 32518, loss_cls: 0.0756, loss_bbox: 0.2259, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3476, d1.loss_cls: 0.1112, d1.loss_bbox: 0.2612, d2.loss_cls: 0.0940, d2.loss_bbox: 0.2390, d3.loss_cls: 0.0808, d3.loss_bbox: 0.2389, d4.loss_cls: 0.0770, d4.loss_bbox: 0.2259, loss: 2.1540, grad_norm: 37.4327
2025-06-11 03:33:02,185 - mmdet - INFO - Epoch [3][450/3517]	lr: 1.501e-04, eta: 7:06:50, time: 1.865, data_time: 0.050, memory: 32518, loss_cls: 0.0712, loss_bbox: 0.2204, d0.loss_cls: 0.1685, d0.loss_bbox: 0.3396, d1.loss_cls: 0.1070, d1.loss_bbox: 0.2536, d2.loss_cls: 0.0888, d2.loss_bbox: 0.2359, d3.loss_cls: 0.0760, d3.loss_bbox: 0.2333, d4.loss_cls: 0.0734, d4.loss_bbox: 0.2204, loss: 2.0881, grad_norm: 15.8583
2025-06-11 03:34:35,676 - mmdet - INFO - Epoch [3][500/3517]	lr: 1.501e-04, eta: 7:05:15, time: 1.870, data_time: 0.050, memory: 32518, loss_cls: 0.0812, loss_bbox: 0.2284, d0.loss_cls: 0.1756, d0.loss_bbox: 0.3455, d1.loss_cls: 0.1140, d1.loss_bbox: 0.2641, d2.loss_cls: 0.0974, d2.loss_bbox: 0.2425, d3.loss_cls: 0.0869, d3.loss_bbox: 0.2393, d4.loss_cls: 0.0838, d4.loss_bbox: 0.2281, loss: 2.1868, grad_norm: 38.9927
2025-06-11 03:36:08,922 - mmdet - INFO - Epoch [3][550/3517]	lr: 1.501e-04, eta: 7:03:40, time: 1.865, data_time: 0.063, memory: 32518, loss_cls: 0.0817, loss_bbox: 0.2247, d0.loss_cls: 0.1772, d0.loss_bbox: 0.3407, d1.loss_cls: 0.1154, d1.loss_bbox: 0.2584, d2.loss_cls: 0.0968, d2.loss_bbox: 0.2374, d3.loss_cls: 0.0861, d3.loss_bbox: 0.2354, d4.loss_cls: 0.0842, d4.loss_bbox: 0.2234, loss: 2.1614, grad_norm: 45.4809
2025-06-11 03:37:42,209 - mmdet - INFO - Epoch [3][600/3517]	lr: 1.501e-04, eta: 7:02:04, time: 1.866, data_time: 0.052, memory: 32518, loss_cls: 0.0773, loss_bbox: 0.2224, d0.loss_cls: 0.1731, d0.loss_bbox: 0.3392, d1.loss_cls: 0.1171, d1.loss_bbox: 0.2601, d2.loss_cls: 0.0965, d2.loss_bbox: 0.2370, d3.loss_cls: 0.0836, d3.loss_bbox: 0.2354, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2217, loss: 2.1441, grad_norm: 100.6304
2025-06-11 03:39:15,028 - mmdet - INFO - Epoch [3][650/3517]	lr: 1.501e-04, eta: 7:00:28, time: 1.856, data_time: 0.054, memory: 32518, loss_cls: 0.0794, loss_bbox: 0.2242, d0.loss_cls: 0.1728, d0.loss_bbox: 0.3439, d1.loss_cls: 0.1121, d1.loss_bbox: 0.2604, d2.loss_cls: 0.0946, d2.loss_bbox: 0.2389, d3.loss_cls: 0.0835, d3.loss_bbox: 0.2354, d4.loss_cls: 0.0797, d4.loss_bbox: 0.2246, loss: 2.1494, grad_norm: 18.6868
2025-06-11 03:40:48,215 - mmdet - INFO - Epoch [3][700/3517]	lr: 1.501e-04, eta: 6:58:53, time: 1.864, data_time: 0.056, memory: 32518, loss_cls: 0.0753, loss_bbox: 0.2212, d0.loss_cls: 0.1720, d0.loss_bbox: 0.3437, d1.loss_cls: 0.1090, d1.loss_bbox: 0.2575, d2.loss_cls: 0.0917, d2.loss_bbox: 0.2348, d3.loss_cls: 0.0805, d3.loss_bbox: 0.2321, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2212, loss: 2.1169, grad_norm: 18.2839
2025-06-11 03:42:22,099 - mmdet - INFO - Epoch [3][750/3517]	lr: 1.501e-04, eta: 6:57:19, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0758, loss_bbox: 0.2208, d0.loss_cls: 0.1727, d0.loss_bbox: 0.3367, d1.loss_cls: 0.1105, d1.loss_bbox: 0.2570, d2.loss_cls: 0.0915, d2.loss_bbox: 0.2340, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2201, loss: 2.1108, grad_norm: 30.4132
2025-06-11 03:43:56,862 - mmdet - INFO - Epoch [3][800/3517]	lr: 1.501e-04, eta: 6:55:46, time: 1.895, data_time: 0.075, memory: 32518, loss_cls: 0.0743, loss_bbox: 0.2151, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3434, d1.loss_cls: 0.1149, d1.loss_bbox: 0.2513, d2.loss_cls: 0.0949, d2.loss_bbox: 0.2286, d3.loss_cls: 0.0814, d3.loss_bbox: 0.2271, d4.loss_cls: 0.0775, d4.loss_bbox: 0.2140, loss: 2.0956, grad_norm: 37.5190
2025-06-11 03:45:30,683 - mmdet - INFO - Epoch [3][850/3517]	lr: 1.501e-04, eta: 6:54:11, time: 1.876, data_time: 0.054, memory: 32518, loss_cls: 0.0808, loss_bbox: 0.2266, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3523, d1.loss_cls: 0.1154, d1.loss_bbox: 0.2619, d2.loss_cls: 0.0973, d2.loss_bbox: 0.2405, d3.loss_cls: 0.0853, d3.loss_bbox: 0.2396, d4.loss_cls: 0.0828, d4.loss_bbox: 0.2249, loss: 2.1844, grad_norm: 36.4296
2025-06-11 03:47:04,314 - mmdet - INFO - Epoch [3][900/3517]	lr: 1.501e-04, eta: 6:52:37, time: 1.873, data_time: 0.052, memory: 32518, loss_cls: 0.0761, loss_bbox: 0.2137, d0.loss_cls: 0.1723, d0.loss_bbox: 0.3345, d1.loss_cls: 0.1134, d1.loss_bbox: 0.2479, d2.loss_cls: 0.0924, d2.loss_bbox: 0.2266, d3.loss_cls: 0.0808, d3.loss_bbox: 0.2258, d4.loss_cls: 0.0783, d4.loss_bbox: 0.2138, loss: 2.0756, grad_norm: 22.3796
2025-06-11 03:48:37,450 - mmdet - INFO - Epoch [3][950/3517]	lr: 1.501e-04, eta: 6:51:01, time: 1.863, data_time: 0.051, memory: 32518, loss_cls: 0.0751, loss_bbox: 0.2171, d0.loss_cls: 0.1680, d0.loss_bbox: 0.3353, d1.loss_cls: 0.1078, d1.loss_bbox: 0.2520, d2.loss_cls: 0.0914, d2.loss_bbox: 0.2307, d3.loss_cls: 0.0801, d3.loss_bbox: 0.2289, d4.loss_cls: 0.0753, d4.loss_bbox: 0.2174, loss: 2.0792, grad_norm: 19.5761
2025-06-11 03:50:10,296 - mmdet - INFO - Epoch [3][1000/3517]	lr: 1.501e-04, eta: 6:49:26, time: 1.857, data_time: 0.052, memory: 32518, loss_cls: 0.0829, loss_bbox: 0.2307, d0.loss_cls: 0.1813, d0.loss_bbox: 0.3517, d1.loss_cls: 0.1224, d1.loss_bbox: 0.2630, d2.loss_cls: 0.1025, d2.loss_bbox: 0.2414, d3.loss_cls: 0.0888, d3.loss_bbox: 0.2409, d4.loss_cls: 0.0848, d4.loss_bbox: 0.2302, loss: 2.2207, grad_norm: 17.2840
2025-06-11 03:51:43,265 - mmdet - INFO - Epoch [3][1050/3517]	lr: 1.501e-04, eta: 6:47:50, time: 1.859, data_time: 0.051, memory: 32518, loss_cls: 0.0785, loss_bbox: 0.2200, d0.loss_cls: 0.1683, d0.loss_bbox: 0.3389, d1.loss_cls: 0.1137, d1.loss_bbox: 0.2556, d2.loss_cls: 0.0937, d2.loss_bbox: 0.2334, d3.loss_cls: 0.0831, d3.loss_bbox: 0.2317, d4.loss_cls: 0.0801, d4.loss_bbox: 0.2183, loss: 2.1154, grad_norm: 19.2099
2025-06-11 03:53:16,309 - mmdet - INFO - Epoch [3][1100/3517]	lr: 1.501e-04, eta: 6:46:14, time: 1.861, data_time: 0.056, memory: 32518, loss_cls: 0.0769, loss_bbox: 0.2147, d0.loss_cls: 0.1747, d0.loss_bbox: 0.3336, d1.loss_cls: 0.1091, d1.loss_bbox: 0.2468, d2.loss_cls: 0.0908, d2.loss_bbox: 0.2262, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2245, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2135, loss: 2.0710, grad_norm: 66.8715
2025-06-11 03:54:49,987 - mmdet - INFO - Epoch [3][1150/3517]	lr: 1.501e-04, eta: 6:44:40, time: 1.874, data_time: 0.056, memory: 32518, loss_cls: 0.0763, loss_bbox: 0.2142, d0.loss_cls: 0.1760, d0.loss_bbox: 0.3409, d1.loss_cls: 0.1139, d1.loss_bbox: 0.2510, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2286, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2253, d4.loss_cls: 0.0782, d4.loss_bbox: 0.2141, loss: 2.0933, grad_norm: 24.4251
2025-06-11 03:56:26,538 - mmdet - INFO - Epoch [3][1200/3517]	lr: 1.501e-04, eta: 6:43:10, time: 1.931, data_time: 0.055, memory: 32518, loss_cls: 0.0723, loss_bbox: 0.2152, d0.loss_cls: 0.1697, d0.loss_bbox: 0.3355, d1.loss_cls: 0.1060, d1.loss_bbox: 0.2487, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2277, d3.loss_cls: 0.0778, d3.loss_bbox: 0.2241, d4.loss_cls: 0.0745, d4.loss_bbox: 0.2141, loss: 2.0541, grad_norm: 20.0741
2025-06-11 03:58:00,802 - mmdet - INFO - Epoch [3][1250/3517]	lr: 1.501e-04, eta: 6:41:36, time: 1.885, data_time: 0.055, memory: 32518, loss_cls: 0.0754, loss_bbox: 0.2116, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3309, d1.loss_cls: 0.1074, d1.loss_bbox: 0.2480, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2254, d3.loss_cls: 0.0793, d3.loss_bbox: 0.2232, d4.loss_cls: 0.0769, d4.loss_bbox: 0.2115, loss: 2.0497, grad_norm: 19.0171
2025-06-11 03:59:34,673 - mmdet - INFO - Epoch [3][1300/3517]	lr: 1.501e-04, eta: 6:40:02, time: 1.877, data_time: 0.055, memory: 32518, loss_cls: 0.0809, loss_bbox: 0.2188, d0.loss_cls: 0.1753, d0.loss_bbox: 0.3369, d1.loss_cls: 0.1151, d1.loss_bbox: 0.2537, d2.loss_cls: 0.0950, d2.loss_bbox: 0.2323, d3.loss_cls: 0.0851, d3.loss_bbox: 0.2291, d4.loss_cls: 0.0825, d4.loss_bbox: 0.2185, loss: 2.1231, grad_norm: 59.0823
2025-06-11 04:01:09,555 - mmdet - INFO - Epoch [3][1350/3517]	lr: 1.501e-04, eta: 6:38:30, time: 1.898, data_time: 0.065, memory: 32518, loss_cls: 0.0812, loss_bbox: 0.2192, d0.loss_cls: 0.1759, d0.loss_bbox: 0.3425, d1.loss_cls: 0.1168, d1.loss_bbox: 0.2527, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2326, d3.loss_cls: 0.0860, d3.loss_bbox: 0.2285, d4.loss_cls: 0.0826, d4.loss_bbox: 0.2187, loss: 2.1320, grad_norm: 45.7676
2025-06-11 04:02:43,261 - mmdet - INFO - Epoch [3][1400/3517]	lr: 1.501e-04, eta: 6:36:55, time: 1.874, data_time: 0.055, memory: 32518, loss_cls: 0.0793, loss_bbox: 0.2154, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3332, d1.loss_cls: 0.1136, d1.loss_bbox: 0.2473, d2.loss_cls: 0.0945, d2.loss_bbox: 0.2282, d3.loss_cls: 0.0832, d3.loss_bbox: 0.2268, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2158, loss: 2.0916, grad_norm: 18.2554
2025-06-11 04:04:17,781 - mmdet - INFO - Epoch [3][1450/3517]	lr: 1.501e-04, eta: 6:35:22, time: 1.890, data_time: 0.059, memory: 32518, loss_cls: 0.0773, loss_bbox: 0.2196, d0.loss_cls: 0.1782, d0.loss_bbox: 0.3422, d1.loss_cls: 0.1173, d1.loss_bbox: 0.2516, d2.loss_cls: 0.0950, d2.loss_bbox: 0.2312, d3.loss_cls: 0.0834, d3.loss_bbox: 0.2293, d4.loss_cls: 0.0808, d4.loss_bbox: 0.2177, loss: 2.1235, grad_norm: 58.7416
2025-06-11 04:05:52,483 - mmdet - INFO - Epoch [3][1500/3517]	lr: 1.501e-04, eta: 6:33:49, time: 1.894, data_time: 0.059, memory: 32518, loss_cls: 0.0762, loss_bbox: 0.2176, d0.loss_cls: 0.1738, d0.loss_bbox: 0.3458, d1.loss_cls: 0.1168, d1.loss_bbox: 0.2519, d2.loss_cls: 0.0950, d2.loss_bbox: 0.2309, d3.loss_cls: 0.0820, d3.loss_bbox: 0.2276, d4.loss_cls: 0.0791, d4.loss_bbox: 0.2171, loss: 2.1139, grad_norm: 20.4913
2025-06-11 04:07:27,299 - mmdet - INFO - Epoch [3][1550/3517]	lr: 1.501e-04, eta: 6:32:16, time: 1.896, data_time: 0.060, memory: 32518, loss_cls: 0.0714, loss_bbox: 0.2118, d0.loss_cls: 0.1694, d0.loss_bbox: 0.3275, d1.loss_cls: 0.1073, d1.loss_bbox: 0.2422, d2.loss_cls: 0.0858, d2.loss_bbox: 0.2240, d3.loss_cls: 0.0763, d3.loss_bbox: 0.2223, d4.loss_cls: 0.0730, d4.loss_bbox: 0.2115, loss: 2.0226, grad_norm: 41.8855
2025-06-11 04:09:01,595 - mmdet - INFO - Epoch [3][1600/3517]	lr: 1.501e-04, eta: 6:30:42, time: 1.886, data_time: 0.056, memory: 32518, loss_cls: 0.0798, loss_bbox: 0.2236, d0.loss_cls: 0.1745, d0.loss_bbox: 0.3400, d1.loss_cls: 0.1164, d1.loss_bbox: 0.2567, d2.loss_cls: 0.0971, d2.loss_bbox: 0.2346, d3.loss_cls: 0.0856, d3.loss_bbox: 0.2333, d4.loss_cls: 0.0807, d4.loss_bbox: 0.2226, loss: 2.1449, grad_norm: 99.1385
2025-06-11 04:10:36,162 - mmdet - INFO - Epoch [3][1650/3517]	lr: 1.501e-04, eta: 6:29:09, time: 1.891, data_time: 0.063, memory: 32518, loss_cls: 0.0814, loss_bbox: 0.2229, d0.loss_cls: 0.1814, d0.loss_bbox: 0.3416, d1.loss_cls: 0.1202, d1.loss_bbox: 0.2552, d2.loss_cls: 0.0996, d2.loss_bbox: 0.2336, d3.loss_cls: 0.0884, d3.loss_bbox: 0.2309, d4.loss_cls: 0.0835, d4.loss_bbox: 0.2200, loss: 2.1588, grad_norm: 44.5671
2025-06-11 04:12:10,598 - mmdet - INFO - Epoch [3][1700/3517]	lr: 1.501e-04, eta: 6:27:36, time: 1.889, data_time: 0.058, memory: 32518, loss_cls: 0.0711, loss_bbox: 0.2220, d0.loss_cls: 0.1730, d0.loss_bbox: 0.3473, d1.loss_cls: 0.1090, d1.loss_bbox: 0.2579, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2351, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2327, d4.loss_cls: 0.0730, d4.loss_bbox: 0.2212, loss: 2.1060, grad_norm: 38.2810
2025-06-11 04:13:44,847 - mmdet - INFO - Epoch [3][1750/3517]	lr: 1.501e-04, eta: 6:26:02, time: 1.885, data_time: 0.051, memory: 32518, loss_cls: 0.0739, loss_bbox: 0.2114, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3299, d1.loss_cls: 0.1095, d1.loss_bbox: 0.2442, d2.loss_cls: 0.0901, d2.loss_bbox: 0.2235, d3.loss_cls: 0.0782, d3.loss_bbox: 0.2220, d4.loss_cls: 0.0750, d4.loss_bbox: 0.2112, loss: 2.0424, grad_norm: 25.5558
2025-06-11 04:15:19,151 - mmdet - INFO - Epoch [3][1800/3517]	lr: 1.501e-04, eta: 6:24:29, time: 1.886, data_time: 0.049, memory: 32518, loss_cls: 0.0757, loss_bbox: 0.2225, d0.loss_cls: 0.1678, d0.loss_bbox: 0.3404, d1.loss_cls: 0.1119, d1.loss_bbox: 0.2558, d2.loss_cls: 0.0915, d2.loss_bbox: 0.2339, d3.loss_cls: 0.0794, d3.loss_bbox: 0.2331, d4.loss_cls: 0.0770, d4.loss_bbox: 0.2209, loss: 2.1100, grad_norm: 34.1312
2025-06-11 04:16:53,242 - mmdet - INFO - Epoch [3][1850/3517]	lr: 1.501e-04, eta: 6:22:55, time: 1.882, data_time: 0.054, memory: 32518, loss_cls: 0.0775, loss_bbox: 0.2209, d0.loss_cls: 0.1733, d0.loss_bbox: 0.3297, d1.loss_cls: 0.1130, d1.loss_bbox: 0.2506, d2.loss_cls: 0.0933, d2.loss_bbox: 0.2312, d3.loss_cls: 0.0821, d3.loss_bbox: 0.2306, d4.loss_cls: 0.0797, d4.loss_bbox: 0.2188, loss: 2.1008, grad_norm: 26.7131
2025-06-11 04:18:27,665 - mmdet - INFO - Epoch [3][1900/3517]	lr: 1.501e-04, eta: 6:21:21, time: 1.889, data_time: 0.054, memory: 32518, loss_cls: 0.0697, loss_bbox: 0.2142, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3307, d1.loss_cls: 0.1022, d1.loss_bbox: 0.2466, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2260, d3.loss_cls: 0.0738, d3.loss_bbox: 0.2235, d4.loss_cls: 0.0707, d4.loss_bbox: 0.2128, loss: 2.0231, grad_norm: 47.0136
2025-06-11 04:20:02,289 - mmdet - INFO - Epoch [3][1950/3517]	lr: 1.501e-04, eta: 6:19:48, time: 1.892, data_time: 0.058, memory: 32518, loss_cls: 0.0759, loss_bbox: 0.2171, d0.loss_cls: 0.1676, d0.loss_bbox: 0.3314, d1.loss_cls: 0.1096, d1.loss_bbox: 0.2476, d2.loss_cls: 0.0914, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0797, d3.loss_bbox: 0.2282, d4.loss_cls: 0.0775, d4.loss_bbox: 0.2156, loss: 2.0699, grad_norm: 4614.1517
2025-06-11 04:21:36,205 - mmdet - INFO - Epoch [3][2000/3517]	lr: 1.501e-04, eta: 6:18:14, time: 1.878, data_time: 0.053, memory: 32518, loss_cls: 0.0770, loss_bbox: 0.2171, d0.loss_cls: 0.1712, d0.loss_bbox: 0.3367, d1.loss_cls: 0.1091, d1.loss_bbox: 0.2526, d2.loss_cls: 0.0918, d2.loss_bbox: 0.2320, d3.loss_cls: 0.0818, d3.loss_bbox: 0.2298, d4.loss_cls: 0.0777, d4.loss_bbox: 0.2182, loss: 2.0950, grad_norm: 19.6600
2025-06-11 04:23:10,419 - mmdet - INFO - Epoch [3][2050/3517]	lr: 1.501e-04, eta: 6:16:40, time: 1.884, data_time: 0.055, memory: 32518, loss_cls: 0.0741, loss_bbox: 0.2090, d0.loss_cls: 0.1668, d0.loss_bbox: 0.3246, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2423, d2.loss_cls: 0.0869, d2.loss_bbox: 0.2239, d3.loss_cls: 0.0775, d3.loss_bbox: 0.2214, d4.loss_cls: 0.0754, d4.loss_bbox: 0.2087, loss: 2.0172, grad_norm: 22.5746
2025-06-11 04:24:44,702 - mmdet - INFO - Epoch [3][2100/3517]	lr: 1.501e-04, eta: 6:15:06, time: 1.886, data_time: 0.061, memory: 32518, loss_cls: 0.0734, loss_bbox: 0.2146, d0.loss_cls: 0.1717, d0.loss_bbox: 0.3373, d1.loss_cls: 0.1102, d1.loss_bbox: 0.2541, d2.loss_cls: 0.0908, d2.loss_bbox: 0.2306, d3.loss_cls: 0.0786, d3.loss_bbox: 0.2290, d4.loss_cls: 0.0754, d4.loss_bbox: 0.2148, loss: 2.0805, grad_norm: 54.1102
2025-06-11 04:26:18,838 - mmdet - INFO - Epoch [3][2150/3517]	lr: 1.501e-04, eta: 6:13:32, time: 1.883, data_time: 0.049, memory: 32518, loss_cls: 0.0765, loss_bbox: 0.2206, d0.loss_cls: 0.1736, d0.loss_bbox: 0.3385, d1.loss_cls: 0.1088, d1.loss_bbox: 0.2538, d2.loss_cls: 0.0926, d2.loss_bbox: 0.2315, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2299, d4.loss_cls: 0.0783, d4.loss_bbox: 0.2194, loss: 2.1047, grad_norm: 23.0184
2025-06-11 04:27:52,474 - mmdet - INFO - Epoch [3][2200/3517]	lr: 1.501e-04, eta: 6:11:58, time: 1.873, data_time: 0.054, memory: 32518, loss_cls: 0.0763, loss_bbox: 0.2072, d0.loss_cls: 0.1687, d0.loss_bbox: 0.3320, d1.loss_cls: 0.1089, d1.loss_bbox: 0.2432, d2.loss_cls: 0.0906, d2.loss_bbox: 0.2208, d3.loss_cls: 0.0810, d3.loss_bbox: 0.2172, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2070, loss: 2.0303, grad_norm: 58.7181
2025-06-11 04:29:27,486 - mmdet - INFO - Epoch [3][2250/3517]	lr: 1.501e-04, eta: 6:10:25, time: 1.900, data_time: 0.067, memory: 32518, loss_cls: 0.0752, loss_bbox: 0.2160, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3408, d1.loss_cls: 0.1071, d1.loss_bbox: 0.2516, d2.loss_cls: 0.0906, d2.loss_bbox: 0.2303, d3.loss_cls: 0.0797, d3.loss_bbox: 0.2276, d4.loss_cls: 0.0773, d4.loss_bbox: 0.2155, loss: 2.0788, grad_norm: 21.9978
2025-06-11 04:31:01,692 - mmdet - INFO - Epoch [3][2300/3517]	lr: 1.501e-04, eta: 6:08:51, time: 1.884, data_time: 0.056, memory: 32518, loss_cls: 0.0758, loss_bbox: 0.2149, d0.loss_cls: 0.1709, d0.loss_bbox: 0.3368, d1.loss_cls: 0.1085, d1.loss_bbox: 0.2501, d2.loss_cls: 0.0903, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0786, d3.loss_bbox: 0.2262, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2154, loss: 2.0721, grad_norm: 19.0930
2025-06-11 04:32:36,273 - mmdet - INFO - Epoch [3][2350/3517]	lr: 1.501e-04, eta: 6:07:18, time: 1.892, data_time: 0.054, memory: 32518, loss_cls: 0.0750, loss_bbox: 0.2188, d0.loss_cls: 0.1724, d0.loss_bbox: 0.3454, d1.loss_cls: 0.1094, d1.loss_bbox: 0.2557, d2.loss_cls: 0.0907, d2.loss_bbox: 0.2333, d3.loss_cls: 0.0800, d3.loss_bbox: 0.2300, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2183, loss: 2.1055, grad_norm: 31.3000
2025-06-11 04:34:10,132 - mmdet - INFO - Epoch [3][2400/3517]	lr: 1.501e-04, eta: 6:05:44, time: 1.877, data_time: 0.052, memory: 32518, loss_cls: 0.0745, loss_bbox: 0.2179, d0.loss_cls: 0.1687, d0.loss_bbox: 0.3326, d1.loss_cls: 0.1059, d1.loss_bbox: 0.2501, d2.loss_cls: 0.0876, d2.loss_bbox: 0.2309, d3.loss_cls: 0.0792, d3.loss_bbox: 0.2296, d4.loss_cls: 0.0759, d4.loss_bbox: 0.2163, loss: 2.0691, grad_norm: 38.4857
2025-06-11 04:35:44,402 - mmdet - INFO - Epoch [3][2450/3517]	lr: 1.501e-04, eta: 6:04:10, time: 1.885, data_time: 0.055, memory: 32518, loss_cls: 0.0743, loss_bbox: 0.2142, d0.loss_cls: 0.1666, d0.loss_bbox: 0.3432, d1.loss_cls: 0.1084, d1.loss_bbox: 0.2548, d2.loss_cls: 0.0901, d2.loss_bbox: 0.2296, d3.loss_cls: 0.0792, d3.loss_bbox: 0.2270, d4.loss_cls: 0.0759, d4.loss_bbox: 0.2144, loss: 2.0777, grad_norm: 17.3413
2025-06-11 04:37:19,028 - mmdet - INFO - Epoch [3][2500/3517]	lr: 1.501e-04, eta: 6:02:37, time: 1.892, data_time: 0.057, memory: 32518, loss_cls: 0.0716, loss_bbox: 0.2112, d0.loss_cls: 0.1674, d0.loss_bbox: 0.3249, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2444, d2.loss_cls: 0.0861, d2.loss_bbox: 0.2257, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2249, d4.loss_cls: 0.0734, d4.loss_bbox: 0.2112, loss: 2.0227, grad_norm: 17.2799
2025-06-11 04:38:52,664 - mmdet - INFO - Epoch [3][2550/3517]	lr: 1.501e-04, eta: 6:01:02, time: 1.873, data_time: 0.052, memory: 32518, loss_cls: 0.0727, loss_bbox: 0.2119, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3289, d1.loss_cls: 0.1033, d1.loss_bbox: 0.2472, d2.loss_cls: 0.0849, d2.loss_bbox: 0.2260, d3.loss_cls: 0.0765, d3.loss_bbox: 0.2221, d4.loss_cls: 0.0743, d4.loss_bbox: 0.2112, loss: 2.0220, grad_norm: 32.0568
2025-06-11 04:40:27,102 - mmdet - INFO - Epoch [3][2600/3517]	lr: 1.501e-04, eta: 5:59:28, time: 1.889, data_time: 0.058, memory: 32518, loss_cls: 0.0753, loss_bbox: 0.2181, d0.loss_cls: 0.1661, d0.loss_bbox: 0.3285, d1.loss_cls: 0.1049, d1.loss_bbox: 0.2502, d2.loss_cls: 0.0889, d2.loss_bbox: 0.2276, d3.loss_cls: 0.0791, d3.loss_bbox: 0.2263, d4.loss_cls: 0.0764, d4.loss_bbox: 0.2163, loss: 2.0576, grad_norm: 42.3477
2025-06-11 04:42:00,832 - mmdet - INFO - Epoch [3][2650/3517]	lr: 1.501e-04, eta: 5:57:54, time: 1.875, data_time: 0.056, memory: 32518, loss_cls: 0.0708, loss_bbox: 0.2112, d0.loss_cls: 0.1664, d0.loss_bbox: 0.3268, d1.loss_cls: 0.1083, d1.loss_bbox: 0.2431, d2.loss_cls: 0.0858, d2.loss_bbox: 0.2236, d3.loss_cls: 0.0753, d3.loss_bbox: 0.2205, d4.loss_cls: 0.0718, d4.loss_bbox: 0.2108, loss: 2.0145, grad_norm: 21.9905
2025-06-11 04:43:34,939 - mmdet - INFO - Epoch [3][2700/3517]	lr: 1.501e-04, eta: 5:56:20, time: 1.882, data_time: 0.055, memory: 32518, loss_cls: 0.0734, loss_bbox: 0.2148, d0.loss_cls: 0.1663, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1108, d1.loss_bbox: 0.2471, d2.loss_cls: 0.0909, d2.loss_bbox: 0.2277, d3.loss_cls: 0.0774, d3.loss_bbox: 0.2260, d4.loss_cls: 0.0749, d4.loss_bbox: 0.2144, loss: 2.0499, grad_norm: 31.2702
2025-06-11 04:45:08,851 - mmdet - INFO - Epoch [3][2750/3517]	lr: 1.501e-04, eta: 5:54:46, time: 1.878, data_time: 0.056, memory: 32518, loss_cls: 0.0754, loss_bbox: 0.2203, d0.loss_cls: 0.1679, d0.loss_bbox: 0.3378, d1.loss_cls: 0.1072, d1.loss_bbox: 0.2559, d2.loss_cls: 0.0902, d2.loss_bbox: 0.2357, d3.loss_cls: 0.0798, d3.loss_bbox: 0.2348, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2188, loss: 2.1004, grad_norm: 21.1074
2025-06-11 04:46:43,680 - mmdet - INFO - Epoch [3][2800/3517]	lr: 1.501e-04, eta: 5:53:13, time: 1.897, data_time: 0.073, memory: 32518, loss_cls: 0.0767, loss_bbox: 0.2219, d0.loss_cls: 0.1698, d0.loss_bbox: 0.3441, d1.loss_cls: 0.1097, d1.loss_bbox: 0.2573, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2346, d3.loss_cls: 0.0820, d3.loss_bbox: 0.2320, d4.loss_cls: 0.0781, d4.loss_bbox: 0.2223, loss: 2.1223, grad_norm: 21.2630
2025-06-11 04:48:18,234 - mmdet - INFO - Epoch [3][2850/3517]	lr: 1.501e-04, eta: 5:51:39, time: 1.891, data_time: 0.062, memory: 32518, loss_cls: 0.0790, loss_bbox: 0.2225, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3425, d1.loss_cls: 0.1156, d1.loss_bbox: 0.2588, d2.loss_cls: 0.0965, d2.loss_bbox: 0.2361, d3.loss_cls: 0.0835, d3.loss_bbox: 0.2349, d4.loss_cls: 0.0799, d4.loss_bbox: 0.2236, loss: 2.1427, grad_norm: 46.5162
2025-06-11 04:49:55,738 - mmdet - INFO - Epoch [3][2900/3517]	lr: 1.501e-04, eta: 5:50:09, time: 1.950, data_time: 0.062, memory: 32518, loss_cls: 0.0734, loss_bbox: 0.2140, d0.loss_cls: 0.1768, d0.loss_bbox: 0.3293, d1.loss_cls: 0.1128, d1.loss_bbox: 0.2482, d2.loss_cls: 0.0925, d2.loss_bbox: 0.2281, d3.loss_cls: 0.0796, d3.loss_bbox: 0.2249, d4.loss_cls: 0.0755, d4.loss_bbox: 0.2140, loss: 2.0691, grad_norm: 28.6231
2025-06-11 04:51:29,521 - mmdet - INFO - Epoch [3][2950/3517]	lr: 1.501e-04, eta: 5:48:35, time: 1.876, data_time: 0.056, memory: 32518, loss_cls: 0.0720, loss_bbox: 0.2163, d0.loss_cls: 0.1658, d0.loss_bbox: 0.3377, d1.loss_cls: 0.1093, d1.loss_bbox: 0.2514, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2299, d3.loss_cls: 0.0779, d3.loss_bbox: 0.2266, d4.loss_cls: 0.0736, d4.loss_bbox: 0.2154, loss: 2.0681, grad_norm: 23.5434
2025-06-11 04:53:03,415 - mmdet - INFO - Epoch [3][3000/3517]	lr: 1.501e-04, eta: 5:47:01, time: 1.878, data_time: 0.066, memory: 32518, loss_cls: 0.0699, loss_bbox: 0.2097, d0.loss_cls: 0.1673, d0.loss_bbox: 0.3302, d1.loss_cls: 0.1096, d1.loss_bbox: 0.2432, d2.loss_cls: 0.0873, d2.loss_bbox: 0.2223, d3.loss_cls: 0.0744, d3.loss_bbox: 0.2215, d4.loss_cls: 0.0720, d4.loss_bbox: 0.2091, loss: 2.0165, grad_norm: 937.6046
2025-06-11 04:54:37,476 - mmdet - INFO - Epoch [3][3050/3517]	lr: 1.501e-04, eta: 5:45:27, time: 1.881, data_time: 0.059, memory: 32518, loss_cls: 0.0715, loss_bbox: 0.2156, d0.loss_cls: 0.1718, d0.loss_bbox: 0.3317, d1.loss_cls: 0.1091, d1.loss_bbox: 0.2491, d2.loss_cls: 0.0889, d2.loss_bbox: 0.2288, d3.loss_cls: 0.0768, d3.loss_bbox: 0.2261, d4.loss_cls: 0.0733, d4.loss_bbox: 0.2153, loss: 2.0582, grad_norm: 31.3402
2025-06-11 04:56:22,162 - mmdet - INFO - Epoch [3][3100/3517]	lr: 1.501e-04, eta: 5:44:04, time: 2.094, data_time: 0.055, memory: 32518, loss_cls: 0.0724, loss_bbox: 0.2180, d0.loss_cls: 0.1709, d0.loss_bbox: 0.3421, d1.loss_cls: 0.1094, d1.loss_bbox: 0.2535, d2.loss_cls: 0.0896, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0772, d3.loss_bbox: 0.2278, d4.loss_cls: 0.0744, d4.loss_bbox: 0.2181, loss: 2.0847, grad_norm: 229.6757
2025-06-11 04:57:56,113 - mmdet - INFO - Epoch [3][3150/3517]	lr: 1.501e-04, eta: 5:42:30, time: 1.879, data_time: 0.063, memory: 32518, loss_cls: 0.0700, loss_bbox: 0.2096, d0.loss_cls: 0.1665, d0.loss_bbox: 0.3278, d1.loss_cls: 0.1073, d1.loss_bbox: 0.2421, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2215, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2204, d4.loss_cls: 0.0719, d4.loss_bbox: 0.2100, loss: 2.0113, grad_norm: 58.1147
2025-06-11 04:59:30,005 - mmdet - INFO - Epoch [3][3200/3517]	lr: 1.501e-04, eta: 5:40:55, time: 1.878, data_time: 0.055, memory: 32518, loss_cls: 0.0743, loss_bbox: 0.2226, d0.loss_cls: 0.1693, d0.loss_bbox: 0.3316, d1.loss_cls: 0.1099, d1.loss_bbox: 0.2505, d2.loss_cls: 0.0909, d2.loss_bbox: 0.2324, d3.loss_cls: 0.0791, d3.loss_bbox: 0.2329, d4.loss_cls: 0.0761, d4.loss_bbox: 0.2220, loss: 2.0913, grad_norm: 517.3726
2025-06-11 05:01:03,915 - mmdet - INFO - Epoch [3][3250/3517]	lr: 1.501e-04, eta: 5:39:21, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0728, loss_bbox: 0.2160, d0.loss_cls: 0.1679, d0.loss_bbox: 0.3337, d1.loss_cls: 0.1082, d1.loss_bbox: 0.2494, d2.loss_cls: 0.0887, d2.loss_bbox: 0.2281, d3.loss_cls: 0.0797, d3.loss_bbox: 0.2253, d4.loss_cls: 0.0756, d4.loss_bbox: 0.2152, loss: 2.0607, grad_norm: 25.4673
2025-06-11 05:02:38,229 - mmdet - INFO - Epoch [3][3300/3517]	lr: 1.501e-04, eta: 5:37:47, time: 1.886, data_time: 0.058, memory: 32518, loss_cls: 0.0786, loss_bbox: 0.2162, d0.loss_cls: 0.1743, d0.loss_bbox: 0.3387, d1.loss_cls: 0.1144, d1.loss_bbox: 0.2502, d2.loss_cls: 0.0953, d2.loss_bbox: 0.2276, d3.loss_cls: 0.0833, d3.loss_bbox: 0.2260, d4.loss_cls: 0.0803, d4.loss_bbox: 0.2153, loss: 2.1003, grad_norm: 32.3106
2025-06-11 05:04:12,054 - mmdet - INFO - Epoch [3][3350/3517]	lr: 1.501e-04, eta: 5:36:13, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.0705, loss_bbox: 0.2082, d0.loss_cls: 0.1686, d0.loss_bbox: 0.3300, d1.loss_cls: 0.1075, d1.loss_bbox: 0.2418, d2.loss_cls: 0.0866, d2.loss_bbox: 0.2207, d3.loss_cls: 0.0746, d3.loss_bbox: 0.2180, d4.loss_cls: 0.0718, d4.loss_bbox: 0.2084, loss: 2.0070, grad_norm: 32.8890
2025-06-11 05:05:45,988 - mmdet - INFO - Epoch [3][3400/3517]	lr: 1.501e-04, eta: 5:34:38, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0758, loss_bbox: 0.2172, d0.loss_cls: 0.1707, d0.loss_bbox: 0.3371, d1.loss_cls: 0.1112, d1.loss_bbox: 0.2507, d2.loss_cls: 0.0935, d2.loss_bbox: 0.2278, d3.loss_cls: 0.0804, d3.loss_bbox: 0.2266, d4.loss_cls: 0.0780, d4.loss_bbox: 0.2155, loss: 2.0844, grad_norm: 47.2834
2025-06-11 05:07:20,294 - mmdet - INFO - Epoch [3][3450/3517]	lr: 1.501e-04, eta: 5:33:04, time: 1.886, data_time: 0.066, memory: 32518, loss_cls: 0.0762, loss_bbox: 0.2147, d0.loss_cls: 0.1794, d0.loss_bbox: 0.3369, d1.loss_cls: 0.1129, d1.loss_bbox: 0.2490, d2.loss_cls: 0.0940, d2.loss_bbox: 0.2275, d3.loss_cls: 0.0819, d3.loss_bbox: 0.2247, d4.loss_cls: 0.0779, d4.loss_bbox: 0.2150, loss: 2.0901, grad_norm: 44.3528
2025-06-11 05:08:54,016 - mmdet - INFO - Epoch [3][3500/3517]	lr: 1.501e-04, eta: 5:31:30, time: 1.875, data_time: 0.053, memory: 32518, loss_cls: 0.0719, loss_bbox: 0.2082, d0.loss_cls: 0.1667, d0.loss_bbox: 0.3320, d1.loss_cls: 0.1062, d1.loss_bbox: 0.2442, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2210, d3.loss_cls: 0.0762, d3.loss_bbox: 0.2179, d4.loss_cls: 0.0735, d4.loss_bbox: 0.2077, loss: 2.0136, grad_norm: 36.0090
2025-06-11 05:09:26,301 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-06-11 05:35:51,938 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 05:35:51,938 - mmdet - INFO - Epoch(val) [3][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7889, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8819, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9108, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9251, pts_bbox_NuScenes/car_trans_err: 0.1985, pts_bbox_NuScenes/car_scale_err: 0.1545, pts_bbox_NuScenes/car_orient_err: 0.0446, pts_bbox_NuScenes/car_vel_err: 0.3098, pts_bbox_NuScenes/car_attr_err: 0.1974, pts_bbox_NuScenes/mATE: 0.2991, pts_bbox_NuScenes/mASE: 0.2654, pts_bbox_NuScenes/mAOE: 0.2583, pts_bbox_NuScenes/mAVE: 0.2960, pts_bbox_NuScenes/mAAE: 0.1888, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4073, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6087, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7036, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7395, pts_bbox_NuScenes/truck_trans_err: 0.3485, pts_bbox_NuScenes/truck_scale_err: 0.2056, pts_bbox_NuScenes/truck_orient_err: 0.0463, pts_bbox_NuScenes/truck_vel_err: 0.2621, pts_bbox_NuScenes/truck_attr_err: 0.2232, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0506, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2016, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3997, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4749, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6698, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4343, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7925, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1120, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2953, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5039, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7331, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8926, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9216, pts_bbox_NuScenes/bus_trans_err: 0.3598, pts_bbox_NuScenes/bus_scale_err: 0.2056, pts_bbox_NuScenes/bus_orient_err: 0.0501, pts_bbox_NuScenes/bus_vel_err: 0.5664, pts_bbox_NuScenes/bus_attr_err: 0.2317, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1561, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4110, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5745, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6614, pts_bbox_NuScenes/trailer_trans_err: 0.4826, pts_bbox_NuScenes/trailer_scale_err: 0.2432, pts_bbox_NuScenes/trailer_orient_err: 0.5138, pts_bbox_NuScenes/trailer_vel_err: 0.2383, pts_bbox_NuScenes/trailer_attr_err: 0.1823, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5998, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7026, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7515, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7669, pts_bbox_NuScenes/barrier_trans_err: 0.2141, pts_bbox_NuScenes/barrier_scale_err: 0.2842, pts_bbox_NuScenes/barrier_orient_err: 0.0509, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6094, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7676, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7984, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8050, pts_bbox_NuScenes/motorcycle_trans_err: 0.2316, pts_bbox_NuScenes/motorcycle_scale_err: 0.2501, pts_bbox_NuScenes/motorcycle_orient_err: 0.2173, pts_bbox_NuScenes/motorcycle_vel_err: 0.4429, pts_bbox_NuScenes/motorcycle_attr_err: 0.2566, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5434, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5911, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6098, pts_bbox_NuScenes/bicycle_trans_err: 0.1782, pts_bbox_NuScenes/bicycle_scale_err: 0.2648, pts_bbox_NuScenes/bicycle_orient_err: 0.2922, pts_bbox_NuScenes/bicycle_vel_err: 0.2141, pts_bbox_NuScenes/bicycle_attr_err: 0.0072, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8169, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8583, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8781, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8907, pts_bbox_NuScenes/pedestrian_trans_err: 0.1533, pts_bbox_NuScenes/pedestrian_scale_err: 0.2934, pts_bbox_NuScenes/pedestrian_orient_err: 0.3169, pts_bbox_NuScenes/pedestrian_vel_err: 0.2221, pts_bbox_NuScenes/pedestrian_attr_err: 0.1163, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7339, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7702, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7971, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8203, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1549, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3186, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7025, pts_bbox_NuScenes/mAP: 0.6664
2025-06-11 05:37:35,946 - mmdet - INFO - Epoch [4][50/3517]	lr: 1.001e-04, eta: 5:28:58, time: 2.006, data_time: 0.182, memory: 32518, loss_cls: 0.0719, loss_bbox: 0.2062, d0.loss_cls: 0.1655, d0.loss_bbox: 0.3220, d1.loss_cls: 0.1081, d1.loss_bbox: 0.2382, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2172, d3.loss_cls: 0.0777, d3.loss_bbox: 0.2148, d4.loss_cls: 0.0744, d4.loss_bbox: 0.2066, loss: 1.9906, grad_norm: 27.2005
2025-06-11 05:39:10,725 - mmdet - INFO - Epoch [4][100/3517]	lr: 1.001e-04, eta: 5:27:25, time: 1.896, data_time: 0.062, memory: 32518, loss_cls: 0.0625, loss_bbox: 0.2099, d0.loss_cls: 0.1600, d0.loss_bbox: 0.3292, d1.loss_cls: 0.0985, d1.loss_bbox: 0.2443, d2.loss_cls: 0.0828, d2.loss_bbox: 0.2224, d3.loss_cls: 0.0698, d3.loss_bbox: 0.2191, d4.loss_cls: 0.0654, d4.loss_bbox: 0.2108, loss: 1.9746, grad_norm: 37.7233
2025-06-11 05:40:45,079 - mmdet - INFO - Epoch [4][150/3517]	lr: 1.001e-04, eta: 5:25:51, time: 1.887, data_time: 0.058, memory: 32518, loss_cls: 0.0689, loss_bbox: 0.2089, d0.loss_cls: 0.1632, d0.loss_bbox: 0.3245, d1.loss_cls: 0.1028, d1.loss_bbox: 0.2433, d2.loss_cls: 0.0849, d2.loss_bbox: 0.2238, d3.loss_cls: 0.0739, d3.loss_bbox: 0.2197, d4.loss_cls: 0.0709, d4.loss_bbox: 0.2097, loss: 1.9945, grad_norm: 18.6636
2025-06-11 05:42:18,352 - mmdet - INFO - Epoch [4][200/3517]	lr: 1.001e-04, eta: 5:24:17, time: 1.865, data_time: 0.052, memory: 32518, loss_cls: 0.0705, loss_bbox: 0.2074, d0.loss_cls: 0.1671, d0.loss_bbox: 0.3297, d1.loss_cls: 0.1069, d1.loss_bbox: 0.2458, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2235, d3.loss_cls: 0.0763, d3.loss_bbox: 0.2190, d4.loss_cls: 0.0723, d4.loss_bbox: 0.2096, loss: 2.0161, grad_norm: 25.6419
2025-06-11 05:43:52,332 - mmdet - INFO - Epoch [4][250/3517]	lr: 1.001e-04, eta: 5:22:43, time: 1.880, data_time: 0.061, memory: 32518, loss_cls: 0.0704, loss_bbox: 0.2079, d0.loss_cls: 0.1673, d0.loss_bbox: 0.3262, d1.loss_cls: 0.1048, d1.loss_bbox: 0.2452, d2.loss_cls: 0.0874, d2.loss_bbox: 0.2227, d3.loss_cls: 0.0765, d3.loss_bbox: 0.2187, d4.loss_cls: 0.0719, d4.loss_bbox: 0.2091, loss: 2.0081, grad_norm: 37.6696
2025-06-11 05:45:26,231 - mmdet - INFO - Epoch [4][300/3517]	lr: 1.001e-04, eta: 5:21:09, time: 1.878, data_time: 0.058, memory: 32518, loss_cls: 0.0694, loss_bbox: 0.2070, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3198, d1.loss_cls: 0.1016, d1.loss_bbox: 0.2400, d2.loss_cls: 0.0853, d2.loss_bbox: 0.2205, d3.loss_cls: 0.0738, d3.loss_bbox: 0.2172, d4.loss_cls: 0.0703, d4.loss_bbox: 0.2082, loss: 1.9725, grad_norm: 15.0011
2025-06-11 05:47:00,684 - mmdet - INFO - Epoch [4][350/3517]	lr: 1.001e-04, eta: 5:19:35, time: 1.889, data_time: 0.059, memory: 32518, loss_cls: 0.0768, loss_bbox: 0.2174, d0.loss_cls: 0.1693, d0.loss_bbox: 0.3316, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2517, d2.loss_cls: 0.0938, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0813, d3.loss_bbox: 0.2294, d4.loss_cls: 0.0783, d4.loss_bbox: 0.2176, loss: 2.0889, grad_norm: 19.8513
2025-06-11 05:48:34,799 - mmdet - INFO - Epoch [4][400/3517]	lr: 1.001e-04, eta: 5:18:01, time: 1.882, data_time: 0.063, memory: 32518, loss_cls: 0.0713, loss_bbox: 0.2170, d0.loss_cls: 0.1619, d0.loss_bbox: 0.3353, d1.loss_cls: 0.1046, d1.loss_bbox: 0.2533, d2.loss_cls: 0.0883, d2.loss_bbox: 0.2303, d3.loss_cls: 0.0779, d3.loss_bbox: 0.2260, d4.loss_cls: 0.0729, d4.loss_bbox: 0.2174, loss: 2.0562, grad_norm: 36.8279
2025-06-11 05:50:08,105 - mmdet - INFO - Epoch [4][450/3517]	lr: 1.001e-04, eta: 5:16:27, time: 1.866, data_time: 0.056, memory: 32518, loss_cls: 0.0724, loss_bbox: 0.2145, d0.loss_cls: 0.1654, d0.loss_bbox: 0.3290, d1.loss_cls: 0.1041, d1.loss_bbox: 0.2503, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2280, d3.loss_cls: 0.0768, d3.loss_bbox: 0.2240, d4.loss_cls: 0.0735, d4.loss_bbox: 0.2161, loss: 2.0427, grad_norm: 40.5753
2025-06-11 05:51:40,732 - mmdet - INFO - Epoch [4][500/3517]	lr: 1.001e-04, eta: 5:14:51, time: 1.853, data_time: 0.053, memory: 32518, loss_cls: 0.0695, loss_bbox: 0.2088, d0.loss_cls: 0.1653, d0.loss_bbox: 0.3284, d1.loss_cls: 0.1060, d1.loss_bbox: 0.2460, d2.loss_cls: 0.0881, d2.loss_bbox: 0.2241, d3.loss_cls: 0.0767, d3.loss_bbox: 0.2197, d4.loss_cls: 0.0709, d4.loss_bbox: 0.2108, loss: 2.0142, grad_norm: 46.2936
2025-06-11 05:53:14,737 - mmdet - INFO - Epoch [4][550/3517]	lr: 1.001e-04, eta: 5:13:18, time: 1.880, data_time: 0.060, memory: 32518, loss_cls: 0.0725, loss_bbox: 0.2106, d0.loss_cls: 0.1699, d0.loss_bbox: 0.3306, d1.loss_cls: 0.1060, d1.loss_bbox: 0.2470, d2.loss_cls: 0.0902, d2.loss_bbox: 0.2243, d3.loss_cls: 0.0778, d3.loss_bbox: 0.2214, d4.loss_cls: 0.0746, d4.loss_bbox: 0.2116, loss: 2.0364, grad_norm: 58.4410
2025-06-11 05:54:48,836 - mmdet - INFO - Epoch [4][600/3517]	lr: 1.001e-04, eta: 5:11:44, time: 1.882, data_time: 0.054, memory: 32518, loss_cls: 0.0731, loss_bbox: 0.2031, d0.loss_cls: 0.1700, d0.loss_bbox: 0.3261, d1.loss_cls: 0.1075, d1.loss_bbox: 0.2429, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2189, d3.loss_cls: 0.0781, d3.loss_bbox: 0.2157, d4.loss_cls: 0.0754, d4.loss_bbox: 0.2037, loss: 2.0046, grad_norm: 28.0436
2025-06-11 05:56:23,030 - mmdet - INFO - Epoch [4][650/3517]	lr: 1.001e-04, eta: 5:10:10, time: 1.884, data_time: 0.053, memory: 32518, loss_cls: 0.0746, loss_bbox: 0.2147, d0.loss_cls: 0.1673, d0.loss_bbox: 0.3295, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2495, d2.loss_cls: 0.0899, d2.loss_bbox: 0.2288, d3.loss_cls: 0.0799, d3.loss_bbox: 0.2262, d4.loss_cls: 0.0766, d4.loss_bbox: 0.2164, loss: 2.0600, grad_norm: 43.6122
2025-06-11 05:57:57,167 - mmdet - INFO - Epoch [4][700/3517]	lr: 1.001e-04, eta: 5:08:36, time: 1.883, data_time: 0.060, memory: 32518, loss_cls: 0.0700, loss_bbox: 0.2085, d0.loss_cls: 0.1712, d0.loss_bbox: 0.3259, d1.loss_cls: 0.1076, d1.loss_bbox: 0.2450, d2.loss_cls: 0.0885, d2.loss_bbox: 0.2235, d3.loss_cls: 0.0763, d3.loss_bbox: 0.2202, d4.loss_cls: 0.0723, d4.loss_bbox: 0.2091, loss: 2.0180, grad_norm: 32.0511
2025-06-11 05:59:30,322 - mmdet - INFO - Epoch [4][750/3517]	lr: 1.001e-04, eta: 5:07:01, time: 1.863, data_time: 0.055, memory: 32518, loss_cls: 0.0710, loss_bbox: 0.1997, d0.loss_cls: 0.1618, d0.loss_bbox: 0.3186, d1.loss_cls: 0.1039, d1.loss_bbox: 0.2372, d2.loss_cls: 0.0871, d2.loss_bbox: 0.2162, d3.loss_cls: 0.0761, d3.loss_bbox: 0.2115, d4.loss_cls: 0.0729, d4.loss_bbox: 0.2002, loss: 1.9562, grad_norm: 25.4165
2025-06-11 06:01:03,019 - mmdet - INFO - Epoch [4][800/3517]	lr: 1.001e-04, eta: 5:05:26, time: 1.854, data_time: 0.054, memory: 32518, loss_cls: 0.0713, loss_bbox: 0.2126, d0.loss_cls: 0.1668, d0.loss_bbox: 0.3240, d1.loss_cls: 0.1063, d1.loss_bbox: 0.2471, d2.loss_cls: 0.0885, d2.loss_bbox: 0.2252, d3.loss_cls: 0.0764, d3.loss_bbox: 0.2210, d4.loss_cls: 0.0731, d4.loss_bbox: 0.2121, loss: 2.0245, grad_norm: 1318.0246
2025-06-11 06:02:35,730 - mmdet - INFO - Epoch [4][850/3517]	lr: 1.001e-04, eta: 5:03:51, time: 1.854, data_time: 0.051, memory: 32518, loss_cls: 0.0694, loss_bbox: 0.2136, d0.loss_cls: 0.1665, d0.loss_bbox: 0.3301, d1.loss_cls: 0.1054, d1.loss_bbox: 0.2498, d2.loss_cls: 0.0861, d2.loss_bbox: 0.2274, d3.loss_cls: 0.0738, d3.loss_bbox: 0.2249, d4.loss_cls: 0.0710, d4.loss_bbox: 0.2143, loss: 2.0323, grad_norm: 125.6907
2025-06-11 06:04:09,014 - mmdet - INFO - Epoch [4][900/3517]	lr: 1.001e-04, eta: 5:02:17, time: 1.866, data_time: 0.053, memory: 32518, loss_cls: 0.0650, loss_bbox: 0.2091, d0.loss_cls: 0.1672, d0.loss_bbox: 0.3237, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2430, d2.loss_cls: 0.0822, d2.loss_bbox: 0.2209, d3.loss_cls: 0.0713, d3.loss_bbox: 0.2185, d4.loss_cls: 0.0685, d4.loss_bbox: 0.2090, loss: 1.9802, grad_norm: 16.3456
2025-06-11 06:05:42,689 - mmdet - INFO - Epoch [4][950/3517]	lr: 1.001e-04, eta: 5:00:42, time: 1.874, data_time: 0.050, memory: 32518, loss_cls: 0.0689, loss_bbox: 0.2058, d0.loss_cls: 0.1613, d0.loss_bbox: 0.3133, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2382, d2.loss_cls: 0.0854, d2.loss_bbox: 0.2186, d3.loss_cls: 0.0735, d3.loss_bbox: 0.2170, d4.loss_cls: 0.0703, d4.loss_bbox: 0.2066, loss: 1.9604, grad_norm: 22.3292
2025-06-11 06:07:16,209 - mmdet - INFO - Epoch [4][1000/3517]	lr: 1.001e-04, eta: 4:59:08, time: 1.870, data_time: 0.056, memory: 32518, loss_cls: 0.0717, loss_bbox: 0.2102, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3208, d1.loss_cls: 0.1030, d1.loss_bbox: 0.2464, d2.loss_cls: 0.0872, d2.loss_bbox: 0.2246, d3.loss_cls: 0.0758, d3.loss_bbox: 0.2212, d4.loss_cls: 0.0730, d4.loss_bbox: 0.2110, loss: 2.0079, grad_norm: 70.6291
2025-06-11 06:08:49,079 - mmdet - INFO - Epoch [4][1050/3517]	lr: 1.001e-04, eta: 4:57:33, time: 1.857, data_time: 0.062, memory: 32518, loss_cls: 0.0679, loss_bbox: 0.2076, d0.loss_cls: 0.1600, d0.loss_bbox: 0.3263, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0828, d2.loss_bbox: 0.2239, d3.loss_cls: 0.0732, d3.loss_bbox: 0.2182, d4.loss_cls: 0.0698, d4.loss_bbox: 0.2091, loss: 1.9857, grad_norm: 30.6189
2025-06-11 06:10:22,489 - mmdet - INFO - Epoch [4][1100/3517]	lr: 1.001e-04, eta: 4:55:59, time: 1.868, data_time: 0.075, memory: 32518, loss_cls: 0.0725, loss_bbox: 0.2135, d0.loss_cls: 0.1624, d0.loss_bbox: 0.3236, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2478, d2.loss_cls: 0.0896, d2.loss_bbox: 0.2273, d3.loss_cls: 0.0780, d3.loss_bbox: 0.2249, d4.loss_cls: 0.0754, d4.loss_bbox: 0.2136, loss: 2.0342, grad_norm: 17.7644
2025-06-11 06:11:54,867 - mmdet - INFO - Epoch [4][1150/3517]	lr: 1.001e-04, eta: 4:54:24, time: 1.848, data_time: 0.052, memory: 32518, loss_cls: 0.0725, loss_bbox: 0.2108, d0.loss_cls: 0.1672, d0.loss_bbox: 0.3233, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2444, d2.loss_cls: 0.0880, d2.loss_bbox: 0.2253, d3.loss_cls: 0.0776, d3.loss_bbox: 0.2227, d4.loss_cls: 0.0745, d4.loss_bbox: 0.2110, loss: 2.0238, grad_norm: 16.6054
2025-06-11 06:13:27,796 - mmdet - INFO - Epoch [4][1200/3517]	lr: 1.001e-04, eta: 4:52:49, time: 1.859, data_time: 0.054, memory: 32518, loss_cls: 0.0732, loss_bbox: 0.2093, d0.loss_cls: 0.1639, d0.loss_bbox: 0.3277, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2473, d2.loss_cls: 0.0918, d2.loss_bbox: 0.2248, d3.loss_cls: 0.0797, d3.loss_bbox: 0.2207, d4.loss_cls: 0.0752, d4.loss_bbox: 0.2098, loss: 2.0313, grad_norm: 18.3316
2025-06-11 06:15:00,343 - mmdet - INFO - Epoch [4][1250/3517]	lr: 1.001e-04, eta: 4:51:14, time: 1.851, data_time: 0.053, memory: 32518, loss_cls: 0.0709, loss_bbox: 0.2032, d0.loss_cls: 0.1622, d0.loss_bbox: 0.3218, d1.loss_cls: 0.1036, d1.loss_bbox: 0.2446, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2208, d3.loss_cls: 0.0753, d3.loss_bbox: 0.2161, d4.loss_cls: 0.0728, d4.loss_bbox: 0.2045, loss: 1.9817, grad_norm: 22.0638
2025-06-11 06:16:32,814 - mmdet - INFO - Epoch [4][1300/3517]	lr: 1.001e-04, eta: 4:49:39, time: 1.849, data_time: 0.050, memory: 32518, loss_cls: 0.0698, loss_bbox: 0.2091, d0.loss_cls: 0.1660, d0.loss_bbox: 0.3274, d1.loss_cls: 0.1035, d1.loss_bbox: 0.2445, d2.loss_cls: 0.0858, d2.loss_bbox: 0.2228, d3.loss_cls: 0.0745, d3.loss_bbox: 0.2204, d4.loss_cls: 0.0720, d4.loss_bbox: 0.2105, loss: 2.0064, grad_norm: 26.3420
2025-06-11 06:18:05,855 - mmdet - INFO - Epoch [4][1350/3517]	lr: 1.001e-04, eta: 4:48:04, time: 1.861, data_time: 0.053, memory: 32518, loss_cls: 0.0695, loss_bbox: 0.2091, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3215, d1.loss_cls: 0.1030, d1.loss_bbox: 0.2438, d2.loss_cls: 0.0856, d2.loss_bbox: 0.2241, d3.loss_cls: 0.0749, d3.loss_bbox: 0.2197, d4.loss_cls: 0.0703, d4.loss_bbox: 0.2107, loss: 1.9954, grad_norm: 29.1931
2025-06-11 06:19:38,568 - mmdet - INFO - Epoch [4][1400/3517]	lr: 1.001e-04, eta: 4:46:29, time: 1.854, data_time: 0.055, memory: 32518, loss_cls: 0.0732, loss_bbox: 0.2065, d0.loss_cls: 0.1634, d0.loss_bbox: 0.3260, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0878, d2.loss_bbox: 0.2218, d3.loss_cls: 0.0770, d3.loss_bbox: 0.2176, d4.loss_cls: 0.0743, d4.loss_bbox: 0.2080, loss: 2.0067, grad_norm: 50.0735
2025-06-11 06:21:11,606 - mmdet - INFO - Epoch [4][1450/3517]	lr: 1.001e-04, eta: 4:44:55, time: 1.861, data_time: 0.059, memory: 32518, loss_cls: 0.0668, loss_bbox: 0.2068, d0.loss_cls: 0.1588, d0.loss_bbox: 0.3248, d1.loss_cls: 0.0978, d1.loss_bbox: 0.2421, d2.loss_cls: 0.0815, d2.loss_bbox: 0.2214, d3.loss_cls: 0.0716, d3.loss_bbox: 0.2170, d4.loss_cls: 0.0679, d4.loss_bbox: 0.2083, loss: 1.9646, grad_norm: 33.2287
2025-06-11 06:22:45,252 - mmdet - INFO - Epoch [4][1500/3517]	lr: 1.001e-04, eta: 4:43:21, time: 1.873, data_time: 0.061, memory: 32518, loss_cls: 0.0720, loss_bbox: 0.2116, d0.loss_cls: 0.1676, d0.loss_bbox: 0.3292, d1.loss_cls: 0.1056, d1.loss_bbox: 0.2498, d2.loss_cls: 0.0893, d2.loss_bbox: 0.2264, d3.loss_cls: 0.0775, d3.loss_bbox: 0.2233, d4.loss_cls: 0.0739, d4.loss_bbox: 0.2123, loss: 2.0385, grad_norm: 25.2756
2025-06-11 06:24:22,114 - mmdet - INFO - Epoch [4][1550/3517]	lr: 1.001e-04, eta: 4:41:49, time: 1.937, data_time: 0.070, memory: 32518, loss_cls: 0.0696, loss_bbox: 0.2074, d0.loss_cls: 0.1630, d0.loss_bbox: 0.3265, d1.loss_cls: 0.1024, d1.loss_bbox: 0.2459, d2.loss_cls: 0.0835, d2.loss_bbox: 0.2224, d3.loss_cls: 0.0728, d3.loss_bbox: 0.2193, d4.loss_cls: 0.0706, d4.loss_bbox: 0.2087, loss: 1.9920, grad_norm: 136.7836
2025-06-11 06:25:55,633 - mmdet - INFO - Epoch [4][1600/3517]	lr: 1.001e-04, eta: 4:40:15, time: 1.870, data_time: 0.059, memory: 32518, loss_cls: 0.0666, loss_bbox: 0.2030, d0.loss_cls: 0.1636, d0.loss_bbox: 0.3210, d1.loss_cls: 0.1022, d1.loss_bbox: 0.2401, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2173, d3.loss_cls: 0.0734, d3.loss_bbox: 0.2133, d4.loss_cls: 0.0684, d4.loss_bbox: 0.2041, loss: 1.9587, grad_norm: 23.7530
2025-06-11 06:27:29,076 - mmdet - INFO - Epoch [4][1650/3517]	lr: 1.001e-04, eta: 4:38:40, time: 1.869, data_time: 0.070, memory: 32518, loss_cls: 0.0721, loss_bbox: 0.2062, d0.loss_cls: 0.1636, d0.loss_bbox: 0.3212, d1.loss_cls: 0.1044, d1.loss_bbox: 0.2406, d2.loss_cls: 0.0865, d2.loss_bbox: 0.2216, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2179, d4.loss_cls: 0.0735, d4.loss_bbox: 0.2066, loss: 1.9898, grad_norm: 126.9698
2025-06-11 06:29:02,004 - mmdet - INFO - Epoch [4][1700/3517]	lr: 1.001e-04, eta: 4:37:06, time: 1.859, data_time: 0.056, memory: 32518, loss_cls: 0.0692, loss_bbox: 0.2012, d0.loss_cls: 0.1584, d0.loss_bbox: 0.3205, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2390, d2.loss_cls: 0.0849, d2.loss_bbox: 0.2174, d3.loss_cls: 0.0751, d3.loss_bbox: 0.2148, d4.loss_cls: 0.0720, d4.loss_bbox: 0.2020, loss: 1.9587, grad_norm: 18.1189
2025-06-11 06:30:35,485 - mmdet - INFO - Epoch [4][1750/3517]	lr: 1.001e-04, eta: 4:35:31, time: 1.870, data_time: 0.059, memory: 32518, loss_cls: 0.0728, loss_bbox: 0.2104, d0.loss_cls: 0.1707, d0.loss_bbox: 0.3264, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2484, d2.loss_cls: 0.0900, d2.loss_bbox: 0.2250, d3.loss_cls: 0.0779, d3.loss_bbox: 0.2218, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2111, loss: 2.0371, grad_norm: 141.1324
2025-06-11 06:32:09,629 - mmdet - INFO - Epoch [4][1800/3517]	lr: 1.001e-04, eta: 4:33:58, time: 1.883, data_time: 0.071, memory: 32518, loss_cls: 0.0738, loss_bbox: 0.2035, d0.loss_cls: 0.1651, d0.loss_bbox: 0.3151, d1.loss_cls: 0.1104, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0936, d2.loss_bbox: 0.2175, d3.loss_cls: 0.0787, d3.loss_bbox: 0.2159, d4.loss_cls: 0.0759, d4.loss_bbox: 0.2048, loss: 1.9954, grad_norm: 31.9381
2025-06-11 06:33:42,903 - mmdet - INFO - Epoch [4][1850/3517]	lr: 1.001e-04, eta: 4:32:23, time: 1.866, data_time: 0.058, memory: 32518, loss_cls: 0.0706, loss_bbox: 0.2043, d0.loss_cls: 0.1635, d0.loss_bbox: 0.3202, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2438, d2.loss_cls: 0.0890, d2.loss_bbox: 0.2205, d3.loss_cls: 0.0760, d3.loss_bbox: 0.2176, d4.loss_cls: 0.0726, d4.loss_bbox: 0.2052, loss: 1.9878, grad_norm: 132.5093
2025-06-11 06:35:17,107 - mmdet - INFO - Epoch [4][1900/3517]	lr: 1.001e-04, eta: 4:30:50, time: 1.884, data_time: 0.060, memory: 32518, loss_cls: 0.0730, loss_bbox: 0.2051, d0.loss_cls: 0.1701, d0.loss_bbox: 0.3305, d1.loss_cls: 0.1096, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0939, d2.loss_bbox: 0.2212, d3.loss_cls: 0.0792, d3.loss_bbox: 0.2175, d4.loss_cls: 0.0747, d4.loss_bbox: 0.2066, loss: 2.0266, grad_norm: 23.0434
2025-06-11 06:36:50,400 - mmdet - INFO - Epoch [4][1950/3517]	lr: 1.001e-04, eta: 4:29:15, time: 1.866, data_time: 0.052, memory: 32518, loss_cls: 0.0745, loss_bbox: 0.2106, d0.loss_cls: 0.1650, d0.loss_bbox: 0.3290, d1.loss_cls: 0.1095, d1.loss_bbox: 0.2467, d2.loss_cls: 0.0921, d2.loss_bbox: 0.2252, d3.loss_cls: 0.0805, d3.loss_bbox: 0.2223, d4.loss_cls: 0.0763, d4.loss_bbox: 0.2117, loss: 2.0432, grad_norm: 50.1767
2025-06-11 06:38:23,329 - mmdet - INFO - Epoch [4][2000/3517]	lr: 1.001e-04, eta: 4:27:41, time: 1.859, data_time: 0.063, memory: 32518, loss_cls: 0.0686, loss_bbox: 0.2033, d0.loss_cls: 0.1678, d0.loss_bbox: 0.3212, d1.loss_cls: 0.1071, d1.loss_bbox: 0.2416, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2181, d3.loss_cls: 0.0771, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0714, d4.loss_bbox: 0.2036, loss: 1.9828, grad_norm: 23.0693
2025-06-11 06:39:57,277 - mmdet - INFO - Epoch [4][2050/3517]	lr: 1.001e-04, eta: 4:26:07, time: 1.879, data_time: 0.059, memory: 32518, loss_cls: 0.0692, loss_bbox: 0.2053, d0.loss_cls: 0.1595, d0.loss_bbox: 0.3259, d1.loss_cls: 0.1034, d1.loss_bbox: 0.2424, d2.loss_cls: 0.0876, d2.loss_bbox: 0.2209, d3.loss_cls: 0.0757, d3.loss_bbox: 0.2167, d4.loss_cls: 0.0713, d4.loss_bbox: 0.2056, loss: 1.9835, grad_norm: 21.3040
2025-06-11 06:41:31,326 - mmdet - INFO - Epoch [4][2100/3517]	lr: 1.001e-04, eta: 4:24:33, time: 1.881, data_time: 0.056, memory: 32518, loss_cls: 0.0654, loss_bbox: 0.2055, d0.loss_cls: 0.1577, d0.loss_bbox: 0.3219, d1.loss_cls: 0.1025, d1.loss_bbox: 0.2425, d2.loss_cls: 0.0834, d2.loss_bbox: 0.2201, d3.loss_cls: 0.0718, d3.loss_bbox: 0.2157, d4.loss_cls: 0.0676, d4.loss_bbox: 0.2058, loss: 1.9597, grad_norm: 25.0606
2025-06-11 06:43:05,017 - mmdet - INFO - Epoch [4][2150/3517]	lr: 1.001e-04, eta: 4:22:59, time: 1.874, data_time: 0.056, memory: 32518, loss_cls: 0.0703, loss_bbox: 0.2125, d0.loss_cls: 0.1737, d0.loss_bbox: 0.3338, d1.loss_cls: 0.1080, d1.loss_bbox: 0.2526, d2.loss_cls: 0.0887, d2.loss_bbox: 0.2274, d3.loss_cls: 0.0753, d3.loss_bbox: 0.2247, d4.loss_cls: 0.0722, d4.loss_bbox: 0.2129, loss: 2.0522, grad_norm: 38.5800
2025-06-11 06:44:38,804 - mmdet - INFO - Epoch [4][2200/3517]	lr: 1.001e-04, eta: 4:21:25, time: 1.876, data_time: 0.057, memory: 32518, loss_cls: 0.0679, loss_bbox: 0.2056, d0.loss_cls: 0.1621, d0.loss_bbox: 0.3286, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2431, d2.loss_cls: 0.0839, d2.loss_bbox: 0.2178, d3.loss_cls: 0.0729, d3.loss_bbox: 0.2146, d4.loss_cls: 0.0699, d4.loss_bbox: 0.2058, loss: 1.9737, grad_norm: 27.0654
2025-06-11 06:46:12,817 - mmdet - INFO - Epoch [4][2250/3517]	lr: 1.001e-04, eta: 4:19:51, time: 1.880, data_time: 0.057, memory: 32518, loss_cls: 0.0695, loss_bbox: 0.2058, d0.loss_cls: 0.1615, d0.loss_bbox: 0.3252, d1.loss_cls: 0.1013, d1.loss_bbox: 0.2453, d2.loss_cls: 0.0858, d2.loss_bbox: 0.2213, d3.loss_cls: 0.0749, d3.loss_bbox: 0.2180, d4.loss_cls: 0.0717, d4.loss_bbox: 0.2068, loss: 1.9873, grad_norm: 111.8160
2025-06-11 06:47:45,868 - mmdet - INFO - Epoch [4][2300/3517]	lr: 1.001e-04, eta: 4:18:16, time: 1.861, data_time: 0.052, memory: 32518, loss_cls: 0.0712, loss_bbox: 0.2086, d0.loss_cls: 0.1662, d0.loss_bbox: 0.3373, d1.loss_cls: 0.1025, d1.loss_bbox: 0.2514, d2.loss_cls: 0.0880, d2.loss_bbox: 0.2240, d3.loss_cls: 0.0765, d3.loss_bbox: 0.2188, d4.loss_cls: 0.0733, d4.loss_bbox: 0.2084, loss: 2.0261, grad_norm: 24.6086
2025-06-11 06:49:19,604 - mmdet - INFO - Epoch [4][2350/3517]	lr: 1.001e-04, eta: 4:16:42, time: 1.875, data_time: 0.055, memory: 32518, loss_cls: 0.0656, loss_bbox: 0.2040, d0.loss_cls: 0.1617, d0.loss_bbox: 0.3199, d1.loss_cls: 0.1003, d1.loss_bbox: 0.2395, d2.loss_cls: 0.0817, d2.loss_bbox: 0.2176, d3.loss_cls: 0.0714, d3.loss_bbox: 0.2139, d4.loss_cls: 0.0672, d4.loss_bbox: 0.2051, loss: 1.9478, grad_norm: 111.3178
2025-06-11 06:50:53,185 - mmdet - INFO - Epoch [4][2400/3517]	lr: 1.001e-04, eta: 4:15:08, time: 1.872, data_time: 0.060, memory: 32518, loss_cls: 0.0690, loss_bbox: 0.2090, d0.loss_cls: 0.1707, d0.loss_bbox: 0.3265, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2465, d2.loss_cls: 0.0893, d2.loss_bbox: 0.2231, d3.loss_cls: 0.0763, d3.loss_bbox: 0.2192, d4.loss_cls: 0.0718, d4.loss_bbox: 0.2088, loss: 2.0168, grad_norm: 25.0475
2025-06-11 06:52:27,678 - mmdet - INFO - Epoch [4][2450/3517]	lr: 1.001e-04, eta: 4:13:35, time: 1.890, data_time: 0.065, memory: 32518, loss_cls: 0.0620, loss_bbox: 0.1999, d0.loss_cls: 0.1633, d0.loss_bbox: 0.3136, d1.loss_cls: 0.1001, d1.loss_bbox: 0.2368, d2.loss_cls: 0.0815, d2.loss_bbox: 0.2153, d3.loss_cls: 0.0686, d3.loss_bbox: 0.2113, d4.loss_cls: 0.0637, d4.loss_bbox: 0.2011, loss: 1.9170, grad_norm: 18.4385
2025-06-11 06:54:01,696 - mmdet - INFO - Epoch [4][2500/3517]	lr: 1.001e-04, eta: 4:12:01, time: 1.880, data_time: 0.055, memory: 32518, loss_cls: 0.0678, loss_bbox: 0.2066, d0.loss_cls: 0.1651, d0.loss_bbox: 0.3216, d1.loss_cls: 0.1046, d1.loss_bbox: 0.2414, d2.loss_cls: 0.0870, d2.loss_bbox: 0.2213, d3.loss_cls: 0.0744, d3.loss_bbox: 0.2191, d4.loss_cls: 0.0701, d4.loss_bbox: 0.2074, loss: 1.9866, grad_norm: 19.3204
2025-06-11 06:55:35,174 - mmdet - INFO - Epoch [4][2550/3517]	lr: 1.001e-04, eta: 4:10:27, time: 1.870, data_time: 0.056, memory: 32518, loss_cls: 0.0703, loss_bbox: 0.2065, d0.loss_cls: 0.1665, d0.loss_bbox: 0.3247, d1.loss_cls: 0.1045, d1.loss_bbox: 0.2432, d2.loss_cls: 0.0873, d2.loss_bbox: 0.2217, d3.loss_cls: 0.0751, d3.loss_bbox: 0.2176, d4.loss_cls: 0.0721, d4.loss_bbox: 0.2079, loss: 1.9975, grad_norm: 18.7047
2025-06-11 06:57:09,077 - mmdet - INFO - Epoch [4][2600/3517]	lr: 1.001e-04, eta: 4:08:53, time: 1.878, data_time: 0.059, memory: 32518, loss_cls: 0.0634, loss_bbox: 0.1968, d0.loss_cls: 0.1577, d0.loss_bbox: 0.3180, d1.loss_cls: 0.0976, d1.loss_bbox: 0.2366, d2.loss_cls: 0.0833, d2.loss_bbox: 0.2122, d3.loss_cls: 0.0693, d3.loss_bbox: 0.2091, d4.loss_cls: 0.0651, d4.loss_bbox: 0.1985, loss: 1.9077, grad_norm: 16.3564
2025-06-11 06:58:43,363 - mmdet - INFO - Epoch [4][2650/3517]	lr: 1.001e-04, eta: 4:07:19, time: 1.886, data_time: 0.058, memory: 32518, loss_cls: 0.0685, loss_bbox: 0.2040, d0.loss_cls: 0.1633, d0.loss_bbox: 0.3263, d1.loss_cls: 0.1043, d1.loss_bbox: 0.2437, d2.loss_cls: 0.0852, d2.loss_bbox: 0.2203, d3.loss_cls: 0.0735, d3.loss_bbox: 0.2160, d4.loss_cls: 0.0714, d4.loss_bbox: 0.2053, loss: 1.9820, grad_norm: 15.3552
2025-06-11 07:00:17,488 - mmdet - INFO - Epoch [4][2700/3517]	lr: 1.001e-04, eta: 4:05:45, time: 1.882, data_time: 0.062, memory: 32518, loss_cls: 0.0671, loss_bbox: 0.1990, d0.loss_cls: 0.1645, d0.loss_bbox: 0.3183, d1.loss_cls: 0.1016, d1.loss_bbox: 0.2347, d2.loss_cls: 0.0825, d2.loss_bbox: 0.2144, d3.loss_cls: 0.0716, d3.loss_bbox: 0.2107, d4.loss_cls: 0.0692, d4.loss_bbox: 0.2003, loss: 1.9340, grad_norm: 16.0780
2025-06-11 07:01:51,025 - mmdet - INFO - Epoch [4][2750/3517]	lr: 1.001e-04, eta: 4:04:11, time: 1.871, data_time: 0.055, memory: 32518, loss_cls: 0.0664, loss_bbox: 0.1979, d0.loss_cls: 0.1582, d0.loss_bbox: 0.3132, d1.loss_cls: 0.1015, d1.loss_bbox: 0.2345, d2.loss_cls: 0.0831, d2.loss_bbox: 0.2126, d3.loss_cls: 0.0714, d3.loss_bbox: 0.2089, d4.loss_cls: 0.0678, d4.loss_bbox: 0.1995, loss: 1.9150, grad_norm: 19.4244
2025-06-11 07:03:24,460 - mmdet - INFO - Epoch [4][2800/3517]	lr: 1.001e-04, eta: 4:02:37, time: 1.869, data_time: 0.058, memory: 32518, loss_cls: 0.0707, loss_bbox: 0.2078, d0.loss_cls: 0.1624, d0.loss_bbox: 0.3228, d1.loss_cls: 0.1030, d1.loss_bbox: 0.2455, d2.loss_cls: 0.0872, d2.loss_bbox: 0.2217, d3.loss_cls: 0.0763, d3.loss_bbox: 0.2188, d4.loss_cls: 0.0728, d4.loss_bbox: 0.2085, loss: 1.9977, grad_norm: 15.6982
2025-06-11 07:05:01,532 - mmdet - INFO - Epoch [4][2850/3517]	lr: 1.001e-04, eta: 4:01:05, time: 1.941, data_time: 0.061, memory: 32518, loss_cls: 0.0668, loss_bbox: 0.2063, d0.loss_cls: 0.1611, d0.loss_bbox: 0.3246, d1.loss_cls: 0.1037, d1.loss_bbox: 0.2417, d2.loss_cls: 0.0856, d2.loss_bbox: 0.2193, d3.loss_cls: 0.0727, d3.loss_bbox: 0.2174, d4.loss_cls: 0.0680, d4.loss_bbox: 0.2076, loss: 1.9749, grad_norm: 18.9263
2025-06-11 07:06:35,299 - mmdet - INFO - Epoch [4][2900/3517]	lr: 1.001e-04, eta: 3:59:31, time: 1.875, data_time: 0.049, memory: 32518, loss_cls: 0.0713, loss_bbox: 0.2088, d0.loss_cls: 0.1625, d0.loss_bbox: 0.3264, d1.loss_cls: 0.1067, d1.loss_bbox: 0.2454, d2.loss_cls: 0.0883, d2.loss_bbox: 0.2239, d3.loss_cls: 0.0769, d3.loss_bbox: 0.2213, d4.loss_cls: 0.0729, d4.loss_bbox: 0.2100, loss: 2.0145, grad_norm: 17.0319
2025-06-11 07:08:09,585 - mmdet - INFO - Epoch [4][2950/3517]	lr: 1.001e-04, eta: 3:57:57, time: 1.886, data_time: 0.059, memory: 32518, loss_cls: 0.0669, loss_bbox: 0.2005, d0.loss_cls: 0.1638, d0.loss_bbox: 0.3208, d1.loss_cls: 0.1016, d1.loss_bbox: 0.2380, d2.loss_cls: 0.0841, d2.loss_bbox: 0.2163, d3.loss_cls: 0.0723, d3.loss_bbox: 0.2132, d4.loss_cls: 0.0692, d4.loss_bbox: 0.2018, loss: 1.9486, grad_norm: 39.1683
2025-06-11 07:09:43,364 - mmdet - INFO - Epoch [4][3000/3517]	lr: 1.001e-04, eta: 3:56:23, time: 1.876, data_time: 0.057, memory: 32518, loss_cls: 0.0725, loss_bbox: 0.2044, d0.loss_cls: 0.1658, d0.loss_bbox: 0.3201, d1.loss_cls: 0.1033, d1.loss_bbox: 0.2429, d2.loss_cls: 0.0875, d2.loss_bbox: 0.2196, d3.loss_cls: 0.0774, d3.loss_bbox: 0.2153, d4.loss_cls: 0.0745, d4.loss_bbox: 0.2049, loss: 1.9884, grad_norm: 16.8471
2025-06-11 07:11:17,306 - mmdet - INFO - Epoch [4][3050/3517]	lr: 1.001e-04, eta: 3:54:49, time: 1.879, data_time: 0.057, memory: 32518, loss_cls: 0.0695, loss_bbox: 0.2011, d0.loss_cls: 0.1599, d0.loss_bbox: 0.3152, d1.loss_cls: 0.1026, d1.loss_bbox: 0.2380, d2.loss_cls: 0.0855, d2.loss_bbox: 0.2163, d3.loss_cls: 0.0758, d3.loss_bbox: 0.2127, d4.loss_cls: 0.0714, d4.loss_bbox: 0.2024, loss: 1.9505, grad_norm: 38.0849
2025-06-11 07:12:50,438 - mmdet - INFO - Epoch [4][3100/3517]	lr: 1.001e-04, eta: 3:53:15, time: 1.863, data_time: 0.056, memory: 32518, loss_cls: 0.0702, loss_bbox: 0.2023, d0.loss_cls: 0.1590, d0.loss_bbox: 0.3156, d1.loss_cls: 0.1027, d1.loss_bbox: 0.2386, d2.loss_cls: 0.0859, d2.loss_bbox: 0.2171, d3.loss_cls: 0.0762, d3.loss_bbox: 0.2133, d4.loss_cls: 0.0724, d4.loss_bbox: 0.2037, loss: 1.9571, grad_norm: 18.0035
2025-06-11 07:14:23,897 - mmdet - INFO - Epoch [4][3150/3517]	lr: 1.001e-04, eta: 3:51:41, time: 1.869, data_time: 0.054, memory: 32518, loss_cls: 0.0694, loss_bbox: 0.2094, d0.loss_cls: 0.1668, d0.loss_bbox: 0.3257, d1.loss_cls: 0.1074, d1.loss_bbox: 0.2451, d2.loss_cls: 0.0894, d2.loss_bbox: 0.2236, d3.loss_cls: 0.0784, d3.loss_bbox: 0.2208, d4.loss_cls: 0.0727, d4.loss_bbox: 0.2101, loss: 2.0188, grad_norm: 22.7262
2025-06-11 07:15:57,870 - mmdet - INFO - Epoch [4][3200/3517]	lr: 1.001e-04, eta: 3:50:07, time: 1.879, data_time: 0.059, memory: 32518, loss_cls: 0.0692, loss_bbox: 0.2031, d0.loss_cls: 0.1643, d0.loss_bbox: 0.3188, d1.loss_cls: 0.1045, d1.loss_bbox: 0.2412, d2.loss_cls: 0.0886, d2.loss_bbox: 0.2172, d3.loss_cls: 0.0756, d3.loss_bbox: 0.2152, d4.loss_cls: 0.0708, d4.loss_bbox: 0.2040, loss: 1.9725, grad_norm: 249.6022
2025-06-11 07:17:31,674 - mmdet - INFO - Epoch [4][3250/3517]	lr: 1.001e-04, eta: 3:48:33, time: 1.876, data_time: 0.060, memory: 32518, loss_cls: 0.0720, loss_bbox: 0.2108, d0.loss_cls: 0.1623, d0.loss_bbox: 0.3251, d1.loss_cls: 0.1058, d1.loss_bbox: 0.2474, d2.loss_cls: 0.0891, d2.loss_bbox: 0.2256, d3.loss_cls: 0.0789, d3.loss_bbox: 0.2208, d4.loss_cls: 0.0738, d4.loss_bbox: 0.2121, loss: 2.0236, grad_norm: 16.3421
2025-06-11 07:19:05,498 - mmdet - INFO - Epoch [4][3300/3517]	lr: 1.001e-04, eta: 3:46:59, time: 1.876, data_time: 0.058, memory: 32518, loss_cls: 0.0639, loss_bbox: 0.2026, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3156, d1.loss_cls: 0.0981, d1.loss_bbox: 0.2385, d2.loss_cls: 0.0802, d2.loss_bbox: 0.2174, d3.loss_cls: 0.0680, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0651, d4.loss_bbox: 0.2042, loss: 1.9250, grad_norm: 13.5171
2025-06-11 07:20:39,404 - mmdet - INFO - Epoch [4][3350/3517]	lr: 1.001e-04, eta: 3:45:25, time: 1.878, data_time: 0.065, memory: 32518, loss_cls: 0.0672, loss_bbox: 0.2046, d0.loss_cls: 0.1597, d0.loss_bbox: 0.3257, d1.loss_cls: 0.1022, d1.loss_bbox: 0.2415, d2.loss_cls: 0.0829, d2.loss_bbox: 0.2202, d3.loss_cls: 0.0736, d3.loss_bbox: 0.2161, d4.loss_cls: 0.0687, d4.loss_bbox: 0.2061, loss: 1.9684, grad_norm: 18.9867
2025-06-11 07:22:12,799 - mmdet - INFO - Epoch [4][3400/3517]	lr: 1.001e-04, eta: 3:43:51, time: 1.868, data_time: 0.056, memory: 32518, loss_cls: 0.0700, loss_bbox: 0.2055, d0.loss_cls: 0.1637, d0.loss_bbox: 0.3266, d1.loss_cls: 0.1066, d1.loss_bbox: 0.2434, d2.loss_cls: 0.0872, d2.loss_bbox: 0.2217, d3.loss_cls: 0.0761, d3.loss_bbox: 0.2181, d4.loss_cls: 0.0720, d4.loss_bbox: 0.2072, loss: 1.9981, grad_norm: 25.6775
2025-06-11 07:23:45,756 - mmdet - INFO - Epoch [4][3450/3517]	lr: 1.001e-04, eta: 3:42:17, time: 1.859, data_time: 0.054, memory: 32518, loss_cls: 0.0780, loss_bbox: 0.2163, d0.loss_cls: 0.1623, d0.loss_bbox: 0.3316, d1.loss_cls: 0.1064, d1.loss_bbox: 0.2546, d2.loss_cls: 0.0937, d2.loss_bbox: 0.2314, d3.loss_cls: 0.0832, d3.loss_bbox: 0.2283, d4.loss_cls: 0.0788, d4.loss_bbox: 0.2177, loss: 2.0823, grad_norm: 14.6537
2025-06-11 07:25:19,621 - mmdet - INFO - Epoch [4][3500/3517]	lr: 1.001e-04, eta: 3:40:43, time: 1.877, data_time: 0.059, memory: 32518, loss_cls: 0.0677, loss_bbox: 0.2072, d0.loss_cls: 0.1585, d0.loss_bbox: 0.3253, d1.loss_cls: 0.0992, d1.loss_bbox: 0.2435, d2.loss_cls: 0.0828, d2.loss_bbox: 0.2220, d3.loss_cls: 0.0704, d3.loss_bbox: 0.2191, d4.loss_cls: 0.0686, d4.loss_bbox: 0.2085, loss: 1.9726, grad_norm: 14.2791
2025-06-11 07:25:51,631 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-06-11 07:51:43,012 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 07:51:43,013 - mmdet - INFO - Epoch(val) [4][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7948, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8836, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9107, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9235, pts_bbox_NuScenes/car_trans_err: 0.1761, pts_bbox_NuScenes/car_scale_err: 0.1495, pts_bbox_NuScenes/car_orient_err: 0.0427, pts_bbox_NuScenes/car_vel_err: 0.3014, pts_bbox_NuScenes/car_attr_err: 0.1891, pts_bbox_NuScenes/mATE: 0.2884, pts_bbox_NuScenes/mASE: 0.2582, pts_bbox_NuScenes/mAOE: 0.2685, pts_bbox_NuScenes/mAVE: 0.2844, pts_bbox_NuScenes/mAAE: 0.1801, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4249, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6266, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7243, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7595, pts_bbox_NuScenes/truck_trans_err: 0.3382, pts_bbox_NuScenes/truck_scale_err: 0.1946, pts_bbox_NuScenes/truck_orient_err: 0.0426, pts_bbox_NuScenes/truck_vel_err: 0.2828, pts_bbox_NuScenes/truck_attr_err: 0.2021, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0564, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2016, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3927, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4635, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6475, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4320, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7777, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1067, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2866, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5115, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7326, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8961, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9261, pts_bbox_NuScenes/bus_trans_err: 0.3420, pts_bbox_NuScenes/bus_scale_err: 0.1831, pts_bbox_NuScenes/bus_orient_err: 0.0406, pts_bbox_NuScenes/bus_vel_err: 0.5216, pts_bbox_NuScenes/bus_attr_err: 0.2490, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1772, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4331, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5963, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6818, pts_bbox_NuScenes/trailer_trans_err: 0.4776, pts_bbox_NuScenes/trailer_scale_err: 0.2057, pts_bbox_NuScenes/trailer_orient_err: 0.6014, pts_bbox_NuScenes/trailer_vel_err: 0.2379, pts_bbox_NuScenes/trailer_attr_err: 0.1727, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5954, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7006, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7502, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7653, pts_bbox_NuScenes/barrier_trans_err: 0.2211, pts_bbox_NuScenes/barrier_scale_err: 0.2881, pts_bbox_NuScenes/barrier_orient_err: 0.0447, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6384, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7749, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.8028, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8105, pts_bbox_NuScenes/motorcycle_trans_err: 0.2164, pts_bbox_NuScenes/motorcycle_scale_err: 0.2486, pts_bbox_NuScenes/motorcycle_orient_err: 0.2272, pts_bbox_NuScenes/motorcycle_vel_err: 0.3918, pts_bbox_NuScenes/motorcycle_attr_err: 0.2289, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5499, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.6010, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6124, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6230, pts_bbox_NuScenes/bicycle_trans_err: 0.1739, pts_bbox_NuScenes/bicycle_scale_err: 0.2642, pts_bbox_NuScenes/bicycle_orient_err: 0.3217, pts_bbox_NuScenes/bicycle_vel_err: 0.2005, pts_bbox_NuScenes/bicycle_attr_err: 0.0037, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8176, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8582, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8787, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8902, pts_bbox_NuScenes/pedestrian_trans_err: 0.1511, pts_bbox_NuScenes/pedestrian_scale_err: 0.2928, pts_bbox_NuScenes/pedestrian_orient_err: 0.3179, pts_bbox_NuScenes/pedestrian_vel_err: 0.2322, pts_bbox_NuScenes/pedestrian_attr_err: 0.1086, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7299, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7669, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7910, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8124, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1405, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3240, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7081, pts_bbox_NuScenes/mAP: 0.6722
2025-06-11 07:53:27,743 - mmdet - INFO - Epoch [5][50/3517]	lr: 5.015e-05, eta: 3:38:25, time: 2.022, data_time: 0.209, memory: 32518, loss_cls: 0.0674, loss_bbox: 0.2034, d0.loss_cls: 0.1608, d0.loss_bbox: 0.3188, d1.loss_cls: 0.1022, d1.loss_bbox: 0.2405, d2.loss_cls: 0.0848, d2.loss_bbox: 0.2186, d3.loss_cls: 0.0743, d3.loss_bbox: 0.2153, d4.loss_cls: 0.0690, d4.loss_bbox: 0.2056, loss: 1.9606, grad_norm: 14.2265
2025-06-11 07:55:01,425 - mmdet - INFO - Epoch [5][100/3517]	lr: 5.015e-05, eta: 3:36:51, time: 1.874, data_time: 0.064, memory: 32518, loss_cls: 0.0679, loss_bbox: 0.2026, d0.loss_cls: 0.1595, d0.loss_bbox: 0.3243, d1.loss_cls: 0.1029, d1.loss_bbox: 0.2431, d2.loss_cls: 0.0846, d2.loss_bbox: 0.2185, d3.loss_cls: 0.0730, d3.loss_bbox: 0.2141, d4.loss_cls: 0.0696, d4.loss_bbox: 0.2047, loss: 1.9648, grad_norm: 22.8184
2025-06-11 07:56:35,632 - mmdet - INFO - Epoch [5][150/3517]	lr: 5.015e-05, eta: 3:35:17, time: 1.884, data_time: 0.057, memory: 32518, loss_cls: 0.0697, loss_bbox: 0.2063, d0.loss_cls: 0.1575, d0.loss_bbox: 0.3122, d1.loss_cls: 0.0999, d1.loss_bbox: 0.2419, d2.loss_cls: 0.0835, d2.loss_bbox: 0.2225, d3.loss_cls: 0.0741, d3.loss_bbox: 0.2176, d4.loss_cls: 0.0718, d4.loss_bbox: 0.2072, loss: 1.9643, grad_norm: 16.0763
2025-06-11 07:58:09,977 - mmdet - INFO - Epoch [5][200/3517]	lr: 5.015e-05, eta: 3:33:43, time: 1.887, data_time: 0.057, memory: 32518, loss_cls: 0.0616, loss_bbox: 0.1967, d0.loss_cls: 0.1563, d0.loss_bbox: 0.3106, d1.loss_cls: 0.0967, d1.loss_bbox: 0.2323, d2.loss_cls: 0.0784, d2.loss_bbox: 0.2109, d3.loss_cls: 0.0664, d3.loss_bbox: 0.2071, d4.loss_cls: 0.0633, d4.loss_bbox: 0.1972, loss: 1.8773, grad_norm: 59.3561
2025-06-11 07:59:44,339 - mmdet - INFO - Epoch [5][250/3517]	lr: 5.015e-05, eta: 3:32:10, time: 1.887, data_time: 0.059, memory: 32518, loss_cls: 0.0645, loss_bbox: 0.2046, d0.loss_cls: 0.1578, d0.loss_bbox: 0.3177, d1.loss_cls: 0.0980, d1.loss_bbox: 0.2414, d2.loss_cls: 0.0802, d2.loss_bbox: 0.2215, d3.loss_cls: 0.0701, d3.loss_bbox: 0.2155, d4.loss_cls: 0.0663, d4.loss_bbox: 0.2068, loss: 1.9443, grad_norm: 13.9164
2025-06-11 08:01:18,204 - mmdet - INFO - Epoch [5][300/3517]	lr: 5.015e-05, eta: 3:30:36, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.0686, loss_bbox: 0.2020, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3170, d1.loss_cls: 0.0996, d1.loss_bbox: 0.2397, d2.loss_cls: 0.0835, d2.loss_bbox: 0.2191, d3.loss_cls: 0.0726, d3.loss_bbox: 0.2137, d4.loss_cls: 0.0699, d4.loss_bbox: 0.2028, loss: 1.9481, grad_norm: 23.1852
2025-06-11 08:02:51,379 - mmdet - INFO - Epoch [5][350/3517]	lr: 5.015e-05, eta: 3:29:02, time: 1.864, data_time: 0.050, memory: 32518, loss_cls: 0.0658, loss_bbox: 0.2049, d0.loss_cls: 0.1589, d0.loss_bbox: 0.3210, d1.loss_cls: 0.0997, d1.loss_bbox: 0.2446, d2.loss_cls: 0.0836, d2.loss_bbox: 0.2220, d3.loss_cls: 0.0722, d3.loss_bbox: 0.2159, d4.loss_cls: 0.0679, d4.loss_bbox: 0.2068, loss: 1.9633, grad_norm: 15.0553
2025-06-11 08:04:25,560 - mmdet - INFO - Epoch [5][400/3517]	lr: 5.015e-05, eta: 3:27:28, time: 1.884, data_time: 0.052, memory: 32518, loss_cls: 0.0627, loss_bbox: 0.1990, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3129, d1.loss_cls: 0.0958, d1.loss_bbox: 0.2370, d2.loss_cls: 0.0785, d2.loss_bbox: 0.2153, d3.loss_cls: 0.0681, d3.loss_bbox: 0.2099, d4.loss_cls: 0.0644, d4.loss_bbox: 0.2010, loss: 1.8976, grad_norm: 16.5719
2025-06-11 08:05:59,536 - mmdet - INFO - Epoch [5][450/3517]	lr: 5.015e-05, eta: 3:25:54, time: 1.879, data_time: 0.055, memory: 32518, loss_cls: 0.0663, loss_bbox: 0.2071, d0.loss_cls: 0.1563, d0.loss_bbox: 0.3226, d1.loss_cls: 0.0982, d1.loss_bbox: 0.2464, d2.loss_cls: 0.0817, d2.loss_bbox: 0.2252, d3.loss_cls: 0.0717, d3.loss_bbox: 0.2203, d4.loss_cls: 0.0677, d4.loss_bbox: 0.2098, loss: 1.9736, grad_norm: 25.8796
2025-06-11 08:07:33,711 - mmdet - INFO - Epoch [5][500/3517]	lr: 5.015e-05, eta: 3:24:21, time: 1.884, data_time: 0.053, memory: 32518, loss_cls: 0.0643, loss_bbox: 0.1940, d0.loss_cls: 0.1508, d0.loss_bbox: 0.3124, d1.loss_cls: 0.0951, d1.loss_bbox: 0.2326, d2.loss_cls: 0.0796, d2.loss_bbox: 0.2119, d3.loss_cls: 0.0683, d3.loss_bbox: 0.2066, d4.loss_cls: 0.0649, d4.loss_bbox: 0.1962, loss: 1.8767, grad_norm: 22.7423
2025-06-11 08:09:07,280 - mmdet - INFO - Epoch [5][550/3517]	lr: 5.015e-05, eta: 3:22:47, time: 1.871, data_time: 0.054, memory: 32518, loss_cls: 0.0663, loss_bbox: 0.2081, d0.loss_cls: 0.1621, d0.loss_bbox: 0.3228, d1.loss_cls: 0.1014, d1.loss_bbox: 0.2454, d2.loss_cls: 0.0844, d2.loss_bbox: 0.2244, d3.loss_cls: 0.0715, d3.loss_bbox: 0.2199, d4.loss_cls: 0.0682, d4.loss_bbox: 0.2103, loss: 1.9849, grad_norm: 23.5725
2025-06-11 08:10:40,783 - mmdet - INFO - Epoch [5][600/3517]	lr: 5.015e-05, eta: 3:21:13, time: 1.870, data_time: 0.050, memory: 32518, loss_cls: 0.0666, loss_bbox: 0.2044, d0.loss_cls: 0.1550, d0.loss_bbox: 0.3210, d1.loss_cls: 0.1004, d1.loss_bbox: 0.2423, d2.loss_cls: 0.0824, d2.loss_bbox: 0.2220, d3.loss_cls: 0.0719, d3.loss_bbox: 0.2163, d4.loss_cls: 0.0679, d4.loss_bbox: 0.2061, loss: 1.9565, grad_norm: 21.5068
2025-06-11 08:12:15,120 - mmdet - INFO - Epoch [5][650/3517]	lr: 5.015e-05, eta: 3:19:39, time: 1.887, data_time: 0.050, memory: 32518, loss_cls: 0.0627, loss_bbox: 0.1979, d0.loss_cls: 0.1594, d0.loss_bbox: 0.3165, d1.loss_cls: 0.0979, d1.loss_bbox: 0.2373, d2.loss_cls: 0.0803, d2.loss_bbox: 0.2151, d3.loss_cls: 0.0690, d3.loss_bbox: 0.2085, d4.loss_cls: 0.0636, d4.loss_bbox: 0.2004, loss: 1.9087, grad_norm: 20.3768
2025-06-11 08:13:49,560 - mmdet - INFO - Epoch [5][700/3517]	lr: 5.015e-05, eta: 3:18:06, time: 1.889, data_time: 0.049, memory: 32518, loss_cls: 0.0612, loss_bbox: 0.1941, d0.loss_cls: 0.1564, d0.loss_bbox: 0.3101, d1.loss_cls: 0.0955, d1.loss_bbox: 0.2296, d2.loss_cls: 0.0775, d2.loss_bbox: 0.2087, d3.loss_cls: 0.0661, d3.loss_bbox: 0.2054, d4.loss_cls: 0.0633, d4.loss_bbox: 0.1957, loss: 1.8635, grad_norm: 14.7429
2025-06-11 08:15:24,163 - mmdet - INFO - Epoch [5][750/3517]	lr: 5.015e-05, eta: 3:16:32, time: 1.892, data_time: 0.058, memory: 32518, loss_cls: 0.0692, loss_bbox: 0.2016, d0.loss_cls: 0.1631, d0.loss_bbox: 0.3227, d1.loss_cls: 0.1027, d1.loss_bbox: 0.2422, d2.loss_cls: 0.0851, d2.loss_bbox: 0.2193, d3.loss_cls: 0.0740, d3.loss_bbox: 0.2147, d4.loss_cls: 0.0707, d4.loss_bbox: 0.2040, loss: 1.9693, grad_norm: 25.4850
2025-06-11 08:16:57,651 - mmdet - INFO - Epoch [5][800/3517]	lr: 5.015e-05, eta: 3:14:58, time: 1.870, data_time: 0.053, memory: 32518, loss_cls: 0.0628, loss_bbox: 0.1980, d0.loss_cls: 0.1553, d0.loss_bbox: 0.3136, d1.loss_cls: 0.0971, d1.loss_bbox: 0.2363, d2.loss_cls: 0.0794, d2.loss_bbox: 0.2142, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2091, d4.loss_cls: 0.0655, d4.loss_bbox: 0.1994, loss: 1.8990, grad_norm: 16.4760
2025-06-11 08:18:32,076 - mmdet - INFO - Epoch [5][850/3517]	lr: 5.015e-05, eta: 3:13:25, time: 1.889, data_time: 0.058, memory: 32518, loss_cls: 0.0660, loss_bbox: 0.2023, d0.loss_cls: 0.1600, d0.loss_bbox: 0.3164, d1.loss_cls: 0.1012, d1.loss_bbox: 0.2373, d2.loss_cls: 0.0840, d2.loss_bbox: 0.2177, d3.loss_cls: 0.0722, d3.loss_bbox: 0.2133, d4.loss_cls: 0.0691, d4.loss_bbox: 0.2033, loss: 1.9427, grad_norm: 22.5394
2025-06-11 08:20:06,015 - mmdet - INFO - Epoch [5][900/3517]	lr: 5.015e-05, eta: 3:11:51, time: 1.879, data_time: 0.056, memory: 32518, loss_cls: 0.0638, loss_bbox: 0.2004, d0.loss_cls: 0.1622, d0.loss_bbox: 0.3140, d1.loss_cls: 0.0990, d1.loss_bbox: 0.2371, d2.loss_cls: 0.0823, d2.loss_bbox: 0.2147, d3.loss_cls: 0.0709, d3.loss_bbox: 0.2109, d4.loss_cls: 0.0670, d4.loss_bbox: 0.2017, loss: 1.9239, grad_norm: 26.4530
2025-06-11 08:21:40,088 - mmdet - INFO - Epoch [5][950/3517]	lr: 5.015e-05, eta: 3:10:17, time: 1.881, data_time: 0.053, memory: 32518, loss_cls: 0.0645, loss_bbox: 0.2007, d0.loss_cls: 0.1563, d0.loss_bbox: 0.3187, d1.loss_cls: 0.1015, d1.loss_bbox: 0.2377, d2.loss_cls: 0.0825, d2.loss_bbox: 0.2163, d3.loss_cls: 0.0707, d3.loss_bbox: 0.2121, d4.loss_cls: 0.0667, d4.loss_bbox: 0.2027, loss: 1.9304, grad_norm: 20.6783
2025-06-11 08:23:13,591 - mmdet - INFO - Epoch [5][1000/3517]	lr: 5.015e-05, eta: 3:08:43, time: 1.870, data_time: 0.051, memory: 32518, loss_cls: 0.0653, loss_bbox: 0.2014, d0.loss_cls: 0.1576, d0.loss_bbox: 0.3180, d1.loss_cls: 0.1017, d1.loss_bbox: 0.2388, d2.loss_cls: 0.0852, d2.loss_bbox: 0.2163, d3.loss_cls: 0.0713, d3.loss_bbox: 0.2132, d4.loss_cls: 0.0677, d4.loss_bbox: 0.2029, loss: 1.9395, grad_norm: 28.6702
2025-06-11 08:24:47,412 - mmdet - INFO - Epoch [5][1050/3517]	lr: 5.015e-05, eta: 3:07:09, time: 1.876, data_time: 0.053, memory: 32518, loss_cls: 0.0672, loss_bbox: 0.1973, d0.loss_cls: 0.1588, d0.loss_bbox: 0.3126, d1.loss_cls: 0.0994, d1.loss_bbox: 0.2350, d2.loss_cls: 0.0833, d2.loss_bbox: 0.2130, d3.loss_cls: 0.0725, d3.loss_bbox: 0.2090, d4.loss_cls: 0.0686, d4.loss_bbox: 0.1991, loss: 1.9160, grad_norm: 15.0044
2025-06-11 08:26:21,041 - mmdet - INFO - Epoch [5][1100/3517]	lr: 5.015e-05, eta: 3:05:35, time: 1.873, data_time: 0.049, memory: 32518, loss_cls: 0.0635, loss_bbox: 0.1985, d0.loss_cls: 0.1579, d0.loss_bbox: 0.3148, d1.loss_cls: 0.0981, d1.loss_bbox: 0.2344, d2.loss_cls: 0.0807, d2.loss_bbox: 0.2131, d3.loss_cls: 0.0707, d3.loss_bbox: 0.2098, d4.loss_cls: 0.0650, d4.loss_bbox: 0.2006, loss: 1.9071, grad_norm: 17.5404
2025-06-11 08:27:54,702 - mmdet - INFO - Epoch [5][1150/3517]	lr: 5.015e-05, eta: 3:04:02, time: 1.873, data_time: 0.051, memory: 32518, loss_cls: 0.0608, loss_bbox: 0.1990, d0.loss_cls: 0.1576, d0.loss_bbox: 0.3141, d1.loss_cls: 0.0958, d1.loss_bbox: 0.2360, d2.loss_cls: 0.0787, d2.loss_bbox: 0.2139, d3.loss_cls: 0.0674, d3.loss_bbox: 0.2097, d4.loss_cls: 0.0630, d4.loss_bbox: 0.2005, loss: 1.8965, grad_norm: 12.4537
2025-06-11 08:29:28,187 - mmdet - INFO - Epoch [5][1200/3517]	lr: 5.015e-05, eta: 3:02:28, time: 1.870, data_time: 0.049, memory: 32518, loss_cls: 0.0630, loss_bbox: 0.1974, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3129, d1.loss_cls: 0.0972, d1.loss_bbox: 0.2356, d2.loss_cls: 0.0787, d2.loss_bbox: 0.2135, d3.loss_cls: 0.0683, d3.loss_bbox: 0.2084, d4.loss_cls: 0.0652, d4.loss_bbox: 0.1987, loss: 1.8928, grad_norm: 20.7295
2025-06-11 08:31:05,316 - mmdet - INFO - Epoch [5][1250/3517]	lr: 5.015e-05, eta: 3:00:55, time: 1.943, data_time: 0.051, memory: 32518, loss_cls: 0.0647, loss_bbox: 0.2026, d0.loss_cls: 0.1581, d0.loss_bbox: 0.3140, d1.loss_cls: 0.0961, d1.loss_bbox: 0.2389, d2.loss_cls: 0.0799, d2.loss_bbox: 0.2194, d3.loss_cls: 0.0714, d3.loss_bbox: 0.2137, d4.loss_cls: 0.0663, d4.loss_bbox: 0.2052, loss: 1.9302, grad_norm: 15.6835
2025-06-11 08:32:38,896 - mmdet - INFO - Epoch [5][1300/3517]	lr: 5.015e-05, eta: 2:59:21, time: 1.872, data_time: 0.052, memory: 32518, loss_cls: 0.0637, loss_bbox: 0.2015, d0.loss_cls: 0.1585, d0.loss_bbox: 0.3115, d1.loss_cls: 0.0984, d1.loss_bbox: 0.2371, d2.loss_cls: 0.0796, d2.loss_bbox: 0.2179, d3.loss_cls: 0.0688, d3.loss_bbox: 0.2129, d4.loss_cls: 0.0662, d4.loss_bbox: 0.2026, loss: 1.9186, grad_norm: 14.1478
2025-06-11 08:34:12,634 - mmdet - INFO - Epoch [5][1350/3517]	lr: 5.015e-05, eta: 2:57:47, time: 1.875, data_time: 0.056, memory: 32518, loss_cls: 0.0628, loss_bbox: 0.1971, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3135, d1.loss_cls: 0.0972, d1.loss_bbox: 0.2347, d2.loss_cls: 0.0792, d2.loss_bbox: 0.2136, d3.loss_cls: 0.0687, d3.loss_bbox: 0.2086, d4.loss_cls: 0.0646, d4.loss_bbox: 0.1983, loss: 1.8951, grad_norm: 12.5250
2025-06-11 08:35:46,786 - mmdet - INFO - Epoch [5][1400/3517]	lr: 5.015e-05, eta: 2:56:13, time: 1.883, data_time: 0.054, memory: 32518, loss_cls: 0.0680, loss_bbox: 0.2016, d0.loss_cls: 0.1602, d0.loss_bbox: 0.3159, d1.loss_cls: 0.1010, d1.loss_bbox: 0.2397, d2.loss_cls: 0.0847, d2.loss_bbox: 0.2181, d3.loss_cls: 0.0725, d3.loss_bbox: 0.2131, d4.loss_cls: 0.0694, d4.loss_bbox: 0.2038, loss: 1.9481, grad_norm: 33.0414
2025-06-11 08:37:21,253 - mmdet - INFO - Epoch [5][1450/3517]	lr: 5.015e-05, eta: 2:54:40, time: 1.889, data_time: 0.057, memory: 32518, loss_cls: 0.0601, loss_bbox: 0.1927, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3094, d1.loss_cls: 0.0960, d1.loss_bbox: 0.2306, d2.loss_cls: 0.0775, d2.loss_bbox: 0.2085, d3.loss_cls: 0.0659, d3.loss_bbox: 0.2040, d4.loss_cls: 0.0624, d4.loss_bbox: 0.1948, loss: 1.8585, grad_norm: 36.4823
2025-06-11 08:38:56,659 - mmdet - INFO - Epoch [5][1500/3517]	lr: 5.015e-05, eta: 2:53:07, time: 1.908, data_time: 0.056, memory: 32518, loss_cls: 0.0676, loss_bbox: 0.2010, d0.loss_cls: 0.1598, d0.loss_bbox: 0.3173, d1.loss_cls: 0.1052, d1.loss_bbox: 0.2391, d2.loss_cls: 0.0863, d2.loss_bbox: 0.2164, d3.loss_cls: 0.0743, d3.loss_bbox: 0.2119, d4.loss_cls: 0.0702, d4.loss_bbox: 0.2027, loss: 1.9519, grad_norm: 33.5667
2025-06-11 08:40:31,029 - mmdet - INFO - Epoch [5][1550/3517]	lr: 5.015e-05, eta: 2:51:33, time: 1.887, data_time: 0.055, memory: 32518, loss_cls: 0.0626, loss_bbox: 0.1931, d0.loss_cls: 0.1570, d0.loss_bbox: 0.3099, d1.loss_cls: 0.0969, d1.loss_bbox: 0.2337, d2.loss_cls: 0.0811, d2.loss_bbox: 0.2093, d3.loss_cls: 0.0698, d3.loss_bbox: 0.2040, d4.loss_cls: 0.0648, d4.loss_bbox: 0.1948, loss: 1.8770, grad_norm: 17.7182
2025-06-11 08:42:05,474 - mmdet - INFO - Epoch [5][1600/3517]	lr: 5.015e-05, eta: 2:49:59, time: 1.889, data_time: 0.056, memory: 32518, loss_cls: 0.0628, loss_bbox: 0.2030, d0.loss_cls: 0.1569, d0.loss_bbox: 0.3144, d1.loss_cls: 0.0967, d1.loss_bbox: 0.2400, d2.loss_cls: 0.0799, d2.loss_bbox: 0.2181, d3.loss_cls: 0.0678, d3.loss_bbox: 0.2140, d4.loss_cls: 0.0654, d4.loss_bbox: 0.2037, loss: 1.9226, grad_norm: 19.0404
2025-06-11 08:43:39,309 - mmdet - INFO - Epoch [5][1650/3517]	lr: 5.015e-05, eta: 2:48:25, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.0663, loss_bbox: 0.2009, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3191, d1.loss_cls: 0.0987, d1.loss_bbox: 0.2413, d2.loss_cls: 0.0829, d2.loss_bbox: 0.2175, d3.loss_cls: 0.0719, d3.loss_bbox: 0.2128, d4.loss_cls: 0.0682, d4.loss_bbox: 0.2023, loss: 1.9387, grad_norm: 139.4428
2025-06-11 08:45:13,016 - mmdet - INFO - Epoch [5][1700/3517]	lr: 5.015e-05, eta: 2:46:51, time: 1.874, data_time: 0.056, memory: 32518, loss_cls: 0.0654, loss_bbox: 0.1967, d0.loss_cls: 0.1562, d0.loss_bbox: 0.3087, d1.loss_cls: 0.0975, d1.loss_bbox: 0.2324, d2.loss_cls: 0.0808, d2.loss_bbox: 0.2124, d3.loss_cls: 0.0705, d3.loss_bbox: 0.2070, d4.loss_cls: 0.0673, d4.loss_bbox: 0.1990, loss: 1.8939, grad_norm: 135.9519
2025-06-11 08:46:46,682 - mmdet - INFO - Epoch [5][1750/3517]	lr: 5.015e-05, eta: 2:45:18, time: 1.873, data_time: 0.053, memory: 32518, loss_cls: 0.0650, loss_bbox: 0.2000, d0.loss_cls: 0.1596, d0.loss_bbox: 0.3162, d1.loss_cls: 0.0999, d1.loss_bbox: 0.2381, d2.loss_cls: 0.0839, d2.loss_bbox: 0.2140, d3.loss_cls: 0.0716, d3.loss_bbox: 0.2104, d4.loss_cls: 0.0670, d4.loss_bbox: 0.2015, loss: 1.9271, grad_norm: 26.8227
2025-06-11 08:48:20,352 - mmdet - INFO - Epoch [5][1800/3517]	lr: 5.015e-05, eta: 2:43:44, time: 1.873, data_time: 0.056, memory: 32518, loss_cls: 0.0660, loss_bbox: 0.1919, d0.loss_cls: 0.1516, d0.loss_bbox: 0.3089, d1.loss_cls: 0.0949, d1.loss_bbox: 0.2318, d2.loss_cls: 0.0800, d2.loss_bbox: 0.2084, d3.loss_cls: 0.0695, d3.loss_bbox: 0.2032, d4.loss_cls: 0.0668, d4.loss_bbox: 0.1936, loss: 1.8665, grad_norm: 44.1910
2025-06-11 08:49:54,536 - mmdet - INFO - Epoch [5][1850/3517]	lr: 5.015e-05, eta: 2:42:10, time: 1.884, data_time: 0.052, memory: 32518, loss_cls: 0.0628, loss_bbox: 0.2001, d0.loss_cls: 0.1594, d0.loss_bbox: 0.3188, d1.loss_cls: 0.0973, d1.loss_bbox: 0.2389, d2.loss_cls: 0.0803, d2.loss_bbox: 0.2159, d3.loss_cls: 0.0692, d3.loss_bbox: 0.2116, d4.loss_cls: 0.0652, d4.loss_bbox: 0.2016, loss: 1.9210, grad_norm: 28.4799
2025-06-11 08:51:28,751 - mmdet - INFO - Epoch [5][1900/3517]	lr: 5.015e-05, eta: 2:40:36, time: 1.884, data_time: 0.054, memory: 32518, loss_cls: 0.0618, loss_bbox: 0.2027, d0.loss_cls: 0.1540, d0.loss_bbox: 0.3174, d1.loss_cls: 0.0939, d1.loss_bbox: 0.2397, d2.loss_cls: 0.0772, d2.loss_bbox: 0.2190, d3.loss_cls: 0.0671, d3.loss_bbox: 0.2147, d4.loss_cls: 0.0640, d4.loss_bbox: 0.2041, loss: 1.9156, grad_norm: 18.2321
2025-06-11 08:53:02,568 - mmdet - INFO - Epoch [5][1950/3517]	lr: 5.015e-05, eta: 2:39:02, time: 1.876, data_time: 0.058, memory: 32518, loss_cls: 0.0637, loss_bbox: 0.1963, d0.loss_cls: 0.1583, d0.loss_bbox: 0.3076, d1.loss_cls: 0.0966, d1.loss_bbox: 0.2335, d2.loss_cls: 0.0797, d2.loss_bbox: 0.2123, d3.loss_cls: 0.0696, d3.loss_bbox: 0.2074, d4.loss_cls: 0.0647, d4.loss_bbox: 0.1979, loss: 1.8877, grad_norm: 13.6762
2025-06-11 08:54:35,822 - mmdet - INFO - Epoch [5][2000/3517]	lr: 5.015e-05, eta: 2:37:28, time: 1.865, data_time: 0.054, memory: 32518, loss_cls: 0.0667, loss_bbox: 0.1974, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3188, d1.loss_cls: 0.0986, d1.loss_bbox: 0.2378, d2.loss_cls: 0.0815, d2.loss_bbox: 0.2171, d3.loss_cls: 0.0709, d3.loss_bbox: 0.2103, d4.loss_cls: 0.0673, d4.loss_bbox: 0.2003, loss: 1.9236, grad_norm: 89.4481
2025-06-11 08:56:09,228 - mmdet - INFO - Epoch [5][2050/3517]	lr: 5.015e-05, eta: 2:35:54, time: 1.868, data_time: 0.054, memory: 32518, loss_cls: 0.0638, loss_bbox: 0.2029, d0.loss_cls: 0.1570, d0.loss_bbox: 0.3104, d1.loss_cls: 0.0970, d1.loss_bbox: 0.2377, d2.loss_cls: 0.0803, d2.loss_bbox: 0.2171, d3.loss_cls: 0.0690, d3.loss_bbox: 0.2127, d4.loss_cls: 0.0651, d4.loss_bbox: 0.2043, loss: 1.9174, grad_norm: 15.8646
2025-06-11 08:57:43,510 - mmdet - INFO - Epoch [5][2100/3517]	lr: 5.015e-05, eta: 2:34:21, time: 1.886, data_time: 0.071, memory: 32518, loss_cls: 0.0591, loss_bbox: 0.1930, d0.loss_cls: 0.1541, d0.loss_bbox: 0.3105, d1.loss_cls: 0.0929, d1.loss_bbox: 0.2330, d2.loss_cls: 0.0777, d2.loss_bbox: 0.2093, d3.loss_cls: 0.0654, d3.loss_bbox: 0.2048, d4.loss_cls: 0.0599, d4.loss_bbox: 0.1959, loss: 1.8557, grad_norm: 19.0023
2025-06-11 08:59:17,850 - mmdet - INFO - Epoch [5][2150/3517]	lr: 5.015e-05, eta: 2:32:47, time: 1.887, data_time: 0.059, memory: 32518, loss_cls: 0.0671, loss_bbox: 0.1961, d0.loss_cls: 0.1559, d0.loss_bbox: 0.3070, d1.loss_cls: 0.1012, d1.loss_bbox: 0.2345, d2.loss_cls: 0.0829, d2.loss_bbox: 0.2120, d3.loss_cls: 0.0727, d3.loss_bbox: 0.2075, d4.loss_cls: 0.0682, d4.loss_bbox: 0.1992, loss: 1.9043, grad_norm: 18.5195
2025-06-11 09:00:52,117 - mmdet - INFO - Epoch [5][2200/3517]	lr: 5.015e-05, eta: 2:31:13, time: 1.885, data_time: 0.066, memory: 32518, loss_cls: 0.0663, loss_bbox: 0.1998, d0.loss_cls: 0.1573, d0.loss_bbox: 0.3144, d1.loss_cls: 0.0991, d1.loss_bbox: 0.2355, d2.loss_cls: 0.0823, d2.loss_bbox: 0.2142, d3.loss_cls: 0.0714, d3.loss_bbox: 0.2098, d4.loss_cls: 0.0681, d4.loss_bbox: 0.2008, loss: 1.9190, grad_norm: 21.9273
2025-06-11 09:02:26,181 - mmdet - INFO - Epoch [5][2250/3517]	lr: 5.015e-05, eta: 2:29:39, time: 1.881, data_time: 0.063, memory: 32518, loss_cls: 0.0621, loss_bbox: 0.1947, d0.loss_cls: 0.1525, d0.loss_bbox: 0.3048, d1.loss_cls: 0.0973, d1.loss_bbox: 0.2301, d2.loss_cls: 0.0791, d2.loss_bbox: 0.2092, d3.loss_cls: 0.0680, d3.loss_bbox: 0.2049, d4.loss_cls: 0.0633, d4.loss_bbox: 0.1964, loss: 1.8624, grad_norm: 19.4717
2025-06-11 09:04:00,222 - mmdet - INFO - Epoch [5][2300/3517]	lr: 5.015e-05, eta: 2:28:06, time: 1.881, data_time: 0.055, memory: 32518, loss_cls: 0.0660, loss_bbox: 0.2010, d0.loss_cls: 0.1504, d0.loss_bbox: 0.3208, d1.loss_cls: 0.1005, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0825, d2.loss_bbox: 0.2187, d3.loss_cls: 0.0716, d3.loss_bbox: 0.2132, d4.loss_cls: 0.0678, d4.loss_bbox: 0.2033, loss: 1.9369, grad_norm: 13.0516
2025-06-11 09:05:33,574 - mmdet - INFO - Epoch [5][2350/3517]	lr: 5.015e-05, eta: 2:26:32, time: 1.867, data_time: 0.052, memory: 32518, loss_cls: 0.0570, loss_bbox: 0.1920, d0.loss_cls: 0.1550, d0.loss_bbox: 0.3118, d1.loss_cls: 0.0945, d1.loss_bbox: 0.2309, d2.loss_cls: 0.0760, d2.loss_bbox: 0.2083, d3.loss_cls: 0.0629, d3.loss_bbox: 0.2038, d4.loss_cls: 0.0589, d4.loss_bbox: 0.1945, loss: 1.8456, grad_norm: 13.8527
2025-06-11 09:07:07,895 - mmdet - INFO - Epoch [5][2400/3517]	lr: 5.015e-05, eta: 2:24:58, time: 1.886, data_time: 0.055, memory: 32518, loss_cls: 0.0680, loss_bbox: 0.1933, d0.loss_cls: 0.1568, d0.loss_bbox: 0.3082, d1.loss_cls: 0.1021, d1.loss_bbox: 0.2301, d2.loss_cls: 0.0849, d2.loss_bbox: 0.2093, d3.loss_cls: 0.0747, d3.loss_bbox: 0.2044, d4.loss_cls: 0.0711, d4.loss_bbox: 0.1945, loss: 1.8974, grad_norm: 19.4387
2025-06-11 09:08:41,528 - mmdet - INFO - Epoch [5][2450/3517]	lr: 5.015e-05, eta: 2:23:24, time: 1.873, data_time: 0.049, memory: 32518, loss_cls: 0.0601, loss_bbox: 0.1942, d0.loss_cls: 0.1537, d0.loss_bbox: 0.3125, d1.loss_cls: 0.0924, d1.loss_bbox: 0.2311, d2.loss_cls: 0.0747, d2.loss_bbox: 0.2092, d3.loss_cls: 0.0646, d3.loss_bbox: 0.2052, d4.loss_cls: 0.0621, d4.loss_bbox: 0.1953, loss: 1.8552, grad_norm: 33.3977
2025-06-11 09:10:15,332 - mmdet - INFO - Epoch [5][2500/3517]	lr: 5.015e-05, eta: 2:21:50, time: 1.876, data_time: 0.049, memory: 32518, loss_cls: 0.0673, loss_bbox: 0.2022, d0.loss_cls: 0.1587, d0.loss_bbox: 0.3195, d1.loss_cls: 0.1010, d1.loss_bbox: 0.2411, d2.loss_cls: 0.0843, d2.loss_bbox: 0.2182, d3.loss_cls: 0.0724, d3.loss_bbox: 0.2129, d4.loss_cls: 0.0686, d4.loss_bbox: 0.2033, loss: 1.9495, grad_norm: 20.9085
2025-06-11 09:11:48,666 - mmdet - INFO - Epoch [5][2550/3517]	lr: 5.015e-05, eta: 2:20:16, time: 1.867, data_time: 0.048, memory: 32518, loss_cls: 0.0713, loss_bbox: 0.2020, d0.loss_cls: 0.1598, d0.loss_bbox: 0.3175, d1.loss_cls: 0.1047, d1.loss_bbox: 0.2402, d2.loss_cls: 0.0876, d2.loss_bbox: 0.2181, d3.loss_cls: 0.0760, d3.loss_bbox: 0.2139, d4.loss_cls: 0.0733, d4.loss_bbox: 0.2037, loss: 1.9680, grad_norm: 13.3080
2025-06-11 09:13:22,439 - mmdet - INFO - Epoch [5][2600/3517]	lr: 5.015e-05, eta: 2:18:42, time: 1.875, data_time: 0.048, memory: 32518, loss_cls: 0.0626, loss_bbox: 0.1960, d0.loss_cls: 0.1524, d0.loss_bbox: 0.3069, d1.loss_cls: 0.0952, d1.loss_bbox: 0.2336, d2.loss_cls: 0.0802, d2.loss_bbox: 0.2117, d3.loss_cls: 0.0683, d3.loss_bbox: 0.2068, d4.loss_cls: 0.0649, d4.loss_bbox: 0.1975, loss: 1.8762, grad_norm: 18.9278
2025-06-11 09:14:55,509 - mmdet - INFO - Epoch [5][2650/3517]	lr: 5.015e-05, eta: 2:17:08, time: 1.861, data_time: 0.053, memory: 32518, loss_cls: 0.0683, loss_bbox: 0.2032, d0.loss_cls: 0.1570, d0.loss_bbox: 0.3233, d1.loss_cls: 0.1029, d1.loss_bbox: 0.2430, d2.loss_cls: 0.0865, d2.loss_bbox: 0.2184, d3.loss_cls: 0.0748, d3.loss_bbox: 0.2144, d4.loss_cls: 0.0698, d4.loss_bbox: 0.2048, loss: 1.9664, grad_norm: 37.9864
2025-06-11 09:16:29,388 - mmdet - INFO - Epoch [5][2700/3517]	lr: 5.015e-05, eta: 2:15:34, time: 1.878, data_time: 0.055, memory: 32518, loss_cls: 0.0620, loss_bbox: 0.1975, d0.loss_cls: 0.1526, d0.loss_bbox: 0.3154, d1.loss_cls: 0.0935, d1.loss_bbox: 0.2376, d2.loss_cls: 0.0796, d2.loss_bbox: 0.2146, d3.loss_cls: 0.0678, d3.loss_bbox: 0.2096, d4.loss_cls: 0.0644, d4.loss_bbox: 0.1997, loss: 1.8944, grad_norm: 16.0014
2025-06-11 09:18:03,323 - mmdet - INFO - Epoch [5][2750/3517]	lr: 5.015e-05, eta: 2:14:00, time: 1.879, data_time: 0.052, memory: 32518, loss_cls: 0.0645, loss_bbox: 0.2006, d0.loss_cls: 0.1548, d0.loss_bbox: 0.3146, d1.loss_cls: 0.0969, d1.loss_bbox: 0.2374, d2.loss_cls: 0.0824, d2.loss_bbox: 0.2167, d3.loss_cls: 0.0711, d3.loss_bbox: 0.2112, d4.loss_cls: 0.0668, d4.loss_bbox: 0.2017, loss: 1.9187, grad_norm: 13.1149
2025-06-11 09:19:37,418 - mmdet - INFO - Epoch [5][2800/3517]	lr: 5.015e-05, eta: 2:12:27, time: 1.882, data_time: 0.054, memory: 32518, loss_cls: 0.0655, loss_bbox: 0.1972, d0.loss_cls: 0.1549, d0.loss_bbox: 0.3104, d1.loss_cls: 0.0977, d1.loss_bbox: 0.2338, d2.loss_cls: 0.0818, d2.loss_bbox: 0.2140, d3.loss_cls: 0.0713, d3.loss_bbox: 0.2097, d4.loss_cls: 0.0669, d4.loss_bbox: 0.1990, loss: 1.9022, grad_norm: 32.1581
2025-06-11 09:21:11,307 - mmdet - INFO - Epoch [5][2850/3517]	lr: 5.015e-05, eta: 2:10:53, time: 1.878, data_time: 0.053, memory: 32518, loss_cls: 0.0646, loss_bbox: 0.2008, d0.loss_cls: 0.1555, d0.loss_bbox: 0.3202, d1.loss_cls: 0.0990, d1.loss_bbox: 0.2384, d2.loss_cls: 0.0813, d2.loss_bbox: 0.2177, d3.loss_cls: 0.0701, d3.loss_bbox: 0.2123, d4.loss_cls: 0.0657, d4.loss_bbox: 0.2025, loss: 1.9279, grad_norm: 17.7540
2025-06-11 09:22:44,818 - mmdet - INFO - Epoch [5][2900/3517]	lr: 5.015e-05, eta: 2:09:19, time: 1.870, data_time: 0.047, memory: 32518, loss_cls: 0.0684, loss_bbox: 0.1999, d0.loss_cls: 0.1578, d0.loss_bbox: 0.3116, d1.loss_cls: 0.0996, d1.loss_bbox: 0.2376, d2.loss_cls: 0.0844, d2.loss_bbox: 0.2154, d3.loss_cls: 0.0740, d3.loss_bbox: 0.2107, d4.loss_cls: 0.0706, d4.loss_bbox: 0.2012, loss: 1.9312, grad_norm: 253.7202
2025-06-11 09:24:21,537 - mmdet - INFO - Epoch [5][2950/3517]	lr: 5.015e-05, eta: 2:07:46, time: 1.934, data_time: 0.049, memory: 32518, loss_cls: 0.0638, loss_bbox: 0.1988, d0.loss_cls: 0.1565, d0.loss_bbox: 0.3147, d1.loss_cls: 0.0966, d1.loss_bbox: 0.2381, d2.loss_cls: 0.0788, d2.loss_bbox: 0.2159, d3.loss_cls: 0.0687, d3.loss_bbox: 0.2109, d4.loss_cls: 0.0651, d4.loss_bbox: 0.2007, loss: 1.9084, grad_norm: 23.8094
2025-06-11 09:25:54,804 - mmdet - INFO - Epoch [5][3000/3517]	lr: 5.015e-05, eta: 2:06:12, time: 1.865, data_time: 0.056, memory: 32518, loss_cls: 0.0583, loss_bbox: 0.1916, d0.loss_cls: 0.1523, d0.loss_bbox: 0.3077, d1.loss_cls: 0.0928, d1.loss_bbox: 0.2297, d2.loss_cls: 0.0777, d2.loss_bbox: 0.2074, d3.loss_cls: 0.0651, d3.loss_bbox: 0.2027, d4.loss_cls: 0.0607, d4.loss_bbox: 0.1932, loss: 1.8392, grad_norm: 25.0546
2025-06-11 09:28:27,129 - mmdet - INFO - Epoch [5][3050/3517]	lr: 5.015e-05, eta: 2:04:52, time: 3.046, data_time: 0.908, memory: 32518, loss_cls: 0.0648, loss_bbox: 0.2028, d0.loss_cls: 0.1556, d0.loss_bbox: 0.3183, d1.loss_cls: 0.0996, d1.loss_bbox: 0.2410, d2.loss_cls: 0.0821, d2.loss_bbox: 0.2191, d3.loss_cls: 0.0705, d3.loss_bbox: 0.2142, d4.loss_cls: 0.0666, d4.loss_bbox: 0.2048, loss: 1.9394, grad_norm: 19.5898
2025-06-11 09:30:06,368 - mmdet - INFO - Epoch [5][3100/3517]	lr: 5.015e-05, eta: 2:03:19, time: 1.985, data_time: 0.142, memory: 32518, loss_cls: 0.0614, loss_bbox: 0.1927, d0.loss_cls: 0.1526, d0.loss_bbox: 0.3105, d1.loss_cls: 0.0970, d1.loss_bbox: 0.2312, d2.loss_cls: 0.0784, d2.loss_bbox: 0.2094, d3.loss_cls: 0.0669, d3.loss_bbox: 0.2050, d4.loss_cls: 0.0629, d4.loss_bbox: 0.1947, loss: 1.8628, grad_norm: 58.2783
2025-06-11 09:31:40,749 - mmdet - INFO - Epoch [5][3150/3517]	lr: 5.015e-05, eta: 2:01:45, time: 1.888, data_time: 0.058, memory: 32518, loss_cls: 0.0661, loss_bbox: 0.1980, d0.loss_cls: 0.1572, d0.loss_bbox: 0.3214, d1.loss_cls: 0.0996, d1.loss_bbox: 0.2387, d2.loss_cls: 0.0830, d2.loss_bbox: 0.2138, d3.loss_cls: 0.0705, d3.loss_bbox: 0.2095, d4.loss_cls: 0.0666, d4.loss_bbox: 0.2008, loss: 1.9253, grad_norm: 21.0298
2025-06-11 09:33:14,606 - mmdet - INFO - Epoch [5][3200/3517]	lr: 5.015e-05, eta: 2:00:11, time: 1.877, data_time: 0.055, memory: 32518, loss_cls: 0.0578, loss_bbox: 0.1930, d0.loss_cls: 0.1544, d0.loss_bbox: 0.3109, d1.loss_cls: 0.0932, d1.loss_bbox: 0.2307, d2.loss_cls: 0.0761, d2.loss_bbox: 0.2089, d3.loss_cls: 0.0645, d3.loss_bbox: 0.2041, d4.loss_cls: 0.0600, d4.loss_bbox: 0.1946, loss: 1.8482, grad_norm: 19.6213
2025-06-11 09:34:49,110 - mmdet - INFO - Epoch [5][3250/3517]	lr: 5.015e-05, eta: 1:58:37, time: 1.890, data_time: 0.056, memory: 32518, loss_cls: 0.0644, loss_bbox: 0.1984, d0.loss_cls: 0.1506, d0.loss_bbox: 0.3221, d1.loss_cls: 0.0978, d1.loss_bbox: 0.2404, d2.loss_cls: 0.0838, d2.loss_bbox: 0.2158, d3.loss_cls: 0.0705, d3.loss_bbox: 0.2111, d4.loss_cls: 0.0657, d4.loss_bbox: 0.2013, loss: 1.9219, grad_norm: 80.4538
2025-06-11 09:36:24,168 - mmdet - INFO - Epoch [5][3300/3517]	lr: 5.015e-05, eta: 1:57:03, time: 1.901, data_time: 0.056, memory: 32518, loss_cls: 0.0616, loss_bbox: 0.2012, d0.loss_cls: 0.1548, d0.loss_bbox: 0.3175, d1.loss_cls: 0.0980, d1.loss_bbox: 0.2374, d2.loss_cls: 0.0806, d2.loss_bbox: 0.2161, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2121, d4.loss_cls: 0.0639, d4.loss_bbox: 0.2020, loss: 1.9136, grad_norm: 23.6799
2025-06-11 09:37:58,355 - mmdet - INFO - Epoch [5][3350/3517]	lr: 5.015e-05, eta: 1:55:29, time: 1.884, data_time: 0.056, memory: 32518, loss_cls: 0.0614, loss_bbox: 0.1933, d0.loss_cls: 0.1497, d0.loss_bbox: 0.3094, d1.loss_cls: 0.0957, d1.loss_bbox: 0.2325, d2.loss_cls: 0.0788, d2.loss_bbox: 0.2109, d3.loss_cls: 0.0677, d3.loss_bbox: 0.2054, d4.loss_cls: 0.0637, d4.loss_bbox: 0.1949, loss: 1.8634, grad_norm: 54.7873
2025-06-11 09:39:32,713 - mmdet - INFO - Epoch [5][3400/3517]	lr: 5.015e-05, eta: 1:53:55, time: 1.887, data_time: 0.057, memory: 32518, loss_cls: 0.0585, loss_bbox: 0.1915, d0.loss_cls: 0.1511, d0.loss_bbox: 0.3098, d1.loss_cls: 0.0947, d1.loss_bbox: 0.2306, d2.loss_cls: 0.0767, d2.loss_bbox: 0.2084, d3.loss_cls: 0.0649, d3.loss_bbox: 0.2045, d4.loss_cls: 0.0606, d4.loss_bbox: 0.1935, loss: 1.8448, grad_norm: 19.9086
2025-06-11 09:41:06,823 - mmdet - INFO - Epoch [5][3450/3517]	lr: 5.015e-05, eta: 1:52:21, time: 1.882, data_time: 0.049, memory: 32518, loss_cls: 0.0643, loss_bbox: 0.1961, d0.loss_cls: 0.1542, d0.loss_bbox: 0.3163, d1.loss_cls: 0.0981, d1.loss_bbox: 0.2395, d2.loss_cls: 0.0830, d2.loss_bbox: 0.2155, d3.loss_cls: 0.0700, d3.loss_bbox: 0.2102, d4.loss_cls: 0.0655, d4.loss_bbox: 0.1986, loss: 1.9114, grad_norm: 22.5959
2025-06-11 09:42:41,059 - mmdet - INFO - Epoch [5][3500/3517]	lr: 5.015e-05, eta: 1:50:47, time: 1.885, data_time: 0.052, memory: 32518, loss_cls: 0.0612, loss_bbox: 0.1954, d0.loss_cls: 0.1540, d0.loss_bbox: 0.3081, d1.loss_cls: 0.0969, d1.loss_bbox: 0.2318, d2.loss_cls: 0.0792, d2.loss_bbox: 0.2127, d3.loss_cls: 0.0674, d3.loss_bbox: 0.2072, d4.loss_cls: 0.0632, d4.loss_bbox: 0.1969, loss: 1.8740, grad_norm: 22.0796
2025-06-11 09:43:13,160 - mmdet - INFO - Saving checkpoint at 5 epochs
2025-06-11 10:10:56,172 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 10:10:56,172 - mmdet - INFO - Epoch(val) [5][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7935, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8839, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9112, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9235, pts_bbox_NuScenes/car_trans_err: 0.1775, pts_bbox_NuScenes/car_scale_err: 0.1511, pts_bbox_NuScenes/car_orient_err: 0.0425, pts_bbox_NuScenes/car_vel_err: 0.3225, pts_bbox_NuScenes/car_attr_err: 0.1823, pts_bbox_NuScenes/mATE: 0.2864, pts_bbox_NuScenes/mASE: 0.2624, pts_bbox_NuScenes/mAOE: 0.2509, pts_bbox_NuScenes/mAVE: 0.2877, pts_bbox_NuScenes/mAAE: 0.1754, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4241, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6262, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7263, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7635, pts_bbox_NuScenes/truck_trans_err: 0.3427, pts_bbox_NuScenes/truck_scale_err: 0.1985, pts_bbox_NuScenes/truck_orient_err: 0.0415, pts_bbox_NuScenes/truck_vel_err: 0.2896, pts_bbox_NuScenes/truck_attr_err: 0.1972, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0529, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2054, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4115, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4781, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6632, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4350, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.7759, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1165, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2957, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5335, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7587, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.9038, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9274, pts_bbox_NuScenes/bus_trans_err: 0.3275, pts_bbox_NuScenes/bus_scale_err: 0.1969, pts_bbox_NuScenes/bus_orient_err: 0.0423, pts_bbox_NuScenes/bus_vel_err: 0.4900, pts_bbox_NuScenes/bus_attr_err: 0.2387, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1823, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4305, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5962, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6856, pts_bbox_NuScenes/trailer_trans_err: 0.4744, pts_bbox_NuScenes/trailer_scale_err: 0.2303, pts_bbox_NuScenes/trailer_orient_err: 0.4844, pts_bbox_NuScenes/trailer_vel_err: 0.2739, pts_bbox_NuScenes/trailer_attr_err: 0.1547, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.6180, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7171, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7653, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7799, pts_bbox_NuScenes/barrier_trans_err: 0.2087, pts_bbox_NuScenes/barrier_scale_err: 0.2904, pts_bbox_NuScenes/barrier_orient_err: 0.0443, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6532, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7759, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.8043, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8137, pts_bbox_NuScenes/motorcycle_trans_err: 0.2116, pts_bbox_NuScenes/motorcycle_scale_err: 0.2455, pts_bbox_NuScenes/motorcycle_orient_err: 0.2148, pts_bbox_NuScenes/motorcycle_vel_err: 0.3712, pts_bbox_NuScenes/motorcycle_attr_err: 0.2193, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5440, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5965, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6073, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6172, pts_bbox_NuScenes/bicycle_trans_err: 0.1700, pts_bbox_NuScenes/bicycle_scale_err: 0.2587, pts_bbox_NuScenes/bicycle_orient_err: 0.2958, pts_bbox_NuScenes/bicycle_vel_err: 0.2190, pts_bbox_NuScenes/bicycle_attr_err: 0.0052, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8211, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8613, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8807, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8929, pts_bbox_NuScenes/pedestrian_trans_err: 0.1472, pts_bbox_NuScenes/pedestrian_scale_err: 0.2955, pts_bbox_NuScenes/pedestrian_orient_err: 0.3164, pts_bbox_NuScenes/pedestrian_vel_err: 0.2187, pts_bbox_NuScenes/pedestrian_attr_err: 0.1098, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7453, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7819, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.8043, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8249, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1416, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3220, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7128, pts_bbox_NuScenes/mAP: 0.6781
2025-06-11 10:12:40,352 - mmdet - INFO - Epoch [6][50/3517]	lr: 1.358e-05, eta: 1:48:36, time: 2.002, data_time: 0.181, memory: 32518, loss_cls: 0.0626, loss_bbox: 0.1968, d0.loss_cls: 0.1564, d0.loss_bbox: 0.3146, d1.loss_cls: 0.0965, d1.loss_bbox: 0.2363, d2.loss_cls: 0.0806, d2.loss_bbox: 0.2138, d3.loss_cls: 0.0680, d3.loss_bbox: 0.2085, d4.loss_cls: 0.0642, d4.loss_bbox: 0.1990, loss: 1.8974, grad_norm: 20.7770
2025-06-11 10:14:14,658 - mmdet - INFO - Epoch [6][100/3517]	lr: 1.358e-05, eta: 1:47:02, time: 1.886, data_time: 0.064, memory: 32518, loss_cls: 0.0622, loss_bbox: 0.1928, d0.loss_cls: 0.1552, d0.loss_bbox: 0.3072, d1.loss_cls: 0.0964, d1.loss_bbox: 0.2326, d2.loss_cls: 0.0811, d2.loss_bbox: 0.2097, d3.loss_cls: 0.0683, d3.loss_bbox: 0.2056, d4.loss_cls: 0.0649, d4.loss_bbox: 0.1949, loss: 1.8709, grad_norm: 20.3790
2025-06-11 10:15:47,770 - mmdet - INFO - Epoch [6][150/3517]	lr: 1.358e-05, eta: 1:45:28, time: 1.862, data_time: 0.054, memory: 32518, loss_cls: 0.0574, loss_bbox: 0.1917, d0.loss_cls: 0.1503, d0.loss_bbox: 0.3098, d1.loss_cls: 0.0938, d1.loss_bbox: 0.2308, d2.loss_cls: 0.0776, d2.loss_bbox: 0.2093, d3.loss_cls: 0.0648, d3.loss_bbox: 0.2045, d4.loss_cls: 0.0607, d4.loss_bbox: 0.1931, loss: 1.8439, grad_norm: 29.5267
2025-06-11 10:17:21,242 - mmdet - INFO - Epoch [6][200/3517]	lr: 1.358e-05, eta: 1:43:54, time: 1.869, data_time: 0.053, memory: 32518, loss_cls: 0.0651, loss_bbox: 0.1993, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3232, d1.loss_cls: 0.1018, d1.loss_bbox: 0.2426, d2.loss_cls: 0.0842, d2.loss_bbox: 0.2175, d3.loss_cls: 0.0717, d3.loss_bbox: 0.2118, d4.loss_cls: 0.0674, d4.loss_bbox: 0.2010, loss: 1.9387, grad_norm: 18.0270
2025-06-11 10:18:56,493 - mmdet - INFO - Epoch [6][250/3517]	lr: 1.358e-05, eta: 1:42:20, time: 1.905, data_time: 0.091, memory: 32518, loss_cls: 0.0639, loss_bbox: 0.1988, d0.loss_cls: 0.1559, d0.loss_bbox: 0.3148, d1.loss_cls: 0.0971, d1.loss_bbox: 0.2388, d2.loss_cls: 0.0799, d2.loss_bbox: 0.2159, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2114, d4.loss_cls: 0.0652, d4.loss_bbox: 0.2017, loss: 1.9119, grad_norm: 21.3942
2025-06-11 10:20:29,495 - mmdet - INFO - Epoch [6][300/3517]	lr: 1.358e-05, eta: 1:40:46, time: 1.860, data_time: 0.052, memory: 32518, loss_cls: 0.0590, loss_bbox: 0.1899, d0.loss_cls: 0.1512, d0.loss_bbox: 0.3045, d1.loss_cls: 0.0923, d1.loss_bbox: 0.2290, d2.loss_cls: 0.0739, d2.loss_bbox: 0.2080, d3.loss_cls: 0.0645, d3.loss_bbox: 0.2026, d4.loss_cls: 0.0623, d4.loss_bbox: 0.1917, loss: 1.8289, grad_norm: 17.3793
2025-06-11 10:22:06,017 - mmdet - INFO - Epoch [6][350/3517]	lr: 1.358e-05, eta: 1:39:12, time: 1.930, data_time: 0.108, memory: 32518, loss_cls: 0.0654, loss_bbox: 0.1959, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3095, d1.loss_cls: 0.0985, d1.loss_bbox: 0.2361, d2.loss_cls: 0.0814, d2.loss_bbox: 0.2131, d3.loss_cls: 0.0719, d3.loss_bbox: 0.2070, d4.loss_cls: 0.0683, d4.loss_bbox: 0.1981, loss: 1.8990, grad_norm: 12.7876
2025-06-11 10:23:39,052 - mmdet - INFO - Epoch [6][400/3517]	lr: 1.358e-05, eta: 1:37:38, time: 1.861, data_time: 0.050, memory: 32518, loss_cls: 0.0610, loss_bbox: 0.1916, d0.loss_cls: 0.1471, d0.loss_bbox: 0.3059, d1.loss_cls: 0.0925, d1.loss_bbox: 0.2308, d2.loss_cls: 0.0767, d2.loss_bbox: 0.2098, d3.loss_cls: 0.0665, d3.loss_bbox: 0.2036, d4.loss_cls: 0.0630, d4.loss_bbox: 0.1937, loss: 1.8422, grad_norm: 36.5864
2025-06-11 10:25:12,481 - mmdet - INFO - Epoch [6][450/3517]	lr: 1.358e-05, eta: 1:36:04, time: 1.869, data_time: 0.051, memory: 32518, loss_cls: 0.0660, loss_bbox: 0.2023, d0.loss_cls: 0.1561, d0.loss_bbox: 0.3182, d1.loss_cls: 0.0989, d1.loss_bbox: 0.2416, d2.loss_cls: 0.0848, d2.loss_bbox: 0.2190, d3.loss_cls: 0.0727, d3.loss_bbox: 0.2130, d4.loss_cls: 0.0685, d4.loss_bbox: 0.2040, loss: 1.9448, grad_norm: 14.1105
2025-06-11 10:26:46,140 - mmdet - INFO - Epoch [6][500/3517]	lr: 1.358e-05, eta: 1:34:30, time: 1.873, data_time: 0.053, memory: 32518, loss_cls: 0.0627, loss_bbox: 0.1943, d0.loss_cls: 0.1460, d0.loss_bbox: 0.3063, d1.loss_cls: 0.0949, d1.loss_bbox: 0.2321, d2.loss_cls: 0.0794, d2.loss_bbox: 0.2089, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2048, d4.loss_cls: 0.0642, d4.loss_bbox: 0.1963, loss: 1.8586, grad_norm: 21.2721
2025-06-11 10:28:19,207 - mmdet - INFO - Epoch [6][550/3517]	lr: 1.358e-05, eta: 1:32:56, time: 1.861, data_time: 0.053, memory: 32518, loss_cls: 0.0622, loss_bbox: 0.1900, d0.loss_cls: 0.1507, d0.loss_bbox: 0.3118, d1.loss_cls: 0.0959, d1.loss_bbox: 0.2297, d2.loss_cls: 0.0793, d2.loss_bbox: 0.2077, d3.loss_cls: 0.0691, d3.loss_bbox: 0.2024, d4.loss_cls: 0.0644, d4.loss_bbox: 0.1919, loss: 1.8551, grad_norm: 19.8966
2025-06-11 10:29:53,038 - mmdet - INFO - Epoch [6][600/3517]	lr: 1.358e-05, eta: 1:31:22, time: 1.877, data_time: 0.062, memory: 32518, loss_cls: 0.0612, loss_bbox: 0.1925, d0.loss_cls: 0.1525, d0.loss_bbox: 0.3063, d1.loss_cls: 0.0971, d1.loss_bbox: 0.2324, d2.loss_cls: 0.0794, d2.loss_bbox: 0.2084, d3.loss_cls: 0.0681, d3.loss_bbox: 0.2037, d4.loss_cls: 0.0631, d4.loss_bbox: 0.1947, loss: 1.8595, grad_norm: 20.1436
2025-06-11 10:31:26,139 - mmdet - INFO - Epoch [6][650/3517]	lr: 1.358e-05, eta: 1:29:48, time: 1.862, data_time: 0.053, memory: 32518, loss_cls: 0.0607, loss_bbox: 0.1951, d0.loss_cls: 0.1509, d0.loss_bbox: 0.3108, d1.loss_cls: 0.0937, d1.loss_bbox: 0.2370, d2.loss_cls: 0.0789, d2.loss_bbox: 0.2135, d3.loss_cls: 0.0670, d3.loss_bbox: 0.2075, d4.loss_cls: 0.0629, d4.loss_bbox: 0.1976, loss: 1.8755, grad_norm: 15.1334
2025-06-11 10:33:00,206 - mmdet - INFO - Epoch [6][700/3517]	lr: 1.358e-05, eta: 1:28:14, time: 1.881, data_time: 0.055, memory: 32518, loss_cls: 0.0613, loss_bbox: 0.1937, d0.loss_cls: 0.1493, d0.loss_bbox: 0.3031, d1.loss_cls: 0.0949, d1.loss_bbox: 0.2299, d2.loss_cls: 0.0781, d2.loss_bbox: 0.2100, d3.loss_cls: 0.0673, d3.loss_bbox: 0.2057, d4.loss_cls: 0.0627, d4.loss_bbox: 0.1969, loss: 1.8528, grad_norm: 37.6379
2025-06-11 10:34:33,975 - mmdet - INFO - Epoch [6][750/3517]	lr: 1.358e-05, eta: 1:26:40, time: 1.875, data_time: 0.055, memory: 32518, loss_cls: 0.0600, loss_bbox: 0.1901, d0.loss_cls: 0.1506, d0.loss_bbox: 0.3068, d1.loss_cls: 0.0943, d1.loss_bbox: 0.2312, d2.loss_cls: 0.0776, d2.loss_bbox: 0.2090, d3.loss_cls: 0.0660, d3.loss_bbox: 0.2035, d4.loss_cls: 0.0619, d4.loss_bbox: 0.1923, loss: 1.8432, grad_norm: 43.0086
2025-06-11 10:36:07,639 - mmdet - INFO - Epoch [6][800/3517]	lr: 1.358e-05, eta: 1:25:06, time: 1.873, data_time: 0.052, memory: 32518, loss_cls: 0.0602, loss_bbox: 0.1948, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3123, d1.loss_cls: 0.0929, d1.loss_bbox: 0.2342, d2.loss_cls: 0.0771, d2.loss_bbox: 0.2120, d3.loss_cls: 0.0660, d3.loss_bbox: 0.2070, d4.loss_cls: 0.0628, d4.loss_bbox: 0.1971, loss: 1.8696, grad_norm: 29.9972
2025-06-11 10:37:40,596 - mmdet - INFO - Epoch [6][850/3517]	lr: 1.358e-05, eta: 1:23:32, time: 1.859, data_time: 0.052, memory: 32518, loss_cls: 0.0573, loss_bbox: 0.1920, d0.loss_cls: 0.1470, d0.loss_bbox: 0.3044, d1.loss_cls: 0.0890, d1.loss_bbox: 0.2316, d2.loss_cls: 0.0742, d2.loss_bbox: 0.2083, d3.loss_cls: 0.0625, d3.loss_bbox: 0.2030, d4.loss_cls: 0.0592, d4.loss_bbox: 0.1937, loss: 1.8221, grad_norm: 44.9774
2025-06-11 10:39:14,545 - mmdet - INFO - Epoch [6][900/3517]	lr: 1.358e-05, eta: 1:21:58, time: 1.879, data_time: 0.058, memory: 32518, loss_cls: 0.0612, loss_bbox: 0.1929, d0.loss_cls: 0.1534, d0.loss_bbox: 0.3117, d1.loss_cls: 0.0955, d1.loss_bbox: 0.2325, d2.loss_cls: 0.0772, d2.loss_bbox: 0.2111, d3.loss_cls: 0.0669, d3.loss_bbox: 0.2052, d4.loss_cls: 0.0631, d4.loss_bbox: 0.1959, loss: 1.8665, grad_norm: 36.4216
2025-06-11 10:40:48,434 - mmdet - INFO - Epoch [6][950/3517]	lr: 1.358e-05, eta: 1:20:24, time: 1.878, data_time: 0.055, memory: 32518, loss_cls: 0.0631, loss_bbox: 0.1941, d0.loss_cls: 0.1539, d0.loss_bbox: 0.3061, d1.loss_cls: 0.0952, d1.loss_bbox: 0.2333, d2.loss_cls: 0.0798, d2.loss_bbox: 0.2123, d3.loss_cls: 0.0680, d3.loss_bbox: 0.2062, d4.loss_cls: 0.0646, d4.loss_bbox: 0.1964, loss: 1.8729, grad_norm: 32.8551
2025-06-11 10:42:21,901 - mmdet - INFO - Epoch [6][1000/3517]	lr: 1.358e-05, eta: 1:18:50, time: 1.869, data_time: 0.048, memory: 32518, loss_cls: 0.0589, loss_bbox: 0.1901, d0.loss_cls: 0.1475, d0.loss_bbox: 0.2940, d1.loss_cls: 0.0925, d1.loss_bbox: 0.2256, d2.loss_cls: 0.0763, d2.loss_bbox: 0.2060, d3.loss_cls: 0.0648, d3.loss_bbox: 0.2019, d4.loss_cls: 0.0609, d4.loss_bbox: 0.1926, loss: 1.8111, grad_norm: 16.9508
2025-06-11 10:43:55,368 - mmdet - INFO - Epoch [6][1050/3517]	lr: 1.358e-05, eta: 1:17:16, time: 1.869, data_time: 0.046, memory: 32518, loss_cls: 0.0622, loss_bbox: 0.1943, d0.loss_cls: 0.1529, d0.loss_bbox: 0.3062, d1.loss_cls: 0.0944, d1.loss_bbox: 0.2313, d2.loss_cls: 0.0787, d2.loss_bbox: 0.2109, d3.loss_cls: 0.0665, d3.loss_bbox: 0.2074, d4.loss_cls: 0.0634, d4.loss_bbox: 0.1972, loss: 1.8653, grad_norm: 25.1852
2025-06-11 10:45:29,069 - mmdet - INFO - Epoch [6][1100/3517]	lr: 1.358e-05, eta: 1:15:42, time: 1.874, data_time: 0.049, memory: 32518, loss_cls: 0.0611, loss_bbox: 0.1847, d0.loss_cls: 0.1512, d0.loss_bbox: 0.2999, d1.loss_cls: 0.0932, d1.loss_bbox: 0.2257, d2.loss_cls: 0.0789, d2.loss_bbox: 0.2025, d3.loss_cls: 0.0657, d3.loss_bbox: 0.1970, d4.loss_cls: 0.0624, d4.loss_bbox: 0.1874, loss: 1.8096, grad_norm: 20.9280
2025-06-11 10:47:03,624 - mmdet - INFO - Epoch [6][1150/3517]	lr: 1.358e-05, eta: 1:14:08, time: 1.891, data_time: 0.061, memory: 32518, loss_cls: 0.0618, loss_bbox: 0.1907, d0.loss_cls: 0.1551, d0.loss_bbox: 0.3038, d1.loss_cls: 0.0961, d1.loss_bbox: 0.2292, d2.loss_cls: 0.0796, d2.loss_bbox: 0.2073, d3.loss_cls: 0.0668, d3.loss_bbox: 0.2035, d4.loss_cls: 0.0635, d4.loss_bbox: 0.1929, loss: 1.8502, grad_norm: 21.3093
2025-06-11 10:48:38,176 - mmdet - INFO - Epoch [6][1200/3517]	lr: 1.358e-05, eta: 1:12:34, time: 1.891, data_time: 0.057, memory: 32518, loss_cls: 0.0579, loss_bbox: 0.1931, d0.loss_cls: 0.1472, d0.loss_bbox: 0.3094, d1.loss_cls: 0.0903, d1.loss_bbox: 0.2312, d2.loss_cls: 0.0748, d2.loss_bbox: 0.2077, d3.loss_cls: 0.0630, d3.loss_bbox: 0.2036, d4.loss_cls: 0.0595, d4.loss_bbox: 0.1954, loss: 1.8329, grad_norm: 24.0343
2025-06-11 10:50:16,189 - mmdet - INFO - Epoch [6][1250/3517]	lr: 1.358e-05, eta: 1:11:00, time: 1.960, data_time: 0.057, memory: 32518, loss_cls: 0.0630, loss_bbox: 0.1984, d0.loss_cls: 0.1482, d0.loss_bbox: 0.3138, d1.loss_cls: 0.0952, d1.loss_bbox: 0.2373, d2.loss_cls: 0.0800, d2.loss_bbox: 0.2159, d3.loss_cls: 0.0698, d3.loss_bbox: 0.2097, d4.loss_cls: 0.0659, d4.loss_bbox: 0.2005, loss: 1.8978, grad_norm: 28.1945
2025-06-11 10:51:50,314 - mmdet - INFO - Epoch [6][1300/3517]	lr: 1.358e-05, eta: 1:09:26, time: 1.882, data_time: 0.054, memory: 32518, loss_cls: 0.0615, loss_bbox: 0.1975, d0.loss_cls: 0.1517, d0.loss_bbox: 0.3055, d1.loss_cls: 0.0944, d1.loss_bbox: 0.2343, d2.loss_cls: 0.0798, d2.loss_bbox: 0.2131, d3.loss_cls: 0.0677, d3.loss_bbox: 0.2080, d4.loss_cls: 0.0637, d4.loss_bbox: 0.1992, loss: 1.8765, grad_norm: 26.4914
2025-06-11 10:53:24,072 - mmdet - INFO - Epoch [6][1350/3517]	lr: 1.358e-05, eta: 1:07:52, time: 1.875, data_time: 0.054, memory: 32518, loss_cls: 0.0581, loss_bbox: 0.1921, d0.loss_cls: 0.1519, d0.loss_bbox: 0.3063, d1.loss_cls: 0.0918, d1.loss_bbox: 0.2293, d2.loss_cls: 0.0747, d2.loss_bbox: 0.2091, d3.loss_cls: 0.0629, d3.loss_bbox: 0.2050, d4.loss_cls: 0.0608, d4.loss_bbox: 0.1943, loss: 1.8364, grad_norm: 113.4058
2025-06-11 10:54:57,569 - mmdet - INFO - Epoch [6][1400/3517]	lr: 1.358e-05, eta: 1:06:18, time: 1.870, data_time: 0.051, memory: 32518, loss_cls: 0.0625, loss_bbox: 0.1935, d0.loss_cls: 0.1492, d0.loss_bbox: 0.3047, d1.loss_cls: 0.0960, d1.loss_bbox: 0.2305, d2.loss_cls: 0.0795, d2.loss_bbox: 0.2090, d3.loss_cls: 0.0669, d3.loss_bbox: 0.2049, d4.loss_cls: 0.0642, d4.loss_bbox: 0.1953, loss: 1.8562, grad_norm: 72.9874
2025-06-11 10:56:31,382 - mmdet - INFO - Epoch [6][1450/3517]	lr: 1.358e-05, eta: 1:04:44, time: 1.876, data_time: 0.056, memory: 32518, loss_cls: 0.0604, loss_bbox: 0.1920, d0.loss_cls: 0.1494, d0.loss_bbox: 0.3107, d1.loss_cls: 0.0933, d1.loss_bbox: 0.2331, d2.loss_cls: 0.0770, d2.loss_bbox: 0.2108, d3.loss_cls: 0.0657, d3.loss_bbox: 0.2050, d4.loss_cls: 0.0617, d4.loss_bbox: 0.1950, loss: 1.8540, grad_norm: 25.9181
2025-06-11 10:58:06,047 - mmdet - INFO - Epoch [6][1500/3517]	lr: 1.358e-05, eta: 1:03:10, time: 1.893, data_time: 0.060, memory: 32518, loss_cls: 0.0615, loss_bbox: 0.1971, d0.loss_cls: 0.1546, d0.loss_bbox: 0.3111, d1.loss_cls: 0.0972, d1.loss_bbox: 0.2338, d2.loss_cls: 0.0805, d2.loss_bbox: 0.2125, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2073, d4.loss_cls: 0.0637, d4.loss_bbox: 0.1987, loss: 1.8866, grad_norm: 13.6724
2025-06-11 10:59:40,201 - mmdet - INFO - Epoch [6][1550/3517]	lr: 1.358e-05, eta: 1:01:37, time: 1.883, data_time: 0.056, memory: 32518, loss_cls: 0.0608, loss_bbox: 0.1952, d0.loss_cls: 0.1510, d0.loss_bbox: 0.3091, d1.loss_cls: 0.0944, d1.loss_bbox: 0.2339, d2.loss_cls: 0.0785, d2.loss_bbox: 0.2115, d3.loss_cls: 0.0658, d3.loss_bbox: 0.2067, d4.loss_cls: 0.0629, d4.loss_bbox: 0.1968, loss: 1.8666, grad_norm: 35.1014
2025-06-11 11:01:13,738 - mmdet - INFO - Epoch [6][1600/3517]	lr: 1.358e-05, eta: 1:00:03, time: 1.871, data_time: 0.064, memory: 32518, loss_cls: 0.0616, loss_bbox: 0.1926, d0.loss_cls: 0.1517, d0.loss_bbox: 0.3016, d1.loss_cls: 0.0936, d1.loss_bbox: 0.2278, d2.loss_cls: 0.0781, d2.loss_bbox: 0.2087, d3.loss_cls: 0.0663, d3.loss_bbox: 0.2038, d4.loss_cls: 0.0633, d4.loss_bbox: 0.1948, loss: 1.8438, grad_norm: 35.2861
2025-06-11 11:02:46,484 - mmdet - INFO - Epoch [6][1650/3517]	lr: 1.358e-05, eta: 0:58:28, time: 1.855, data_time: 0.050, memory: 32518, loss_cls: 0.0636, loss_bbox: 0.1910, d0.loss_cls: 0.1525, d0.loss_bbox: 0.3000, d1.loss_cls: 0.0956, d1.loss_bbox: 0.2284, d2.loss_cls: 0.0785, d2.loss_bbox: 0.2078, d3.loss_cls: 0.0689, d3.loss_bbox: 0.2031, d4.loss_cls: 0.0651, d4.loss_bbox: 0.1930, loss: 1.8474, grad_norm: 22.0558
2025-06-11 11:04:30,133 - mmdet - INFO - Epoch [6][1700/3517]	lr: 1.358e-05, eta: 0:56:55, time: 2.073, data_time: 0.050, memory: 32518, loss_cls: 0.0607, loss_bbox: 0.1929, d0.loss_cls: 0.1538, d0.loss_bbox: 0.3068, d1.loss_cls: 0.0960, d1.loss_bbox: 0.2320, d2.loss_cls: 0.0787, d2.loss_bbox: 0.2094, d3.loss_cls: 0.0685, d3.loss_bbox: 0.2032, d4.loss_cls: 0.0630, d4.loss_bbox: 0.1948, loss: 1.8598, grad_norm: 24.6632
2025-06-11 11:06:02,721 - mmdet - INFO - Epoch [6][1750/3517]	lr: 1.358e-05, eta: 0:55:21, time: 1.852, data_time: 0.049, memory: 32518, loss_cls: 0.0632, loss_bbox: 0.1947, d0.loss_cls: 0.1504, d0.loss_bbox: 0.3068, d1.loss_cls: 0.0968, d1.loss_bbox: 0.2320, d2.loss_cls: 0.0808, d2.loss_bbox: 0.2106, d3.loss_cls: 0.0684, d3.loss_bbox: 0.2064, d4.loss_cls: 0.0644, d4.loss_bbox: 0.1977, loss: 1.8721, grad_norm: 25.5737
2025-06-11 11:07:59,023 - mmdet - INFO - Epoch [6][1800/3517]	lr: 1.358e-05, eta: 0:53:49, time: 2.326, data_time: 0.051, memory: 32518, loss_cls: 0.0597, loss_bbox: 0.1957, d0.loss_cls: 0.1551, d0.loss_bbox: 0.3074, d1.loss_cls: 0.0953, d1.loss_bbox: 0.2350, d2.loss_cls: 0.0797, d2.loss_bbox: 0.2110, d3.loss_cls: 0.0667, d3.loss_bbox: 0.2067, d4.loss_cls: 0.0619, d4.loss_bbox: 0.1974, loss: 1.8715, grad_norm: 18.9035
2025-06-11 11:09:31,937 - mmdet - INFO - Epoch [6][1850/3517]	lr: 1.358e-05, eta: 0:52:15, time: 1.858, data_time: 0.049, memory: 32518, loss_cls: 0.0581, loss_bbox: 0.1909, d0.loss_cls: 0.1493, d0.loss_bbox: 0.3053, d1.loss_cls: 0.0913, d1.loss_bbox: 0.2293, d2.loss_cls: 0.0753, d2.loss_bbox: 0.2069, d3.loss_cls: 0.0648, d3.loss_bbox: 0.2010, d4.loss_cls: 0.0602, d4.loss_bbox: 0.1924, loss: 1.8247, grad_norm: 18.5646
2025-06-11 11:11:05,660 - mmdet - INFO - Epoch [6][1900/3517]	lr: 1.358e-05, eta: 0:50:41, time: 1.874, data_time: 0.056, memory: 32518, loss_cls: 0.0581, loss_bbox: 0.1904, d0.loss_cls: 0.1523, d0.loss_bbox: 0.3018, d1.loss_cls: 0.0915, d1.loss_bbox: 0.2290, d2.loss_cls: 0.0741, d2.loss_bbox: 0.2057, d3.loss_cls: 0.0635, d3.loss_bbox: 0.2013, d4.loss_cls: 0.0599, d4.loss_bbox: 0.1923, loss: 1.8198, grad_norm: 35.3778
2025-06-11 11:12:39,370 - mmdet - INFO - Epoch [6][1950/3517]	lr: 1.358e-05, eta: 0:49:07, time: 1.874, data_time: 0.057, memory: 32518, loss_cls: 0.0570, loss_bbox: 0.1943, d0.loss_cls: 0.1510, d0.loss_bbox: 0.3115, d1.loss_cls: 0.0922, d1.loss_bbox: 0.2329, d2.loss_cls: 0.0754, d2.loss_bbox: 0.2105, d3.loss_cls: 0.0639, d3.loss_bbox: 0.2059, d4.loss_cls: 0.0590, d4.loss_bbox: 0.1959, loss: 1.8495, grad_norm: 18.4580
2025-06-11 11:14:12,423 - mmdet - INFO - Epoch [6][2000/3517]	lr: 1.358e-05, eta: 0:47:33, time: 1.861, data_time: 0.054, memory: 32518, loss_cls: 0.0581, loss_bbox: 0.1958, d0.loss_cls: 0.1537, d0.loss_bbox: 0.3112, d1.loss_cls: 0.0922, d1.loss_bbox: 0.2339, d2.loss_cls: 0.0753, d2.loss_bbox: 0.2119, d3.loss_cls: 0.0646, d3.loss_bbox: 0.2062, d4.loss_cls: 0.0603, d4.loss_bbox: 0.1978, loss: 1.8610, grad_norm: 37.5133
2025-06-11 11:15:45,468 - mmdet - INFO - Epoch [6][2050/3517]	lr: 1.358e-05, eta: 0:45:59, time: 1.861, data_time: 0.052, memory: 32518, loss_cls: 0.0617, loss_bbox: 0.1913, d0.loss_cls: 0.1541, d0.loss_bbox: 0.3044, d1.loss_cls: 0.0976, d1.loss_bbox: 0.2281, d2.loss_cls: 0.0787, d2.loss_bbox: 0.2075, d3.loss_cls: 0.0682, d3.loss_bbox: 0.2032, d4.loss_cls: 0.0641, d4.loss_bbox: 0.1929, loss: 1.8518, grad_norm: 14.8861
2025-06-11 11:17:19,834 - mmdet - INFO - Epoch [6][2100/3517]	lr: 1.358e-05, eta: 0:44:25, time: 1.887, data_time: 0.059, memory: 32518, loss_cls: 0.0592, loss_bbox: 0.1967, d0.loss_cls: 0.1545, d0.loss_bbox: 0.3111, d1.loss_cls: 0.0963, d1.loss_bbox: 0.2343, d2.loss_cls: 0.0782, d2.loss_bbox: 0.2134, d3.loss_cls: 0.0670, d3.loss_bbox: 0.2076, d4.loss_cls: 0.0613, d4.loss_bbox: 0.1986, loss: 1.8782, grad_norm: 21.3688
2025-06-11 11:18:53,513 - mmdet - INFO - Epoch [6][2150/3517]	lr: 1.358e-05, eta: 0:42:51, time: 1.874, data_time: 0.053, memory: 32518, loss_cls: 0.0612, loss_bbox: 0.1913, d0.loss_cls: 0.1492, d0.loss_bbox: 0.3052, d1.loss_cls: 0.0919, d1.loss_bbox: 0.2305, d2.loss_cls: 0.0766, d2.loss_bbox: 0.2076, d3.loss_cls: 0.0660, d3.loss_bbox: 0.2028, d4.loss_cls: 0.0625, d4.loss_bbox: 0.1939, loss: 1.8386, grad_norm: 16.3150
2025-06-11 11:20:27,292 - mmdet - INFO - Epoch [6][2200/3517]	lr: 1.358e-05, eta: 0:41:17, time: 1.876, data_time: 0.052, memory: 32518, loss_cls: 0.0557, loss_bbox: 0.1915, d0.loss_cls: 0.1453, d0.loss_bbox: 0.3051, d1.loss_cls: 0.0906, d1.loss_bbox: 0.2314, d2.loss_cls: 0.0732, d2.loss_bbox: 0.2072, d3.loss_cls: 0.0617, d3.loss_bbox: 0.2024, d4.loss_cls: 0.0570, d4.loss_bbox: 0.1934, loss: 1.8144, grad_norm: 24.2219
2025-06-11 11:22:00,661 - mmdet - INFO - Epoch [6][2250/3517]	lr: 1.358e-05, eta: 0:39:42, time: 1.867, data_time: 0.056, memory: 32518, loss_cls: 0.0603, loss_bbox: 0.1902, d0.loss_cls: 0.1505, d0.loss_bbox: 0.3047, d1.loss_cls: 0.0909, d1.loss_bbox: 0.2284, d2.loss_cls: 0.0763, d2.loss_bbox: 0.2067, d3.loss_cls: 0.0656, d3.loss_bbox: 0.2009, d4.loss_cls: 0.0611, d4.loss_bbox: 0.1921, loss: 1.8276, grad_norm: 37.1554
2025-06-11 11:23:34,241 - mmdet - INFO - Epoch [6][2300/3517]	lr: 1.358e-05, eta: 0:38:08, time: 1.872, data_time: 0.055, memory: 32518, loss_cls: 0.0618, loss_bbox: 0.1935, d0.loss_cls: 0.1522, d0.loss_bbox: 0.3121, d1.loss_cls: 0.0955, d1.loss_bbox: 0.2345, d2.loss_cls: 0.0807, d2.loss_bbox: 0.2108, d3.loss_cls: 0.0685, d3.loss_bbox: 0.2053, d4.loss_cls: 0.0642, d4.loss_bbox: 0.1958, loss: 1.8750, grad_norm: 62.7754
2025-06-11 11:25:08,084 - mmdet - INFO - Epoch [6][2350/3517]	lr: 1.358e-05, eta: 0:36:34, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.0609, loss_bbox: 0.1900, d0.loss_cls: 0.1496, d0.loss_bbox: 0.3019, d1.loss_cls: 0.0933, d1.loss_bbox: 0.2258, d2.loss_cls: 0.0781, d2.loss_bbox: 0.2061, d3.loss_cls: 0.0663, d3.loss_bbox: 0.2011, d4.loss_cls: 0.0636, d4.loss_bbox: 0.1917, loss: 1.8284, grad_norm: 17.7329
2025-06-11 11:26:42,008 - mmdet - INFO - Epoch [6][2400/3517]	lr: 1.358e-05, eta: 0:35:00, time: 1.879, data_time: 0.056, memory: 32518, loss_cls: 0.0596, loss_bbox: 0.1969, d0.loss_cls: 0.1514, d0.loss_bbox: 0.3097, d1.loss_cls: 0.0943, d1.loss_bbox: 0.2339, d2.loss_cls: 0.0780, d2.loss_bbox: 0.2123, d3.loss_cls: 0.0660, d3.loss_bbox: 0.2074, d4.loss_cls: 0.0618, d4.loss_bbox: 0.1990, loss: 1.8704, grad_norm: 16.7654
2025-06-11 11:28:15,979 - mmdet - INFO - Epoch [6][2450/3517]	lr: 1.358e-05, eta: 0:33:26, time: 1.879, data_time: 0.054, memory: 32518, loss_cls: 0.0602, loss_bbox: 0.1907, d0.loss_cls: 0.1450, d0.loss_bbox: 0.3008, d1.loss_cls: 0.0904, d1.loss_bbox: 0.2281, d2.loss_cls: 0.0755, d2.loss_bbox: 0.2075, d3.loss_cls: 0.0655, d3.loss_bbox: 0.2021, d4.loss_cls: 0.0610, d4.loss_bbox: 0.1928, loss: 1.8195, grad_norm: 14.3373
2025-06-11 11:29:49,521 - mmdet - INFO - Epoch [6][2500/3517]	lr: 1.358e-05, eta: 0:31:52, time: 1.871, data_time: 0.052, memory: 32518, loss_cls: 0.0624, loss_bbox: 0.1979, d0.loss_cls: 0.1511, d0.loss_bbox: 0.3169, d1.loss_cls: 0.0959, d1.loss_bbox: 0.2393, d2.loss_cls: 0.0804, d2.loss_bbox: 0.2156, d3.loss_cls: 0.0694, d3.loss_bbox: 0.2090, d4.loss_cls: 0.0640, d4.loss_bbox: 0.2003, loss: 1.9021, grad_norm: 30.2477
2025-06-11 11:31:22,928 - mmdet - INFO - Epoch [6][2550/3517]	lr: 1.358e-05, eta: 0:30:18, time: 1.868, data_time: 0.053, memory: 32518, loss_cls: 0.0604, loss_bbox: 0.1929, d0.loss_cls: 0.1507, d0.loss_bbox: 0.3132, d1.loss_cls: 0.0919, d1.loss_bbox: 0.2331, d2.loss_cls: 0.0774, d2.loss_bbox: 0.2104, d3.loss_cls: 0.0663, d3.loss_bbox: 0.2055, d4.loss_cls: 0.0621, d4.loss_bbox: 0.1956, loss: 1.8595, grad_norm: 15.9369
2025-06-11 11:32:56,469 - mmdet - INFO - Epoch [6][2600/3517]	lr: 1.358e-05, eta: 0:28:44, time: 1.871, data_time: 0.052, memory: 32518, loss_cls: 0.0578, loss_bbox: 0.1877, d0.loss_cls: 0.1445, d0.loss_bbox: 0.2996, d1.loss_cls: 0.0895, d1.loss_bbox: 0.2259, d2.loss_cls: 0.0745, d2.loss_bbox: 0.2049, d3.loss_cls: 0.0640, d3.loss_bbox: 0.1993, d4.loss_cls: 0.0591, d4.loss_bbox: 0.1896, loss: 1.7964, grad_norm: 80.2364
2025-06-11 11:34:29,927 - mmdet - INFO - Epoch [6][2650/3517]	lr: 1.358e-05, eta: 0:27:10, time: 1.869, data_time: 0.057, memory: 32518, loss_cls: 0.0605, loss_bbox: 0.1939, d0.loss_cls: 0.1530, d0.loss_bbox: 0.3064, d1.loss_cls: 0.0925, d1.loss_bbox: 0.2318, d2.loss_cls: 0.0784, d2.loss_bbox: 0.2093, d3.loss_cls: 0.0672, d3.loss_bbox: 0.2054, d4.loss_cls: 0.0630, d4.loss_bbox: 0.1962, loss: 1.8576, grad_norm: 15.9708
2025-06-11 11:36:03,411 - mmdet - INFO - Epoch [6][2700/3517]	lr: 1.358e-05, eta: 0:25:36, time: 1.870, data_time: 0.051, memory: 32518, loss_cls: 0.0565, loss_bbox: 0.1855, d0.loss_cls: 0.1443, d0.loss_bbox: 0.2998, d1.loss_cls: 0.0885, d1.loss_bbox: 0.2235, d2.loss_cls: 0.0734, d2.loss_bbox: 0.2012, d3.loss_cls: 0.0621, d3.loss_bbox: 0.1967, d4.loss_cls: 0.0574, d4.loss_bbox: 0.1879, loss: 1.7768, grad_norm: 16.5374
2025-06-11 11:37:36,861 - mmdet - INFO - Epoch [6][2750/3517]	lr: 1.358e-05, eta: 0:24:02, time: 1.869, data_time: 0.053, memory: 32518, loss_cls: 0.0655, loss_bbox: 0.2000, d0.loss_cls: 0.1516, d0.loss_bbox: 0.3128, d1.loss_cls: 0.0987, d1.loss_bbox: 0.2388, d2.loss_cls: 0.0843, d2.loss_bbox: 0.2152, d3.loss_cls: 0.0725, d3.loss_bbox: 0.2099, d4.loss_cls: 0.0674, d4.loss_bbox: 0.2021, loss: 1.9186, grad_norm: 38.3444
2025-06-11 11:39:10,629 - mmdet - INFO - Epoch [6][2800/3517]	lr: 1.358e-05, eta: 0:22:28, time: 1.875, data_time: 0.052, memory: 32518, loss_cls: 0.0593, loss_bbox: 0.1966, d0.loss_cls: 0.1490, d0.loss_bbox: 0.3171, d1.loss_cls: 0.0926, d1.loss_bbox: 0.2364, d2.loss_cls: 0.0783, d2.loss_bbox: 0.2128, d3.loss_cls: 0.0653, d3.loss_bbox: 0.2084, d4.loss_cls: 0.0616, d4.loss_bbox: 0.1985, loss: 1.8759, grad_norm: 15.1548
2025-06-11 11:40:44,272 - mmdet - INFO - Epoch [6][2850/3517]	lr: 1.358e-05, eta: 0:20:54, time: 1.873, data_time: 0.059, memory: 32518, loss_cls: 0.0562, loss_bbox: 0.1931, d0.loss_cls: 0.1492, d0.loss_bbox: 0.3111, d1.loss_cls: 0.0901, d1.loss_bbox: 0.2333, d2.loss_cls: 0.0736, d2.loss_bbox: 0.2109, d3.loss_cls: 0.0619, d3.loss_bbox: 0.2057, d4.loss_cls: 0.0579, d4.loss_bbox: 0.1958, loss: 1.8390, grad_norm: 20.9836
2025-06-11 11:42:17,866 - mmdet - INFO - Epoch [6][2900/3517]	lr: 1.358e-05, eta: 0:19:20, time: 1.872, data_time: 0.055, memory: 32518, loss_cls: 0.0571, loss_bbox: 0.1858, d0.loss_cls: 0.1499, d0.loss_bbox: 0.3027, d1.loss_cls: 0.0904, d1.loss_bbox: 0.2261, d2.loss_cls: 0.0739, d2.loss_bbox: 0.2035, d3.loss_cls: 0.0633, d3.loss_bbox: 0.1979, d4.loss_cls: 0.0585, d4.loss_bbox: 0.1885, loss: 1.7976, grad_norm: 25.0111
2025-06-11 11:43:51,147 - mmdet - INFO - Epoch [6][2950/3517]	lr: 1.358e-05, eta: 0:17:46, time: 1.866, data_time: 0.053, memory: 32518, loss_cls: 0.0616, loss_bbox: 0.1948, d0.loss_cls: 0.1485, d0.loss_bbox: 0.3119, d1.loss_cls: 0.0918, d1.loss_bbox: 0.2366, d2.loss_cls: 0.0776, d2.loss_bbox: 0.2132, d3.loss_cls: 0.0679, d3.loss_bbox: 0.2073, d4.loss_cls: 0.0634, d4.loss_bbox: 0.1975, loss: 1.8721, grad_norm: 23.9394
2025-06-11 11:45:25,485 - mmdet - INFO - Epoch [6][3000/3517]	lr: 1.358e-05, eta: 0:16:12, time: 1.887, data_time: 0.054, memory: 32518, loss_cls: 0.0624, loss_bbox: 0.1926, d0.loss_cls: 0.1517, d0.loss_bbox: 0.3013, d1.loss_cls: 0.0972, d1.loss_bbox: 0.2296, d2.loss_cls: 0.0808, d2.loss_bbox: 0.2089, d3.loss_cls: 0.0704, d3.loss_bbox: 0.2026, d4.loss_cls: 0.0649, d4.loss_bbox: 0.1945, loss: 1.8569, grad_norm: 22.3717
2025-06-11 11:46:59,236 - mmdet - INFO - Epoch [6][3050/3517]	lr: 1.358e-05, eta: 0:14:38, time: 1.875, data_time: 0.053, memory: 32518, loss_cls: 0.0610, loss_bbox: 0.1933, d0.loss_cls: 0.1521, d0.loss_bbox: 0.3075, d1.loss_cls: 0.0959, d1.loss_bbox: 0.2310, d2.loss_cls: 0.0790, d2.loss_bbox: 0.2100, d3.loss_cls: 0.0667, d3.loss_bbox: 0.2049, d4.loss_cls: 0.0634, d4.loss_bbox: 0.1951, loss: 1.8599, grad_norm: 16.6294
2025-06-11 11:48:32,494 - mmdet - INFO - Epoch [6][3100/3517]	lr: 1.358e-05, eta: 0:13:04, time: 1.865, data_time: 0.054, memory: 32518, loss_cls: 0.0600, loss_bbox: 0.1943, d0.loss_cls: 0.1522, d0.loss_bbox: 0.3077, d1.loss_cls: 0.0948, d1.loss_bbox: 0.2323, d2.loss_cls: 0.0784, d2.loss_bbox: 0.2110, d3.loss_cls: 0.0671, d3.loss_bbox: 0.2055, d4.loss_cls: 0.0616, d4.loss_bbox: 0.1967, loss: 1.8616, grad_norm: 21.9356
2025-06-11 11:50:09,391 - mmdet - INFO - Epoch [6][3150/3517]	lr: 1.358e-05, eta: 0:11:30, time: 1.938, data_time: 0.052, memory: 32518, loss_cls: 0.0609, loss_bbox: 0.1883, d0.loss_cls: 0.1495, d0.loss_bbox: 0.3026, d1.loss_cls: 0.0952, d1.loss_bbox: 0.2283, d2.loss_cls: 0.0798, d2.loss_bbox: 0.2049, d3.loss_cls: 0.0680, d3.loss_bbox: 0.2000, d4.loss_cls: 0.0632, d4.loss_bbox: 0.1905, loss: 1.8312, grad_norm: 11.7225
2025-06-11 11:51:43,244 - mmdet - INFO - Epoch [6][3200/3517]	lr: 1.358e-05, eta: 0:09:56, time: 1.877, data_time: 0.054, memory: 32518, loss_cls: 0.0631, loss_bbox: 0.1954, d0.loss_cls: 0.1465, d0.loss_bbox: 0.3091, d1.loss_cls: 0.0978, d1.loss_bbox: 0.2350, d2.loss_cls: 0.0809, d2.loss_bbox: 0.2135, d3.loss_cls: 0.0703, d3.loss_bbox: 0.2064, d4.loss_cls: 0.0651, d4.loss_bbox: 0.1970, loss: 1.8801, grad_norm: 27.6246
2025-06-11 11:53:16,659 - mmdet - INFO - Epoch [6][3250/3517]	lr: 1.358e-05, eta: 0:08:22, time: 1.868, data_time: 0.050, memory: 32518, loss_cls: 0.0637, loss_bbox: 0.1960, d0.loss_cls: 0.1509, d0.loss_bbox: 0.3056, d1.loss_cls: 0.0951, d1.loss_bbox: 0.2330, d2.loss_cls: 0.0806, d2.loss_bbox: 0.2121, d3.loss_cls: 0.0693, d3.loss_bbox: 0.2068, d4.loss_cls: 0.0646, d4.loss_bbox: 0.1985, loss: 1.8762, grad_norm: 24.2509
2025-06-11 11:54:50,306 - mmdet - INFO - Epoch [6][3300/3517]	lr: 1.358e-05, eta: 0:06:48, time: 1.873, data_time: 0.059, memory: 32518, loss_cls: 0.0586, loss_bbox: 0.1875, d0.loss_cls: 0.1474, d0.loss_bbox: 0.3019, d1.loss_cls: 0.0925, d1.loss_bbox: 0.2265, d2.loss_cls: 0.0759, d2.loss_bbox: 0.2045, d3.loss_cls: 0.0653, d3.loss_bbox: 0.1982, d4.loss_cls: 0.0610, d4.loss_bbox: 0.1899, loss: 1.8093, grad_norm: 19.5300
2025-06-11 11:56:24,414 - mmdet - INFO - Epoch [6][3350/3517]	lr: 1.358e-05, eta: 0:05:14, time: 1.882, data_time: 0.059, memory: 32518, loss_cls: 0.0619, loss_bbox: 0.1945, d0.loss_cls: 0.1517, d0.loss_bbox: 0.3072, d1.loss_cls: 0.0980, d1.loss_bbox: 0.2322, d2.loss_cls: 0.0817, d2.loss_bbox: 0.2115, d3.loss_cls: 0.0685, d3.loss_bbox: 0.2060, d4.loss_cls: 0.0637, d4.loss_bbox: 0.1965, loss: 1.8734, grad_norm: 11.2318
2025-06-11 11:57:58,150 - mmdet - INFO - Epoch [6][3400/3517]	lr: 1.358e-05, eta: 0:03:40, time: 1.875, data_time: 0.056, memory: 32518, loss_cls: 0.0617, loss_bbox: 0.1894, d0.loss_cls: 0.1463, d0.loss_bbox: 0.3042, d1.loss_cls: 0.0935, d1.loss_bbox: 0.2305, d2.loss_cls: 0.0793, d2.loss_bbox: 0.2067, d3.loss_cls: 0.0677, d3.loss_bbox: 0.2008, d4.loss_cls: 0.0640, d4.loss_bbox: 0.1914, loss: 1.8355, grad_norm: 19.2355
2025-06-11 11:59:31,290 - mmdet - INFO - Epoch [6][3450/3517]	lr: 1.358e-05, eta: 0:02:05, time: 1.863, data_time: 0.053, memory: 32518, loss_cls: 0.0602, loss_bbox: 0.1913, d0.loss_cls: 0.1527, d0.loss_bbox: 0.3049, d1.loss_cls: 0.0932, d1.loss_bbox: 0.2307, d2.loss_cls: 0.0782, d2.loss_bbox: 0.2084, d3.loss_cls: 0.0664, d3.loss_bbox: 0.2031, d4.loss_cls: 0.0621, d4.loss_bbox: 0.1933, loss: 1.8446, grad_norm: 16.8895
2025-06-11 12:01:05,763 - mmdet - INFO - Epoch [6][3500/3517]	lr: 1.358e-05, eta: 0:00:31, time: 1.889, data_time: 0.056, memory: 32518, loss_cls: 0.0619, loss_bbox: 0.1993, d0.loss_cls: 0.1536, d0.loss_bbox: 0.3147, d1.loss_cls: 0.0963, d1.loss_bbox: 0.2384, d2.loss_cls: 0.0795, d2.loss_bbox: 0.2173, d3.loss_cls: 0.0678, d3.loss_bbox: 0.2109, d4.loss_cls: 0.0647, d4.loss_bbox: 0.2015, loss: 1.9059, grad_norm: 90.9139
2025-06-11 12:01:40,984 - mmdet - INFO - Saving checkpoint at 6 epochs
2025-06-11 12:27:52,405 - mmdet - INFO - Exp name: lidar_0075v_cam_res_2x2_hednetmiddleencoder_hednetbackbone4_dss0511_dp03_hugeep2_num2_morton_conv_xy_rope_bs4.py
2025-06-11 12:27:52,405 - mmdet - INFO - Epoch(val) [6][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7916, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8807, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9073, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9202, pts_bbox_NuScenes/car_trans_err: 0.1743, pts_bbox_NuScenes/car_scale_err: 0.1508, pts_bbox_NuScenes/car_orient_err: 0.0419, pts_bbox_NuScenes/car_vel_err: 0.2928, pts_bbox_NuScenes/car_attr_err: 0.1912, pts_bbox_NuScenes/mATE: 0.2823, pts_bbox_NuScenes/mASE: 0.2615, pts_bbox_NuScenes/mAOE: 0.2567, pts_bbox_NuScenes/mAVE: 0.2756, pts_bbox_NuScenes/mAAE: 0.1819, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.4266, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.6250, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7233, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7586, pts_bbox_NuScenes/truck_trans_err: 0.3379, pts_bbox_NuScenes/truck_scale_err: 0.1957, pts_bbox_NuScenes/truck_orient_err: 0.0428, pts_bbox_NuScenes/truck_vel_err: 0.2722, pts_bbox_NuScenes/truck_attr_err: 0.2011, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0553, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1984, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3991, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4677, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6623, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4372, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8127, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1100, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2936, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.5380, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7494, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8979, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9260, pts_bbox_NuScenes/bus_trans_err: 0.3182, pts_bbox_NuScenes/bus_scale_err: 0.1940, pts_bbox_NuScenes/bus_orient_err: 0.0449, pts_bbox_NuScenes/bus_vel_err: 0.4756, pts_bbox_NuScenes/bus_attr_err: 0.2614, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1892, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4402, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.6019, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6806, pts_bbox_NuScenes/trailer_trans_err: 0.4713, pts_bbox_NuScenes/trailer_scale_err: 0.2240, pts_bbox_NuScenes/trailer_orient_err: 0.4873, pts_bbox_NuScenes/trailer_vel_err: 0.2266, pts_bbox_NuScenes/trailer_attr_err: 0.1735, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.6102, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7133, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7610, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7755, pts_bbox_NuScenes/barrier_trans_err: 0.2092, pts_bbox_NuScenes/barrier_scale_err: 0.2876, pts_bbox_NuScenes/barrier_orient_err: 0.0445, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6427, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7705, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.8000, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.8075, pts_bbox_NuScenes/motorcycle_trans_err: 0.2060, pts_bbox_NuScenes/motorcycle_scale_err: 0.2469, pts_bbox_NuScenes/motorcycle_orient_err: 0.2082, pts_bbox_NuScenes/motorcycle_vel_err: 0.3884, pts_bbox_NuScenes/motorcycle_attr_err: 0.2143, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5536, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.6045, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6132, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6232, pts_bbox_NuScenes/bicycle_trans_err: 0.1682, pts_bbox_NuScenes/bicycle_scale_err: 0.2601, pts_bbox_NuScenes/bicycle_orient_err: 0.3034, pts_bbox_NuScenes/bicycle_vel_err: 0.2183, pts_bbox_NuScenes/bicycle_attr_err: 0.0053, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.8150, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8542, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8742, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8871, pts_bbox_NuScenes/pedestrian_trans_err: 0.1427, pts_bbox_NuScenes/pedestrian_scale_err: 0.2957, pts_bbox_NuScenes/pedestrian_orient_err: 0.3247, pts_bbox_NuScenes/pedestrian_vel_err: 0.2212, pts_bbox_NuScenes/pedestrian_attr_err: 0.1144, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.7397, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7725, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7976, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8172, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1325, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3230, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.7118, pts_bbox_NuScenes/mAP: 0.6752
