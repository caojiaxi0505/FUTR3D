2025-06-20 02:42:39,392 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090 D
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0+cu116
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0+cu116
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+3056288
spconv2.0: True
------------------------------------------------------------

2025-06-20 02:42:39,980 - mmdet - INFO - 分布式训练: True
2025-06-20 02:42:40,564 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='ResizeCropFlipImage',
        data_aug_conf=dict(
            resize_lim=(0.94, 1.25),
            final_dim=(640, 1600),
            bot_pct_lim=(0.0, 0.0),
            rot_lim=(0.0, 0.0),
            H=900,
            W=1600,
            rand_flip=True),
        training=True),
    dict(
        type='GlobalRotScaleTransImage',
        rot_range=[-0.3925, 0.3925],
        translation_std=[0, 0, 0],
        scale_ratio_range=[0.95, 1.05],
        reverse_angle=True,
        training=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='ResizeCropFlipImage',
        data_aug_conf=dict(
            resize_lim=(0.94, 1.25),
            final_dim=(640, 1600),
            bot_pct_lim=(0.0, 0.0),
            rot_lim=(0.0, 0.0),
            H=900,
            W=1600,
            rand_flip=True),
        training=False),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['points', 'img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='ResizeCropFlipImage',
                data_aug_conf=dict(
                    resize_lim=(0.94, 1.25),
                    final_dim=(640, 1600),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=True),
                training=True),
            dict(
                type='GlobalRotScaleTransImage',
                rot_range=[-0.3925, 0.3925],
                translation_std=[0, 0, 0],
                scale_ratio_range=[0.95, 1.05],
                reverse_angle=True,
                training=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='ResizeCropFlipImage',
                data_aug_conf=dict(
                    resize_lim=(0.94, 1.25),
                    final_dim=(640, 1600),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=True),
                training=False),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='ResizeCropFlipImage',
                data_aug_conf=dict(
                    resize_lim=(0.94, 1.25),
                    final_dim=(640, 1600),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=True),
                training=False),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/lidar_0075v_900q_enhance_petr_vov_1600/vov_petr_bs2'
load_from = 'pretrained/petr_fused_convert.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[57.375, 57.12, 58.395], to_rgb=False)
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_grid_mask=True,
    freeze_backbone=True,
    img_backbone=dict(
        type='VoVNetCP',
        spec_name='V-99-eSE',
        norm_eval=True,
        frozen_stages=-1,
        input_ch=3,
        out_features=('stage4', 'stage5')),
    img_neck=dict(
        type='CPFPN', in_channels=[768, 1024], out_channels=256, num_outs=2),
    pts_voxel_layer=dict(
        max_num_points=-1,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(-1, -1),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(
        type='DynamicVFE',
        in_channels=5,
        feat_channels=[64, 128],
        with_distance=False,
        with_cluster_center=True,
        with_voxel_center=True,
        voxel_size=[0.075, 0.075, 0.2],
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_middle_encoder=dict(
        type='HEDNet',
        in_channels=128,
        sparse_shape=[41, 1440, 1440],
        model_cfg=dict(
            FEATURE_DIM=128,
            NUM_LAYERS=2,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDE=[1, 2, 2],
            DOWN_KERNEL_SIZE=[3, 3, 3])),
    pts_backbone=dict(
        type='CascadeDEDBackbone',
        in_channels=256,
        model_cfg=dict(
            USE_SECONDMAMBA=False,
            FEATURE_DIM=256,
            NUM_LAYERS=4,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDES=[1, 2, 2])),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        dss_date_version='0511',
        dss_drop_prob=0.3,
        dss_mamba_version='DSSMamba_Huge_EP2',
        dss_num_layers=2,
        dss_use_morton=True,
        dss_use_conv=True,
        dss_use_xy=True,
        dss_use_rope=True,
        dss_stack=True,
        dss_strong_cls=True,
        anchor_size=3,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='FUTR3DAttention',
                            use_lidar=True,
                            use_camera=True,
                            use_radar=False,
                            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
ida_aug_conf = dict(
    resize_lim=(0.94, 1.25),
    final_dim=(640, 1600),
    bot_pct_lim=(0.0, 0.0),
    rot_lim=(0.0, 0.0),
    H=900,
    W=1600,
    rand_flip=True)
find_unused_parameters = True
cudnn_benchmark = True
runner = dict(type='EpochBasedRunner', max_epochs=6)
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    paramwise_cfg=dict(
        custom_keys=dict(
            img_backbone=dict(lr_mult=0.1),
            img_neck=dict(lr_mult=0.1),
            pts_middle_encoder=dict(lr_mult=0.1),
            pts_backbone=dict(lr_mult=0.1),
            pts_neck=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
gpu_ids = range(0, 2)

2025-06-20 02:42:40,565 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-06-20 02:42:41,479 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-06-20 02:42:41,769 - mmdet - INFO - initialize CPFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_voxel_encoder.vfe_layers.0.0.weight - torch.Size([64, 11]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.0.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_voxel_encoder.vfe_layers.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.0.weight - torch.Size([16, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.0.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.0.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.1.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.2.conv2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.2.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.0.weight - torch.Size([32, 3, 3, 3, 16]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv1.3.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv1.3.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.0.blocks.2.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.1.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.conv2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.encoder.2.blocks.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.0.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder.1.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.0.decoder_norm.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.0.weight - torch.Size([64, 3, 3, 3, 32]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv2.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv2.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.0.blocks.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.1.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.conv2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.encoder.2.blocks.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.0.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.0.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder.1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.0.decoder_norm.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.0.weight - torch.Size([128, 3, 3, 3, 64]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv3.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv3.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.0.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.0.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.0.blocks.2.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.0.blocks.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.1.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.1.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.layers.1.encoder.2.blocks.1.conv2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.encoder.2.blocks.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.0.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.layers.1.decoder_norm.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.3.weight - torch.Size([128, 3, 1, 1, 128]): 
Initialized by user-defined `init_weights` in HEDNet  

pts_middle_encoder.conv_out.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_f_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.A_log_b_xy - torch.Size([512, 64]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_f_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.D_b_xy - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.in_proj_xy.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_f_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.x_proj_b_xy.weight - torch.Size([144, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_f.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_x_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.conv1d_z_xy_b.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.out_proj.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mamba.global_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.1.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight - torch.Size([12, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.weight - torch.Size([256, 3]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight - torch.Size([256, 768]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.A_log_h2t - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.D_h2t - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.A_log_t2h - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.D_t2h - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight - torch.Size([512, 1, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight - torch.Size([48, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight - torch.Size([512, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/conv.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_1/norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_2/norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/conv.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stem.stem_3/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.0.OSA2_1_0/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.1.OSA2_1_1/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.2.OSA2_1_2/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.3.OSA2_1_3/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.layers.4.OSA2_1_4/norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/conv.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.concat.OSA2_1_concat/norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.ese.fc.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage2.OSA2_1.ese.fc.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/conv.weight - torch.Size([160, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.0.OSA3_1_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.1.OSA3_1_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.2.OSA3_1_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.3.OSA3_1_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.layers.4.OSA3_1_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/conv.weight - torch.Size([512, 1056, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.concat.OSA3_1_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_1.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/conv.weight - torch.Size([160, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.0.OSA3_2_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.1.OSA3_2_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.2.OSA3_2_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.3.OSA3_2_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.layers.4.OSA3_2_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/conv.weight - torch.Size([512, 1312, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.concat.OSA3_2_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_2.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/conv.weight - torch.Size([160, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.0.OSA3_3_0/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.1.OSA3_3_1/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.2.OSA3_3_2/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.3.OSA3_3_3/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/conv.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.layers.4.OSA3_3_4/norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/conv.weight - torch.Size([512, 1312, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.concat.OSA3_3_concat/norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.ese.fc.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage3.OSA3_3.ese.fc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/conv.weight - torch.Size([192, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.0.OSA4_1_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.1.OSA4_1_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.2.OSA4_1_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.3.OSA4_1_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.layers.4.OSA4_1_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/conv.weight - torch.Size([768, 1472, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.concat.OSA4_1_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_1.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.0.OSA4_2_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.1.OSA4_2_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.2.OSA4_2_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.3.OSA4_2_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.layers.4.OSA4_2_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.concat.OSA4_2_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_2.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.0.OSA4_3_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.1.OSA4_3_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.2.OSA4_3_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.3.OSA4_3_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.layers.4.OSA4_3_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.concat.OSA4_3_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_3.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.0.OSA4_4_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.1.OSA4_4_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.2.OSA4_4_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.3.OSA4_4_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.layers.4.OSA4_4_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.concat.OSA4_4_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_4.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.0.OSA4_5_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.1.OSA4_5_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.2.OSA4_5_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.3.OSA4_5_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.layers.4.OSA4_5_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.concat.OSA4_5_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_5.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.0.OSA4_6_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.1.OSA4_6_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.2.OSA4_6_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.3.OSA4_6_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.layers.4.OSA4_6_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.concat.OSA4_6_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_6.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.0.OSA4_7_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.1.OSA4_7_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.2.OSA4_7_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.3.OSA4_7_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.layers.4.OSA4_7_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.concat.OSA4_7_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_7.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.0.OSA4_8_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.1.OSA4_8_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.2.OSA4_8_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.3.OSA4_8_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.layers.4.OSA4_8_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.concat.OSA4_8_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_8.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/conv.weight - torch.Size([192, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.0.OSA4_9_0/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.1.OSA4_9_1/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.2.OSA4_9_2/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.3.OSA4_9_3/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/conv.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.layers.4.OSA4_9_4/norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/conv.weight - torch.Size([768, 1728, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.concat.OSA4_9_concat/norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.ese.fc.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage4.OSA4_9.ese.fc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/conv.weight - torch.Size([224, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.0.OSA5_1_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.1.OSA5_1_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.2.OSA5_1_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.3.OSA5_1_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.layers.4.OSA5_1_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/conv.weight - torch.Size([1024, 1888, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.concat.OSA5_1_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_1.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/conv.weight - torch.Size([224, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.0.OSA5_2_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.1.OSA5_2_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.2.OSA5_2_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.3.OSA5_2_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.layers.4.OSA5_2_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/conv.weight - torch.Size([1024, 2144, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.concat.OSA5_2_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_2.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/conv.weight - torch.Size([224, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.0.OSA5_3_0/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.1.OSA5_3_1/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.2.OSA5_3_2/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.3.OSA5_3_3/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/conv.weight - torch.Size([224, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.layers.4.OSA5_3_4/norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/conv.weight - torch.Size([1024, 2144, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.concat.OSA5_3_concat/norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.ese.fc.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_backbone.stage5.OSA5_3.ese.fc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.0.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

img_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

img_neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-06-20 02:42:41,816 - mmdet - INFO - 使用SyncBN
2025-06-20 02:42:41,906 - mmdet - INFO - Model:
FUTR3D(
  (grid_mask): GridMask()
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=-1, max_voxels=(-1, -1), deterministic=True)
  (pts_voxel_encoder): DynamicVFE(
    (scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
    (vfe_layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=11, out_features=64, bias=False)
        (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (vfe_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=False)
    (cluster_scatter): DynamicScatter(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], average_points=True)
  )
  (pts_middle_encoder): HEDNet(
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SubMConv3d(128, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (3): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv2): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv3): SparseSequential(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[1, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (layers): ModuleList(
      (0): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): SEDLayer(
        (encoder): ModuleList(
          (0): SEDBlock(
            (blocks): SparseSequential(
              (0): Identity()
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
              (2): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (1): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
          (2): SEDBlock(
            (blocks): SparseSequential(
              (0): SparseSequential(
                (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
                (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): SparseBasicBlock(
                (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU()
                (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (decoder): ModuleList(
          (0): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SparseSequential(
            (0): SparseInverseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
            (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU()
    )
  )
  (pts_backbone): CascadeDEDBackbone(
    (layers): ModuleList(
      (0): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (2): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (3): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): RMSNorm()
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): RMSNorm()
                    )
                    (1): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=2048, bias=False)
                        (in_proj_xy): Linear(in_features=256, out_features=2048, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=512, bias=True)
                        (act_xy): SiLU()
                        (x_proj_f_xy): Linear(in_features=512, out_features=144, bias=False)
                        (x_proj_b_xy): Linear(in_features=512, out_features=144, bias=False)
                        (dt_proj_f_xy): Linear(in_features=16, out_features=512, bias=True)
                        (dt_proj_b_xy): Linear(in_features=16, out_features=512, bias=True)
                        (conv1d_x_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_f): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_x_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (conv1d_z_xy_b): Conv1d(512, 512, kernel_size=(4,), stride=(1,), groups=512)
                        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
                        (global_proj): Linear(in_features=2048, out_features=2048, bias=True)
                      )
                      (dropout): DropPath(drop_prob=0.300)
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): RotaryEmbedding()
                )
                (3): DropPath(drop_prob=0.100)
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
                (img_attention_weights): Linear(in_features=256, out_features=12, bias=True)
                (img_output_proj): Linear(in_features=256, out_features=256, bias=True)
                (position_encoder): Sequential(
                  (0): Linear(in_features=3, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (5): ReLU(inplace=True)
                )
                (weight_dropout): Dropout(p=0.0, inplace=False)
                (modality_fusion_layer): Sequential(
                  (0): Linear(in_features=768, out_features=256, bias=True)
                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (2): ReLU()
                  (3): Linear(in_features=256, out_features=256, bias=True)
                  (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (camera_mixer): LidarCameraFusionMambaBlock(
                  (layers): ModuleList(
                    (0): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                    (1): LidarCameraFusionMambaV2(
                      (activation_fn): SiLU()
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (conv1d_h2t): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_h2t): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_h2t): Linear(in_features=16, out_features=512, bias=True)
                      (conv1d_t2h): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
                      (x_proj_t2h): Linear(in_features=512, out_features=48, bias=False)
                      (dt_proj_t2h): Linear(in_features=16, out_features=512, bias=True)
                      (lidar_guidance_proj): Linear(in_features=512, out_features=512, bias=True)
                      (out_proj): Linear(in_features=512, out_features=256, bias=False)
                    )
                  )
                  (norm): ModuleList(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (dropout): ModuleList(
                    (0): DropPath(drop_prob=0.100)
                    (1): DropPath(drop_prob=0.100)
                  )
                )
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (1): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (2): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (3): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (4): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (5): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
  )
  (img_backbone): VoVNetCP(
    (stem): Sequential(
      (stem_1/conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (stem_1/norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_1/relu): ReLU(inplace=True)
      (stem_2/conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (stem_2/norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_2/relu): ReLU(inplace=True)
      (stem_3/conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (stem_3/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (stem_3/relu): ReLU(inplace=True)
    )
    (stage2): _OSA_stage(
      (OSA2_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA2_1_0/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_0/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA2_1_1/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_1/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA2_1_2/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_2/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA2_1_3/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_3/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA2_1_4/conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA2_1_4/norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA2_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA2_1_concat/conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA2_1_concat/norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA2_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage3): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA3_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_1_0/conv): Conv2d(256, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_0/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_1_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_1/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_1_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_2/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_1_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_3/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_1_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_1_4/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_1_concat/conv): Conv2d(1056, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_1_concat/norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA3_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_2_0/conv): Conv2d(512, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_0/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_2_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_1/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_2_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_2/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_2_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_3/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_2_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_2_4/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_2_concat/conv): Conv2d(1312, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_2_concat/norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA3_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA3_3_0/conv): Conv2d(512, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_0/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA3_3_1/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_1/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA3_3_2/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_2/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA3_3_3/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_3/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA3_3_4/conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA3_3_4/norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA3_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA3_3_concat/conv): Conv2d(1312, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA3_3_concat/norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA3_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage4): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA4_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_1_0/conv): Conv2d(512, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_1_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_1_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_1_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_1_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_1_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_1_concat/conv): Conv2d(1472, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_1_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_2_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_2_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_2_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_2_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_2_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_2_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_2_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_2_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_3_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_3_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_3_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_3_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_3_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_3_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_3_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_3_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_4): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_4_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_4_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_4_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_4_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_4_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_4_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_4_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_4_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_4_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_4_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_5): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_5_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_5_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_5_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_5_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_5_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_5_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_5_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_5_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_5_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_5_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_6): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_6_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_6_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_6_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_6_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_6_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_6_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_6_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_6_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_6_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_6_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_7): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_7_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_7_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_7_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_7_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_7_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_7_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_7_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_7_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_7_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_7_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_8): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_8_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_8_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_8_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_8_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_8_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_8_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_8_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_8_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_8_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_8_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA4_9): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA4_9_0/conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_0/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA4_9_1/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_1/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA4_9_2/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_2/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA4_9_3/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_3/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA4_9_4/conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA4_9_4/norm): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA4_9_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA4_9_concat/conv): Conv2d(1728, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA4_9_concat/norm): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA4_9_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
    (stage5): _OSA_stage(
      (Pooling): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (OSA5_1): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_1_0/conv): Conv2d(768, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_0/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_1_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_1/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_1_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_2/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_1_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_3/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_1_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_1_4/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_1_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_1_concat/conv): Conv2d(1888, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_1_concat/norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_1_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA5_2): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_2_0/conv): Conv2d(1024, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_0/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_2_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_1/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_2_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_2/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_2_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_3/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_2_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_2_4/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_2_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_2_concat/conv): Conv2d(2144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_2_concat/norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_2_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
      (OSA5_3): _OSA_module(
        (layers): ModuleList(
          (0): Sequential(
            (OSA5_3_0/conv): Conv2d(1024, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_0/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_0/relu): ReLU(inplace=True)
          )
          (1): Sequential(
            (OSA5_3_1/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_1/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_1/relu): ReLU(inplace=True)
          )
          (2): Sequential(
            (OSA5_3_2/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_2/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_2/relu): ReLU(inplace=True)
          )
          (3): Sequential(
            (OSA5_3_3/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_3/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_3/relu): ReLU(inplace=True)
          )
          (4): Sequential(
            (OSA5_3_4/conv): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (OSA5_3_4/norm): SyncBatchNorm(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (OSA5_3_4/relu): ReLU(inplace=True)
          )
        )
        (concat): Sequential(
          (OSA5_3_concat/conv): Conv2d(2144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (OSA5_3_concat/norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (OSA5_3_concat/relu): ReLU(inplace=True)
        )
        (ese): eSEModule(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (hsigmoid): Hsigmoid()
        )
      )
    )
  )
  (img_neck): CPFPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
)
2025-06-20 02:42:54,771 - mmdet - INFO - load checkpoint from local path: pretrained/petr_fused_convert.pth
2025-06-20 02:42:55,354 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.code_weights, pts_bbox_head.input_proj.weight, pts_bbox_head.input_proj.bias, pts_bbox_head.adapt_pos3d.0.weight, pts_bbox_head.adapt_pos3d.0.bias, pts_bbox_head.adapt_pos3d.2.weight, pts_bbox_head.adapt_pos3d.2.bias, pts_bbox_head.position_encoder.0.weight, pts_bbox_head.position_encoder.0.bias, pts_bbox_head.position_encoder.2.weight, pts_bbox_head.position_encoder.2.bias, pts_bbox_head.reference_points.weight, pts_bbox_head.query_embedding.0.weight, pts_bbox_head.query_embedding.0.bias, pts_bbox_head.query_embedding.2.weight, pts_bbox_head.query_embedding.2.bias, pts_bbox_head.aux_head.shared_conv.conv.weight, pts_bbox_head.aux_head.shared_conv.bn.weight, pts_bbox_head.aux_head.shared_conv.bn.bias, pts_bbox_head.aux_head.shared_conv.bn.running_mean, pts_bbox_head.aux_head.shared_conv.bn.running_var, pts_bbox_head.aux_head.shared_conv.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.reg.1.weight, pts_bbox_head.aux_head.task_heads.0.reg.1.bias, pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.height.1.weight, pts_bbox_head.aux_head.task_heads.0.height.1.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.dim.1.weight, pts_bbox_head.aux_head.task_heads.0.dim.1.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.rot.1.weight, pts_bbox_head.aux_head.task_heads.0.rot.1.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.vel.1.weight, pts_bbox_head.aux_head.task_heads.0.vel.1.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.reg.1.weight, pts_bbox_head.aux_head.task_heads.1.reg.1.bias, pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.height.1.weight, pts_bbox_head.aux_head.task_heads.1.height.1.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.dim.1.weight, pts_bbox_head.aux_head.task_heads.1.dim.1.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.rot.1.weight, pts_bbox_head.aux_head.task_heads.1.rot.1.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.vel.1.weight, pts_bbox_head.aux_head.task_heads.1.vel.1.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.reg.1.weight, pts_bbox_head.aux_head.task_heads.2.reg.1.bias, pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.height.1.weight, pts_bbox_head.aux_head.task_heads.2.height.1.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.dim.1.weight, pts_bbox_head.aux_head.task_heads.2.dim.1.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.rot.1.weight, pts_bbox_head.aux_head.task_heads.2.rot.1.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.vel.1.weight, pts_bbox_head.aux_head.task_heads.2.vel.1.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.reg.1.weight, pts_bbox_head.aux_head.task_heads.3.reg.1.bias, pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.height.1.weight, pts_bbox_head.aux_head.task_heads.3.height.1.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.dim.1.weight, pts_bbox_head.aux_head.task_heads.3.dim.1.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.rot.1.weight, pts_bbox_head.aux_head.task_heads.3.rot.1.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.vel.1.weight, pts_bbox_head.aux_head.task_heads.3.vel.1.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.reg.1.weight, pts_bbox_head.aux_head.task_heads.4.reg.1.bias, pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.height.1.weight, pts_bbox_head.aux_head.task_heads.4.height.1.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.dim.1.weight, pts_bbox_head.aux_head.task_heads.4.dim.1.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.rot.1.weight, pts_bbox_head.aux_head.task_heads.4.rot.1.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.vel.1.weight, pts_bbox_head.aux_head.task_heads.4.vel.1.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.reg.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.reg.1.weight, pts_bbox_head.aux_head.task_heads.5.reg.1.bias, pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.height.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.height.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.height.1.weight, pts_bbox_head.aux_head.task_heads.5.height.1.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.dim.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.dim.1.weight, pts_bbox_head.aux_head.task_heads.5.dim.1.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.rot.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.rot.1.weight, pts_bbox_head.aux_head.task_heads.5.rot.1.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.vel.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.vel.1.weight, pts_bbox_head.aux_head.task_heads.5.vel.1.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_mean, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.running_var, pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.num_batches_tracked, pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight, pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias, pts_bbox_head.transformer.decoder.post_norm.weight, pts_bbox_head.transformer.decoder.post_norm.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.inv_freq, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.cos_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.rope.sin_cached, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.bias, pts_bbox_head.cls_branches.0.0.weight, pts_bbox_head.cls_branches.0.0.bias, pts_bbox_head.cls_branches.0.1.weight, pts_bbox_head.cls_branches.0.1.bias, pts_bbox_head.cls_branches.0.3.weight, pts_bbox_head.cls_branches.0.3.bias, pts_bbox_head.cls_branches.0.4.weight, pts_bbox_head.cls_branches.0.4.bias, pts_bbox_head.cls_branches.0.6.weight, pts_bbox_head.cls_branches.0.6.bias, pts_bbox_head.cls_branches.1.0.weight, pts_bbox_head.cls_branches.1.0.bias, pts_bbox_head.cls_branches.1.1.weight, pts_bbox_head.cls_branches.1.1.bias, pts_bbox_head.cls_branches.1.3.weight, pts_bbox_head.cls_branches.1.3.bias, pts_bbox_head.cls_branches.1.4.weight, pts_bbox_head.cls_branches.1.4.bias, pts_bbox_head.cls_branches.1.6.weight, pts_bbox_head.cls_branches.1.6.bias, pts_bbox_head.cls_branches.2.0.weight, pts_bbox_head.cls_branches.2.0.bias, pts_bbox_head.cls_branches.2.1.weight, pts_bbox_head.cls_branches.2.1.bias, pts_bbox_head.cls_branches.2.3.weight, pts_bbox_head.cls_branches.2.3.bias, pts_bbox_head.cls_branches.2.4.weight, pts_bbox_head.cls_branches.2.4.bias, pts_bbox_head.cls_branches.2.6.weight, pts_bbox_head.cls_branches.2.6.bias, pts_bbox_head.cls_branches.3.0.weight, pts_bbox_head.cls_branches.3.0.bias, pts_bbox_head.cls_branches.3.1.weight, pts_bbox_head.cls_branches.3.1.bias, pts_bbox_head.cls_branches.3.3.weight, pts_bbox_head.cls_branches.3.3.bias, pts_bbox_head.cls_branches.3.4.weight, pts_bbox_head.cls_branches.3.4.bias, pts_bbox_head.cls_branches.3.6.weight, pts_bbox_head.cls_branches.3.6.bias, pts_bbox_head.cls_branches.4.0.weight, pts_bbox_head.cls_branches.4.0.bias, pts_bbox_head.cls_branches.4.1.weight, pts_bbox_head.cls_branches.4.1.bias, pts_bbox_head.cls_branches.4.3.weight, pts_bbox_head.cls_branches.4.3.bias, pts_bbox_head.cls_branches.4.4.weight, pts_bbox_head.cls_branches.4.4.bias, pts_bbox_head.cls_branches.4.6.weight, pts_bbox_head.cls_branches.4.6.bias, pts_bbox_head.cls_branches.5.0.weight, pts_bbox_head.cls_branches.5.0.bias, pts_bbox_head.cls_branches.5.1.weight, pts_bbox_head.cls_branches.5.1.bias, pts_bbox_head.cls_branches.5.3.weight, pts_bbox_head.cls_branches.5.3.bias, pts_bbox_head.cls_branches.5.4.weight, pts_bbox_head.cls_branches.5.4.bias, pts_bbox_head.cls_branches.5.6.weight, pts_bbox_head.cls_branches.5.6.bias

missing keys in source state_dict: pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.camera_mixer.norm.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.camera_mixer.norm.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.camera_mixer.norm.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.camera_mixer.norm.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.camera_mixer.norm.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_attention_weights.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.img_output_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.3.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.position_encoder.4.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.1.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.3.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.modality_fusion_layer.4.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.A_log_h2t, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.D_h2t, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.A_log_t2h, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.D_t2h, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.in_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.0.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.A_log_h2t, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.D_h2t, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.A_log_t2h, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.D_t2h, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.in_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_h2t.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.x_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_h2t.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_h2t.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.conv1d_t2h.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.x_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_t2h.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.dt_proj_t2h.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.lidar_guidance_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.layers.1.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.0.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.0.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.1.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.camera_mixer.norm.1.bias

2025-06-20 02:42:55,371 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_900q_enhance_petr_vov_1600/vov_petr_bs2
2025-06-20 02:42:55,447 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-06-20 02:42:55,508 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-06-20 02:42:55,508 - mmdet - INFO - Checkpoints will be saved to /mnt/sdc/FUTR3D/work_dirs/lidar_0075v_900q_enhance_petr_vov_1600/vov_petr_bs2 by HardDiskBackend.
2025-06-20 02:44:19,585 - mmdet - INFO - Epoch [1][50/7033]	lr: 7.973e-05, eta: 19:35:59, time: 1.674, data_time: 0.104, memory: 18096, loss_cls: 1.1249, loss_bbox: 1.5302, d0.loss_cls: 1.0792, d0.loss_bbox: 1.5583, d1.loss_cls: 1.0714, d1.loss_bbox: 1.5370, d2.loss_cls: 1.0302, d2.loss_bbox: 1.5229, d3.loss_cls: 1.0603, d3.loss_bbox: 1.5112, d4.loss_cls: 1.0727, d4.loss_bbox: 1.4936, loss: 15.5918, grad_norm: 796.7797
2025-06-20 02:45:28,583 - mmdet - INFO - Epoch [1][100/7033]	lr: 9.307e-05, eta: 17:51:24, time: 1.380, data_time: 0.022, memory: 18096, loss_cls: 0.8831, loss_bbox: 1.3335, d0.loss_cls: 0.8714, d0.loss_bbox: 1.3735, d1.loss_cls: 0.8560, d1.loss_bbox: 1.3473, d2.loss_cls: 0.8418, d2.loss_bbox: 1.3441, d3.loss_cls: 0.8470, d3.loss_bbox: 1.3473, d4.loss_cls: 0.8584, d4.loss_bbox: 1.3293, loss: 13.2326, grad_norm: 52.4505
2025-06-20 02:46:37,735 - mmdet - INFO - Epoch [1][150/7033]	lr: 1.064e-04, eta: 17:16:29, time: 1.383, data_time: 0.021, memory: 18096, loss_cls: 0.7872, loss_bbox: 1.2957, d0.loss_cls: 0.7770, d0.loss_bbox: 1.3546, d1.loss_cls: 0.7588, d1.loss_bbox: 1.3137, d2.loss_cls: 0.7575, d2.loss_bbox: 1.3114, d3.loss_cls: 0.7707, d3.loss_bbox: 1.3003, d4.loss_cls: 0.7746, d4.loss_bbox: 1.2978, loss: 12.4993, grad_norm: 39.2332
2025-06-20 02:47:44,876 - mmdet - INFO - Epoch [1][200/7033]	lr: 1.197e-04, eta: 16:51:25, time: 1.343, data_time: 0.020, memory: 18096, loss_cls: 0.7438, loss_bbox: 1.2755, d0.loss_cls: 0.7211, d0.loss_bbox: 1.3522, d1.loss_cls: 0.7206, d1.loss_bbox: 1.3098, d2.loss_cls: 0.7324, d2.loss_bbox: 1.2954, d3.loss_cls: 0.7339, d3.loss_bbox: 1.2859, d4.loss_cls: 0.7303, d4.loss_bbox: 1.2795, loss: 12.1804, grad_norm: 30.9266
2025-06-20 02:48:52,047 - mmdet - INFO - Epoch [1][250/7033]	lr: 1.331e-04, eta: 16:36:01, time: 1.343, data_time: 0.023, memory: 18096, loss_cls: 0.7089, loss_bbox: 1.2370, d0.loss_cls: 0.6792, d0.loss_bbox: 1.3076, d1.loss_cls: 0.6980, d1.loss_bbox: 1.2679, d2.loss_cls: 0.7040, d2.loss_bbox: 1.2596, d3.loss_cls: 0.7035, d3.loss_bbox: 1.2506, d4.loss_cls: 0.6978, d4.loss_bbox: 1.2352, loss: 11.7494, grad_norm: 33.3953
2025-06-20 02:49:59,000 - mmdet - INFO - Epoch [1][300/7033]	lr: 1.464e-04, eta: 16:24:52, time: 1.339, data_time: 0.020, memory: 18096, loss_cls: 0.6427, loss_bbox: 1.1799, d0.loss_cls: 0.6125, d0.loss_bbox: 1.2401, d1.loss_cls: 0.6248, d1.loss_bbox: 1.2180, d2.loss_cls: 0.6343, d2.loss_bbox: 1.2199, d3.loss_cls: 0.6355, d3.loss_bbox: 1.2016, d4.loss_cls: 0.6312, d4.loss_bbox: 1.1799, loss: 11.0203, grad_norm: 23.2473
2025-06-20 02:51:06,218 - mmdet - INFO - Epoch [1][350/7033]	lr: 1.597e-04, eta: 16:17:06, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.6492, loss_bbox: 1.2232, d0.loss_cls: 0.6374, d0.loss_bbox: 1.2622, d1.loss_cls: 0.6409, d1.loss_bbox: 1.2563, d2.loss_cls: 0.6484, d2.loss_bbox: 1.2382, d3.loss_cls: 0.6359, d3.loss_bbox: 1.2351, d4.loss_cls: 0.6293, d4.loss_bbox: 1.2268, loss: 11.2827, grad_norm: 23.0092
2025-06-20 02:52:13,337 - mmdet - INFO - Epoch [1][400/7033]	lr: 1.731e-04, eta: 16:10:50, time: 1.342, data_time: 0.023, memory: 18096, loss_cls: 0.5991, loss_bbox: 1.2026, d0.loss_cls: 0.5985, d0.loss_bbox: 1.2555, d1.loss_cls: 0.6165, d1.loss_bbox: 1.2269, d2.loss_cls: 0.6141, d2.loss_bbox: 1.2161, d3.loss_cls: 0.6018, d3.loss_bbox: 1.2104, d4.loss_cls: 0.5841, d4.loss_bbox: 1.2047, loss: 10.9303, grad_norm: 20.8118
2025-06-20 02:53:20,410 - mmdet - INFO - Epoch [1][450/7033]	lr: 1.864e-04, eta: 16:05:39, time: 1.341, data_time: 0.020, memory: 18096, loss_cls: 0.6242, loss_bbox: 1.1563, d0.loss_cls: 0.5971, d0.loss_bbox: 1.2284, d1.loss_cls: 0.6090, d1.loss_bbox: 1.1983, d2.loss_cls: 0.6152, d2.loss_bbox: 1.1851, d3.loss_cls: 0.6085, d3.loss_bbox: 1.1834, d4.loss_cls: 0.6089, d4.loss_bbox: 1.1616, loss: 10.7760, grad_norm: 19.3289
2025-06-20 02:54:27,529 - mmdet - INFO - Epoch [1][500/7033]	lr: 1.997e-04, eta: 16:01:20, time: 1.342, data_time: 0.022, memory: 18096, loss_cls: 0.6106, loss_bbox: 1.1270, d0.loss_cls: 0.5959, d0.loss_bbox: 1.1776, d1.loss_cls: 0.6063, d1.loss_bbox: 1.1570, d2.loss_cls: 0.6026, d2.loss_bbox: 1.1549, d3.loss_cls: 0.6026, d3.loss_bbox: 1.1370, d4.loss_cls: 0.5990, d4.loss_bbox: 1.1287, loss: 10.4992, grad_norm: 19.2366
2025-06-20 02:55:34,906 - mmdet - INFO - Epoch [1][550/7033]	lr: 2.000e-04, eta: 15:57:55, time: 1.348, data_time: 0.024, memory: 18096, loss_cls: 0.5775, loss_bbox: 1.0934, d0.loss_cls: 0.5661, d0.loss_bbox: 1.1444, d1.loss_cls: 0.5693, d1.loss_bbox: 1.1412, d2.loss_cls: 0.5620, d2.loss_bbox: 1.1324, d3.loss_cls: 0.5695, d3.loss_bbox: 1.1043, d4.loss_cls: 0.5644, d4.loss_bbox: 1.0996, loss: 10.1242, grad_norm: 16.2770
2025-06-20 02:56:42,375 - mmdet - INFO - Epoch [1][600/7033]	lr: 2.000e-04, eta: 15:55:00, time: 1.349, data_time: 0.022, memory: 18096, loss_cls: 0.5705, loss_bbox: 1.0756, d0.loss_cls: 0.5523, d0.loss_bbox: 1.1413, d1.loss_cls: 0.5546, d1.loss_bbox: 1.1341, d2.loss_cls: 0.5591, d2.loss_bbox: 1.1051, d3.loss_cls: 0.5537, d3.loss_bbox: 1.0940, d4.loss_cls: 0.5541, d4.loss_bbox: 1.0879, loss: 9.9822, grad_norm: 19.7518
2025-06-20 02:57:49,679 - mmdet - INFO - Epoch [1][650/7033]	lr: 2.000e-04, eta: 15:52:11, time: 1.346, data_time: 0.021, memory: 18096, loss_cls: 0.5700, loss_bbox: 1.1076, d0.loss_cls: 0.5557, d0.loss_bbox: 1.1748, d1.loss_cls: 0.5658, d1.loss_bbox: 1.1621, d2.loss_cls: 0.5657, d2.loss_bbox: 1.1380, d3.loss_cls: 0.5593, d3.loss_bbox: 1.1227, d4.loss_cls: 0.5560, d4.loss_bbox: 1.1201, loss: 10.1979, grad_norm: 19.4803
2025-06-20 02:58:56,824 - mmdet - INFO - Epoch [1][700/7033]	lr: 2.000e-04, eta: 15:49:26, time: 1.343, data_time: 0.020, memory: 18096, loss_cls: 0.5893, loss_bbox: 1.0549, d0.loss_cls: 0.5818, d0.loss_bbox: 1.1118, d1.loss_cls: 0.5912, d1.loss_bbox: 1.0997, d2.loss_cls: 0.5911, d2.loss_bbox: 1.0887, d3.loss_cls: 0.5828, d3.loss_bbox: 1.0627, d4.loss_cls: 0.5873, d4.loss_bbox: 1.0556, loss: 9.9967, grad_norm: 17.6608
2025-06-20 03:00:44,155 - mmdet - INFO - Epoch [1][750/7033]	lr: 2.000e-04, eta: 16:23:56, time: 2.147, data_time: 0.822, memory: 18096, loss_cls: 0.5965, loss_bbox: 1.0638, d0.loss_cls: 0.5916, d0.loss_bbox: 1.1185, d1.loss_cls: 0.6037, d1.loss_bbox: 1.1100, d2.loss_cls: 0.5985, d2.loss_bbox: 1.0986, d3.loss_cls: 0.5953, d3.loss_bbox: 1.0664, d4.loss_cls: 0.5980, d4.loss_bbox: 1.0545, loss: 10.0954, grad_norm: 17.9712
2025-06-20 03:01:51,462 - mmdet - INFO - Epoch [1][800/7033]	lr: 2.000e-04, eta: 16:19:23, time: 1.346, data_time: 0.021, memory: 18096, loss_cls: 0.5904, loss_bbox: 1.0244, d0.loss_cls: 0.5985, d0.loss_bbox: 1.0847, d1.loss_cls: 0.6082, d1.loss_bbox: 1.0737, d2.loss_cls: 0.6020, d2.loss_bbox: 1.0605, d3.loss_cls: 0.5904, d3.loss_bbox: 1.0302, d4.loss_cls: 0.5866, d4.loss_bbox: 1.0243, loss: 9.8740, grad_norm: 28.9726
2025-06-20 03:02:58,730 - mmdet - INFO - Epoch [1][850/7033]	lr: 2.000e-04, eta: 16:15:11, time: 1.345, data_time: 0.020, memory: 18096, loss_cls: 0.5926, loss_bbox: 1.0256, d0.loss_cls: 0.5903, d0.loss_bbox: 1.0907, d1.loss_cls: 0.6058, d1.loss_bbox: 1.0826, d2.loss_cls: 0.5878, d2.loss_bbox: 1.0790, d3.loss_cls: 0.5866, d3.loss_bbox: 1.0415, d4.loss_cls: 0.5920, d4.loss_bbox: 1.0271, loss: 9.9015, grad_norm: 20.5163
2025-06-20 03:04:06,117 - mmdet - INFO - Epoch [1][900/7033]	lr: 2.000e-04, eta: 16:11:26, time: 1.348, data_time: 0.022, memory: 18096, loss_cls: 0.5600, loss_bbox: 0.9957, d0.loss_cls: 0.5625, d0.loss_bbox: 1.0427, d1.loss_cls: 0.5658, d1.loss_bbox: 1.0435, d2.loss_cls: 0.5604, d2.loss_bbox: 1.0354, d3.loss_cls: 0.5637, d3.loss_bbox: 0.9886, d4.loss_cls: 0.5573, d4.loss_bbox: 0.9947, loss: 9.4703, grad_norm: 21.4171
2025-06-20 03:05:13,415 - mmdet - INFO - Epoch [1][950/7033]	lr: 2.000e-04, eta: 16:07:53, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.5570, loss_bbox: 0.9917, d0.loss_cls: 0.5500, d0.loss_bbox: 1.0637, d1.loss_cls: 0.5513, d1.loss_bbox: 1.0659, d2.loss_cls: 0.5460, d2.loss_bbox: 1.0506, d3.loss_cls: 0.5523, d3.loss_bbox: 1.0004, d4.loss_cls: 0.5528, d4.loss_bbox: 0.9912, loss: 9.4730, grad_norm: 21.0529
2025-06-20 03:06:20,746 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 03:06:20,746 - mmdet - INFO - Epoch [1][1000/7033]	lr: 2.000e-04, eta: 16:04:37, time: 1.347, data_time: 0.022, memory: 18096, loss_cls: 0.5390, loss_bbox: 0.9941, d0.loss_cls: 0.5604, d0.loss_bbox: 1.0331, d1.loss_cls: 0.5502, d1.loss_bbox: 1.0500, d2.loss_cls: 0.5427, d2.loss_bbox: 1.0359, d3.loss_cls: 0.5404, d3.loss_bbox: 1.0002, d4.loss_cls: 0.5348, d4.loss_bbox: 0.9934, loss: 9.3742, grad_norm: 18.3101
2025-06-20 03:07:27,938 - mmdet - INFO - Epoch [1][1050/7033]	lr: 2.000e-04, eta: 16:01:27, time: 1.344, data_time: 0.020, memory: 18096, loss_cls: 0.5289, loss_bbox: 1.0113, d0.loss_cls: 0.5448, d0.loss_bbox: 1.0596, d1.loss_cls: 0.5354, d1.loss_bbox: 1.0745, d2.loss_cls: 0.5342, d2.loss_bbox: 1.0510, d3.loss_cls: 0.5250, d3.loss_bbox: 1.0220, d4.loss_cls: 0.5255, d4.loss_bbox: 1.0098, loss: 9.4222, grad_norm: 21.5951
2025-06-20 03:08:34,798 - mmdet - INFO - Epoch [1][1100/7033]	lr: 2.000e-04, eta: 15:58:16, time: 1.337, data_time: 0.018, memory: 18096, loss_cls: 0.5246, loss_bbox: 0.9736, d0.loss_cls: 0.5559, d0.loss_bbox: 1.0003, d1.loss_cls: 0.5471, d1.loss_bbox: 1.0187, d2.loss_cls: 0.5345, d2.loss_bbox: 1.0080, d3.loss_cls: 0.5231, d3.loss_bbox: 0.9756, d4.loss_cls: 0.5189, d4.loss_bbox: 0.9672, loss: 9.1474, grad_norm: 23.4526
2025-06-20 03:09:42,122 - mmdet - INFO - Epoch [1][1150/7033]	lr: 2.000e-04, eta: 15:55:32, time: 1.346, data_time: 0.018, memory: 18096, loss_cls: 0.5255, loss_bbox: 0.9715, d0.loss_cls: 0.5515, d0.loss_bbox: 1.0017, d1.loss_cls: 0.5379, d1.loss_bbox: 1.0294, d2.loss_cls: 0.5284, d2.loss_bbox: 1.0141, d3.loss_cls: 0.5205, d3.loss_bbox: 0.9787, d4.loss_cls: 0.5217, d4.loss_bbox: 0.9725, loss: 9.1534, grad_norm: 19.7864
2025-06-20 03:10:49,389 - mmdet - INFO - Epoch [1][1200/7033]	lr: 2.000e-04, eta: 15:52:55, time: 1.345, data_time: 0.021, memory: 18096, loss_cls: 0.5307, loss_bbox: 1.0284, d0.loss_cls: 0.5366, d0.loss_bbox: 1.0574, d1.loss_cls: 0.5368, d1.loss_bbox: 1.0885, d2.loss_cls: 0.5372, d2.loss_bbox: 1.0665, d3.loss_cls: 0.5265, d3.loss_bbox: 1.0385, d4.loss_cls: 0.5303, d4.loss_bbox: 1.0283, loss: 9.5058, grad_norm: 19.0283
2025-06-20 03:11:56,760 - mmdet - INFO - Epoch [1][1250/7033]	lr: 2.000e-04, eta: 15:50:27, time: 1.347, data_time: 0.021, memory: 18096, loss_cls: 0.5223, loss_bbox: 1.0532, d0.loss_cls: 0.5474, d0.loss_bbox: 1.1292, d1.loss_cls: 0.5485, d1.loss_bbox: 1.1186, d2.loss_cls: 0.5405, d2.loss_bbox: 1.0959, d3.loss_cls: 0.5331, d3.loss_bbox: 1.0528, d4.loss_cls: 0.5212, d4.loss_bbox: 1.0476, loss: 9.7102, grad_norm: 22.5146
2025-06-20 03:13:05,797 - mmdet - INFO - Epoch [1][1300/7033]	lr: 2.000e-04, eta: 15:48:59, time: 1.381, data_time: 0.024, memory: 18096, loss_cls: 0.5175, loss_bbox: 0.9928, d0.loss_cls: 0.5398, d0.loss_bbox: 1.0406, d1.loss_cls: 0.5333, d1.loss_bbox: 1.0649, d2.loss_cls: 0.5307, d2.loss_bbox: 1.0471, d3.loss_cls: 0.5169, d3.loss_bbox: 0.9985, d4.loss_cls: 0.5128, d4.loss_bbox: 0.9894, loss: 9.2844, grad_norm: 19.1386
2025-06-20 03:14:12,722 - mmdet - INFO - Epoch [1][1350/7033]	lr: 2.000e-04, eta: 15:46:28, time: 1.338, data_time: 0.023, memory: 18096, loss_cls: 0.5054, loss_bbox: 0.9593, d0.loss_cls: 0.5510, d0.loss_bbox: 0.9958, d1.loss_cls: 0.5414, d1.loss_bbox: 1.0226, d2.loss_cls: 0.5286, d2.loss_bbox: 1.0116, d3.loss_cls: 0.5135, d3.loss_bbox: 0.9634, d4.loss_cls: 0.5018, d4.loss_bbox: 0.9646, loss: 9.0590, grad_norm: 18.9340
2025-06-20 03:15:20,227 - mmdet - INFO - Epoch [1][1400/7033]	lr: 2.000e-04, eta: 15:44:20, time: 1.350, data_time: 0.023, memory: 18096, loss_cls: 0.5248, loss_bbox: 0.9432, d0.loss_cls: 0.5647, d0.loss_bbox: 0.9547, d1.loss_cls: 0.5663, d1.loss_bbox: 0.9964, d2.loss_cls: 0.5552, d2.loss_bbox: 0.9848, d3.loss_cls: 0.5316, d3.loss_bbox: 0.9460, d4.loss_cls: 0.5212, d4.loss_bbox: 0.9434, loss: 9.0322, grad_norm: 25.8727
2025-06-20 03:16:27,588 - mmdet - INFO - Epoch [1][1450/7033]	lr: 2.000e-04, eta: 15:42:12, time: 1.347, data_time: 0.020, memory: 18096, loss_cls: 0.5061, loss_bbox: 0.9607, d0.loss_cls: 0.5684, d0.loss_bbox: 0.9776, d1.loss_cls: 0.5520, d1.loss_bbox: 1.0137, d2.loss_cls: 0.5294, d2.loss_bbox: 1.0013, d3.loss_cls: 0.5141, d3.loss_bbox: 0.9595, d4.loss_cls: 0.5062, d4.loss_bbox: 0.9556, loss: 9.0446, grad_norm: 24.0523
2025-06-20 03:17:34,653 - mmdet - INFO - Epoch [1][1500/7033]	lr: 2.000e-04, eta: 15:40:00, time: 1.341, data_time: 0.021, memory: 18096, loss_cls: 0.5157, loss_bbox: 0.9489, d0.loss_cls: 0.5767, d0.loss_bbox: 0.9679, d1.loss_cls: 0.5638, d1.loss_bbox: 1.0107, d2.loss_cls: 0.5528, d2.loss_bbox: 0.9904, d3.loss_cls: 0.5242, d3.loss_bbox: 0.9528, d4.loss_cls: 0.5154, d4.loss_bbox: 0.9452, loss: 9.0647, grad_norm: 22.5382
2025-06-20 03:18:41,740 - mmdet - INFO - Epoch [1][1550/7033]	lr: 2.000e-04, eta: 15:37:53, time: 1.342, data_time: 0.022, memory: 18096, loss_cls: 0.5267, loss_bbox: 0.9133, d0.loss_cls: 0.5761, d0.loss_bbox: 0.9511, d1.loss_cls: 0.5562, d1.loss_bbox: 0.9990, d2.loss_cls: 0.5552, d2.loss_bbox: 0.9720, d3.loss_cls: 0.5383, d3.loss_bbox: 0.9187, d4.loss_cls: 0.5243, d4.loss_bbox: 0.9143, loss: 8.9453, grad_norm: 19.9647
2025-06-20 03:19:48,842 - mmdet - INFO - Epoch [1][1600/7033]	lr: 2.000e-04, eta: 15:35:50, time: 1.342, data_time: 0.021, memory: 18096, loss_cls: 0.4915, loss_bbox: 0.9285, d0.loss_cls: 0.5608, d0.loss_bbox: 0.9528, d1.loss_cls: 0.5487, d1.loss_bbox: 0.9819, d2.loss_cls: 0.5223, d2.loss_bbox: 0.9754, d3.loss_cls: 0.4996, d3.loss_bbox: 0.9367, d4.loss_cls: 0.4896, d4.loss_bbox: 0.9285, loss: 8.8163, grad_norm: 20.5748
2025-06-20 03:20:56,028 - mmdet - INFO - Epoch [1][1650/7033]	lr: 2.000e-04, eta: 15:33:53, time: 1.344, data_time: 0.022, memory: 18096, loss_cls: 0.4557, loss_bbox: 0.9010, d0.loss_cls: 0.5229, d0.loss_bbox: 0.9340, d1.loss_cls: 0.5170, d1.loss_bbox: 0.9623, d2.loss_cls: 0.4904, d2.loss_bbox: 0.9509, d3.loss_cls: 0.4793, d3.loss_bbox: 0.9005, d4.loss_cls: 0.4608, d4.loss_bbox: 0.8970, loss: 8.4718, grad_norm: 21.1194
2025-06-20 03:22:04,897 - mmdet - INFO - Epoch [1][1700/7033]	lr: 2.000e-04, eta: 15:32:38, time: 1.377, data_time: 0.022, memory: 18096, loss_cls: 0.5107, loss_bbox: 0.9497, d0.loss_cls: 0.5611, d0.loss_bbox: 0.9940, d1.loss_cls: 0.5654, d1.loss_bbox: 1.0177, d2.loss_cls: 0.5382, d2.loss_bbox: 1.0123, d3.loss_cls: 0.5247, d3.loss_bbox: 0.9595, d4.loss_cls: 0.5168, d4.loss_bbox: 0.9432, loss: 9.0932, grad_norm: 22.0189
2025-06-20 03:23:12,342 - mmdet - INFO - Epoch [1][1750/7033]	lr: 2.000e-04, eta: 15:30:51, time: 1.349, data_time: 0.022, memory: 18096, loss_cls: 0.4723, loss_bbox: 0.9181, d0.loss_cls: 0.5581, d0.loss_bbox: 0.9761, d1.loss_cls: 0.5468, d1.loss_bbox: 0.9833, d2.loss_cls: 0.5128, d2.loss_bbox: 0.9738, d3.loss_cls: 0.4868, d3.loss_bbox: 0.9269, d4.loss_cls: 0.4778, d4.loss_bbox: 0.9110, loss: 8.7437, grad_norm: 20.3452
2025-06-20 03:24:19,397 - mmdet - INFO - Epoch [1][1800/7033]	lr: 2.000e-04, eta: 15:28:58, time: 1.341, data_time: 0.024, memory: 18096, loss_cls: 0.4946, loss_bbox: 0.9475, d0.loss_cls: 0.5478, d0.loss_bbox: 0.9738, d1.loss_cls: 0.5399, d1.loss_bbox: 1.0049, d2.loss_cls: 0.5263, d2.loss_bbox: 0.9915, d3.loss_cls: 0.5175, d3.loss_bbox: 0.9450, d4.loss_cls: 0.4977, d4.loss_bbox: 0.9389, loss: 8.9253, grad_norm: 27.9571
2025-06-20 03:25:26,771 - mmdet - INFO - Epoch [1][1850/7033]	lr: 2.000e-04, eta: 15:27:13, time: 1.347, data_time: 0.023, memory: 18096, loss_cls: 0.4471, loss_bbox: 0.8929, d0.loss_cls: 0.5524, d0.loss_bbox: 0.9322, d1.loss_cls: 0.5332, d1.loss_bbox: 0.9580, d2.loss_cls: 0.4975, d2.loss_bbox: 0.9466, d3.loss_cls: 0.4708, d3.loss_bbox: 0.8873, d4.loss_cls: 0.4470, d4.loss_bbox: 0.8886, loss: 8.4536, grad_norm: 21.2758
2025-06-20 03:26:35,482 - mmdet - INFO - Epoch [1][1900/7033]	lr: 2.000e-04, eta: 15:26:00, time: 1.374, data_time: 0.022, memory: 18096, loss_cls: 0.4567, loss_bbox: 0.8974, d0.loss_cls: 0.5442, d0.loss_bbox: 0.9736, d1.loss_cls: 0.5302, d1.loss_bbox: 0.9772, d2.loss_cls: 0.5003, d2.loss_bbox: 0.9634, d3.loss_cls: 0.4763, d3.loss_bbox: 0.9142, d4.loss_cls: 0.4552, d4.loss_bbox: 0.8959, loss: 8.5847, grad_norm: 21.5626
2025-06-20 03:27:43,075 - mmdet - INFO - Epoch [1][1950/7033]	lr: 2.000e-04, eta: 15:24:23, time: 1.352, data_time: 0.021, memory: 18096, loss_cls: 0.4476, loss_bbox: 0.9107, d0.loss_cls: 0.5398, d0.loss_bbox: 0.9725, d1.loss_cls: 0.5276, d1.loss_bbox: 0.9838, d2.loss_cls: 0.4843, d2.loss_bbox: 0.9780, d3.loss_cls: 0.4554, d3.loss_bbox: 0.9212, d4.loss_cls: 0.4450, d4.loss_bbox: 0.9070, loss: 8.5728, grad_norm: 23.1396
2025-06-20 03:28:50,375 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 03:28:50,376 - mmdet - INFO - Epoch [1][2000/7033]	lr: 2.000e-04, eta: 15:22:42, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.4643, loss_bbox: 0.9063, d0.loss_cls: 0.5607, d0.loss_bbox: 0.9657, d1.loss_cls: 0.5451, d1.loss_bbox: 0.9855, d2.loss_cls: 0.5086, d2.loss_bbox: 0.9831, d3.loss_cls: 0.4864, d3.loss_bbox: 0.9208, d4.loss_cls: 0.4650, d4.loss_bbox: 0.9067, loss: 8.6983, grad_norm: 23.6682
2025-06-20 03:29:57,433 - mmdet - INFO - Epoch [1][2050/7033]	lr: 2.000e-04, eta: 15:20:58, time: 1.341, data_time: 0.021, memory: 18096, loss_cls: 0.4542, loss_bbox: 0.8488, d0.loss_cls: 0.5654, d0.loss_bbox: 0.9276, d1.loss_cls: 0.5478, d1.loss_bbox: 0.9453, d2.loss_cls: 0.5064, d2.loss_bbox: 0.9380, d3.loss_cls: 0.4852, d3.loss_bbox: 0.8661, d4.loss_cls: 0.4560, d4.loss_bbox: 0.8466, loss: 8.3877, grad_norm: 22.8773
2025-06-20 03:31:04,628 - mmdet - INFO - Epoch [1][2100/7033]	lr: 2.000e-04, eta: 15:19:18, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.4309, loss_bbox: 0.8887, d0.loss_cls: 0.5289, d0.loss_bbox: 0.9648, d1.loss_cls: 0.5213, d1.loss_bbox: 0.9793, d2.loss_cls: 0.4831, d2.loss_bbox: 0.9710, d3.loss_cls: 0.4539, d3.loss_bbox: 0.9184, d4.loss_cls: 0.4351, d4.loss_bbox: 0.8887, loss: 8.4641, grad_norm: 27.1767
2025-06-20 03:32:11,979 - mmdet - INFO - Epoch [1][2150/7033]	lr: 2.000e-04, eta: 15:17:42, time: 1.347, data_time: 0.023, memory: 18096, loss_cls: 0.4359, loss_bbox: 0.8725, d0.loss_cls: 0.5546, d0.loss_bbox: 0.9537, d1.loss_cls: 0.5265, d1.loss_bbox: 0.9535, d2.loss_cls: 0.4893, d2.loss_bbox: 0.9420, d3.loss_cls: 0.4612, d3.loss_bbox: 0.8967, d4.loss_cls: 0.4382, d4.loss_bbox: 0.8680, loss: 8.3922, grad_norm: 23.1606
2025-06-20 03:33:19,184 - mmdet - INFO - Epoch [1][2200/7033]	lr: 2.000e-04, eta: 15:16:06, time: 1.344, data_time: 0.023, memory: 18096, loss_cls: 0.4193, loss_bbox: 0.8609, d0.loss_cls: 0.5302, d0.loss_bbox: 0.9276, d1.loss_cls: 0.5077, d1.loss_bbox: 0.9587, d2.loss_cls: 0.4771, d2.loss_bbox: 0.9446, d3.loss_cls: 0.4545, d3.loss_bbox: 0.8925, d4.loss_cls: 0.4241, d4.loss_bbox: 0.8615, loss: 8.2586, grad_norm: 19.8340
2025-06-20 03:34:26,482 - mmdet - INFO - Epoch [1][2250/7033]	lr: 2.000e-04, eta: 15:14:32, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.4224, loss_bbox: 0.8604, d0.loss_cls: 0.5458, d0.loss_bbox: 0.9325, d1.loss_cls: 0.5216, d1.loss_bbox: 0.9461, d2.loss_cls: 0.4952, d2.loss_bbox: 0.9363, d3.loss_cls: 0.4648, d3.loss_bbox: 0.8904, d4.loss_cls: 0.4289, d4.loss_bbox: 0.8612, loss: 8.3054, grad_norm: 26.8864
2025-06-20 03:35:33,607 - mmdet - INFO - Epoch [1][2300/7033]	lr: 2.000e-04, eta: 15:12:56, time: 1.342, data_time: 0.021, memory: 18096, loss_cls: 0.4142, loss_bbox: 0.8342, d0.loss_cls: 0.5413, d0.loss_bbox: 0.9263, d1.loss_cls: 0.5268, d1.loss_bbox: 0.9324, d2.loss_cls: 0.4941, d2.loss_bbox: 0.9259, d3.loss_cls: 0.4538, d3.loss_bbox: 0.8764, d4.loss_cls: 0.4187, d4.loss_bbox: 0.8386, loss: 8.1826, grad_norm: 24.4739
2025-06-20 03:36:41,193 - mmdet - INFO - Epoch [1][2350/7033]	lr: 2.000e-04, eta: 15:11:29, time: 1.352, data_time: 0.022, memory: 18096, loss_cls: 0.4203, loss_bbox: 0.8687, d0.loss_cls: 0.5502, d0.loss_bbox: 0.9414, d1.loss_cls: 0.5275, d1.loss_bbox: 0.9617, d2.loss_cls: 0.4969, d2.loss_bbox: 0.9447, d3.loss_cls: 0.4712, d3.loss_bbox: 0.9007, d4.loss_cls: 0.4264, d4.loss_bbox: 0.8707, loss: 8.3804, grad_norm: 25.1851
2025-06-20 03:37:48,430 - mmdet - INFO - Epoch [1][2400/7033]	lr: 2.000e-04, eta: 15:09:58, time: 1.345, data_time: 0.020, memory: 18096, loss_cls: 0.4122, loss_bbox: 0.8229, d0.loss_cls: 0.5333, d0.loss_bbox: 0.9329, d1.loss_cls: 0.5207, d1.loss_bbox: 0.9287, d2.loss_cls: 0.4775, d2.loss_bbox: 0.9123, d3.loss_cls: 0.4542, d3.loss_bbox: 0.8609, d4.loss_cls: 0.4149, d4.loss_bbox: 0.8226, loss: 8.0932, grad_norm: 25.8238
2025-06-20 03:38:55,812 - mmdet - INFO - Epoch [1][2450/7033]	lr: 2.000e-04, eta: 15:08:30, time: 1.347, data_time: 0.022, memory: 18096, loss_cls: 0.3954, loss_bbox: 0.8075, d0.loss_cls: 0.5423, d0.loss_bbox: 0.9105, d1.loss_cls: 0.5347, d1.loss_bbox: 0.9105, d2.loss_cls: 0.4818, d2.loss_bbox: 0.9058, d3.loss_cls: 0.4575, d3.loss_bbox: 0.8441, d4.loss_cls: 0.4068, d4.loss_bbox: 0.8049, loss: 8.0019, grad_norm: 19.5092
2025-06-20 03:40:03,073 - mmdet - INFO - Epoch [1][2500/7033]	lr: 2.000e-04, eta: 15:07:00, time: 1.345, data_time: 0.021, memory: 18096, loss_cls: 0.3692, loss_bbox: 0.8040, d0.loss_cls: 0.5203, d0.loss_bbox: 0.9246, d1.loss_cls: 0.5122, d1.loss_bbox: 0.9044, d2.loss_cls: 0.4481, d2.loss_bbox: 0.9025, d3.loss_cls: 0.4171, d3.loss_bbox: 0.8546, d4.loss_cls: 0.3757, d4.loss_bbox: 0.8006, loss: 7.8333, grad_norm: 20.1883
2025-06-20 03:41:10,318 - mmdet - INFO - Epoch [1][2550/7033]	lr: 2.000e-04, eta: 15:05:32, time: 1.345, data_time: 0.023, memory: 18096, loss_cls: 0.3904, loss_bbox: 0.8210, d0.loss_cls: 0.5295, d0.loss_bbox: 0.9282, d1.loss_cls: 0.5196, d1.loss_bbox: 0.9405, d2.loss_cls: 0.4678, d2.loss_bbox: 0.9360, d3.loss_cls: 0.4434, d3.loss_bbox: 0.8758, d4.loss_cls: 0.4037, d4.loss_bbox: 0.8160, loss: 8.0719, grad_norm: 21.7347
2025-06-20 03:42:17,704 - mmdet - INFO - Epoch [1][2600/7033]	lr: 2.000e-04, eta: 15:04:06, time: 1.348, data_time: 0.023, memory: 18096, loss_cls: 0.3709, loss_bbox: 0.7936, d0.loss_cls: 0.5276, d0.loss_bbox: 0.9105, d1.loss_cls: 0.5000, d1.loss_bbox: 0.9135, d2.loss_cls: 0.4562, d2.loss_bbox: 0.8930, d3.loss_cls: 0.4273, d3.loss_bbox: 0.8390, d4.loss_cls: 0.3894, d4.loss_bbox: 0.7885, loss: 7.8097, grad_norm: 38.0148
2025-06-20 03:43:25,185 - mmdet - INFO - Epoch [1][2650/7033]	lr: 2.000e-04, eta: 15:02:42, time: 1.350, data_time: 0.023, memory: 18096, loss_cls: 0.3664, loss_bbox: 0.8119, d0.loss_cls: 0.5108, d0.loss_bbox: 0.9109, d1.loss_cls: 0.4963, d1.loss_bbox: 0.9199, d2.loss_cls: 0.4605, d2.loss_bbox: 0.9157, d3.loss_cls: 0.4283, d3.loss_bbox: 0.8655, d4.loss_cls: 0.3797, d4.loss_bbox: 0.8106, loss: 7.8765, grad_norm: 19.5211
2025-06-20 03:44:32,367 - mmdet - INFO - Epoch [1][2700/7033]	lr: 2.000e-04, eta: 15:01:15, time: 1.344, data_time: 0.023, memory: 18096, loss_cls: 0.3497, loss_bbox: 0.7706, d0.loss_cls: 0.5225, d0.loss_bbox: 0.8961, d1.loss_cls: 0.4968, d1.loss_bbox: 0.9073, d2.loss_cls: 0.4500, d2.loss_bbox: 0.8917, d3.loss_cls: 0.4078, d3.loss_bbox: 0.8323, d4.loss_cls: 0.3618, d4.loss_bbox: 0.7689, loss: 7.6557, grad_norm: 19.3267
2025-06-20 03:45:39,432 - mmdet - INFO - Epoch [1][2750/7033]	lr: 2.000e-04, eta: 14:59:46, time: 1.341, data_time: 0.022, memory: 18096, loss_cls: 0.3381, loss_bbox: 0.7843, d0.loss_cls: 0.5182, d0.loss_bbox: 0.8969, d1.loss_cls: 0.4938, d1.loss_bbox: 0.9031, d2.loss_cls: 0.4432, d2.loss_bbox: 0.8958, d3.loss_cls: 0.4024, d3.loss_bbox: 0.8389, d4.loss_cls: 0.3620, d4.loss_bbox: 0.7742, loss: 7.6509, grad_norm: 18.5247
2025-06-20 03:46:46,748 - mmdet - INFO - Epoch [1][2800/7033]	lr: 2.000e-04, eta: 14:58:22, time: 1.346, data_time: 0.023, memory: 18096, loss_cls: 0.3619, loss_bbox: 0.7936, d0.loss_cls: 0.5428, d0.loss_bbox: 0.9042, d1.loss_cls: 0.5204, d1.loss_bbox: 0.9126, d2.loss_cls: 0.4696, d2.loss_bbox: 0.9086, d3.loss_cls: 0.4285, d3.loss_bbox: 0.8505, d4.loss_cls: 0.3879, d4.loss_bbox: 0.7814, loss: 7.8620, grad_norm: 27.0496
2025-06-20 03:47:55,778 - mmdet - INFO - Epoch [1][2850/7033]	lr: 2.000e-04, eta: 14:57:22, time: 1.381, data_time: 0.022, memory: 18096, loss_cls: 0.3457, loss_bbox: 0.7767, d0.loss_cls: 0.5375, d0.loss_bbox: 0.9102, d1.loss_cls: 0.5170, d1.loss_bbox: 0.9280, d2.loss_cls: 0.4664, d2.loss_bbox: 0.9166, d3.loss_cls: 0.4252, d3.loss_bbox: 0.8600, d4.loss_cls: 0.3651, d4.loss_bbox: 0.7687, loss: 7.8171, grad_norm: 23.4567
2025-06-20 03:49:02,882 - mmdet - INFO - Epoch [1][2900/7033]	lr: 2.000e-04, eta: 14:55:56, time: 1.342, data_time: 0.021, memory: 18096, loss_cls: 0.3148, loss_bbox: 0.7524, d0.loss_cls: 0.5156, d0.loss_bbox: 0.8779, d1.loss_cls: 0.4870, d1.loss_bbox: 0.8856, d2.loss_cls: 0.4311, d2.loss_bbox: 0.8716, d3.loss_cls: 0.3932, d3.loss_bbox: 0.8085, d4.loss_cls: 0.3355, d4.loss_bbox: 0.7462, loss: 7.4195, grad_norm: 21.0905
2025-06-20 03:50:10,096 - mmdet - INFO - Epoch [1][2950/7033]	lr: 2.000e-04, eta: 14:54:32, time: 1.344, data_time: 0.022, memory: 18096, loss_cls: 0.3294, loss_bbox: 0.7563, d0.loss_cls: 0.5464, d0.loss_bbox: 0.9019, d1.loss_cls: 0.5316, d1.loss_bbox: 0.8964, d2.loss_cls: 0.4680, d2.loss_bbox: 0.8950, d3.loss_cls: 0.4137, d3.loss_bbox: 0.8342, d4.loss_cls: 0.3500, d4.loss_bbox: 0.7440, loss: 7.6671, grad_norm: 18.2173
2025-06-20 03:51:19,028 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 03:51:19,029 - mmdet - INFO - Epoch [1][3000/7033]	lr: 2.000e-04, eta: 14:53:31, time: 1.379, data_time: 0.023, memory: 18096, loss_cls: 0.3146, loss_bbox: 0.7635, d0.loss_cls: 0.5282, d0.loss_bbox: 0.9191, d1.loss_cls: 0.5051, d1.loss_bbox: 0.9282, d2.loss_cls: 0.4558, d2.loss_bbox: 0.9187, d3.loss_cls: 0.3927, d3.loss_bbox: 0.8387, d4.loss_cls: 0.3390, d4.loss_bbox: 0.7539, loss: 7.6573, grad_norm: 22.8194
2025-06-20 03:52:26,246 - mmdet - INFO - Epoch [1][3050/7033]	lr: 2.000e-04, eta: 14:52:08, time: 1.344, data_time: 0.022, memory: 18096, loss_cls: 0.3176, loss_bbox: 0.7428, d0.loss_cls: 0.5334, d0.loss_bbox: 0.8956, d1.loss_cls: 0.5126, d1.loss_bbox: 0.9067, d2.loss_cls: 0.4620, d2.loss_bbox: 0.8978, d3.loss_cls: 0.4017, d3.loss_bbox: 0.8228, d4.loss_cls: 0.3387, d4.loss_bbox: 0.7388, loss: 7.5704, grad_norm: 18.9206
2025-06-20 03:53:33,464 - mmdet - INFO - Epoch [1][3100/7033]	lr: 2.000e-04, eta: 14:50:45, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.2858, loss_bbox: 0.7168, d0.loss_cls: 0.5143, d0.loss_bbox: 0.8992, d1.loss_cls: 0.4842, d1.loss_bbox: 0.9087, d2.loss_cls: 0.4299, d2.loss_bbox: 0.8886, d3.loss_cls: 0.3725, d3.loss_bbox: 0.8114, d4.loss_cls: 0.3161, d4.loss_bbox: 0.7032, loss: 7.3308, grad_norm: 18.7380
2025-06-20 03:54:40,910 - mmdet - INFO - Epoch [1][3150/7033]	lr: 2.000e-04, eta: 14:49:25, time: 1.349, data_time: 0.021, memory: 18096, loss_cls: 0.3020, loss_bbox: 0.7425, d0.loss_cls: 0.5171, d0.loss_bbox: 0.9185, d1.loss_cls: 0.4966, d1.loss_bbox: 0.9173, d2.loss_cls: 0.4383, d2.loss_bbox: 0.9124, d3.loss_cls: 0.3740, d3.loss_bbox: 0.8347, d4.loss_cls: 0.3281, d4.loss_bbox: 0.7297, loss: 7.5112, grad_norm: 18.4448
2025-06-20 03:55:48,166 - mmdet - INFO - Epoch [1][3200/7033]	lr: 2.000e-04, eta: 14:48:04, time: 1.345, data_time: 0.021, memory: 18096, loss_cls: 0.3099, loss_bbox: 0.7290, d0.loss_cls: 0.5339, d0.loss_bbox: 0.8962, d1.loss_cls: 0.5161, d1.loss_bbox: 0.9005, d2.loss_cls: 0.4656, d2.loss_bbox: 0.8925, d3.loss_cls: 0.3922, d3.loss_bbox: 0.8049, d4.loss_cls: 0.3343, d4.loss_bbox: 0.7237, loss: 7.4987, grad_norm: 21.3269
2025-06-20 03:56:55,236 - mmdet - INFO - Epoch [1][3250/7033]	lr: 2.000e-04, eta: 14:46:40, time: 1.341, data_time: 0.021, memory: 18096, loss_cls: 0.3081, loss_bbox: 0.7373, d0.loss_cls: 0.5232, d0.loss_bbox: 0.9044, d1.loss_cls: 0.5094, d1.loss_bbox: 0.8972, d2.loss_cls: 0.4516, d2.loss_bbox: 0.8874, d3.loss_cls: 0.3866, d3.loss_bbox: 0.8089, d4.loss_cls: 0.3363, d4.loss_bbox: 0.7245, loss: 7.4749, grad_norm: 20.7602
2025-06-20 03:58:02,721 - mmdet - INFO - Epoch [1][3300/7033]	lr: 2.000e-04, eta: 14:45:23, time: 1.350, data_time: 0.024, memory: 18096, loss_cls: 0.2989, loss_bbox: 0.7137, d0.loss_cls: 0.5116, d0.loss_bbox: 0.9112, d1.loss_cls: 0.4896, d1.loss_bbox: 0.8948, d2.loss_cls: 0.4337, d2.loss_bbox: 0.8810, d3.loss_cls: 0.3748, d3.loss_bbox: 0.7897, d4.loss_cls: 0.3245, d4.loss_bbox: 0.7070, loss: 7.3305, grad_norm: 25.1654
2025-06-20 03:59:09,949 - mmdet - INFO - Epoch [1][3350/7033]	lr: 2.000e-04, eta: 14:44:02, time: 1.345, data_time: 0.022, memory: 18096, loss_cls: 0.2954, loss_bbox: 0.7405, d0.loss_cls: 0.5151, d0.loss_bbox: 0.9490, d1.loss_cls: 0.4933, d1.loss_bbox: 0.9389, d2.loss_cls: 0.4463, d2.loss_bbox: 0.9237, d3.loss_cls: 0.3724, d3.loss_bbox: 0.8297, d4.loss_cls: 0.3262, d4.loss_bbox: 0.7290, loss: 7.5596, grad_norm: 29.1514
2025-06-20 04:00:17,284 - mmdet - INFO - Epoch [1][3400/7033]	lr: 2.000e-04, eta: 14:42:43, time: 1.347, data_time: 0.023, memory: 18096, loss_cls: 0.2875, loss_bbox: 0.7119, d0.loss_cls: 0.5054, d0.loss_bbox: 0.9074, d1.loss_cls: 0.4886, d1.loss_bbox: 0.9000, d2.loss_cls: 0.4259, d2.loss_bbox: 0.8886, d3.loss_cls: 0.3606, d3.loss_bbox: 0.7808, d4.loss_cls: 0.3153, d4.loss_bbox: 0.6940, loss: 7.2659, grad_norm: 42.7531
2025-06-20 04:01:26,533 - mmdet - INFO - Epoch [1][3450/7033]	lr: 2.000e-04, eta: 14:41:46, time: 1.385, data_time: 0.022, memory: 18096, loss_cls: 0.2727, loss_bbox: 0.6929, d0.loss_cls: 0.5147, d0.loss_bbox: 0.9128, d1.loss_cls: 0.4941, d1.loss_bbox: 0.9123, d2.loss_cls: 0.4287, d2.loss_bbox: 0.8987, d3.loss_cls: 0.3495, d3.loss_bbox: 0.7832, d4.loss_cls: 0.3027, d4.loss_bbox: 0.6818, loss: 7.2442, grad_norm: 18.2664
2025-06-20 04:02:33,730 - mmdet - INFO - Epoch [1][3500/7033]	lr: 2.000e-04, eta: 14:40:26, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.2917, loss_bbox: 0.6908, d0.loss_cls: 0.5397, d0.loss_bbox: 0.8907, d1.loss_cls: 0.5077, d1.loss_bbox: 0.8836, d2.loss_cls: 0.4375, d2.loss_bbox: 0.8729, d3.loss_cls: 0.3600, d3.loss_bbox: 0.7487, d4.loss_cls: 0.3214, d4.loss_bbox: 0.6763, loss: 7.2210, grad_norm: 20.2922
2025-06-20 04:03:41,015 - mmdet - INFO - Epoch [1][3550/7033]	lr: 2.000e-04, eta: 14:39:07, time: 1.346, data_time: 0.021, memory: 18096, loss_cls: 0.2830, loss_bbox: 0.6885, d0.loss_cls: 0.5213, d0.loss_bbox: 0.8880, d1.loss_cls: 0.4965, d1.loss_bbox: 0.8892, d2.loss_cls: 0.4404, d2.loss_bbox: 0.8673, d3.loss_cls: 0.3449, d3.loss_bbox: 0.7483, d4.loss_cls: 0.3121, d4.loss_bbox: 0.6755, loss: 7.1550, grad_norm: 19.2744
2025-06-20 04:04:49,913 - mmdet - INFO - Epoch [1][3600/7033]	lr: 2.000e-04, eta: 14:38:06, time: 1.378, data_time: 0.024, memory: 18096, loss_cls: 0.2678, loss_bbox: 0.6935, d0.loss_cls: 0.5141, d0.loss_bbox: 0.8785, d1.loss_cls: 0.4934, d1.loss_bbox: 0.8759, d2.loss_cls: 0.4292, d2.loss_bbox: 0.8683, d3.loss_cls: 0.3388, d3.loss_bbox: 0.7466, d4.loss_cls: 0.3017, d4.loss_bbox: 0.6737, loss: 7.0813, grad_norm: 35.8475
2025-06-20 04:05:57,122 - mmdet - INFO - Epoch [1][3650/7033]	lr: 2.000e-04, eta: 14:36:47, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.2726, loss_bbox: 0.7237, d0.loss_cls: 0.5274, d0.loss_bbox: 0.9009, d1.loss_cls: 0.5049, d1.loss_bbox: 0.8891, d2.loss_cls: 0.4335, d2.loss_bbox: 0.8776, d3.loss_cls: 0.3473, d3.loss_bbox: 0.7546, d4.loss_cls: 0.3085, d4.loss_bbox: 0.7009, loss: 7.2411, grad_norm: 22.0121
2025-06-20 04:07:04,519 - mmdet - INFO - Epoch [1][3700/7033]	lr: 2.000e-04, eta: 14:35:30, time: 1.348, data_time: 0.023, memory: 18096, loss_cls: 0.2915, loss_bbox: 0.7238, d0.loss_cls: 0.5235, d0.loss_bbox: 0.9040, d1.loss_cls: 0.4986, d1.loss_bbox: 0.9074, d2.loss_cls: 0.4392, d2.loss_bbox: 0.8820, d3.loss_cls: 0.3499, d3.loss_bbox: 0.7546, d4.loss_cls: 0.3177, d4.loss_bbox: 0.7084, loss: 7.3006, grad_norm: 25.1945
2025-06-20 04:08:11,642 - mmdet - INFO - Epoch [1][3750/7033]	lr: 2.000e-04, eta: 14:34:10, time: 1.342, data_time: 0.021, memory: 18096, loss_cls: 0.2656, loss_bbox: 0.6743, d0.loss_cls: 0.5123, d0.loss_bbox: 0.8596, d1.loss_cls: 0.4886, d1.loss_bbox: 0.8619, d2.loss_cls: 0.4215, d2.loss_bbox: 0.8491, d3.loss_cls: 0.3320, d3.loss_bbox: 0.7090, d4.loss_cls: 0.3002, d4.loss_bbox: 0.6572, loss: 6.9313, grad_norm: 20.7509
2025-06-20 04:09:19,105 - mmdet - INFO - Epoch [1][3800/7033]	lr: 2.000e-04, eta: 14:32:54, time: 1.349, data_time: 0.023, memory: 18096, loss_cls: 0.2672, loss_bbox: 0.6752, d0.loss_cls: 0.5181, d0.loss_bbox: 0.8903, d1.loss_cls: 0.4960, d1.loss_bbox: 0.8805, d2.loss_cls: 0.4227, d2.loss_bbox: 0.8617, d3.loss_cls: 0.3255, d3.loss_bbox: 0.7084, d4.loss_cls: 0.3008, d4.loss_bbox: 0.6583, loss: 7.0046, grad_norm: 24.2439
2025-06-20 04:10:26,552 - mmdet - INFO - Epoch [1][3850/7033]	lr: 2.000e-04, eta: 14:31:39, time: 1.349, data_time: 0.023, memory: 18096, loss_cls: 0.2556, loss_bbox: 0.6729, d0.loss_cls: 0.5092, d0.loss_bbox: 0.8824, d1.loss_cls: 0.4869, d1.loss_bbox: 0.8798, d2.loss_cls: 0.4284, d2.loss_bbox: 0.8606, d3.loss_cls: 0.3158, d3.loss_bbox: 0.7026, d4.loss_cls: 0.2883, d4.loss_bbox: 0.6544, loss: 6.9370, grad_norm: 26.6107
2025-06-20 04:11:33,883 - mmdet - INFO - Epoch [1][3900/7033]	lr: 2.000e-04, eta: 14:30:22, time: 1.347, data_time: 0.022, memory: 18096, loss_cls: 0.2606, loss_bbox: 0.6758, d0.loss_cls: 0.5066, d0.loss_bbox: 0.8603, d1.loss_cls: 0.4861, d1.loss_bbox: 0.8458, d2.loss_cls: 0.4121, d2.loss_bbox: 0.8256, d3.loss_cls: 0.3048, d3.loss_bbox: 0.7019, d4.loss_cls: 0.2855, d4.loss_bbox: 0.6595, loss: 6.8247, grad_norm: 22.4919
2025-06-20 04:12:41,237 - mmdet - INFO - Epoch [1][3950/7033]	lr: 2.000e-04, eta: 14:29:06, time: 1.347, data_time: 0.022, memory: 18096, loss_cls: 0.2608, loss_bbox: 0.6807, d0.loss_cls: 0.5267, d0.loss_bbox: 0.8900, d1.loss_cls: 0.4962, d1.loss_bbox: 0.8746, d2.loss_cls: 0.4293, d2.loss_bbox: 0.8482, d3.loss_cls: 0.3204, d3.loss_bbox: 0.7105, d4.loss_cls: 0.2874, d4.loss_bbox: 0.6681, loss: 6.9929, grad_norm: 19.6372
2025-06-20 04:13:48,436 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 04:13:48,436 - mmdet - INFO - Epoch [1][4000/7033]	lr: 2.000e-04, eta: 14:27:48, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.2716, loss_bbox: 0.6736, d0.loss_cls: 0.5097, d0.loss_bbox: 0.8730, d1.loss_cls: 0.4863, d1.loss_bbox: 0.8676, d2.loss_cls: 0.4306, d2.loss_bbox: 0.8399, d3.loss_cls: 0.3184, d3.loss_bbox: 0.7009, d4.loss_cls: 0.2928, d4.loss_bbox: 0.6617, loss: 6.9261, grad_norm: 22.0814
2025-06-20 04:14:55,597 - mmdet - INFO - Epoch [1][4050/7033]	lr: 2.000e-04, eta: 14:26:31, time: 1.343, data_time: 0.021, memory: 18096, loss_cls: 0.2648, loss_bbox: 0.6760, d0.loss_cls: 0.5088, d0.loss_bbox: 0.8851, d1.loss_cls: 0.4856, d1.loss_bbox: 0.8765, d2.loss_cls: 0.4184, d2.loss_bbox: 0.8407, d3.loss_cls: 0.3061, d3.loss_bbox: 0.7106, d4.loss_cls: 0.2872, d4.loss_bbox: 0.6668, loss: 6.9266, grad_norm: 25.0715
2025-06-20 04:16:03,020 - mmdet - INFO - Epoch [1][4100/7033]	lr: 2.000e-04, eta: 14:25:16, time: 1.348, data_time: 0.021, memory: 18096, loss_cls: 0.2648, loss_bbox: 0.6696, d0.loss_cls: 0.5219, d0.loss_bbox: 0.8630, d1.loss_cls: 0.4953, d1.loss_bbox: 0.8647, d2.loss_cls: 0.4299, d2.loss_bbox: 0.8331, d3.loss_cls: 0.3134, d3.loss_bbox: 0.7039, d4.loss_cls: 0.2908, d4.loss_bbox: 0.6589, loss: 6.9095, grad_norm: 29.0251
2025-06-20 04:17:10,565 - mmdet - INFO - Epoch [1][4150/7033]	lr: 2.000e-04, eta: 14:24:03, time: 1.351, data_time: 0.021, memory: 18096, loss_cls: 0.2555, loss_bbox: 0.6564, d0.loss_cls: 0.5090, d0.loss_bbox: 0.8760, d1.loss_cls: 0.4927, d1.loss_bbox: 0.8643, d2.loss_cls: 0.4126, d2.loss_bbox: 0.8321, d3.loss_cls: 0.3030, d3.loss_bbox: 0.6779, d4.loss_cls: 0.2816, d4.loss_bbox: 0.6437, loss: 6.8047, grad_norm: 20.6890
2025-06-20 04:18:17,758 - mmdet - INFO - Epoch [1][4200/7033]	lr: 2.000e-04, eta: 14:22:46, time: 1.344, data_time: 0.023, memory: 18096, loss_cls: 0.2670, loss_bbox: 0.6751, d0.loss_cls: 0.5016, d0.loss_bbox: 0.8885, d1.loss_cls: 0.4826, d1.loss_bbox: 0.8740, d2.loss_cls: 0.4195, d2.loss_bbox: 0.8508, d3.loss_cls: 0.3077, d3.loss_bbox: 0.6958, d4.loss_cls: 0.2880, d4.loss_bbox: 0.6661, loss: 6.9166, grad_norm: 22.1171
2025-06-20 04:19:25,097 - mmdet - INFO - Epoch [1][4250/7033]	lr: 2.000e-04, eta: 14:21:31, time: 1.347, data_time: 0.021, memory: 18096, loss_cls: 0.2573, loss_bbox: 0.6664, d0.loss_cls: 0.5055, d0.loss_bbox: 0.8803, d1.loss_cls: 0.4870, d1.loss_bbox: 0.8849, d2.loss_cls: 0.4283, d2.loss_bbox: 0.8515, d3.loss_cls: 0.3178, d3.loss_bbox: 0.6762, d4.loss_cls: 0.2890, d4.loss_bbox: 0.6484, loss: 6.8926, grad_norm: 19.4221
2025-06-20 04:20:32,496 - mmdet - INFO - Epoch [1][4300/7033]	lr: 2.000e-04, eta: 14:20:16, time: 1.348, data_time: 0.023, memory: 18096, loss_cls: 0.2514, loss_bbox: 0.6771, d0.loss_cls: 0.5110, d0.loss_bbox: 0.8945, d1.loss_cls: 0.4869, d1.loss_bbox: 0.8880, d2.loss_cls: 0.4081, d2.loss_bbox: 0.8572, d3.loss_cls: 0.3047, d3.loss_bbox: 0.6914, d4.loss_cls: 0.2738, d4.loss_bbox: 0.6656, loss: 6.9096, grad_norm: 24.8413
2025-06-20 04:21:39,948 - mmdet - INFO - Epoch [1][4350/7033]	lr: 2.000e-04, eta: 14:19:03, time: 1.349, data_time: 0.023, memory: 18096, loss_cls: 0.2431, loss_bbox: 0.6611, d0.loss_cls: 0.5021, d0.loss_bbox: 0.8764, d1.loss_cls: 0.4755, d1.loss_bbox: 0.8689, d2.loss_cls: 0.3994, d2.loss_bbox: 0.8355, d3.loss_cls: 0.2938, d3.loss_bbox: 0.6805, d4.loss_cls: 0.2636, d4.loss_bbox: 0.6513, loss: 6.7511, grad_norm: 22.1512
2025-06-20 04:22:47,431 - mmdet - INFO - Epoch [1][4400/7033]	lr: 2.000e-04, eta: 14:17:49, time: 1.350, data_time: 0.021, memory: 18096, loss_cls: 0.2556, loss_bbox: 0.6754, d0.loss_cls: 0.5072, d0.loss_bbox: 0.9051, d1.loss_cls: 0.4865, d1.loss_bbox: 0.8934, d2.loss_cls: 0.3992, d2.loss_bbox: 0.8538, d3.loss_cls: 0.3016, d3.loss_bbox: 0.6966, d4.loss_cls: 0.2718, d4.loss_bbox: 0.6672, loss: 6.9134, grad_norm: 23.1929
2025-06-20 04:23:54,744 - mmdet - INFO - Epoch [1][4450/7033]	lr: 2.000e-04, eta: 14:16:35, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.2465, loss_bbox: 0.6421, d0.loss_cls: 0.5077, d0.loss_bbox: 0.8717, d1.loss_cls: 0.4868, d1.loss_bbox: 0.8578, d2.loss_cls: 0.3992, d2.loss_bbox: 0.8192, d3.loss_cls: 0.2922, d3.loss_bbox: 0.6725, d4.loss_cls: 0.2644, d4.loss_bbox: 0.6392, loss: 6.6994, grad_norm: 21.0279
2025-06-20 04:25:02,147 - mmdet - INFO - Epoch [1][4500/7033]	lr: 2.000e-04, eta: 14:15:21, time: 1.348, data_time: 0.021, memory: 18096, loss_cls: 0.2429, loss_bbox: 0.6482, d0.loss_cls: 0.5181, d0.loss_bbox: 0.8819, d1.loss_cls: 0.4923, d1.loss_bbox: 0.8890, d2.loss_cls: 0.4070, d2.loss_bbox: 0.8409, d3.loss_cls: 0.2936, d3.loss_bbox: 0.6815, d4.loss_cls: 0.2636, d4.loss_bbox: 0.6412, loss: 6.8003, grad_norm: 21.4221
2025-06-20 04:26:11,192 - mmdet - INFO - Epoch [1][4550/7033]	lr: 2.000e-04, eta: 14:14:21, time: 1.381, data_time: 0.021, memory: 18096, loss_cls: 0.2575, loss_bbox: 0.6642, d0.loss_cls: 0.5316, d0.loss_bbox: 0.8977, d1.loss_cls: 0.5133, d1.loss_bbox: 0.8847, d2.loss_cls: 0.4242, d2.loss_bbox: 0.8298, d3.loss_cls: 0.3143, d3.loss_bbox: 0.6861, d4.loss_cls: 0.2867, d4.loss_bbox: 0.6544, loss: 6.9445, grad_norm: 26.3947
2025-06-20 04:27:18,444 - mmdet - INFO - Epoch [1][4600/7033]	lr: 2.000e-04, eta: 14:13:06, time: 1.345, data_time: 0.020, memory: 18096, loss_cls: 0.2497, loss_bbox: 0.6548, d0.loss_cls: 0.5088, d0.loss_bbox: 0.8602, d1.loss_cls: 0.4882, d1.loss_bbox: 0.8461, d2.loss_cls: 0.3997, d2.loss_bbox: 0.7985, d3.loss_cls: 0.2989, d3.loss_bbox: 0.6738, d4.loss_cls: 0.2779, d4.loss_bbox: 0.6421, loss: 6.6988, grad_norm: 113.4737
2025-06-20 04:28:25,852 - mmdet - INFO - Epoch [1][4650/7033]	lr: 2.000e-04, eta: 14:11:53, time: 1.348, data_time: 0.021, memory: 18096, loss_cls: 0.2440, loss_bbox: 0.6625, d0.loss_cls: 0.5240, d0.loss_bbox: 0.8798, d1.loss_cls: 0.5116, d1.loss_bbox: 0.8660, d2.loss_cls: 0.4130, d2.loss_bbox: 0.8175, d3.loss_cls: 0.2990, d3.loss_bbox: 0.6895, d4.loss_cls: 0.2658, d4.loss_bbox: 0.6562, loss: 6.8290, grad_norm: 20.7242
2025-06-20 04:29:34,778 - mmdet - INFO - Epoch [1][4700/7033]	lr: 2.000e-04, eta: 14:10:52, time: 1.379, data_time: 0.020, memory: 18096, loss_cls: 0.2403, loss_bbox: 0.6658, d0.loss_cls: 0.4986, d0.loss_bbox: 0.8910, d1.loss_cls: 0.4811, d1.loss_bbox: 0.8811, d2.loss_cls: 0.3915, d2.loss_bbox: 0.8257, d3.loss_cls: 0.2907, d3.loss_bbox: 0.6885, d4.loss_cls: 0.2606, d4.loss_bbox: 0.6619, loss: 6.7768, grad_norm: 20.0884
2025-06-20 04:30:41,983 - mmdet - INFO - Epoch [1][4750/7033]	lr: 2.000e-04, eta: 14:09:37, time: 1.344, data_time: 0.022, memory: 18096, loss_cls: 0.2276, loss_bbox: 0.6070, d0.loss_cls: 0.4886, d0.loss_bbox: 0.8565, d1.loss_cls: 0.4575, d1.loss_bbox: 0.8519, d2.loss_cls: 0.3622, d2.loss_bbox: 0.7776, d3.loss_cls: 0.2709, d3.loss_bbox: 0.6343, d4.loss_cls: 0.2444, d4.loss_bbox: 0.6060, loss: 6.3845, grad_norm: 18.0502
2025-06-20 04:31:49,401 - mmdet - INFO - Epoch [1][4800/7033]	lr: 2.000e-04, eta: 14:08:24, time: 1.348, data_time: 0.021, memory: 18096, loss_cls: 0.2335, loss_bbox: 0.6440, d0.loss_cls: 0.4995, d0.loss_bbox: 0.8726, d1.loss_cls: 0.4777, d1.loss_bbox: 0.8544, d2.loss_cls: 0.3774, d2.loss_bbox: 0.7836, d3.loss_cls: 0.2866, d3.loss_bbox: 0.6672, d4.loss_cls: 0.2562, d4.loss_bbox: 0.6313, loss: 6.5841, grad_norm: 21.8816
2025-06-20 04:32:56,991 - mmdet - INFO - Epoch [1][4850/7033]	lr: 2.000e-04, eta: 14:07:12, time: 1.352, data_time: 0.022, memory: 18096, loss_cls: 0.2458, loss_bbox: 0.6565, d0.loss_cls: 0.5148, d0.loss_bbox: 0.8707, d1.loss_cls: 0.4982, d1.loss_bbox: 0.8745, d2.loss_cls: 0.3994, d2.loss_bbox: 0.8246, d3.loss_cls: 0.2977, d3.loss_bbox: 0.6913, d4.loss_cls: 0.2738, d4.loss_bbox: 0.6485, loss: 6.7959, grad_norm: 22.5703
2025-06-20 04:34:04,030 - mmdet - INFO - Epoch [1][4900/7033]	lr: 2.000e-04, eta: 14:05:56, time: 1.341, data_time: 0.020, memory: 18096, loss_cls: 0.2428, loss_bbox: 0.6467, d0.loss_cls: 0.5011, d0.loss_bbox: 0.8810, d1.loss_cls: 0.4785, d1.loss_bbox: 0.8718, d2.loss_cls: 0.3829, d2.loss_bbox: 0.7864, d3.loss_cls: 0.2901, d3.loss_bbox: 0.6704, d4.loss_cls: 0.2608, d4.loss_bbox: 0.6433, loss: 6.6557, grad_norm: 32.7724
2025-06-20 04:35:11,430 - mmdet - INFO - Epoch [1][4950/7033]	lr: 2.000e-04, eta: 14:04:43, time: 1.348, data_time: 0.020, memory: 18096, loss_cls: 0.2452, loss_bbox: 0.6414, d0.loss_cls: 0.5077, d0.loss_bbox: 0.8909, d1.loss_cls: 0.4946, d1.loss_bbox: 0.8775, d2.loss_cls: 0.3800, d2.loss_bbox: 0.7962, d3.loss_cls: 0.2988, d3.loss_bbox: 0.6613, d4.loss_cls: 0.2653, d4.loss_bbox: 0.6310, loss: 6.6900, grad_norm: 28.8326
2025-06-20 04:36:18,718 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 04:36:18,718 - mmdet - INFO - Epoch [1][5000/7033]	lr: 2.000e-04, eta: 14:03:30, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.2251, loss_bbox: 0.6304, d0.loss_cls: 0.4991, d0.loss_bbox: 0.8506, d1.loss_cls: 0.4827, d1.loss_bbox: 0.8391, d2.loss_cls: 0.3632, d2.loss_bbox: 0.7670, d3.loss_cls: 0.2840, d3.loss_bbox: 0.6450, d4.loss_cls: 0.2483, d4.loss_bbox: 0.6210, loss: 6.4555, grad_norm: 24.1228
2025-06-20 04:37:26,018 - mmdet - INFO - Epoch [1][5050/7033]	lr: 2.000e-04, eta: 14:02:16, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.2383, loss_bbox: 0.6324, d0.loss_cls: 0.5116, d0.loss_bbox: 0.8724, d1.loss_cls: 0.4906, d1.loss_bbox: 0.8521, d2.loss_cls: 0.3734, d2.loss_bbox: 0.7840, d3.loss_cls: 0.2885, d3.loss_bbox: 0.6603, d4.loss_cls: 0.2578, d4.loss_bbox: 0.6305, loss: 6.5919, grad_norm: 23.6135
2025-06-20 04:38:33,296 - mmdet - INFO - Epoch [1][5100/7033]	lr: 2.000e-04, eta: 14:01:03, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.2483, loss_bbox: 0.6259, d0.loss_cls: 0.5210, d0.loss_bbox: 0.8746, d1.loss_cls: 0.4841, d1.loss_bbox: 0.8732, d2.loss_cls: 0.3870, d2.loss_bbox: 0.7951, d3.loss_cls: 0.2979, d3.loss_bbox: 0.6581, d4.loss_cls: 0.2703, d4.loss_bbox: 0.6229, loss: 6.6582, grad_norm: 20.1882
2025-06-20 04:39:42,361 - mmdet - INFO - Epoch [1][5150/7033]	lr: 2.000e-04, eta: 14:00:02, time: 1.381, data_time: 0.021, memory: 18096, loss_cls: 0.2522, loss_bbox: 0.6492, d0.loss_cls: 0.5164, d0.loss_bbox: 0.8778, d1.loss_cls: 0.4871, d1.loss_bbox: 0.8714, d2.loss_cls: 0.3927, d2.loss_bbox: 0.7826, d3.loss_cls: 0.3024, d3.loss_bbox: 0.6727, d4.loss_cls: 0.2701, d4.loss_bbox: 0.6450, loss: 6.7196, grad_norm: 20.2952
2025-06-20 04:40:49,456 - mmdet - INFO - Epoch [1][5200/7033]	lr: 2.000e-04, eta: 13:58:48, time: 1.342, data_time: 0.019, memory: 18096, loss_cls: 0.2313, loss_bbox: 0.6244, d0.loss_cls: 0.4897, d0.loss_bbox: 0.8511, d1.loss_cls: 0.4658, d1.loss_bbox: 0.8380, d2.loss_cls: 0.3650, d2.loss_bbox: 0.7618, d3.loss_cls: 0.2811, d3.loss_bbox: 0.6524, d4.loss_cls: 0.2519, d4.loss_bbox: 0.6215, loss: 6.4340, grad_norm: 17.5203
2025-06-20 04:41:56,695 - mmdet - INFO - Epoch [1][5250/7033]	lr: 2.000e-04, eta: 13:57:34, time: 1.345, data_time: 0.022, memory: 18096, loss_cls: 0.2415, loss_bbox: 0.6480, d0.loss_cls: 0.5186, d0.loss_bbox: 0.8701, d1.loss_cls: 0.4998, d1.loss_bbox: 0.8556, d2.loss_cls: 0.3755, d2.loss_bbox: 0.7705, d3.loss_cls: 0.2902, d3.loss_bbox: 0.6799, d4.loss_cls: 0.2648, d4.loss_bbox: 0.6455, loss: 6.6599, grad_norm: 40.3367
2025-06-20 04:43:05,329 - mmdet - INFO - Epoch [1][5300/7033]	lr: 2.000e-04, eta: 13:56:31, time: 1.373, data_time: 0.021, memory: 18096, loss_cls: 0.2348, loss_bbox: 0.6543, d0.loss_cls: 0.4937, d0.loss_bbox: 0.8774, d1.loss_cls: 0.4778, d1.loss_bbox: 0.8657, d2.loss_cls: 0.3745, d2.loss_bbox: 0.7939, d3.loss_cls: 0.2919, d3.loss_bbox: 0.6888, d4.loss_cls: 0.2642, d4.loss_bbox: 0.6411, loss: 6.6579, grad_norm: 23.1016
2025-06-20 04:44:12,651 - mmdet - INFO - Epoch [1][5350/7033]	lr: 2.000e-04, eta: 13:55:18, time: 1.346, data_time: 0.020, memory: 18096, loss_cls: 0.2451, loss_bbox: 0.6402, d0.loss_cls: 0.5131, d0.loss_bbox: 0.8870, d1.loss_cls: 0.4926, d1.loss_bbox: 0.8695, d2.loss_cls: 0.3775, d2.loss_bbox: 0.7735, d3.loss_cls: 0.2934, d3.loss_bbox: 0.6736, d4.loss_cls: 0.2703, d4.loss_bbox: 0.6337, loss: 6.6694, grad_norm: 23.0893
2025-06-20 04:45:19,965 - mmdet - INFO - Epoch [1][5400/7033]	lr: 2.000e-04, eta: 13:54:05, time: 1.346, data_time: 0.020, memory: 18096, loss_cls: 0.2607, loss_bbox: 0.6428, d0.loss_cls: 0.5011, d0.loss_bbox: 0.9079, d1.loss_cls: 0.4907, d1.loss_bbox: 0.8749, d2.loss_cls: 0.3879, d2.loss_bbox: 0.7725, d3.loss_cls: 0.3211, d3.loss_bbox: 0.6621, d4.loss_cls: 0.2812, d4.loss_bbox: 0.6411, loss: 6.7440, grad_norm: 25.4338
2025-06-20 04:46:27,139 - mmdet - INFO - Epoch [1][5450/7033]	lr: 2.000e-04, eta: 13:52:52, time: 1.343, data_time: 0.020, memory: 18096, loss_cls: 0.2406, loss_bbox: 0.6489, d0.loss_cls: 0.4958, d0.loss_bbox: 0.8946, d1.loss_cls: 0.4799, d1.loss_bbox: 0.8772, d2.loss_cls: 0.3725, d2.loss_bbox: 0.7844, d3.loss_cls: 0.2945, d3.loss_bbox: 0.6776, d4.loss_cls: 0.2634, d4.loss_bbox: 0.6424, loss: 6.6719, grad_norm: 26.9005
2025-06-20 04:47:35,412 - mmdet - INFO - Epoch [1][5500/7033]	lr: 2.000e-04, eta: 13:51:45, time: 1.365, data_time: 0.041, memory: 18096, loss_cls: 0.2366, loss_bbox: 0.6124, d0.loss_cls: 0.5017, d0.loss_bbox: 0.8439, d1.loss_cls: 0.4828, d1.loss_bbox: 0.8315, d2.loss_cls: 0.3705, d2.loss_bbox: 0.7377, d3.loss_cls: 0.2876, d3.loss_bbox: 0.6377, d4.loss_cls: 0.2603, d4.loss_bbox: 0.6079, loss: 6.4105, grad_norm: 20.3274
2025-06-20 04:48:42,773 - mmdet - INFO - Epoch [1][5550/7033]	lr: 2.000e-04, eta: 13:50:33, time: 1.347, data_time: 0.021, memory: 18096, loss_cls: 0.2460, loss_bbox: 0.6283, d0.loss_cls: 0.5165, d0.loss_bbox: 0.8893, d1.loss_cls: 0.4790, d1.loss_bbox: 0.8666, d2.loss_cls: 0.3691, d2.loss_bbox: 0.7586, d3.loss_cls: 0.3009, d3.loss_bbox: 0.6550, d4.loss_cls: 0.2724, d4.loss_bbox: 0.6209, loss: 6.6026, grad_norm: 31.1893
2025-06-20 04:49:49,848 - mmdet - INFO - Epoch [1][5600/7033]	lr: 2.000e-04, eta: 13:49:19, time: 1.341, data_time: 0.020, memory: 18096, loss_cls: 0.2229, loss_bbox: 0.6098, d0.loss_cls: 0.4851, d0.loss_bbox: 0.8647, d1.loss_cls: 0.4480, d1.loss_bbox: 0.8640, d2.loss_cls: 0.3443, d2.loss_bbox: 0.7515, d3.loss_cls: 0.2694, d3.loss_bbox: 0.6444, d4.loss_cls: 0.2429, d4.loss_bbox: 0.6052, loss: 6.3522, grad_norm: 20.7499
2025-06-20 04:50:56,931 - mmdet - INFO - Epoch [1][5650/7033]	lr: 2.000e-04, eta: 13:48:05, time: 1.342, data_time: 0.020, memory: 18096, loss_cls: 0.2444, loss_bbox: 0.6427, d0.loss_cls: 0.5060, d0.loss_bbox: 0.8762, d1.loss_cls: 0.4876, d1.loss_bbox: 0.8605, d2.loss_cls: 0.3628, d2.loss_bbox: 0.7645, d3.loss_cls: 0.2931, d3.loss_bbox: 0.6560, d4.loss_cls: 0.2660, d4.loss_bbox: 0.6360, loss: 6.5957, grad_norm: 24.4069
2025-06-20 04:52:03,972 - mmdet - INFO - Epoch [1][5700/7033]	lr: 2.000e-04, eta: 13:46:52, time: 1.341, data_time: 0.020, memory: 18096, loss_cls: 0.2282, loss_bbox: 0.6018, d0.loss_cls: 0.4841, d0.loss_bbox: 0.8671, d1.loss_cls: 0.4626, d1.loss_bbox: 0.8521, d2.loss_cls: 0.3492, d2.loss_bbox: 0.7493, d3.loss_cls: 0.2768, d3.loss_bbox: 0.6318, d4.loss_cls: 0.2517, d4.loss_bbox: 0.5933, loss: 6.3480, grad_norm: 20.0861
2025-06-20 04:53:11,151 - mmdet - INFO - Epoch [1][5750/7033]	lr: 2.000e-04, eta: 13:45:39, time: 1.344, data_time: 0.021, memory: 18096, loss_cls: 0.2248, loss_bbox: 0.6163, d0.loss_cls: 0.4916, d0.loss_bbox: 0.8527, d1.loss_cls: 0.4782, d1.loss_bbox: 0.8450, d2.loss_cls: 0.3489, d2.loss_bbox: 0.7336, d3.loss_cls: 0.2757, d3.loss_bbox: 0.6468, d4.loss_cls: 0.2478, d4.loss_bbox: 0.6119, loss: 6.3732, grad_norm: 20.1819
2025-06-20 04:54:18,235 - mmdet - INFO - Epoch [1][5800/7033]	lr: 2.000e-04, eta: 13:44:25, time: 1.342, data_time: 0.020, memory: 18096, loss_cls: 0.2373, loss_bbox: 0.6196, d0.loss_cls: 0.4700, d0.loss_bbox: 0.8847, d1.loss_cls: 0.4539, d1.loss_bbox: 0.8702, d2.loss_cls: 0.3387, d2.loss_bbox: 0.7558, d3.loss_cls: 0.2739, d3.loss_bbox: 0.6561, d4.loss_cls: 0.2565, d4.loss_bbox: 0.6185, loss: 6.4353, grad_norm: 20.4541
2025-06-20 04:55:25,327 - mmdet - INFO - Epoch [1][5850/7033]	lr: 2.000e-04, eta: 13:43:12, time: 1.342, data_time: 0.022, memory: 18096, loss_cls: 0.2446, loss_bbox: 0.6408, d0.loss_cls: 0.4742, d0.loss_bbox: 0.8591, d1.loss_cls: 0.4576, d1.loss_bbox: 0.8415, d2.loss_cls: 0.3484, d2.loss_bbox: 0.7356, d3.loss_cls: 0.2963, d3.loss_bbox: 0.6607, d4.loss_cls: 0.2688, d4.loss_bbox: 0.6340, loss: 6.4616, grad_norm: 18.3410
2025-06-20 04:56:32,796 - mmdet - INFO - Epoch [1][5900/7033]	lr: 2.000e-04, eta: 13:42:01, time: 1.349, data_time: 0.022, memory: 18096, loss_cls: 0.2388, loss_bbox: 0.6296, d0.loss_cls: 0.4821, d0.loss_bbox: 0.8772, d1.loss_cls: 0.4637, d1.loss_bbox: 0.8660, d2.loss_cls: 0.3398, d2.loss_bbox: 0.7423, d3.loss_cls: 0.2864, d3.loss_bbox: 0.6550, d4.loss_cls: 0.2593, d4.loss_bbox: 0.6244, loss: 6.4644, grad_norm: 19.9872
2025-06-20 04:57:40,138 - mmdet - INFO - Epoch [1][5950/7033]	lr: 2.000e-04, eta: 13:40:49, time: 1.346, data_time: 0.022, memory: 18096, loss_cls: 0.2303, loss_bbox: 0.6139, d0.loss_cls: 0.4545, d0.loss_bbox: 0.8633, d1.loss_cls: 0.4477, d1.loss_bbox: 0.8427, d2.loss_cls: 0.3309, d2.loss_bbox: 0.7290, d3.loss_cls: 0.2733, d3.loss_bbox: 0.6401, d4.loss_cls: 0.2515, d4.loss_bbox: 0.6102, loss: 6.2875, grad_norm: 21.7567
2025-06-20 04:58:47,770 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 04:58:47,770 - mmdet - INFO - Epoch [1][6000/7033]	lr: 2.000e-04, eta: 13:39:40, time: 1.354, data_time: 0.022, memory: 18168, loss_cls: 0.2254, loss_bbox: 0.6182, d0.loss_cls: 0.4530, d0.loss_bbox: 0.8706, d1.loss_cls: 0.4464, d1.loss_bbox: 0.8539, d2.loss_cls: 0.3282, d2.loss_bbox: 0.7194, d3.loss_cls: 0.2775, d3.loss_bbox: 0.6383, d4.loss_cls: 0.2543, d4.loss_bbox: 0.6090, loss: 6.2943, grad_norm: 25.6620
2025-06-20 04:59:54,960 - mmdet - INFO - Epoch [1][6050/7033]	lr: 2.000e-04, eta: 13:38:27, time: 1.344, data_time: 0.020, memory: 18168, loss_cls: 0.2237, loss_bbox: 0.6122, d0.loss_cls: 0.4656, d0.loss_bbox: 0.8647, d1.loss_cls: 0.4441, d1.loss_bbox: 0.8432, d2.loss_cls: 0.3256, d2.loss_bbox: 0.7116, d3.loss_cls: 0.2674, d3.loss_bbox: 0.6432, d4.loss_cls: 0.2448, d4.loss_bbox: 0.6106, loss: 6.2569, grad_norm: 34.6825
2025-06-20 05:01:02,223 - mmdet - INFO - Epoch [1][6100/7033]	lr: 2.000e-04, eta: 13:37:15, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.2383, loss_bbox: 0.6088, d0.loss_cls: 0.4678, d0.loss_bbox: 0.8561, d1.loss_cls: 0.4653, d1.loss_bbox: 0.8408, d2.loss_cls: 0.3396, d2.loss_bbox: 0.7227, d3.loss_cls: 0.2872, d3.loss_bbox: 0.6403, d4.loss_cls: 0.2598, d4.loss_bbox: 0.6041, loss: 6.3307, grad_norm: 24.3447
2025-06-20 05:02:09,812 - mmdet - INFO - Epoch [1][6150/7033]	lr: 2.000e-04, eta: 13:36:06, time: 1.352, data_time: 0.020, memory: 18168, loss_cls: 0.2250, loss_bbox: 0.6197, d0.loss_cls: 0.4657, d0.loss_bbox: 0.8523, d1.loss_cls: 0.4545, d1.loss_bbox: 0.8398, d2.loss_cls: 0.3236, d2.loss_bbox: 0.7272, d3.loss_cls: 0.2685, d3.loss_bbox: 0.6432, d4.loss_cls: 0.2442, d4.loss_bbox: 0.6138, loss: 6.2775, grad_norm: 23.0386
2025-06-20 05:03:17,044 - mmdet - INFO - Epoch [1][6200/7033]	lr: 2.000e-04, eta: 13:34:54, time: 1.345, data_time: 0.020, memory: 18168, loss_cls: 0.2251, loss_bbox: 0.6120, d0.loss_cls: 0.4829, d0.loss_bbox: 0.8523, d1.loss_cls: 0.4525, d1.loss_bbox: 0.8435, d2.loss_cls: 0.3250, d2.loss_bbox: 0.7025, d3.loss_cls: 0.2775, d3.loss_bbox: 0.6333, d4.loss_cls: 0.2419, d4.loss_bbox: 0.6106, loss: 6.2593, grad_norm: 20.7819
2025-06-20 05:04:25,786 - mmdet - INFO - Epoch [1][6250/7033]	lr: 2.000e-04, eta: 13:33:51, time: 1.375, data_time: 0.020, memory: 18168, loss_cls: 0.2320, loss_bbox: 0.6200, d0.loss_cls: 0.4804, d0.loss_bbox: 0.8487, d1.loss_cls: 0.4581, d1.loss_bbox: 0.8348, d2.loss_cls: 0.3274, d2.loss_bbox: 0.7353, d3.loss_cls: 0.2810, d3.loss_bbox: 0.6506, d4.loss_cls: 0.2454, d4.loss_bbox: 0.6211, loss: 6.3348, grad_norm: 28.1561
2025-06-20 05:05:33,178 - mmdet - INFO - Epoch [1][6300/7033]	lr: 2.000e-04, eta: 13:32:40, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.2198, loss_bbox: 0.6132, d0.loss_cls: 0.4422, d0.loss_bbox: 0.8871, d1.loss_cls: 0.4315, d1.loss_bbox: 0.8663, d2.loss_cls: 0.3100, d2.loss_bbox: 0.7285, d3.loss_cls: 0.2647, d3.loss_bbox: 0.6504, d4.loss_cls: 0.2419, d4.loss_bbox: 0.6115, loss: 6.2669, grad_norm: 26.8845
2025-06-20 05:06:40,540 - mmdet - INFO - Epoch [1][6350/7033]	lr: 2.000e-04, eta: 13:31:29, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.2335, loss_bbox: 0.6248, d0.loss_cls: 0.4629, d0.loss_bbox: 0.8749, d1.loss_cls: 0.4483, d1.loss_bbox: 0.8520, d2.loss_cls: 0.3227, d2.loss_bbox: 0.7154, d3.loss_cls: 0.2832, d3.loss_bbox: 0.6402, d4.loss_cls: 0.2496, d4.loss_bbox: 0.6215, loss: 6.3289, grad_norm: 28.5230
2025-06-20 05:07:49,349 - mmdet - INFO - Epoch [1][6400/7033]	lr: 2.000e-04, eta: 13:30:26, time: 1.376, data_time: 0.019, memory: 18168, loss_cls: 0.2514, loss_bbox: 0.6545, d0.loss_cls: 0.4725, d0.loss_bbox: 0.8935, d1.loss_cls: 0.4699, d1.loss_bbox: 0.8660, d2.loss_cls: 0.3514, d2.loss_bbox: 0.7331, d3.loss_cls: 0.3071, d3.loss_bbox: 0.6718, d4.loss_cls: 0.2776, d4.loss_bbox: 0.6483, loss: 6.5971, grad_norm: 36.1590
2025-06-20 05:08:56,687 - mmdet - INFO - Epoch [1][6450/7033]	lr: 2.000e-04, eta: 13:29:15, time: 1.347, data_time: 0.020, memory: 18168, loss_cls: 0.2341, loss_bbox: 0.6056, d0.loss_cls: 0.4529, d0.loss_bbox: 0.8588, d1.loss_cls: 0.4460, d1.loss_bbox: 0.8348, d2.loss_cls: 0.3299, d2.loss_bbox: 0.7204, d3.loss_cls: 0.2869, d3.loss_bbox: 0.6312, d4.loss_cls: 0.2608, d4.loss_bbox: 0.6030, loss: 6.2643, grad_norm: 22.1376
2025-06-20 05:10:03,781 - mmdet - INFO - Epoch [1][6500/7033]	lr: 2.000e-04, eta: 13:28:02, time: 1.342, data_time: 0.020, memory: 18168, loss_cls: 0.2331, loss_bbox: 0.6131, d0.loss_cls: 0.4588, d0.loss_bbox: 0.8635, d1.loss_cls: 0.4563, d1.loss_bbox: 0.8359, d2.loss_cls: 0.3323, d2.loss_bbox: 0.7033, d3.loss_cls: 0.2788, d3.loss_bbox: 0.6392, d4.loss_cls: 0.2542, d4.loss_bbox: 0.6109, loss: 6.2793, grad_norm: 24.4854
2025-06-20 05:11:10,876 - mmdet - INFO - Epoch [1][6550/7033]	lr: 2.000e-04, eta: 13:26:50, time: 1.342, data_time: 0.020, memory: 18168, loss_cls: 0.2436, loss_bbox: 0.6275, d0.loss_cls: 0.4634, d0.loss_bbox: 0.8663, d1.loss_cls: 0.4523, d1.loss_bbox: 0.8352, d2.loss_cls: 0.3377, d2.loss_bbox: 0.7396, d3.loss_cls: 0.2928, d3.loss_bbox: 0.6660, d4.loss_cls: 0.2636, d4.loss_bbox: 0.6293, loss: 6.4171, grad_norm: 23.1507
2025-06-20 05:12:18,043 - mmdet - INFO - Epoch [1][6600/7033]	lr: 2.000e-04, eta: 13:25:38, time: 1.343, data_time: 0.019, memory: 18168, loss_cls: 0.2323, loss_bbox: 0.6451, d0.loss_cls: 0.4548, d0.loss_bbox: 0.8643, d1.loss_cls: 0.4373, d1.loss_bbox: 0.8450, d2.loss_cls: 0.3359, d2.loss_bbox: 0.7293, d3.loss_cls: 0.2961, d3.loss_bbox: 0.6603, d4.loss_cls: 0.2577, d4.loss_bbox: 0.6393, loss: 6.3973, grad_norm: 27.3073
2025-06-20 05:13:25,269 - mmdet - INFO - Epoch [1][6650/7033]	lr: 2.000e-04, eta: 13:24:26, time: 1.345, data_time: 0.020, memory: 18168, loss_cls: 0.2348, loss_bbox: 0.6139, d0.loss_cls: 0.4377, d0.loss_bbox: 0.8731, d1.loss_cls: 0.4214, d1.loss_bbox: 0.8536, d2.loss_cls: 0.3247, d2.loss_bbox: 0.7137, d3.loss_cls: 0.2787, d3.loss_bbox: 0.6351, d4.loss_cls: 0.2539, d4.loss_bbox: 0.6150, loss: 6.2555, grad_norm: 23.9568
2025-06-20 05:14:32,535 - mmdet - INFO - Epoch [1][6700/7033]	lr: 2.000e-04, eta: 13:23:15, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.2350, loss_bbox: 0.6063, d0.loss_cls: 0.4443, d0.loss_bbox: 0.8687, d1.loss_cls: 0.4319, d1.loss_bbox: 0.8355, d2.loss_cls: 0.3341, d2.loss_bbox: 0.6948, d3.loss_cls: 0.2908, d3.loss_bbox: 0.6297, d4.loss_cls: 0.2584, d4.loss_bbox: 0.6052, loss: 6.2346, grad_norm: 28.6653
2025-06-20 05:15:39,900 - mmdet - INFO - Epoch [1][6750/7033]	lr: 2.000e-04, eta: 13:22:05, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.2269, loss_bbox: 0.6095, d0.loss_cls: 0.4326, d0.loss_bbox: 0.8527, d1.loss_cls: 0.4125, d1.loss_bbox: 0.8329, d2.loss_cls: 0.3129, d2.loss_bbox: 0.6924, d3.loss_cls: 0.2653, d3.loss_bbox: 0.6389, d4.loss_cls: 0.2437, d4.loss_bbox: 0.6086, loss: 6.1289, grad_norm: 23.7266
2025-06-20 05:16:47,146 - mmdet - INFO - Epoch [1][6800/7033]	lr: 2.000e-04, eta: 13:20:53, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.2259, loss_bbox: 0.6157, d0.loss_cls: 0.4342, d0.loss_bbox: 0.8522, d1.loss_cls: 0.4183, d1.loss_bbox: 0.8237, d2.loss_cls: 0.3107, d2.loss_bbox: 0.7017, d3.loss_cls: 0.2794, d3.loss_bbox: 0.6241, d4.loss_cls: 0.2499, d4.loss_bbox: 0.6042, loss: 6.1401, grad_norm: 22.0462
2025-06-20 05:17:55,802 - mmdet - INFO - Epoch [1][6850/7033]	lr: 2.000e-04, eta: 13:19:50, time: 1.373, data_time: 0.020, memory: 18168, loss_cls: 0.2286, loss_bbox: 0.6095, d0.loss_cls: 0.4255, d0.loss_bbox: 0.8499, d1.loss_cls: 0.4049, d1.loss_bbox: 0.8312, d2.loss_cls: 0.3155, d2.loss_bbox: 0.7003, d3.loss_cls: 0.2780, d3.loss_bbox: 0.6275, d4.loss_cls: 0.2507, d4.loss_bbox: 0.6070, loss: 6.1285, grad_norm: 27.7537
2025-06-20 05:19:02,976 - mmdet - INFO - Epoch [1][6900/7033]	lr: 2.000e-04, eta: 13:18:38, time: 1.343, data_time: 0.020, memory: 18168, loss_cls: 0.2352, loss_bbox: 0.6334, d0.loss_cls: 0.4201, d0.loss_bbox: 0.8746, d1.loss_cls: 0.4066, d1.loss_bbox: 0.8512, d2.loss_cls: 0.3269, d2.loss_bbox: 0.7049, d3.loss_cls: 0.2816, d3.loss_bbox: 0.6501, d4.loss_cls: 0.2526, d4.loss_bbox: 0.6312, loss: 6.2683, grad_norm: 29.1981
2025-06-20 05:20:10,104 - mmdet - INFO - Epoch [1][6950/7033]	lr: 2.000e-04, eta: 13:17:26, time: 1.343, data_time: 0.019, memory: 18168, loss_cls: 0.2203, loss_bbox: 0.6080, d0.loss_cls: 0.4222, d0.loss_bbox: 0.8481, d1.loss_cls: 0.4050, d1.loss_bbox: 0.8282, d2.loss_cls: 0.3156, d2.loss_bbox: 0.6968, d3.loss_cls: 0.2754, d3.loss_bbox: 0.6318, d4.loss_cls: 0.2440, d4.loss_bbox: 0.6084, loss: 6.1038, grad_norm: 47.4335
2025-06-20 05:21:17,454 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 05:21:17,454 - mmdet - INFO - Epoch [1][7000/7033]	lr: 2.000e-04, eta: 13:16:16, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.2211, loss_bbox: 0.5889, d0.loss_cls: 0.4329, d0.loss_bbox: 0.8373, d1.loss_cls: 0.4135, d1.loss_bbox: 0.8127, d2.loss_cls: 0.3094, d2.loss_bbox: 0.6836, d3.loss_cls: 0.2737, d3.loss_bbox: 0.6126, d4.loss_cls: 0.2457, d4.loss_bbox: 0.5860, loss: 6.0175, grad_norm: 26.1130
2025-06-20 05:22:03,560 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-06-20 05:47:56,336 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 05:47:56,336 - mmdet - INFO - Epoch(val) [1][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.4555, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8079, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8909, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9113, pts_bbox_NuScenes/car_trans_err: 0.3752, pts_bbox_NuScenes/car_scale_err: 0.1512, pts_bbox_NuScenes/car_orient_err: 0.0823, pts_bbox_NuScenes/car_vel_err: 0.3155, pts_bbox_NuScenes/car_attr_err: 0.1824, pts_bbox_NuScenes/mATE: 0.4965, pts_bbox_NuScenes/mASE: 0.2691, pts_bbox_NuScenes/mAOE: 0.2798, pts_bbox_NuScenes/mAVE: 0.2895, pts_bbox_NuScenes/mAAE: 0.1800, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.1197, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.4651, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6618, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7176, pts_bbox_NuScenes/truck_trans_err: 0.5981, pts_bbox_NuScenes/truck_scale_err: 0.2019, pts_bbox_NuScenes/truck_orient_err: 0.0909, pts_bbox_NuScenes/truck_vel_err: 0.2397, pts_bbox_NuScenes/truck_attr_err: 0.2299, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0100, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1324, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3588, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4824, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.8346, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4398, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8755, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1155, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3092, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.2206, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.6344, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8536, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.8885, pts_bbox_NuScenes/bus_trans_err: 0.5232, pts_bbox_NuScenes/bus_scale_err: 0.1985, pts_bbox_NuScenes/bus_orient_err: 0.0529, pts_bbox_NuScenes/bus_vel_err: 0.5168, pts_bbox_NuScenes/bus_attr_err: 0.1740, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0225, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.2822, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5849, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6950, pts_bbox_NuScenes/trailer_trans_err: 0.7368, pts_bbox_NuScenes/trailer_scale_err: 0.2529, pts_bbox_NuScenes/trailer_orient_err: 0.4246, pts_bbox_NuScenes/trailer_vel_err: 0.1902, pts_bbox_NuScenes/trailer_attr_err: 0.1669, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.2689, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.5490, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.6526, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.6862, pts_bbox_NuScenes/barrier_trans_err: 0.4765, pts_bbox_NuScenes/barrier_scale_err: 0.3042, pts_bbox_NuScenes/barrier_orient_err: 0.0800, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.3830, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.6671, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7396, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7545, pts_bbox_NuScenes/motorcycle_trans_err: 0.3849, pts_bbox_NuScenes/motorcycle_scale_err: 0.2353, pts_bbox_NuScenes/motorcycle_orient_err: 0.2242, pts_bbox_NuScenes/motorcycle_vel_err: 0.4521, pts_bbox_NuScenes/motorcycle_attr_err: 0.2501, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.3367, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5263, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5538, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.5649, pts_bbox_NuScenes/bicycle_trans_err: 0.3507, pts_bbox_NuScenes/bicycle_scale_err: 0.2826, pts_bbox_NuScenes/bicycle_orient_err: 0.3188, pts_bbox_NuScenes/bicycle_vel_err: 0.2511, pts_bbox_NuScenes/bicycle_attr_err: 0.0182, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.4786, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.7686, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8414, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8626, pts_bbox_NuScenes/pedestrian_trans_err: 0.3848, pts_bbox_NuScenes/pedestrian_scale_err: 0.2873, pts_bbox_NuScenes/pedestrian_orient_err: 0.3695, pts_bbox_NuScenes/pedestrian_vel_err: 0.2352, pts_bbox_NuScenes/pedestrian_attr_err: 0.1091, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.5180, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.6677, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7266, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7664, pts_bbox_NuScenes/traffic_cone_trans_err: 0.3001, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3368, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6299, pts_bbox_NuScenes/mAP: 0.5627
2025-06-20 05:49:11,864 - mmdet - INFO - Epoch [2][50/7033]	lr: 1.866e-04, eta: 13:11:01, time: 1.438, data_time: 0.101, memory: 18168, loss_cls: 0.2227, loss_bbox: 0.5850, d0.loss_cls: 0.4121, d0.loss_bbox: 0.8310, d1.loss_cls: 0.4035, d1.loss_bbox: 0.7976, d2.loss_cls: 0.3169, d2.loss_bbox: 0.6501, d3.loss_cls: 0.2722, d3.loss_bbox: 0.5988, d4.loss_cls: 0.2469, d4.loss_bbox: 0.5812, loss: 5.9179, grad_norm: 22.2002
2025-06-20 05:50:19,196 - mmdet - INFO - Epoch [2][100/7033]	lr: 1.866e-04, eta: 13:09:52, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.2339, loss_bbox: 0.6206, d0.loss_cls: 0.4269, d0.loss_bbox: 0.8626, d1.loss_cls: 0.4228, d1.loss_bbox: 0.8239, d2.loss_cls: 0.3417, d2.loss_bbox: 0.6919, d3.loss_cls: 0.2805, d3.loss_bbox: 0.6364, d4.loss_cls: 0.2559, d4.loss_bbox: 0.6186, loss: 6.2156, grad_norm: 29.9330
2025-06-20 05:51:26,883 - mmdet - INFO - Epoch [2][150/7033]	lr: 1.866e-04, eta: 13:08:45, time: 1.354, data_time: 0.025, memory: 18168, loss_cls: 0.2182, loss_bbox: 0.5981, d0.loss_cls: 0.3992, d0.loss_bbox: 0.8267, d1.loss_cls: 0.3855, d1.loss_bbox: 0.8023, d2.loss_cls: 0.3149, d2.loss_bbox: 0.6781, d3.loss_cls: 0.2729, d3.loss_bbox: 0.6164, d4.loss_cls: 0.2362, d4.loss_bbox: 0.5975, loss: 5.9461, grad_norm: 32.7794
2025-06-20 05:52:34,304 - mmdet - INFO - Epoch [2][200/7033]	lr: 1.866e-04, eta: 13:07:37, time: 1.348, data_time: 0.023, memory: 18168, loss_cls: 0.2288, loss_bbox: 0.6375, d0.loss_cls: 0.4166, d0.loss_bbox: 0.8612, d1.loss_cls: 0.4026, d1.loss_bbox: 0.8321, d2.loss_cls: 0.3199, d2.loss_bbox: 0.7060, d3.loss_cls: 0.2850, d3.loss_bbox: 0.6548, d4.loss_cls: 0.2540, d4.loss_bbox: 0.6355, loss: 6.2338, grad_norm: 25.5522
2025-06-20 05:53:41,490 - mmdet - INFO - Epoch [2][250/7033]	lr: 1.866e-04, eta: 13:06:27, time: 1.344, data_time: 0.023, memory: 18168, loss_cls: 0.2226, loss_bbox: 0.6172, d0.loss_cls: 0.4128, d0.loss_bbox: 0.8277, d1.loss_cls: 0.4001, d1.loss_bbox: 0.7984, d2.loss_cls: 0.3218, d2.loss_bbox: 0.6899, d3.loss_cls: 0.2805, d3.loss_bbox: 0.6322, d4.loss_cls: 0.2422, d4.loss_bbox: 0.6160, loss: 6.0616, grad_norm: 25.2494
2025-06-20 05:54:49,105 - mmdet - INFO - Epoch [2][300/7033]	lr: 1.866e-04, eta: 13:05:20, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.2096, loss_bbox: 0.6011, d0.loss_cls: 0.4091, d0.loss_bbox: 0.8219, d1.loss_cls: 0.3844, d1.loss_bbox: 0.7941, d2.loss_cls: 0.3053, d2.loss_bbox: 0.6748, d3.loss_cls: 0.2554, d3.loss_bbox: 0.6206, d4.loss_cls: 0.2300, d4.loss_bbox: 0.6023, loss: 5.9085, grad_norm: 27.6999
2025-06-20 05:55:56,824 - mmdet - INFO - Epoch [2][350/7033]	lr: 1.866e-04, eta: 13:04:13, time: 1.354, data_time: 0.024, memory: 18168, loss_cls: 0.2352, loss_bbox: 0.6164, d0.loss_cls: 0.4106, d0.loss_bbox: 0.8801, d1.loss_cls: 0.3993, d1.loss_bbox: 0.8441, d2.loss_cls: 0.3321, d2.loss_bbox: 0.7073, d3.loss_cls: 0.2908, d3.loss_bbox: 0.6435, d4.loss_cls: 0.2572, d4.loss_bbox: 0.6184, loss: 6.2350, grad_norm: 33.0010
2025-06-20 05:57:06,138 - mmdet - INFO - Epoch [2][400/7033]	lr: 1.866e-04, eta: 13:03:14, time: 1.386, data_time: 0.064, memory: 18168, loss_cls: 0.2185, loss_bbox: 0.5871, d0.loss_cls: 0.3933, d0.loss_bbox: 0.8077, d1.loss_cls: 0.3812, d1.loss_bbox: 0.7788, d2.loss_cls: 0.3074, d2.loss_bbox: 0.6613, d3.loss_cls: 0.2663, d3.loss_bbox: 0.6034, d4.loss_cls: 0.2371, d4.loss_bbox: 0.5876, loss: 5.8299, grad_norm: 33.1098
2025-06-20 05:58:13,489 - mmdet - INFO - Epoch [2][450/7033]	lr: 1.866e-04, eta: 13:02:05, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.2268, loss_bbox: 0.6069, d0.loss_cls: 0.4118, d0.loss_bbox: 0.8407, d1.loss_cls: 0.3974, d1.loss_bbox: 0.7996, d2.loss_cls: 0.3232, d2.loss_bbox: 0.6879, d3.loss_cls: 0.2836, d3.loss_bbox: 0.6252, d4.loss_cls: 0.2460, d4.loss_bbox: 0.6079, loss: 6.0569, grad_norm: 25.9455
2025-06-20 05:59:20,926 - mmdet - INFO - Epoch [2][500/7033]	lr: 1.866e-04, eta: 13:00:57, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.2178, loss_bbox: 0.5774, d0.loss_cls: 0.4041, d0.loss_bbox: 0.8096, d1.loss_cls: 0.3879, d1.loss_bbox: 0.7764, d2.loss_cls: 0.3141, d2.loss_bbox: 0.6540, d3.loss_cls: 0.2694, d3.loss_bbox: 0.5981, d4.loss_cls: 0.2356, d4.loss_bbox: 0.5796, loss: 5.8241, grad_norm: 25.7840
2025-06-20 06:00:28,168 - mmdet - INFO - Epoch [2][550/7033]	lr: 1.866e-04, eta: 12:59:48, time: 1.345, data_time: 0.024, memory: 18168, loss_cls: 0.2275, loss_bbox: 0.6091, d0.loss_cls: 0.3937, d0.loss_bbox: 0.8283, d1.loss_cls: 0.3921, d1.loss_bbox: 0.7741, d2.loss_cls: 0.3300, d2.loss_bbox: 0.6468, d3.loss_cls: 0.2795, d3.loss_bbox: 0.6141, d4.loss_cls: 0.2491, d4.loss_bbox: 0.6030, loss: 5.9471, grad_norm: 27.2616
2025-06-20 06:01:35,904 - mmdet - INFO - Epoch [2][600/7033]	lr: 1.866e-04, eta: 12:58:41, time: 1.355, data_time: 0.024, memory: 18168, loss_cls: 0.2257, loss_bbox: 0.5883, d0.loss_cls: 0.3838, d0.loss_bbox: 0.8193, d1.loss_cls: 0.3821, d1.loss_bbox: 0.7715, d2.loss_cls: 0.3242, d2.loss_bbox: 0.6592, d3.loss_cls: 0.2810, d3.loss_bbox: 0.6003, d4.loss_cls: 0.2461, d4.loss_bbox: 0.5877, loss: 5.8693, grad_norm: 28.8503
2025-06-20 06:02:43,351 - mmdet - INFO - Epoch [2][650/7033]	lr: 1.866e-04, eta: 12:57:32, time: 1.349, data_time: 0.024, memory: 18168, loss_cls: 0.2288, loss_bbox: 0.6072, d0.loss_cls: 0.3998, d0.loss_bbox: 0.8256, d1.loss_cls: 0.3854, d1.loss_bbox: 0.7777, d2.loss_cls: 0.3321, d2.loss_bbox: 0.6723, d3.loss_cls: 0.2895, d3.loss_bbox: 0.6224, d4.loss_cls: 0.2514, d4.loss_bbox: 0.6064, loss: 5.9985, grad_norm: 26.1924
2025-06-20 06:03:50,927 - mmdet - INFO - Epoch [2][700/7033]	lr: 1.866e-04, eta: 12:56:25, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.2302, loss_bbox: 0.6010, d0.loss_cls: 0.3940, d0.loss_bbox: 0.8298, d1.loss_cls: 0.3773, d1.loss_bbox: 0.7823, d2.loss_cls: 0.3271, d2.loss_bbox: 0.6788, d3.loss_cls: 0.2870, d3.loss_bbox: 0.6265, d4.loss_cls: 0.2523, d4.loss_bbox: 0.6013, loss: 5.9876, grad_norm: 31.4014
2025-06-20 06:04:58,191 - mmdet - INFO - Epoch [2][750/7033]	lr: 1.866e-04, eta: 12:55:16, time: 1.345, data_time: 0.023, memory: 18168, loss_cls: 0.2351, loss_bbox: 0.6109, d0.loss_cls: 0.3862, d0.loss_bbox: 0.8382, d1.loss_cls: 0.3686, d1.loss_bbox: 0.7875, d2.loss_cls: 0.3333, d2.loss_bbox: 0.6924, d3.loss_cls: 0.2943, d3.loss_bbox: 0.6292, d4.loss_cls: 0.2525, d4.loss_bbox: 0.6142, loss: 6.0424, grad_norm: 29.7415
2025-06-20 06:06:05,683 - mmdet - INFO - Epoch [2][800/7033]	lr: 1.866e-04, eta: 12:54:08, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.2301, loss_bbox: 0.5920, d0.loss_cls: 0.4038, d0.loss_bbox: 0.8173, d1.loss_cls: 0.3726, d1.loss_bbox: 0.7873, d2.loss_cls: 0.3259, d2.loss_bbox: 0.6896, d3.loss_cls: 0.2913, d3.loss_bbox: 0.6170, d4.loss_cls: 0.2523, d4.loss_bbox: 0.5942, loss: 5.9733, grad_norm: 35.7973
2025-06-20 06:07:14,717 - mmdet - INFO - Epoch [2][850/7033]	lr: 1.866e-04, eta: 12:53:07, time: 1.381, data_time: 0.021, memory: 18168, loss_cls: 0.2305, loss_bbox: 0.5911, d0.loss_cls: 0.3895, d0.loss_bbox: 0.8123, d1.loss_cls: 0.3658, d1.loss_bbox: 0.7594, d2.loss_cls: 0.3223, d2.loss_bbox: 0.6540, d3.loss_cls: 0.2875, d3.loss_bbox: 0.6042, d4.loss_cls: 0.2511, d4.loss_bbox: 0.5893, loss: 5.8570, grad_norm: 32.1312
2025-06-20 06:08:21,943 - mmdet - INFO - Epoch [2][900/7033]	lr: 1.866e-04, eta: 12:51:57, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.2189, loss_bbox: 0.6007, d0.loss_cls: 0.3914, d0.loss_bbox: 0.8194, d1.loss_cls: 0.3628, d1.loss_bbox: 0.7822, d2.loss_cls: 0.3118, d2.loss_bbox: 0.6718, d3.loss_cls: 0.2814, d3.loss_bbox: 0.6159, d4.loss_cls: 0.2424, d4.loss_bbox: 0.5957, loss: 5.8943, grad_norm: 26.3282
2025-06-20 06:09:29,444 - mmdet - INFO - Epoch [2][950/7033]	lr: 1.866e-04, eta: 12:50:49, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.2179, loss_bbox: 0.5998, d0.loss_cls: 0.3925, d0.loss_bbox: 0.7857, d1.loss_cls: 0.3683, d1.loss_bbox: 0.7385, d2.loss_cls: 0.3050, d2.loss_bbox: 0.6620, d3.loss_cls: 0.2661, d3.loss_bbox: 0.6101, d4.loss_cls: 0.2403, d4.loss_bbox: 0.5927, loss: 5.7788, grad_norm: 25.0975
2025-06-20 06:10:36,856 - mmdet - INFO - Epoch [2][1000/7033]	lr: 1.866e-04, eta: 12:49:41, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.2149, loss_bbox: 0.5752, d0.loss_cls: 0.3639, d0.loss_bbox: 0.7902, d1.loss_cls: 0.3377, d1.loss_bbox: 0.7389, d2.loss_cls: 0.2947, d2.loss_bbox: 0.6471, d3.loss_cls: 0.2597, d3.loss_bbox: 0.5936, d4.loss_cls: 0.2336, d4.loss_bbox: 0.5775, loss: 5.6269, grad_norm: 34.5482
2025-06-20 06:11:44,274 - mmdet - INFO - Epoch [2][1050/7033]	lr: 1.866e-04, eta: 12:48:33, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.2295, loss_bbox: 0.5997, d0.loss_cls: 0.3798, d0.loss_bbox: 0.8195, d1.loss_cls: 0.3575, d1.loss_bbox: 0.7635, d2.loss_cls: 0.3250, d2.loss_bbox: 0.6697, d3.loss_cls: 0.2899, d3.loss_bbox: 0.6133, d4.loss_cls: 0.2560, d4.loss_bbox: 0.5940, loss: 5.8972, grad_norm: 25.8876
2025-06-20 06:12:51,723 - mmdet - INFO - Epoch [2][1100/7033]	lr: 1.866e-04, eta: 12:47:25, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.2117, loss_bbox: 0.5912, d0.loss_cls: 0.3797, d0.loss_bbox: 0.8062, d1.loss_cls: 0.3633, d1.loss_bbox: 0.7567, d2.loss_cls: 0.3180, d2.loss_bbox: 0.6656, d3.loss_cls: 0.2712, d3.loss_bbox: 0.6099, d4.loss_cls: 0.2353, d4.loss_bbox: 0.5899, loss: 5.7986, grad_norm: 30.7935
2025-06-20 06:13:59,082 - mmdet - INFO - Epoch [2][1150/7033]	lr: 1.866e-04, eta: 12:46:16, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.2094, loss_bbox: 0.5885, d0.loss_cls: 0.3662, d0.loss_bbox: 0.7734, d1.loss_cls: 0.3482, d1.loss_bbox: 0.7312, d2.loss_cls: 0.3050, d2.loss_bbox: 0.6443, d3.loss_cls: 0.2597, d3.loss_bbox: 0.6119, d4.loss_cls: 0.2298, d4.loss_bbox: 0.5898, loss: 5.6573, grad_norm: 24.5457
2025-06-20 06:15:06,295 - mmdet - INFO - Epoch [2][1200/7033]	lr: 1.866e-04, eta: 12:45:07, time: 1.344, data_time: 0.024, memory: 18168, loss_cls: 0.2164, loss_bbox: 0.6302, d0.loss_cls: 0.3402, d0.loss_bbox: 0.8286, d1.loss_cls: 0.3223, d1.loss_bbox: 0.7615, d2.loss_cls: 0.2920, d2.loss_bbox: 0.6902, d3.loss_cls: 0.2651, d3.loss_bbox: 0.6408, d4.loss_cls: 0.2352, d4.loss_bbox: 0.6256, loss: 5.8482, grad_norm: 30.1921
2025-06-20 06:16:27,492 - mmdet - INFO - Epoch [2][1250/7033]	lr: 1.866e-04, eta: 12:44:55, time: 1.624, data_time: 0.292, memory: 18168, loss_cls: 0.2142, loss_bbox: 0.6212, d0.loss_cls: 0.3654, d0.loss_bbox: 0.8027, d1.loss_cls: 0.3350, d1.loss_bbox: 0.7533, d2.loss_cls: 0.3019, d2.loss_bbox: 0.6701, d3.loss_cls: 0.2605, d3.loss_bbox: 0.6250, d4.loss_cls: 0.2299, d4.loss_bbox: 0.6180, loss: 5.7972, grad_norm: 37.8885
2025-06-20 06:17:34,723 - mmdet - INFO - Epoch [2][1300/7033]	lr: 1.866e-04, eta: 12:43:46, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.2238, loss_bbox: 0.5932, d0.loss_cls: 0.3656, d0.loss_bbox: 0.8080, d1.loss_cls: 0.3476, d1.loss_bbox: 0.7677, d2.loss_cls: 0.3154, d2.loss_bbox: 0.6751, d3.loss_cls: 0.2713, d3.loss_bbox: 0.6184, d4.loss_cls: 0.2429, d4.loss_bbox: 0.5940, loss: 5.8230, grad_norm: 39.9954
2025-06-20 06:18:41,977 - mmdet - INFO - Epoch [2][1350/7033]	lr: 1.866e-04, eta: 12:42:37, time: 1.345, data_time: 0.020, memory: 18168, loss_cls: 0.2151, loss_bbox: 0.5868, d0.loss_cls: 0.3637, d0.loss_bbox: 0.8133, d1.loss_cls: 0.3409, d1.loss_bbox: 0.7568, d2.loss_cls: 0.2967, d2.loss_bbox: 0.6569, d3.loss_cls: 0.2590, d3.loss_bbox: 0.6060, d4.loss_cls: 0.2303, d4.loss_bbox: 0.5889, loss: 5.7146, grad_norm: 27.9232
2025-06-20 06:19:49,153 - mmdet - INFO - Epoch [2][1400/7033]	lr: 1.866e-04, eta: 12:41:27, time: 1.344, data_time: 0.020, memory: 18168, loss_cls: 0.2339, loss_bbox: 0.6314, d0.loss_cls: 0.3858, d0.loss_bbox: 0.8368, d1.loss_cls: 0.3524, d1.loss_bbox: 0.8065, d2.loss_cls: 0.3147, d2.loss_bbox: 0.7121, d3.loss_cls: 0.2895, d3.loss_bbox: 0.6390, d4.loss_cls: 0.2503, d4.loss_bbox: 0.6325, loss: 6.0850, grad_norm: 26.5664
2025-06-20 06:20:58,195 - mmdet - INFO - Epoch [2][1450/7033]	lr: 1.866e-04, eta: 12:40:25, time: 1.381, data_time: 0.022, memory: 18168, loss_cls: 0.2387, loss_bbox: 0.6607, d0.loss_cls: 0.3454, d0.loss_bbox: 0.8861, d1.loss_cls: 0.3373, d1.loss_bbox: 0.8167, d2.loss_cls: 0.3165, d2.loss_bbox: 0.7461, d3.loss_cls: 0.2855, d3.loss_bbox: 0.6872, d4.loss_cls: 0.2546, d4.loss_bbox: 0.6632, loss: 6.2378, grad_norm: 36.1369
2025-06-20 06:22:05,814 - mmdet - INFO - Epoch [2][1500/7033]	lr: 1.866e-04, eta: 12:39:17, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.2348, loss_bbox: 0.6252, d0.loss_cls: 0.3655, d0.loss_bbox: 0.8243, d1.loss_cls: 0.3522, d1.loss_bbox: 0.7669, d2.loss_cls: 0.3293, d2.loss_bbox: 0.6932, d3.loss_cls: 0.2950, d3.loss_bbox: 0.6408, d4.loss_cls: 0.2547, d4.loss_bbox: 0.6265, loss: 6.0083, grad_norm: 22.8654
2025-06-20 06:23:12,782 - mmdet - INFO - Epoch [2][1550/7033]	lr: 1.866e-04, eta: 12:38:07, time: 1.339, data_time: 0.021, memory: 18168, loss_cls: 0.2190, loss_bbox: 0.6177, d0.loss_cls: 0.3520, d0.loss_bbox: 0.8072, d1.loss_cls: 0.3329, d1.loss_bbox: 0.7573, d2.loss_cls: 0.3108, d2.loss_bbox: 0.6704, d3.loss_cls: 0.2824, d3.loss_bbox: 0.6217, d4.loss_cls: 0.2424, d4.loss_bbox: 0.6152, loss: 5.8291, grad_norm: 33.4617
2025-06-20 06:24:19,780 - mmdet - INFO - Epoch [2][1600/7033]	lr: 1.866e-04, eta: 12:36:56, time: 1.340, data_time: 0.021, memory: 18168, loss_cls: 0.2220, loss_bbox: 0.6010, d0.loss_cls: 0.3733, d0.loss_bbox: 0.8009, d1.loss_cls: 0.3371, d1.loss_bbox: 0.7659, d2.loss_cls: 0.3078, d2.loss_bbox: 0.6704, d3.loss_cls: 0.2745, d3.loss_bbox: 0.6076, d4.loss_cls: 0.2387, d4.loss_bbox: 0.6016, loss: 5.8010, grad_norm: 27.8744
2025-06-20 06:25:27,176 - mmdet - INFO - Epoch [2][1650/7033]	lr: 1.866e-04, eta: 12:35:48, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.2237, loss_bbox: 0.5879, d0.loss_cls: 0.3711, d0.loss_bbox: 0.7728, d1.loss_cls: 0.3426, d1.loss_bbox: 0.7373, d2.loss_cls: 0.3118, d2.loss_bbox: 0.6650, d3.loss_cls: 0.2690, d3.loss_bbox: 0.6096, d4.loss_cls: 0.2428, d4.loss_bbox: 0.5888, loss: 5.7224, grad_norm: 26.4143
2025-06-20 06:26:34,426 - mmdet - INFO - Epoch [2][1700/7033]	lr: 1.866e-04, eta: 12:34:38, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.2151, loss_bbox: 0.5988, d0.loss_cls: 0.3498, d0.loss_bbox: 0.8037, d1.loss_cls: 0.3215, d1.loss_bbox: 0.7453, d2.loss_cls: 0.3025, d2.loss_bbox: 0.6540, d3.loss_cls: 0.2623, d3.loss_bbox: 0.6189, d4.loss_cls: 0.2348, d4.loss_bbox: 0.6028, loss: 5.7095, grad_norm: 28.5273
2025-06-20 06:27:41,631 - mmdet - INFO - Epoch [2][1750/7033]	lr: 1.866e-04, eta: 12:33:29, time: 1.344, data_time: 0.021, memory: 18168, loss_cls: 0.2199, loss_bbox: 0.6166, d0.loss_cls: 0.3560, d0.loss_bbox: 0.8267, d1.loss_cls: 0.3302, d1.loss_bbox: 0.7804, d2.loss_cls: 0.3047, d2.loss_bbox: 0.6861, d3.loss_cls: 0.2638, d3.loss_bbox: 0.6371, d4.loss_cls: 0.2359, d4.loss_bbox: 0.6201, loss: 5.8776, grad_norm: 37.5807
2025-06-20 06:28:48,887 - mmdet - INFO - Epoch [2][1800/7033]	lr: 1.866e-04, eta: 12:32:20, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.2055, loss_bbox: 0.6031, d0.loss_cls: 0.3629, d0.loss_bbox: 0.8178, d1.loss_cls: 0.3310, d1.loss_bbox: 0.7847, d2.loss_cls: 0.2900, d2.loss_bbox: 0.6796, d3.loss_cls: 0.2522, d3.loss_bbox: 0.6221, d4.loss_cls: 0.2256, d4.loss_bbox: 0.6027, loss: 5.7771, grad_norm: 77.2948
2025-06-20 06:29:56,257 - mmdet - INFO - Epoch [2][1850/7033]	lr: 1.866e-04, eta: 12:31:11, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.2128, loss_bbox: 0.6407, d0.loss_cls: 0.3285, d0.loss_bbox: 0.8329, d1.loss_cls: 0.3045, d1.loss_bbox: 0.7892, d2.loss_cls: 0.2807, d2.loss_bbox: 0.7116, d3.loss_cls: 0.2496, d3.loss_bbox: 0.6588, d4.loss_cls: 0.2266, d4.loss_bbox: 0.6417, loss: 5.8776, grad_norm: 32.0326
2025-06-20 06:31:03,608 - mmdet - INFO - Epoch [2][1900/7033]	lr: 1.866e-04, eta: 12:30:03, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.2098, loss_bbox: 0.5702, d0.loss_cls: 0.3545, d0.loss_bbox: 0.7587, d1.loss_cls: 0.3166, d1.loss_bbox: 0.7064, d2.loss_cls: 0.2978, d2.loss_bbox: 0.6304, d3.loss_cls: 0.2591, d3.loss_bbox: 0.5854, d4.loss_cls: 0.2302, d4.loss_bbox: 0.5710, loss: 5.4899, grad_norm: 25.6436
2025-06-20 06:32:10,780 - mmdet - INFO - Epoch [2][1950/7033]	lr: 1.866e-04, eta: 12:28:53, time: 1.343, data_time: 0.021, memory: 18168, loss_cls: 0.2137, loss_bbox: 0.6108, d0.loss_cls: 0.3543, d0.loss_bbox: 0.7918, d1.loss_cls: 0.3271, d1.loss_bbox: 0.7422, d2.loss_cls: 0.3023, d2.loss_bbox: 0.6702, d3.loss_cls: 0.2599, d3.loss_bbox: 0.6187, d4.loss_cls: 0.2333, d4.loss_bbox: 0.6080, loss: 5.7322, grad_norm: 28.8665
2025-06-20 06:33:18,281 - mmdet - INFO - Epoch [2][2000/7033]	lr: 1.866e-04, eta: 12:27:45, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.2082, loss_bbox: 0.5671, d0.loss_cls: 0.3357, d0.loss_bbox: 0.7825, d1.loss_cls: 0.3101, d1.loss_bbox: 0.7296, d2.loss_cls: 0.2876, d2.loss_bbox: 0.6229, d3.loss_cls: 0.2538, d3.loss_bbox: 0.5761, d4.loss_cls: 0.2302, d4.loss_bbox: 0.5620, loss: 5.4658, grad_norm: 24.5616
2025-06-20 06:34:25,757 - mmdet - INFO - Epoch [2][2050/7033]	lr: 1.866e-04, eta: 12:26:37, time: 1.350, data_time: 0.021, memory: 18168, loss_cls: 0.2125, loss_bbox: 0.5815, d0.loss_cls: 0.3362, d0.loss_bbox: 0.7808, d1.loss_cls: 0.3133, d1.loss_bbox: 0.7158, d2.loss_cls: 0.2921, d2.loss_bbox: 0.6352, d3.loss_cls: 0.2649, d3.loss_bbox: 0.5951, d4.loss_cls: 0.2334, d4.loss_bbox: 0.5799, loss: 5.5406, grad_norm: 31.2361
2025-06-20 06:35:33,077 - mmdet - INFO - Epoch [2][2100/7033]	lr: 1.866e-04, eta: 12:25:28, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.2039, loss_bbox: 0.5799, d0.loss_cls: 0.3215, d0.loss_bbox: 0.7784, d1.loss_cls: 0.2962, d1.loss_bbox: 0.7104, d2.loss_cls: 0.2758, d2.loss_bbox: 0.6398, d3.loss_cls: 0.2496, d3.loss_bbox: 0.5955, d4.loss_cls: 0.2196, d4.loss_bbox: 0.5838, loss: 5.4543, grad_norm: 28.7588
2025-06-20 06:36:40,550 - mmdet - INFO - Epoch [2][2150/7033]	lr: 1.866e-04, eta: 12:24:20, time: 1.349, data_time: 0.022, memory: 18168, loss_cls: 0.2089, loss_bbox: 0.5892, d0.loss_cls: 0.3097, d0.loss_bbox: 0.7603, d1.loss_cls: 0.2873, d1.loss_bbox: 0.7256, d2.loss_cls: 0.2720, d2.loss_bbox: 0.6357, d3.loss_cls: 0.2465, d3.loss_bbox: 0.5989, d4.loss_cls: 0.2213, d4.loss_bbox: 0.5933, loss: 5.4488, grad_norm: 29.9877
2025-06-20 06:37:47,614 - mmdet - INFO - Epoch [2][2200/7033]	lr: 1.866e-04, eta: 12:23:10, time: 1.341, data_time: 0.020, memory: 18168, loss_cls: 0.2076, loss_bbox: 0.5743, d0.loss_cls: 0.3113, d0.loss_bbox: 0.7621, d1.loss_cls: 0.2817, d1.loss_bbox: 0.7173, d2.loss_cls: 0.2691, d2.loss_bbox: 0.6504, d3.loss_cls: 0.2490, d3.loss_bbox: 0.5915, d4.loss_cls: 0.2251, d4.loss_bbox: 0.5748, loss: 5.4141, grad_norm: 38.4923
2025-06-20 06:38:54,887 - mmdet - INFO - Epoch [2][2250/7033]	lr: 1.866e-04, eta: 12:22:01, time: 1.345, data_time: 0.023, memory: 18168, loss_cls: 0.1995, loss_bbox: 0.5968, d0.loss_cls: 0.3127, d0.loss_bbox: 0.7937, d1.loss_cls: 0.2919, d1.loss_bbox: 0.7620, d2.loss_cls: 0.2702, d2.loss_bbox: 0.6702, d3.loss_cls: 0.2396, d3.loss_bbox: 0.6256, d4.loss_cls: 0.2127, d4.loss_bbox: 0.6003, loss: 5.5753, grad_norm: 29.2006
2025-06-20 06:40:02,082 - mmdet - INFO - Epoch [2][2300/7033]	lr: 1.866e-04, eta: 12:20:52, time: 1.344, data_time: 0.021, memory: 18168, loss_cls: 0.2111, loss_bbox: 0.6158, d0.loss_cls: 0.3106, d0.loss_bbox: 0.7894, d1.loss_cls: 0.2961, d1.loss_bbox: 0.7410, d2.loss_cls: 0.2774, d2.loss_bbox: 0.6811, d3.loss_cls: 0.2508, d3.loss_bbox: 0.6301, d4.loss_cls: 0.2269, d4.loss_bbox: 0.6173, loss: 5.6476, grad_norm: 32.6452
2025-06-20 06:41:09,293 - mmdet - INFO - Epoch [2][2350/7033]	lr: 1.866e-04, eta: 12:19:43, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.2134, loss_bbox: 0.5744, d0.loss_cls: 0.3139, d0.loss_bbox: 0.7653, d1.loss_cls: 0.2995, d1.loss_bbox: 0.7148, d2.loss_cls: 0.2807, d2.loss_bbox: 0.6386, d3.loss_cls: 0.2632, d3.loss_bbox: 0.5869, d4.loss_cls: 0.2350, d4.loss_bbox: 0.5723, loss: 5.4580, grad_norm: 32.5334
2025-06-20 06:42:16,628 - mmdet - INFO - Epoch [2][2400/7033]	lr: 1.866e-04, eta: 12:18:34, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.2073, loss_bbox: 0.5929, d0.loss_cls: 0.3158, d0.loss_bbox: 0.7957, d1.loss_cls: 0.2978, d1.loss_bbox: 0.7388, d2.loss_cls: 0.2723, d2.loss_bbox: 0.6496, d3.loss_cls: 0.2516, d3.loss_bbox: 0.6003, d4.loss_cls: 0.2251, d4.loss_bbox: 0.5911, loss: 5.5384, grad_norm: 33.1503
2025-06-20 06:43:24,053 - mmdet - INFO - Epoch [2][2450/7033]	lr: 1.866e-04, eta: 12:17:26, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.2053, loss_bbox: 0.5786, d0.loss_cls: 0.3144, d0.loss_bbox: 0.7672, d1.loss_cls: 0.3014, d1.loss_bbox: 0.7109, d2.loss_cls: 0.2764, d2.loss_bbox: 0.6384, d3.loss_cls: 0.2494, d3.loss_bbox: 0.5970, d4.loss_cls: 0.2197, d4.loss_bbox: 0.5853, loss: 5.4440, grad_norm: 31.8600
2025-06-20 06:44:32,390 - mmdet - INFO - Epoch [2][2500/7033]	lr: 1.866e-04, eta: 12:16:21, time: 1.367, data_time: 0.043, memory: 18168, loss_cls: 0.2041, loss_bbox: 0.5680, d0.loss_cls: 0.3084, d0.loss_bbox: 0.7506, d1.loss_cls: 0.2894, d1.loss_bbox: 0.7086, d2.loss_cls: 0.2646, d2.loss_bbox: 0.6326, d3.loss_cls: 0.2394, d3.loss_bbox: 0.5899, d4.loss_cls: 0.2222, d4.loss_bbox: 0.5699, loss: 5.3475, grad_norm: 23.0449
2025-06-20 06:45:41,564 - mmdet - INFO - Epoch [2][2550/7033]	lr: 1.866e-04, eta: 12:15:18, time: 1.383, data_time: 0.023, memory: 18168, loss_cls: 0.2057, loss_bbox: 0.5941, d0.loss_cls: 0.3127, d0.loss_bbox: 0.8044, d1.loss_cls: 0.2971, d1.loss_bbox: 0.7508, d2.loss_cls: 0.2774, d2.loss_bbox: 0.6626, d3.loss_cls: 0.2482, d3.loss_bbox: 0.6229, d4.loss_cls: 0.2272, d4.loss_bbox: 0.5933, loss: 5.5963, grad_norm: 29.3079
2025-06-20 06:46:48,865 - mmdet - INFO - Epoch [2][2600/7033]	lr: 1.866e-04, eta: 12:14:10, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.2101, loss_bbox: 0.5880, d0.loss_cls: 0.3302, d0.loss_bbox: 0.7958, d1.loss_cls: 0.3071, d1.loss_bbox: 0.7513, d2.loss_cls: 0.2933, d2.loss_bbox: 0.6571, d3.loss_cls: 0.2658, d3.loss_bbox: 0.6039, d4.loss_cls: 0.2311, d4.loss_bbox: 0.5911, loss: 5.6249, grad_norm: 32.1298
2025-06-20 06:47:56,206 - mmdet - INFO - Epoch [2][2650/7033]	lr: 1.866e-04, eta: 12:13:01, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.2108, loss_bbox: 0.5533, d0.loss_cls: 0.3114, d0.loss_bbox: 0.7599, d1.loss_cls: 0.2889, d1.loss_bbox: 0.7182, d2.loss_cls: 0.2761, d2.loss_bbox: 0.6329, d3.loss_cls: 0.2537, d3.loss_bbox: 0.5753, d4.loss_cls: 0.2285, d4.loss_bbox: 0.5576, loss: 5.3666, grad_norm: 26.1570
2025-06-20 06:49:03,484 - mmdet - INFO - Epoch [2][2700/7033]	lr: 1.866e-04, eta: 12:11:52, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.2022, loss_bbox: 0.6065, d0.loss_cls: 0.3040, d0.loss_bbox: 0.7538, d1.loss_cls: 0.2785, d1.loss_bbox: 0.7158, d2.loss_cls: 0.2660, d2.loss_bbox: 0.6582, d3.loss_cls: 0.2420, d3.loss_bbox: 0.6206, d4.loss_cls: 0.2180, d4.loss_bbox: 0.6085, loss: 5.4741, grad_norm: 34.0651
2025-06-20 06:50:10,854 - mmdet - INFO - Epoch [2][2750/7033]	lr: 1.866e-04, eta: 12:10:44, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.2068, loss_bbox: 0.5721, d0.loss_cls: 0.3034, d0.loss_bbox: 0.7629, d1.loss_cls: 0.2787, d1.loss_bbox: 0.7266, d2.loss_cls: 0.2623, d2.loss_bbox: 0.6375, d3.loss_cls: 0.2480, d3.loss_bbox: 0.5876, d4.loss_cls: 0.2232, d4.loss_bbox: 0.5691, loss: 5.3783, grad_norm: 25.7393
2025-06-20 06:51:18,238 - mmdet - INFO - Epoch [2][2800/7033]	lr: 1.866e-04, eta: 12:09:35, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1909, loss_bbox: 0.5847, d0.loss_cls: 0.2918, d0.loss_bbox: 0.7693, d1.loss_cls: 0.2680, d1.loss_bbox: 0.7343, d2.loss_cls: 0.2502, d2.loss_bbox: 0.6492, d3.loss_cls: 0.2334, d3.loss_bbox: 0.6018, d4.loss_cls: 0.2104, d4.loss_bbox: 0.5816, loss: 5.3657, grad_norm: 27.8907
2025-06-20 06:52:25,853 - mmdet - INFO - Epoch [2][2850/7033]	lr: 1.866e-04, eta: 12:08:28, time: 1.352, data_time: 0.021, memory: 18168, loss_cls: 0.2029, loss_bbox: 0.5913, d0.loss_cls: 0.2937, d0.loss_bbox: 0.7805, d1.loss_cls: 0.2709, d1.loss_bbox: 0.7465, d2.loss_cls: 0.2560, d2.loss_bbox: 0.6749, d3.loss_cls: 0.2397, d3.loss_bbox: 0.6132, d4.loss_cls: 0.2162, d4.loss_bbox: 0.5927, loss: 5.4784, grad_norm: 37.5742
2025-06-20 06:53:33,115 - mmdet - INFO - Epoch [2][2900/7033]	lr: 1.866e-04, eta: 12:07:19, time: 1.345, data_time: 0.023, memory: 18168, loss_cls: 0.2022, loss_bbox: 0.5703, d0.loss_cls: 0.3064, d0.loss_bbox: 0.7479, d1.loss_cls: 0.2833, d1.loss_bbox: 0.7149, d2.loss_cls: 0.2661, d2.loss_bbox: 0.6363, d3.loss_cls: 0.2428, d3.loss_bbox: 0.5899, d4.loss_cls: 0.2168, d4.loss_bbox: 0.5714, loss: 5.3485, grad_norm: 29.9506
2025-06-20 06:54:40,476 - mmdet - INFO - Epoch [2][2950/7033]	lr: 1.866e-04, eta: 12:06:10, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1976, loss_bbox: 0.5620, d0.loss_cls: 0.2806, d0.loss_bbox: 0.7452, d1.loss_cls: 0.2667, d1.loss_bbox: 0.7086, d2.loss_cls: 0.2500, d2.loss_bbox: 0.6274, d3.loss_cls: 0.2301, d3.loss_bbox: 0.5871, d4.loss_cls: 0.2091, d4.loss_bbox: 0.5674, loss: 5.2320, grad_norm: 28.5388
2025-06-20 06:55:47,692 - mmdet - INFO - Epoch [2][3000/7033]	lr: 1.866e-04, eta: 12:05:01, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.1855, loss_bbox: 0.5554, d0.loss_cls: 0.2906, d0.loss_bbox: 0.7424, d1.loss_cls: 0.2653, d1.loss_bbox: 0.7037, d2.loss_cls: 0.2441, d2.loss_bbox: 0.6141, d3.loss_cls: 0.2203, d3.loss_bbox: 0.5714, d4.loss_cls: 0.2019, d4.loss_bbox: 0.5549, loss: 5.1496, grad_norm: 29.4796
2025-06-20 06:56:55,162 - mmdet - INFO - Epoch [2][3050/7033]	lr: 1.866e-04, eta: 12:03:53, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.2055, loss_bbox: 0.5827, d0.loss_cls: 0.2949, d0.loss_bbox: 0.7713, d1.loss_cls: 0.2761, d1.loss_bbox: 0.7396, d2.loss_cls: 0.2656, d2.loss_bbox: 0.6503, d3.loss_cls: 0.2448, d3.loss_bbox: 0.5988, d4.loss_cls: 0.2219, d4.loss_bbox: 0.5806, loss: 5.4322, grad_norm: 35.4548
2025-06-20 06:58:02,824 - mmdet - INFO - Epoch [2][3100/7033]	lr: 1.866e-04, eta: 12:02:46, time: 1.353, data_time: 0.024, memory: 18168, loss_cls: 0.2123, loss_bbox: 0.5663, d0.loss_cls: 0.2989, d0.loss_bbox: 0.7647, d1.loss_cls: 0.2721, d1.loss_bbox: 0.7262, d2.loss_cls: 0.2626, d2.loss_bbox: 0.6373, d3.loss_cls: 0.2447, d3.loss_bbox: 0.5908, d4.loss_cls: 0.2279, d4.loss_bbox: 0.5668, loss: 5.3708, grad_norm: 39.4494
2025-06-20 06:59:10,045 - mmdet - INFO - Epoch [2][3150/7033]	lr: 1.866e-04, eta: 12:01:37, time: 1.344, data_time: 0.021, memory: 18168, loss_cls: 0.2100, loss_bbox: 0.6000, d0.loss_cls: 0.2906, d0.loss_bbox: 0.7743, d1.loss_cls: 0.2729, d1.loss_bbox: 0.7330, d2.loss_cls: 0.2594, d2.loss_bbox: 0.6583, d3.loss_cls: 0.2448, d3.loss_bbox: 0.6215, d4.loss_cls: 0.2244, d4.loss_bbox: 0.5995, loss: 5.4886, grad_norm: 28.3941
2025-06-20 07:00:19,120 - mmdet - INFO - Epoch [2][3200/7033]	lr: 1.866e-04, eta: 12:00:34, time: 1.381, data_time: 0.022, memory: 18168, loss_cls: 0.2106, loss_bbox: 0.5880, d0.loss_cls: 0.3096, d0.loss_bbox: 0.7814, d1.loss_cls: 0.2825, d1.loss_bbox: 0.7496, d2.loss_cls: 0.2700, d2.loss_bbox: 0.6624, d3.loss_cls: 0.2532, d3.loss_bbox: 0.6069, d4.loss_cls: 0.2220, d4.loss_bbox: 0.5916, loss: 5.5278, grad_norm: 36.7578
2025-06-20 07:01:26,277 - mmdet - INFO - Epoch [2][3250/7033]	lr: 1.866e-04, eta: 11:59:25, time: 1.343, data_time: 0.022, memory: 18168, loss_cls: 0.2035, loss_bbox: 0.5949, d0.loss_cls: 0.3058, d0.loss_bbox: 0.7620, d1.loss_cls: 0.2786, d1.loss_bbox: 0.7229, d2.loss_cls: 0.2626, d2.loss_bbox: 0.6616, d3.loss_cls: 0.2415, d3.loss_bbox: 0.6096, d4.loss_cls: 0.2187, d4.loss_bbox: 0.5939, loss: 5.4557, grad_norm: 32.3621
2025-06-20 07:02:33,774 - mmdet - INFO - Epoch [2][3300/7033]	lr: 1.866e-04, eta: 11:58:17, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1929, loss_bbox: 0.5572, d0.loss_cls: 0.2678, d0.loss_bbox: 0.7185, d1.loss_cls: 0.2481, d1.loss_bbox: 0.6796, d2.loss_cls: 0.2434, d2.loss_bbox: 0.6140, d3.loss_cls: 0.2260, d3.loss_bbox: 0.5695, d4.loss_cls: 0.2077, d4.loss_bbox: 0.5527, loss: 5.0776, grad_norm: 33.1391
2025-06-20 07:03:41,119 - mmdet - INFO - Epoch [2][3350/7033]	lr: 1.866e-04, eta: 11:57:08, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.2021, loss_bbox: 0.5717, d0.loss_cls: 0.2857, d0.loss_bbox: 0.7444, d1.loss_cls: 0.2673, d1.loss_bbox: 0.7118, d2.loss_cls: 0.2510, d2.loss_bbox: 0.6343, d3.loss_cls: 0.2355, d3.loss_bbox: 0.5903, d4.loss_cls: 0.2207, d4.loss_bbox: 0.5711, loss: 5.2857, grad_norm: 32.9587
2025-06-20 07:04:48,486 - mmdet - INFO - Epoch [2][3400/7033]	lr: 1.866e-04, eta: 11:56:00, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.2084, loss_bbox: 0.5873, d0.loss_cls: 0.2925, d0.loss_bbox: 0.7708, d1.loss_cls: 0.2842, d1.loss_bbox: 0.7280, d2.loss_cls: 0.2644, d2.loss_bbox: 0.6515, d3.loss_cls: 0.2453, d3.loss_bbox: 0.6069, d4.loss_cls: 0.2253, d4.loss_bbox: 0.5868, loss: 5.4514, grad_norm: 33.7222
2025-06-20 07:05:55,626 - mmdet - INFO - Epoch [2][3450/7033]	lr: 1.866e-04, eta: 11:54:51, time: 1.343, data_time: 0.021, memory: 18168, loss_cls: 0.2055, loss_bbox: 0.5571, d0.loss_cls: 0.3004, d0.loss_bbox: 0.7456, d1.loss_cls: 0.2894, d1.loss_bbox: 0.7012, d2.loss_cls: 0.2738, d2.loss_bbox: 0.6234, d3.loss_cls: 0.2505, d3.loss_bbox: 0.5778, d4.loss_cls: 0.2212, d4.loss_bbox: 0.5591, loss: 5.3050, grad_norm: 32.0654
2025-06-20 07:07:02,964 - mmdet - INFO - Epoch [2][3500/7033]	lr: 1.866e-04, eta: 11:53:42, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.1963, loss_bbox: 0.5819, d0.loss_cls: 0.2772, d0.loss_bbox: 0.7147, d1.loss_cls: 0.2572, d1.loss_bbox: 0.6775, d2.loss_cls: 0.2473, d2.loss_bbox: 0.6135, d3.loss_cls: 0.2232, d3.loss_bbox: 0.5918, d4.loss_cls: 0.2093, d4.loss_bbox: 0.5770, loss: 5.1670, grad_norm: 30.1042
2025-06-20 07:08:10,558 - mmdet - INFO - Epoch [2][3550/7033]	lr: 1.866e-04, eta: 11:52:35, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1931, loss_bbox: 0.5735, d0.loss_cls: 0.2831, d0.loss_bbox: 0.7394, d1.loss_cls: 0.2612, d1.loss_bbox: 0.7023, d2.loss_cls: 0.2500, d2.loss_bbox: 0.6313, d3.loss_cls: 0.2284, d3.loss_bbox: 0.5958, d4.loss_cls: 0.2092, d4.loss_bbox: 0.5778, loss: 5.2451, grad_norm: 29.3183
2025-06-20 07:09:18,120 - mmdet - INFO - Epoch [2][3600/7033]	lr: 1.866e-04, eta: 11:51:27, time: 1.351, data_time: 0.024, memory: 18168, loss_cls: 0.1941, loss_bbox: 0.5951, d0.loss_cls: 0.2839, d0.loss_bbox: 0.7570, d1.loss_cls: 0.2667, d1.loss_bbox: 0.7200, d2.loss_cls: 0.2611, d2.loss_bbox: 0.6451, d3.loss_cls: 0.2357, d3.loss_bbox: 0.6052, d4.loss_cls: 0.2113, d4.loss_bbox: 0.5917, loss: 5.3669, grad_norm: 31.0517
2025-06-20 07:10:25,693 - mmdet - INFO - Epoch [2][3650/7033]	lr: 1.866e-04, eta: 11:50:19, time: 1.351, data_time: 0.022, memory: 18168, loss_cls: 0.1953, loss_bbox: 0.5753, d0.loss_cls: 0.2878, d0.loss_bbox: 0.7319, d1.loss_cls: 0.2609, d1.loss_bbox: 0.7054, d2.loss_cls: 0.2565, d2.loss_bbox: 0.6283, d3.loss_cls: 0.2328, d3.loss_bbox: 0.5879, d4.loss_cls: 0.2089, d4.loss_bbox: 0.5761, loss: 5.2470, grad_norm: 26.0023
2025-06-20 07:11:33,162 - mmdet - INFO - Epoch [2][3700/7033]	lr: 1.866e-04, eta: 11:49:11, time: 1.349, data_time: 0.024, memory: 18168, loss_cls: 0.2033, loss_bbox: 0.5853, d0.loss_cls: 0.2804, d0.loss_bbox: 0.7469, d1.loss_cls: 0.2607, d1.loss_bbox: 0.7178, d2.loss_cls: 0.2537, d2.loss_bbox: 0.6375, d3.loss_cls: 0.2333, d3.loss_bbox: 0.6008, d4.loss_cls: 0.2152, d4.loss_bbox: 0.5872, loss: 5.3221, grad_norm: 50.3113
2025-06-20 07:12:40,599 - mmdet - INFO - Epoch [2][3750/7033]	lr: 1.866e-04, eta: 11:48:03, time: 1.349, data_time: 0.024, memory: 18168, loss_cls: 0.1931, loss_bbox: 0.5803, d0.loss_cls: 0.2707, d0.loss_bbox: 0.7557, d1.loss_cls: 0.2477, d1.loss_bbox: 0.7305, d2.loss_cls: 0.2397, d2.loss_bbox: 0.6449, d3.loss_cls: 0.2243, d3.loss_bbox: 0.5927, d4.loss_cls: 0.2074, d4.loss_bbox: 0.5808, loss: 5.2677, grad_norm: 89.6270
2025-06-20 07:13:48,066 - mmdet - INFO - Epoch [2][3800/7033]	lr: 1.866e-04, eta: 11:46:55, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1899, loss_bbox: 0.5677, d0.loss_cls: 0.2839, d0.loss_bbox: 0.7264, d1.loss_cls: 0.2637, d1.loss_bbox: 0.6894, d2.loss_cls: 0.2472, d2.loss_bbox: 0.6208, d3.loss_cls: 0.2241, d3.loss_bbox: 0.5829, d4.loss_cls: 0.2016, d4.loss_bbox: 0.5672, loss: 5.1649, grad_norm: 55.3637
2025-06-20 07:14:55,743 - mmdet - INFO - Epoch [2][3850/7033]	lr: 1.866e-04, eta: 11:45:47, time: 1.354, data_time: 0.022, memory: 18168, loss_cls: 0.1908, loss_bbox: 0.5820, d0.loss_cls: 0.2792, d0.loss_bbox: 0.7406, d1.loss_cls: 0.2532, d1.loss_bbox: 0.7153, d2.loss_cls: 0.2393, d2.loss_bbox: 0.6483, d3.loss_cls: 0.2204, d3.loss_bbox: 0.6034, d4.loss_cls: 0.2004, d4.loss_bbox: 0.5854, loss: 5.2583, grad_norm: 32.1707
2025-06-20 07:16:03,291 - mmdet - INFO - Epoch [2][3900/7033]	lr: 1.866e-04, eta: 11:44:40, time: 1.351, data_time: 0.021, memory: 18168, loss_cls: 0.1906, loss_bbox: 0.5868, d0.loss_cls: 0.2708, d0.loss_bbox: 0.7233, d1.loss_cls: 0.2456, d1.loss_bbox: 0.6953, d2.loss_cls: 0.2473, d2.loss_bbox: 0.6337, d3.loss_cls: 0.2302, d3.loss_bbox: 0.5951, d4.loss_cls: 0.2044, d4.loss_bbox: 0.5835, loss: 5.2065, grad_norm: 60.3992
2025-06-20 07:17:10,445 - mmdet - INFO - Epoch [2][3950/7033]	lr: 1.866e-04, eta: 11:43:31, time: 1.343, data_time: 0.022, memory: 18168, loss_cls: 0.1957, loss_bbox: 0.5359, d0.loss_cls: 0.2752, d0.loss_bbox: 0.7274, d1.loss_cls: 0.2539, d1.loss_bbox: 0.6960, d2.loss_cls: 0.2505, d2.loss_bbox: 0.6108, d3.loss_cls: 0.2332, d3.loss_bbox: 0.5564, d4.loss_cls: 0.2111, d4.loss_bbox: 0.5384, loss: 5.0844, grad_norm: 30.6637
2025-06-20 07:18:17,855 - mmdet - INFO - Epoch [2][4000/7033]	lr: 1.866e-04, eta: 11:42:22, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.1979, loss_bbox: 0.5730, d0.loss_cls: 0.2870, d0.loss_bbox: 0.7664, d1.loss_cls: 0.2680, d1.loss_bbox: 0.7308, d2.loss_cls: 0.2566, d2.loss_bbox: 0.6390, d3.loss_cls: 0.2412, d3.loss_bbox: 0.5841, d4.loss_cls: 0.2125, d4.loss_bbox: 0.5742, loss: 5.3306, grad_norm: 31.8268
2025-06-20 07:19:25,341 - mmdet - INFO - Epoch [2][4050/7033]	lr: 1.866e-04, eta: 11:41:14, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1972, loss_bbox: 0.5599, d0.loss_cls: 0.2688, d0.loss_bbox: 0.7228, d1.loss_cls: 0.2438, d1.loss_bbox: 0.6833, d2.loss_cls: 0.2369, d2.loss_bbox: 0.6152, d3.loss_cls: 0.2228, d3.loss_bbox: 0.5747, d4.loss_cls: 0.2074, d4.loss_bbox: 0.5605, loss: 5.0933, grad_norm: 41.8080
2025-06-20 07:20:32,704 - mmdet - INFO - Epoch [2][4100/7033]	lr: 1.866e-04, eta: 11:40:06, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1884, loss_bbox: 0.5601, d0.loss_cls: 0.2531, d0.loss_bbox: 0.7078, d1.loss_cls: 0.2358, d1.loss_bbox: 0.6666, d2.loss_cls: 0.2321, d2.loss_bbox: 0.6052, d3.loss_cls: 0.2148, d3.loss_bbox: 0.5708, d4.loss_cls: 0.2002, d4.loss_bbox: 0.5582, loss: 4.9930, grad_norm: 29.4960
2025-06-20 07:21:40,220 - mmdet - INFO - Epoch [2][4150/7033]	lr: 1.866e-04, eta: 11:38:58, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1967, loss_bbox: 0.5607, d0.loss_cls: 0.2776, d0.loss_bbox: 0.7266, d1.loss_cls: 0.2554, d1.loss_bbox: 0.6987, d2.loss_cls: 0.2447, d2.loss_bbox: 0.6264, d3.loss_cls: 0.2249, d3.loss_bbox: 0.5770, d4.loss_cls: 0.2072, d4.loss_bbox: 0.5620, loss: 5.1579, grad_norm: 43.4771
2025-06-20 07:22:47,841 - mmdet - INFO - Epoch [2][4200/7033]	lr: 1.866e-04, eta: 11:37:51, time: 1.352, data_time: 0.023, memory: 18168, loss_cls: 0.2002, loss_bbox: 0.5921, d0.loss_cls: 0.2760, d0.loss_bbox: 0.7440, d1.loss_cls: 0.2512, d1.loss_bbox: 0.7097, d2.loss_cls: 0.2487, d2.loss_bbox: 0.6443, d3.loss_cls: 0.2285, d3.loss_bbox: 0.6072, d4.loss_cls: 0.2122, d4.loss_bbox: 0.5935, loss: 5.3076, grad_norm: 28.3997
2025-06-20 07:23:55,033 - mmdet - INFO - Epoch [2][4250/7033]	lr: 1.866e-04, eta: 11:36:42, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.2057, loss_bbox: 0.5821, d0.loss_cls: 0.2686, d0.loss_bbox: 0.7306, d1.loss_cls: 0.2500, d1.loss_bbox: 0.7000, d2.loss_cls: 0.2439, d2.loss_bbox: 0.6412, d3.loss_cls: 0.2356, d3.loss_bbox: 0.5987, d4.loss_cls: 0.2156, d4.loss_bbox: 0.5814, loss: 5.2535, grad_norm: 31.2352
2025-06-20 07:25:03,591 - mmdet - INFO - Epoch [2][4300/7033]	lr: 1.866e-04, eta: 11:35:37, time: 1.371, data_time: 0.021, memory: 18168, loss_cls: 0.1862, loss_bbox: 0.5791, d0.loss_cls: 0.2707, d0.loss_bbox: 0.7154, d1.loss_cls: 0.2503, d1.loss_bbox: 0.6814, d2.loss_cls: 0.2421, d2.loss_bbox: 0.6263, d3.loss_cls: 0.2204, d3.loss_bbox: 0.5915, d4.loss_cls: 0.1985, d4.loss_bbox: 0.5778, loss: 5.1397, grad_norm: 33.8446
2025-06-20 07:26:11,318 - mmdet - INFO - Epoch [2][4350/7033]	lr: 1.866e-04, eta: 11:34:30, time: 1.355, data_time: 0.024, memory: 18168, loss_cls: 0.1910, loss_bbox: 0.5424, d0.loss_cls: 0.2761, d0.loss_bbox: 0.7184, d1.loss_cls: 0.2483, d1.loss_bbox: 0.6828, d2.loss_cls: 0.2433, d2.loss_bbox: 0.6103, d3.loss_cls: 0.2162, d3.loss_bbox: 0.5668, d4.loss_cls: 0.2027, d4.loss_bbox: 0.5463, loss: 5.0444, grad_norm: 35.0552
2025-06-20 07:27:19,015 - mmdet - INFO - Epoch [2][4400/7033]	lr: 1.866e-04, eta: 11:33:22, time: 1.354, data_time: 0.024, memory: 18168, loss_cls: 0.1833, loss_bbox: 0.5431, d0.loss_cls: 0.2387, d0.loss_bbox: 0.6967, d1.loss_cls: 0.2181, d1.loss_bbox: 0.6632, d2.loss_cls: 0.2184, d2.loss_bbox: 0.6047, d3.loss_cls: 0.2041, d3.loss_bbox: 0.5647, d4.loss_cls: 0.1915, d4.loss_bbox: 0.5484, loss: 4.8748, grad_norm: 29.7523
2025-06-20 07:28:26,365 - mmdet - INFO - Epoch [2][4450/7033]	lr: 1.866e-04, eta: 11:32:14, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.1889, loss_bbox: 0.5519, d0.loss_cls: 0.2665, d0.loss_bbox: 0.7011, d1.loss_cls: 0.2387, d1.loss_bbox: 0.6756, d2.loss_cls: 0.2312, d2.loss_bbox: 0.6055, d3.loss_cls: 0.2143, d3.loss_bbox: 0.5668, d4.loss_cls: 0.1974, d4.loss_bbox: 0.5545, loss: 4.9925, grad_norm: 38.3951
2025-06-20 07:29:40,408 - mmdet - INFO - Epoch [2][4500/7033]	lr: 1.866e-04, eta: 11:31:23, time: 1.481, data_time: 0.022, memory: 18168, loss_cls: 0.1855, loss_bbox: 0.5769, d0.loss_cls: 0.2667, d0.loss_bbox: 0.7170, d1.loss_cls: 0.2406, d1.loss_bbox: 0.6929, d2.loss_cls: 0.2329, d2.loss_bbox: 0.6218, d3.loss_cls: 0.2141, d3.loss_bbox: 0.5892, d4.loss_cls: 0.1979, d4.loss_bbox: 0.5788, loss: 5.1143, grad_norm: 30.4420
2025-06-20 07:30:47,764 - mmdet - INFO - Epoch [2][4550/7033]	lr: 1.866e-04, eta: 11:30:15, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.1866, loss_bbox: 0.5648, d0.loss_cls: 0.2568, d0.loss_bbox: 0.7181, d1.loss_cls: 0.2361, d1.loss_bbox: 0.6875, d2.loss_cls: 0.2289, d2.loss_bbox: 0.6231, d3.loss_cls: 0.2105, d3.loss_bbox: 0.5841, d4.loss_cls: 0.1948, d4.loss_bbox: 0.5646, loss: 5.0558, grad_norm: 39.7891
2025-06-20 07:31:55,054 - mmdet - INFO - Epoch [2][4600/7033]	lr: 1.866e-04, eta: 11:29:06, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1829, loss_bbox: 0.5718, d0.loss_cls: 0.2601, d0.loss_bbox: 0.7173, d1.loss_cls: 0.2376, d1.loss_bbox: 0.6821, d2.loss_cls: 0.2252, d2.loss_bbox: 0.6226, d3.loss_cls: 0.2156, d3.loss_bbox: 0.5821, d4.loss_cls: 0.2009, d4.loss_bbox: 0.5652, loss: 5.0634, grad_norm: 29.7642
2025-06-20 07:33:02,082 - mmdet - INFO - Epoch [2][4650/7033]	lr: 1.866e-04, eta: 11:27:57, time: 1.341, data_time: 0.021, memory: 18168, loss_cls: 0.1792, loss_bbox: 0.5475, d0.loss_cls: 0.2476, d0.loss_bbox: 0.6859, d1.loss_cls: 0.2247, d1.loss_bbox: 0.6548, d2.loss_cls: 0.2194, d2.loss_bbox: 0.5982, d3.loss_cls: 0.2022, d3.loss_bbox: 0.5591, d4.loss_cls: 0.1893, d4.loss_bbox: 0.5474, loss: 4.8553, grad_norm: 32.8669
2025-06-20 07:34:09,377 - mmdet - INFO - Epoch [2][4700/7033]	lr: 1.866e-04, eta: 11:26:49, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1911, loss_bbox: 0.5644, d0.loss_cls: 0.2613, d0.loss_bbox: 0.7219, d1.loss_cls: 0.2409, d1.loss_bbox: 0.6898, d2.loss_cls: 0.2458, d2.loss_bbox: 0.6226, d3.loss_cls: 0.2256, d3.loss_bbox: 0.5753, d4.loss_cls: 0.2039, d4.loss_bbox: 0.5639, loss: 5.1066, grad_norm: 31.5208
2025-06-20 07:35:16,825 - mmdet - INFO - Epoch [2][4750/7033]	lr: 1.866e-04, eta: 11:25:41, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1734, loss_bbox: 0.5562, d0.loss_cls: 0.2420, d0.loss_bbox: 0.7211, d1.loss_cls: 0.2215, d1.loss_bbox: 0.6859, d2.loss_cls: 0.2186, d2.loss_bbox: 0.6137, d3.loss_cls: 0.1954, d3.loss_bbox: 0.5742, d4.loss_cls: 0.1817, d4.loss_bbox: 0.5561, loss: 4.9399, grad_norm: 27.4253
2025-06-20 07:36:24,203 - mmdet - INFO - Epoch [2][4800/7033]	lr: 1.866e-04, eta: 11:24:32, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1786, loss_bbox: 0.5369, d0.loss_cls: 0.2572, d0.loss_bbox: 0.6871, d1.loss_cls: 0.2319, d1.loss_bbox: 0.6673, d2.loss_cls: 0.2255, d2.loss_bbox: 0.5955, d3.loss_cls: 0.2069, d3.loss_bbox: 0.5524, d4.loss_cls: 0.1910, d4.loss_bbox: 0.5359, loss: 4.8662, grad_norm: 36.3179
2025-06-20 07:37:31,525 - mmdet - INFO - Epoch [2][4850/7033]	lr: 1.866e-04, eta: 11:23:24, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1683, loss_bbox: 0.5244, d0.loss_cls: 0.2517, d0.loss_bbox: 0.6666, d1.loss_cls: 0.2214, d1.loss_bbox: 0.6263, d2.loss_cls: 0.2096, d2.loss_bbox: 0.5785, d3.loss_cls: 0.1938, d3.loss_bbox: 0.5416, d4.loss_cls: 0.1791, d4.loss_bbox: 0.5281, loss: 4.6894, grad_norm: 28.3853
2025-06-20 07:38:40,706 - mmdet - INFO - Epoch [2][4900/7033]	lr: 1.866e-04, eta: 11:22:20, time: 1.384, data_time: 0.022, memory: 18168, loss_cls: 0.1900, loss_bbox: 0.5365, d0.loss_cls: 0.2600, d0.loss_bbox: 0.6824, d1.loss_cls: 0.2362, d1.loss_bbox: 0.6574, d2.loss_cls: 0.2295, d2.loss_bbox: 0.5953, d3.loss_cls: 0.2160, d3.loss_bbox: 0.5537, d4.loss_cls: 0.2013, d4.loss_bbox: 0.5395, loss: 4.8979, grad_norm: 41.8697
2025-06-20 07:39:48,275 - mmdet - INFO - Epoch [2][4950/7033]	lr: 1.866e-04, eta: 11:21:12, time: 1.351, data_time: 0.023, memory: 18168, loss_cls: 0.1934, loss_bbox: 0.5518, d0.loss_cls: 0.2631, d0.loss_bbox: 0.6897, d1.loss_cls: 0.2357, d1.loss_bbox: 0.6680, d2.loss_cls: 0.2310, d2.loss_bbox: 0.6045, d3.loss_cls: 0.2154, d3.loss_bbox: 0.5699, d4.loss_cls: 0.2044, d4.loss_bbox: 0.5501, loss: 4.9770, grad_norm: 28.4157
2025-06-20 07:40:55,579 - mmdet - INFO - Epoch [2][5000/7033]	lr: 1.866e-04, eta: 11:20:04, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1898, loss_bbox: 0.5717, d0.loss_cls: 0.2523, d0.loss_bbox: 0.7371, d1.loss_cls: 0.2359, d1.loss_bbox: 0.7023, d2.loss_cls: 0.2250, d2.loss_bbox: 0.6310, d3.loss_cls: 0.2145, d3.loss_bbox: 0.5936, d4.loss_cls: 0.1974, d4.loss_bbox: 0.5767, loss: 5.1273, grad_norm: 42.0035
2025-06-20 07:42:02,987 - mmdet - INFO - Epoch [2][5050/7033]	lr: 1.866e-04, eta: 11:18:56, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1883, loss_bbox: 0.5403, d0.loss_cls: 0.2481, d0.loss_bbox: 0.7012, d1.loss_cls: 0.2251, d1.loss_bbox: 0.6561, d2.loss_cls: 0.2236, d2.loss_bbox: 0.5996, d3.loss_cls: 0.2099, d3.loss_bbox: 0.5615, d4.loss_cls: 0.1939, d4.loss_bbox: 0.5434, loss: 4.8909, grad_norm: 28.8457
2025-06-20 07:43:10,418 - mmdet - INFO - Epoch [2][5100/7033]	lr: 1.866e-04, eta: 11:17:48, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1796, loss_bbox: 0.5453, d0.loss_cls: 0.2496, d0.loss_bbox: 0.6981, d1.loss_cls: 0.2236, d1.loss_bbox: 0.6565, d2.loss_cls: 0.2207, d2.loss_bbox: 0.6000, d3.loss_cls: 0.1983, d3.loss_bbox: 0.5643, d4.loss_cls: 0.1886, d4.loss_bbox: 0.5487, loss: 4.8733, grad_norm: 33.7808
2025-06-20 07:44:17,622 - mmdet - INFO - Epoch [2][5150/7033]	lr: 1.866e-04, eta: 11:16:39, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.1881, loss_bbox: 0.5644, d0.loss_cls: 0.2508, d0.loss_bbox: 0.7013, d1.loss_cls: 0.2272, d1.loss_bbox: 0.6757, d2.loss_cls: 0.2210, d2.loss_bbox: 0.6073, d3.loss_cls: 0.2090, d3.loss_bbox: 0.5761, d4.loss_cls: 0.1977, d4.loss_bbox: 0.5632, loss: 4.9816, grad_norm: 52.9548
2025-06-20 07:45:24,767 - mmdet - INFO - Epoch [2][5200/7033]	lr: 1.866e-04, eta: 11:15:30, time: 1.343, data_time: 0.023, memory: 18168, loss_cls: 0.1941, loss_bbox: 0.5675, d0.loss_cls: 0.2606, d0.loss_bbox: 0.7254, d1.loss_cls: 0.2340, d1.loss_bbox: 0.6903, d2.loss_cls: 0.2231, d2.loss_bbox: 0.6202, d3.loss_cls: 0.2143, d3.loss_bbox: 0.5805, d4.loss_cls: 0.2017, d4.loss_bbox: 0.5697, loss: 5.0814, grad_norm: 43.8961
2025-06-20 07:46:34,142 - mmdet - INFO - Epoch [2][5250/7033]	lr: 1.866e-04, eta: 11:14:27, time: 1.388, data_time: 0.025, memory: 18168, loss_cls: 0.1906, loss_bbox: 0.5668, d0.loss_cls: 0.2493, d0.loss_bbox: 0.7091, d1.loss_cls: 0.2253, d1.loss_bbox: 0.6853, d2.loss_cls: 0.2260, d2.loss_bbox: 0.6255, d3.loss_cls: 0.2172, d3.loss_bbox: 0.5850, d4.loss_cls: 0.2026, d4.loss_bbox: 0.5694, loss: 5.0520, grad_norm: 37.9781
2025-06-20 07:47:41,510 - mmdet - INFO - Epoch [2][5300/7033]	lr: 1.866e-04, eta: 11:13:18, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.1839, loss_bbox: 0.5610, d0.loss_cls: 0.2535, d0.loss_bbox: 0.7001, d1.loss_cls: 0.2314, d1.loss_bbox: 0.6717, d2.loss_cls: 0.2219, d2.loss_bbox: 0.6064, d3.loss_cls: 0.2079, d3.loss_bbox: 0.5769, d4.loss_cls: 0.1926, d4.loss_bbox: 0.5618, loss: 4.9691, grad_norm: 37.9262
2025-06-20 07:48:48,895 - mmdet - INFO - Epoch [2][5350/7033]	lr: 1.866e-04, eta: 11:12:10, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1729, loss_bbox: 0.5618, d0.loss_cls: 0.2409, d0.loss_bbox: 0.7029, d1.loss_cls: 0.2131, d1.loss_bbox: 0.6781, d2.loss_cls: 0.2042, d2.loss_bbox: 0.6084, d3.loss_cls: 0.1933, d3.loss_bbox: 0.5770, d4.loss_cls: 0.1809, d4.loss_bbox: 0.5631, loss: 4.8966, grad_norm: 48.5786
2025-06-20 07:49:56,166 - mmdet - INFO - Epoch [2][5400/7033]	lr: 1.866e-04, eta: 11:11:02, time: 1.345, data_time: 0.025, memory: 18168, loss_cls: 0.1716, loss_bbox: 0.5515, d0.loss_cls: 0.2342, d0.loss_bbox: 0.6868, d1.loss_cls: 0.2097, d1.loss_bbox: 0.6574, d2.loss_cls: 0.2052, d2.loss_bbox: 0.6072, d3.loss_cls: 0.1923, d3.loss_bbox: 0.5729, d4.loss_cls: 0.1768, d4.loss_bbox: 0.5581, loss: 4.8235, grad_norm: 28.2665
2025-06-20 07:51:03,750 - mmdet - INFO - Epoch [2][5450/7033]	lr: 1.866e-04, eta: 11:09:54, time: 1.352, data_time: 0.022, memory: 18168, loss_cls: 0.1771, loss_bbox: 0.5629, d0.loss_cls: 0.2381, d0.loss_bbox: 0.7302, d1.loss_cls: 0.2164, d1.loss_bbox: 0.6937, d2.loss_cls: 0.2067, d2.loss_bbox: 0.6261, d3.loss_cls: 0.1996, d3.loss_bbox: 0.5834, d4.loss_cls: 0.1864, d4.loss_bbox: 0.5697, loss: 4.9903, grad_norm: 30.1835
2025-06-20 07:52:11,248 - mmdet - INFO - Epoch [2][5500/7033]	lr: 1.866e-04, eta: 11:08:46, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1817, loss_bbox: 0.5516, d0.loss_cls: 0.2454, d0.loss_bbox: 0.7102, d1.loss_cls: 0.2229, d1.loss_bbox: 0.6698, d2.loss_cls: 0.2200, d2.loss_bbox: 0.5972, d3.loss_cls: 0.2181, d3.loss_bbox: 0.5593, d4.loss_cls: 0.1965, d4.loss_bbox: 0.5488, loss: 4.9213, grad_norm: 33.9886
2025-06-20 07:53:18,584 - mmdet - INFO - Epoch [2][5550/7033]	lr: 1.866e-04, eta: 11:07:38, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.1950, loss_bbox: 0.5565, d0.loss_cls: 0.2433, d0.loss_bbox: 0.7302, d1.loss_cls: 0.2194, d1.loss_bbox: 0.6994, d2.loss_cls: 0.2241, d2.loss_bbox: 0.6285, d3.loss_cls: 0.2169, d3.loss_bbox: 0.5782, d4.loss_cls: 0.2023, d4.loss_bbox: 0.5616, loss: 5.0555, grad_norm: 44.3240
2025-06-20 07:54:25,708 - mmdet - INFO - Epoch [2][5600/7033]	lr: 1.866e-04, eta: 11:06:29, time: 1.342, data_time: 0.022, memory: 18168, loss_cls: 0.1773, loss_bbox: 0.5405, d0.loss_cls: 0.2308, d0.loss_bbox: 0.6990, d1.loss_cls: 0.2063, d1.loss_bbox: 0.6704, d2.loss_cls: 0.2054, d2.loss_bbox: 0.6047, d3.loss_cls: 0.1982, d3.loss_bbox: 0.5609, d4.loss_cls: 0.1853, d4.loss_bbox: 0.5419, loss: 4.8205, grad_norm: 35.4585
2025-06-20 07:55:33,067 - mmdet - INFO - Epoch [2][5650/7033]	lr: 1.866e-04, eta: 11:05:20, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.1810, loss_bbox: 0.5773, d0.loss_cls: 0.2525, d0.loss_bbox: 0.7301, d1.loss_cls: 0.2224, d1.loss_bbox: 0.6978, d2.loss_cls: 0.2103, d2.loss_bbox: 0.6298, d3.loss_cls: 0.2043, d3.loss_bbox: 0.5920, d4.loss_cls: 0.1888, d4.loss_bbox: 0.5800, loss: 5.0663, grad_norm: 29.8720
2025-06-20 07:56:40,347 - mmdet - INFO - Epoch [2][5700/7033]	lr: 1.866e-04, eta: 11:04:12, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1659, loss_bbox: 0.5415, d0.loss_cls: 0.2334, d0.loss_bbox: 0.6762, d1.loss_cls: 0.2066, d1.loss_bbox: 0.6439, d2.loss_cls: 0.2022, d2.loss_bbox: 0.5900, d3.loss_cls: 0.1875, d3.loss_bbox: 0.5569, d4.loss_cls: 0.1738, d4.loss_bbox: 0.5436, loss: 4.7217, grad_norm: 44.0134
2025-06-20 07:57:48,000 - mmdet - INFO - Epoch [2][5750/7033]	lr: 1.866e-04, eta: 11:03:04, time: 1.353, data_time: 0.025, memory: 18168, loss_cls: 0.1876, loss_bbox: 0.5758, d0.loss_cls: 0.2525, d0.loss_bbox: 0.7151, d1.loss_cls: 0.2233, d1.loss_bbox: 0.6804, d2.loss_cls: 0.2193, d2.loss_bbox: 0.6191, d3.loss_cls: 0.2082, d3.loss_bbox: 0.5879, d4.loss_cls: 0.1938, d4.loss_bbox: 0.5767, loss: 5.0395, grad_norm: 41.9618
2025-06-20 07:58:55,402 - mmdet - INFO - Epoch [2][5800/7033]	lr: 1.866e-04, eta: 11:01:56, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.1691, loss_bbox: 0.5437, d0.loss_cls: 0.2356, d0.loss_bbox: 0.6771, d1.loss_cls: 0.2090, d1.loss_bbox: 0.6390, d2.loss_cls: 0.2018, d2.loss_bbox: 0.5878, d3.loss_cls: 0.1884, d3.loss_bbox: 0.5601, d4.loss_cls: 0.1778, d4.loss_bbox: 0.5452, loss: 4.7347, grad_norm: 36.0132
2025-06-20 08:00:02,900 - mmdet - INFO - Epoch [2][5850/7033]	lr: 1.866e-04, eta: 11:00:48, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.1776, loss_bbox: 0.5402, d0.loss_cls: 0.2454, d0.loss_bbox: 0.7015, d1.loss_cls: 0.2193, d1.loss_bbox: 0.6664, d2.loss_cls: 0.2117, d2.loss_bbox: 0.5985, d3.loss_cls: 0.1976, d3.loss_bbox: 0.5589, d4.loss_cls: 0.1865, d4.loss_bbox: 0.5388, loss: 4.8423, grad_norm: 35.4670
2025-06-20 08:01:10,599 - mmdet - INFO - Epoch [2][5900/7033]	lr: 1.866e-04, eta: 10:59:41, time: 1.354, data_time: 0.023, memory: 18168, loss_cls: 0.1766, loss_bbox: 0.5462, d0.loss_cls: 0.2439, d0.loss_bbox: 0.6985, d1.loss_cls: 0.2159, d1.loss_bbox: 0.6691, d2.loss_cls: 0.2087, d2.loss_bbox: 0.5986, d3.loss_cls: 0.1997, d3.loss_bbox: 0.5586, d4.loss_cls: 0.1858, d4.loss_bbox: 0.5475, loss: 4.8491, grad_norm: 52.7449
2025-06-20 08:02:17,992 - mmdet - INFO - Epoch [2][5950/7033]	lr: 1.866e-04, eta: 10:58:33, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1833, loss_bbox: 0.5510, d0.loss_cls: 0.2524, d0.loss_bbox: 0.7064, d1.loss_cls: 0.2220, d1.loss_bbox: 0.6664, d2.loss_cls: 0.2162, d2.loss_bbox: 0.6026, d3.loss_cls: 0.2057, d3.loss_bbox: 0.5624, d4.loss_cls: 0.1880, d4.loss_bbox: 0.5517, loss: 4.9081, grad_norm: 39.9344
2025-06-20 08:03:27,035 - mmdet - INFO - Epoch [2][6000/7033]	lr: 1.866e-04, eta: 10:57:28, time: 1.381, data_time: 0.023, memory: 18168, loss_cls: 0.1721, loss_bbox: 0.5442, d0.loss_cls: 0.2454, d0.loss_bbox: 0.6642, d1.loss_cls: 0.2185, d1.loss_bbox: 0.6257, d2.loss_cls: 0.2031, d2.loss_bbox: 0.5910, d3.loss_cls: 0.1920, d3.loss_bbox: 0.5597, d4.loss_cls: 0.1786, d4.loss_bbox: 0.5442, loss: 4.7388, grad_norm: 34.7811
2025-06-20 08:04:34,525 - mmdet - INFO - Epoch [2][6050/7033]	lr: 1.866e-04, eta: 10:56:20, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.1819, loss_bbox: 0.5692, d0.loss_cls: 0.2482, d0.loss_bbox: 0.7110, d1.loss_cls: 0.2205, d1.loss_bbox: 0.6702, d2.loss_cls: 0.2150, d2.loss_bbox: 0.6111, d3.loss_cls: 0.2033, d3.loss_bbox: 0.5843, d4.loss_cls: 0.1886, d4.loss_bbox: 0.5730, loss: 4.9760, grad_norm: 33.8644
2025-06-20 08:05:41,781 - mmdet - INFO - Epoch [2][6100/7033]	lr: 1.866e-04, eta: 10:55:12, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.1732, loss_bbox: 0.5480, d0.loss_cls: 0.2292, d0.loss_bbox: 0.6779, d1.loss_cls: 0.2016, d1.loss_bbox: 0.6424, d2.loss_cls: 0.1992, d2.loss_bbox: 0.5882, d3.loss_cls: 0.1894, d3.loss_bbox: 0.5588, d4.loss_cls: 0.1799, d4.loss_bbox: 0.5481, loss: 4.7360, grad_norm: 36.3169
2025-06-20 08:06:49,110 - mmdet - INFO - Epoch [2][6150/7033]	lr: 1.866e-04, eta: 10:54:04, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.1760, loss_bbox: 0.5675, d0.loss_cls: 0.2397, d0.loss_bbox: 0.6938, d1.loss_cls: 0.2164, d1.loss_bbox: 0.6566, d2.loss_cls: 0.2055, d2.loss_bbox: 0.6064, d3.loss_cls: 0.1950, d3.loss_bbox: 0.5775, d4.loss_cls: 0.1827, d4.loss_bbox: 0.5693, loss: 4.8864, grad_norm: 32.3174
2025-06-20 08:07:56,612 - mmdet - INFO - Epoch [2][6200/7033]	lr: 1.866e-04, eta: 10:52:56, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1779, loss_bbox: 0.5533, d0.loss_cls: 0.2433, d0.loss_bbox: 0.6821, d1.loss_cls: 0.2190, d1.loss_bbox: 0.6496, d2.loss_cls: 0.2114, d2.loss_bbox: 0.6006, d3.loss_cls: 0.1967, d3.loss_bbox: 0.5704, d4.loss_cls: 0.1856, d4.loss_bbox: 0.5553, loss: 4.8452, grad_norm: 32.7394
2025-06-20 08:09:04,201 - mmdet - INFO - Epoch [2][6250/7033]	lr: 1.866e-04, eta: 10:51:48, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1761, loss_bbox: 0.5535, d0.loss_cls: 0.2392, d0.loss_bbox: 0.6816, d1.loss_cls: 0.2106, d1.loss_bbox: 0.6552, d2.loss_cls: 0.2071, d2.loss_bbox: 0.5983, d3.loss_cls: 0.1944, d3.loss_bbox: 0.5652, d4.loss_cls: 0.1838, d4.loss_bbox: 0.5544, loss: 4.8192, grad_norm: 29.4804
2025-06-20 08:10:11,503 - mmdet - INFO - Epoch [2][6300/7033]	lr: 1.866e-04, eta: 10:50:40, time: 1.346, data_time: 0.023, memory: 18168, loss_cls: 0.1730, loss_bbox: 0.5733, d0.loss_cls: 0.2446, d0.loss_bbox: 0.7090, d1.loss_cls: 0.2160, d1.loss_bbox: 0.6766, d2.loss_cls: 0.2085, d2.loss_bbox: 0.6283, d3.loss_cls: 0.1980, d3.loss_bbox: 0.5873, d4.loss_cls: 0.1851, d4.loss_bbox: 0.5731, loss: 4.9728, grad_norm: 34.6724
2025-06-20 08:11:18,930 - mmdet - INFO - Epoch [2][6350/7033]	lr: 1.866e-04, eta: 10:49:32, time: 1.349, data_time: 0.022, memory: 18168, loss_cls: 0.1756, loss_bbox: 0.5670, d0.loss_cls: 0.2387, d0.loss_bbox: 0.6913, d1.loss_cls: 0.2113, d1.loss_bbox: 0.6587, d2.loss_cls: 0.2038, d2.loss_bbox: 0.6132, d3.loss_cls: 0.1954, d3.loss_bbox: 0.5792, d4.loss_cls: 0.1853, d4.loss_bbox: 0.5662, loss: 4.8858, grad_norm: 30.0207
2025-06-20 08:12:26,622 - mmdet - INFO - Epoch [2][6400/7033]	lr: 1.866e-04, eta: 10:48:24, time: 1.354, data_time: 0.022, memory: 18168, loss_cls: 0.1609, loss_bbox: 0.5390, d0.loss_cls: 0.2364, d0.loss_bbox: 0.6663, d1.loss_cls: 0.1986, d1.loss_bbox: 0.6363, d2.loss_cls: 0.1903, d2.loss_bbox: 0.5855, d3.loss_cls: 0.1832, d3.loss_bbox: 0.5532, d4.loss_cls: 0.1686, d4.loss_bbox: 0.5406, loss: 4.6590, grad_norm: 56.6913
2025-06-20 08:13:33,994 - mmdet - INFO - Epoch [2][6450/7033]	lr: 1.866e-04, eta: 10:47:16, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1687, loss_bbox: 0.5735, d0.loss_cls: 0.2338, d0.loss_bbox: 0.6907, d1.loss_cls: 0.2051, d1.loss_bbox: 0.6558, d2.loss_cls: 0.1938, d2.loss_bbox: 0.6033, d3.loss_cls: 0.1854, d3.loss_bbox: 0.5830, d4.loss_cls: 0.1740, d4.loss_bbox: 0.5747, loss: 4.8417, grad_norm: 53.6992
2025-06-20 08:14:41,451 - mmdet - INFO - Epoch [2][6500/7033]	lr: 1.866e-04, eta: 10:46:08, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1790, loss_bbox: 0.5532, d0.loss_cls: 0.2383, d0.loss_bbox: 0.6914, d1.loss_cls: 0.2176, d1.loss_bbox: 0.6690, d2.loss_cls: 0.2096, d2.loss_bbox: 0.5934, d3.loss_cls: 0.2001, d3.loss_bbox: 0.5673, d4.loss_cls: 0.1888, d4.loss_bbox: 0.5509, loss: 4.8584, grad_norm: 35.1076
2025-06-20 08:15:48,805 - mmdet - INFO - Epoch [2][6550/7033]	lr: 1.866e-04, eta: 10:45:00, time: 1.347, data_time: 0.024, memory: 18168, loss_cls: 0.1617, loss_bbox: 0.5479, d0.loss_cls: 0.2224, d0.loss_bbox: 0.6769, d1.loss_cls: 0.1973, d1.loss_bbox: 0.6492, d2.loss_cls: 0.1930, d2.loss_bbox: 0.5893, d3.loss_cls: 0.1812, d3.loss_bbox: 0.5650, d4.loss_cls: 0.1698, d4.loss_bbox: 0.5477, loss: 4.7014, grad_norm: 38.3614
2025-06-20 08:16:58,232 - mmdet - INFO - Epoch [2][6600/7033]	lr: 1.866e-04, eta: 10:43:56, time: 1.389, data_time: 0.023, memory: 18168, loss_cls: 0.1668, loss_bbox: 0.5396, d0.loss_cls: 0.2213, d0.loss_bbox: 0.6777, d1.loss_cls: 0.1977, d1.loss_bbox: 0.6377, d2.loss_cls: 0.1943, d2.loss_bbox: 0.5810, d3.loss_cls: 0.1823, d3.loss_bbox: 0.5541, d4.loss_cls: 0.1723, d4.loss_bbox: 0.5428, loss: 4.6675, grad_norm: 37.5131
2025-06-20 08:18:05,702 - mmdet - INFO - Epoch [2][6650/7033]	lr: 1.866e-04, eta: 10:42:48, time: 1.349, data_time: 0.024, memory: 18168, loss_cls: 0.1710, loss_bbox: 0.5415, d0.loss_cls: 0.2332, d0.loss_bbox: 0.6722, d1.loss_cls: 0.1998, d1.loss_bbox: 0.6398, d2.loss_cls: 0.1965, d2.loss_bbox: 0.5787, d3.loss_cls: 0.1826, d3.loss_bbox: 0.5551, d4.loss_cls: 0.1752, d4.loss_bbox: 0.5426, loss: 4.6881, grad_norm: 31.0537
2025-06-20 08:19:12,941 - mmdet - INFO - Epoch [2][6700/7033]	lr: 1.866e-04, eta: 10:41:40, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.1647, loss_bbox: 0.5322, d0.loss_cls: 0.2310, d0.loss_bbox: 0.6689, d1.loss_cls: 0.2030, d1.loss_bbox: 0.6364, d2.loss_cls: 0.1931, d2.loss_bbox: 0.5829, d3.loss_cls: 0.1817, d3.loss_bbox: 0.5511, d4.loss_cls: 0.1736, d4.loss_bbox: 0.5318, loss: 4.6503, grad_norm: 35.0280
2025-06-20 08:20:20,442 - mmdet - INFO - Epoch [2][6750/7033]	lr: 1.866e-04, eta: 10:40:32, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.1682, loss_bbox: 0.5442, d0.loss_cls: 0.2375, d0.loss_bbox: 0.6863, d1.loss_cls: 0.2070, d1.loss_bbox: 0.6488, d2.loss_cls: 0.1938, d2.loss_bbox: 0.5869, d3.loss_cls: 0.1861, d3.loss_bbox: 0.5545, d4.loss_cls: 0.1765, d4.loss_bbox: 0.5448, loss: 4.7347, grad_norm: 36.6946
2025-06-20 08:21:29,192 - mmdet - INFO - Epoch [2][6800/7033]	lr: 1.866e-04, eta: 10:39:26, time: 1.375, data_time: 0.022, memory: 18168, loss_cls: 0.1660, loss_bbox: 0.5460, d0.loss_cls: 0.2339, d0.loss_bbox: 0.6940, d1.loss_cls: 0.2002, d1.loss_bbox: 0.6650, d2.loss_cls: 0.1902, d2.loss_bbox: 0.6014, d3.loss_cls: 0.1774, d3.loss_bbox: 0.5679, d4.loss_cls: 0.1723, d4.loss_bbox: 0.5485, loss: 4.7628, grad_norm: 57.1584
2025-06-20 08:22:36,506 - mmdet - INFO - Epoch [2][6850/7033]	lr: 1.866e-04, eta: 10:38:18, time: 1.346, data_time: 0.023, memory: 18168, loss_cls: 0.1725, loss_bbox: 0.5607, d0.loss_cls: 0.2369, d0.loss_bbox: 0.6884, d1.loss_cls: 0.2082, d1.loss_bbox: 0.6629, d2.loss_cls: 0.1959, d2.loss_bbox: 0.6071, d3.loss_cls: 0.1886, d3.loss_bbox: 0.5766, d4.loss_cls: 0.1780, d4.loss_bbox: 0.5634, loss: 4.8392, grad_norm: 40.2647
2025-06-20 08:23:43,796 - mmdet - INFO - Epoch [2][6900/7033]	lr: 1.866e-04, eta: 10:37:10, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1795, loss_bbox: 0.5687, d0.loss_cls: 0.2473, d0.loss_bbox: 0.6762, d1.loss_cls: 0.2138, d1.loss_bbox: 0.6454, d2.loss_cls: 0.2039, d2.loss_bbox: 0.6047, d3.loss_cls: 0.1951, d3.loss_bbox: 0.5826, d4.loss_cls: 0.1871, d4.loss_bbox: 0.5692, loss: 4.8735, grad_norm: 39.6010
2025-06-20 08:24:51,052 - mmdet - INFO - Epoch [2][6950/7033]	lr: 1.866e-04, eta: 10:36:01, time: 1.345, data_time: 0.023, memory: 18168, loss_cls: 0.1740, loss_bbox: 0.5559, d0.loss_cls: 0.2389, d0.loss_bbox: 0.6895, d1.loss_cls: 0.2101, d1.loss_bbox: 0.6565, d2.loss_cls: 0.2023, d2.loss_bbox: 0.6048, d3.loss_cls: 0.1904, d3.loss_bbox: 0.5669, d4.loss_cls: 0.1827, d4.loss_bbox: 0.5571, loss: 4.8291, grad_norm: 43.8077
2025-06-20 08:25:58,346 - mmdet - INFO - Epoch [2][7000/7033]	lr: 1.866e-04, eta: 10:34:53, time: 1.346, data_time: 0.024, memory: 18168, loss_cls: 0.1710, loss_bbox: 0.5384, d0.loss_cls: 0.2297, d0.loss_bbox: 0.6848, d1.loss_cls: 0.2072, d1.loss_bbox: 0.6417, d2.loss_cls: 0.2002, d2.loss_bbox: 0.5882, d3.loss_cls: 0.1898, d3.loss_bbox: 0.5542, d4.loss_cls: 0.1768, d4.loss_bbox: 0.5406, loss: 4.7227, grad_norm: 35.7021
2025-06-20 08:26:43,565 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-06-20 08:52:50,195 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 08:52:50,195 - mmdet - INFO - Epoch(val) [2][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.5342, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8217, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9055, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9236, pts_bbox_NuScenes/car_trans_err: 0.3127, pts_bbox_NuScenes/car_scale_err: 0.1633, pts_bbox_NuScenes/car_orient_err: 0.0824, pts_bbox_NuScenes/car_vel_err: 0.2656, pts_bbox_NuScenes/car_attr_err: 0.1754, pts_bbox_NuScenes/mATE: 0.4711, pts_bbox_NuScenes/mASE: 0.2700, pts_bbox_NuScenes/mAOE: 0.2832, pts_bbox_NuScenes/mAVE: 0.2662, pts_bbox_NuScenes/mAAE: 0.1834, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.2324, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5527, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7009, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7615, pts_bbox_NuScenes/truck_trans_err: 0.4786, pts_bbox_NuScenes/truck_scale_err: 0.2070, pts_bbox_NuScenes/truck_orient_err: 0.0853, pts_bbox_NuScenes/truck_vel_err: 0.2451, pts_bbox_NuScenes/truck_attr_err: 0.2369, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0335, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2098, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.3995, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.4977, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6963, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4413, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8892, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1078, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.2991, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.2923, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.6260, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8723, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.8988, pts_bbox_NuScenes/bus_trans_err: 0.4766, pts_bbox_NuScenes/bus_scale_err: 0.2034, pts_bbox_NuScenes/bus_orient_err: 0.0499, pts_bbox_NuScenes/bus_vel_err: 0.4955, pts_bbox_NuScenes/bus_attr_err: 0.2025, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0954, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3704, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5881, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6864, pts_bbox_NuScenes/trailer_trans_err: 0.6020, pts_bbox_NuScenes/trailer_scale_err: 0.2345, pts_bbox_NuScenes/trailer_orient_err: 0.4222, pts_bbox_NuScenes/trailer_vel_err: 0.1840, pts_bbox_NuScenes/trailer_attr_err: 0.1751, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.2399, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.5559, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.6575, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.6931, pts_bbox_NuScenes/barrier_trans_err: 0.4907, pts_bbox_NuScenes/barrier_scale_err: 0.2875, pts_bbox_NuScenes/barrier_orient_err: 0.0645, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.3958, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.6818, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7668, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7787, pts_bbox_NuScenes/motorcycle_trans_err: 0.3840, pts_bbox_NuScenes/motorcycle_scale_err: 0.2612, pts_bbox_NuScenes/motorcycle_orient_err: 0.2397, pts_bbox_NuScenes/motorcycle_vel_err: 0.3658, pts_bbox_NuScenes/motorcycle_attr_err: 0.2541, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.3469, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.5685, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.5998, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6104, pts_bbox_NuScenes/bicycle_trans_err: 0.3596, pts_bbox_NuScenes/bicycle_scale_err: 0.2778, pts_bbox_NuScenes/bicycle_orient_err: 0.3392, pts_bbox_NuScenes/bicycle_vel_err: 0.2304, pts_bbox_NuScenes/bicycle_attr_err: 0.0122, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.3730, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.7437, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8591, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8833, pts_bbox_NuScenes/pedestrian_trans_err: 0.4481, pts_bbox_NuScenes/pedestrian_scale_err: 0.2976, pts_bbox_NuScenes/pedestrian_orient_err: 0.3762, pts_bbox_NuScenes/pedestrian_vel_err: 0.2350, pts_bbox_NuScenes/pedestrian_attr_err: 0.1118, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.2971, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.6807, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7676, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8004, pts_bbox_NuScenes/traffic_cone_trans_err: 0.4624, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3265, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6439, pts_bbox_NuScenes/mAP: 0.5826
2025-06-20 08:54:06,592 - mmdet - INFO - Epoch [3][50/7033]	lr: 1.501e-04, eta: 10:31:39, time: 1.423, data_time: 0.104, memory: 18168, loss_cls: 0.1707, loss_bbox: 0.5302, d0.loss_cls: 0.2263, d0.loss_bbox: 0.6614, d1.loss_cls: 0.2009, d1.loss_bbox: 0.6293, d2.loss_cls: 0.1892, d2.loss_bbox: 0.5776, d3.loss_cls: 0.1842, d3.loss_bbox: 0.5468, d4.loss_cls: 0.1765, d4.loss_bbox: 0.5341, loss: 4.6272, grad_norm: 41.9560
2025-06-20 08:55:14,032 - mmdet - INFO - Epoch [3][100/7033]	lr: 1.501e-04, eta: 10:30:32, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1662, loss_bbox: 0.5300, d0.loss_cls: 0.2312, d0.loss_bbox: 0.6484, d1.loss_cls: 0.2029, d1.loss_bbox: 0.6153, d2.loss_cls: 0.1931, d2.loss_bbox: 0.5744, d3.loss_cls: 0.1818, d3.loss_bbox: 0.5462, d4.loss_cls: 0.1702, d4.loss_bbox: 0.5360, loss: 4.5957, grad_norm: 27.8285
2025-06-20 08:56:21,650 - mmdet - INFO - Epoch [3][150/7033]	lr: 1.501e-04, eta: 10:29:24, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1633, loss_bbox: 0.5126, d0.loss_cls: 0.2284, d0.loss_bbox: 0.6222, d1.loss_cls: 0.1955, d1.loss_bbox: 0.5972, d2.loss_cls: 0.1861, d2.loss_bbox: 0.5559, d3.loss_cls: 0.1771, d3.loss_bbox: 0.5275, d4.loss_cls: 0.1685, d4.loss_bbox: 0.5155, loss: 4.4497, grad_norm: 35.2558
2025-06-20 08:57:29,128 - mmdet - INFO - Epoch [3][200/7033]	lr: 1.501e-04, eta: 10:28:17, time: 1.350, data_time: 0.021, memory: 18168, loss_cls: 0.1622, loss_bbox: 0.5370, d0.loss_cls: 0.2248, d0.loss_bbox: 0.6635, d1.loss_cls: 0.2017, d1.loss_bbox: 0.6267, d2.loss_cls: 0.1907, d2.loss_bbox: 0.5818, d3.loss_cls: 0.1791, d3.loss_bbox: 0.5529, d4.loss_cls: 0.1685, d4.loss_bbox: 0.5378, loss: 4.6267, grad_norm: 39.3451
2025-06-20 08:58:36,778 - mmdet - INFO - Epoch [3][250/7033]	lr: 1.501e-04, eta: 10:27:10, time: 1.353, data_time: 0.023, memory: 18168, loss_cls: 0.1568, loss_bbox: 0.5394, d0.loss_cls: 0.2267, d0.loss_bbox: 0.6536, d1.loss_cls: 0.1918, d1.loss_bbox: 0.6318, d2.loss_cls: 0.1828, d2.loss_bbox: 0.5794, d3.loss_cls: 0.1728, d3.loss_bbox: 0.5515, d4.loss_cls: 0.1624, d4.loss_bbox: 0.5413, loss: 4.5904, grad_norm: 33.1935
2025-06-20 08:59:44,196 - mmdet - INFO - Epoch [3][300/7033]	lr: 1.501e-04, eta: 10:26:02, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1652, loss_bbox: 0.5367, d0.loss_cls: 0.2358, d0.loss_bbox: 0.6514, d1.loss_cls: 0.2037, d1.loss_bbox: 0.6180, d2.loss_cls: 0.1909, d2.loss_bbox: 0.5690, d3.loss_cls: 0.1807, d3.loss_bbox: 0.5509, d4.loss_cls: 0.1728, d4.loss_bbox: 0.5380, loss: 4.6132, grad_norm: 83.9132
2025-06-20 09:00:53,545 - mmdet - INFO - Epoch [3][350/7033]	lr: 1.501e-04, eta: 10:24:58, time: 1.387, data_time: 0.022, memory: 18168, loss_cls: 0.1618, loss_bbox: 0.5437, d0.loss_cls: 0.2294, d0.loss_bbox: 0.6500, d1.loss_cls: 0.1936, d1.loss_bbox: 0.6226, d2.loss_cls: 0.1852, d2.loss_bbox: 0.5789, d3.loss_cls: 0.1753, d3.loss_bbox: 0.5553, d4.loss_cls: 0.1687, d4.loss_bbox: 0.5425, loss: 4.6071, grad_norm: 47.6435
2025-06-20 09:02:00,847 - mmdet - INFO - Epoch [3][400/7033]	lr: 1.501e-04, eta: 10:23:50, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1644, loss_bbox: 0.5308, d0.loss_cls: 0.2349, d0.loss_bbox: 0.6541, d1.loss_cls: 0.2064, d1.loss_bbox: 0.6233, d2.loss_cls: 0.1938, d2.loss_bbox: 0.5689, d3.loss_cls: 0.1822, d3.loss_bbox: 0.5427, d4.loss_cls: 0.1712, d4.loss_bbox: 0.5312, loss: 4.6037, grad_norm: 32.1533
2025-06-20 09:03:07,882 - mmdet - INFO - Epoch [3][450/7033]	lr: 1.501e-04, eta: 10:22:42, time: 1.341, data_time: 0.020, memory: 18168, loss_cls: 0.1598, loss_bbox: 0.4902, d0.loss_cls: 0.2352, d0.loss_bbox: 0.6064, d1.loss_cls: 0.1990, d1.loss_bbox: 0.5706, d2.loss_cls: 0.1886, d2.loss_bbox: 0.5234, d3.loss_cls: 0.1752, d3.loss_bbox: 0.4989, d4.loss_cls: 0.1644, d4.loss_bbox: 0.4904, loss: 4.3021, grad_norm: 27.5176
2025-06-20 09:04:15,245 - mmdet - INFO - Epoch [3][500/7033]	lr: 1.501e-04, eta: 10:21:34, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1671, loss_bbox: 0.5315, d0.loss_cls: 0.2269, d0.loss_bbox: 0.6689, d1.loss_cls: 0.1995, d1.loss_bbox: 0.6343, d2.loss_cls: 0.1894, d2.loss_bbox: 0.5779, d3.loss_cls: 0.1824, d3.loss_bbox: 0.5440, d4.loss_cls: 0.1730, d4.loss_bbox: 0.5312, loss: 4.6262, grad_norm: 34.5835
2025-06-20 09:05:22,568 - mmdet - INFO - Epoch [3][550/7033]	lr: 1.501e-04, eta: 10:20:26, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1556, loss_bbox: 0.5531, d0.loss_cls: 0.2286, d0.loss_bbox: 0.6492, d1.loss_cls: 0.1978, d1.loss_bbox: 0.6179, d2.loss_cls: 0.1846, d2.loss_bbox: 0.5863, d3.loss_cls: 0.1712, d3.loss_bbox: 0.5599, d4.loss_cls: 0.1634, d4.loss_bbox: 0.5495, loss: 4.6171, grad_norm: 32.4404
2025-06-20 09:06:30,058 - mmdet - INFO - Epoch [3][600/7033]	lr: 1.501e-04, eta: 10:19:19, time: 1.350, data_time: 0.021, memory: 18168, loss_cls: 0.1706, loss_bbox: 0.5269, d0.loss_cls: 0.2298, d0.loss_bbox: 0.6479, d1.loss_cls: 0.2029, d1.loss_bbox: 0.6157, d2.loss_cls: 0.1929, d2.loss_bbox: 0.5679, d3.loss_cls: 0.1869, d3.loss_bbox: 0.5367, d4.loss_cls: 0.1777, d4.loss_bbox: 0.5267, loss: 4.5826, grad_norm: 37.6603
2025-06-20 09:07:37,283 - mmdet - INFO - Epoch [3][650/7033]	lr: 1.501e-04, eta: 10:18:11, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.1542, loss_bbox: 0.5048, d0.loss_cls: 0.2294, d0.loss_bbox: 0.6366, d1.loss_cls: 0.2015, d1.loss_bbox: 0.5931, d2.loss_cls: 0.1871, d2.loss_bbox: 0.5442, d3.loss_cls: 0.1730, d3.loss_bbox: 0.5184, d4.loss_cls: 0.1635, d4.loss_bbox: 0.5058, loss: 4.4115, grad_norm: 37.3688
2025-06-20 09:08:44,656 - mmdet - INFO - Epoch [3][700/7033]	lr: 1.501e-04, eta: 10:17:03, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1888, loss_bbox: 0.5566, d0.loss_cls: 0.2498, d0.loss_bbox: 0.6728, d1.loss_cls: 0.2199, d1.loss_bbox: 0.6438, d2.loss_cls: 0.2079, d2.loss_bbox: 0.6062, d3.loss_cls: 0.2004, d3.loss_bbox: 0.5788, d4.loss_cls: 0.1942, d4.loss_bbox: 0.5600, loss: 4.8790, grad_norm: 42.8839
2025-06-20 09:09:52,178 - mmdet - INFO - Epoch [3][750/7033]	lr: 1.501e-04, eta: 10:15:56, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.1647, loss_bbox: 0.5524, d0.loss_cls: 0.2324, d0.loss_bbox: 0.6778, d1.loss_cls: 0.1988, d1.loss_bbox: 0.6416, d2.loss_cls: 0.1898, d2.loss_bbox: 0.5916, d3.loss_cls: 0.1787, d3.loss_bbox: 0.5655, d4.loss_cls: 0.1693, d4.loss_bbox: 0.5548, loss: 4.7175, grad_norm: 37.7443
2025-06-20 09:10:59,814 - mmdet - INFO - Epoch [3][800/7033]	lr: 1.501e-04, eta: 10:14:49, time: 1.353, data_time: 0.024, memory: 18168, loss_cls: 0.1643, loss_bbox: 0.5244, d0.loss_cls: 0.2279, d0.loss_bbox: 0.6416, d1.loss_cls: 0.1988, d1.loss_bbox: 0.6105, d2.loss_cls: 0.1917, d2.loss_bbox: 0.5674, d3.loss_cls: 0.1798, d3.loss_bbox: 0.5394, d4.loss_cls: 0.1697, d4.loss_bbox: 0.5265, loss: 4.5419, grad_norm: 46.3079
2025-06-20 09:12:07,433 - mmdet - INFO - Epoch [3][850/7033]	lr: 1.501e-04, eta: 10:13:41, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1557, loss_bbox: 0.5237, d0.loss_cls: 0.2222, d0.loss_bbox: 0.6778, d1.loss_cls: 0.1942, d1.loss_bbox: 0.6323, d2.loss_cls: 0.1838, d2.loss_bbox: 0.5728, d3.loss_cls: 0.1728, d3.loss_bbox: 0.5411, d4.loss_cls: 0.1644, d4.loss_bbox: 0.5244, loss: 4.5654, grad_norm: 34.4557
2025-06-20 09:13:15,193 - mmdet - INFO - Epoch [3][900/7033]	lr: 1.501e-04, eta: 10:12:34, time: 1.355, data_time: 0.022, memory: 18168, loss_cls: 0.1720, loss_bbox: 0.5398, d0.loss_cls: 0.2320, d0.loss_bbox: 0.6715, d1.loss_cls: 0.2031, d1.loss_bbox: 0.6373, d2.loss_cls: 0.1962, d2.loss_bbox: 0.5771, d3.loss_cls: 0.1865, d3.loss_bbox: 0.5533, d4.loss_cls: 0.1765, d4.loss_bbox: 0.5432, loss: 4.6886, grad_norm: 38.3528
2025-06-20 09:14:22,665 - mmdet - INFO - Epoch [3][950/7033]	lr: 1.501e-04, eta: 10:11:27, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1595, loss_bbox: 0.5229, d0.loss_cls: 0.2292, d0.loss_bbox: 0.6574, d1.loss_cls: 0.2000, d1.loss_bbox: 0.6147, d2.loss_cls: 0.1893, d2.loss_bbox: 0.5642, d3.loss_cls: 0.1748, d3.loss_bbox: 0.5368, d4.loss_cls: 0.1640, d4.loss_bbox: 0.5244, loss: 4.5370, grad_norm: 31.5007
2025-06-20 09:15:30,426 - mmdet - INFO - Epoch [3][1000/7033]	lr: 1.501e-04, eta: 10:10:20, time: 1.355, data_time: 0.022, memory: 18168, loss_cls: 0.1570, loss_bbox: 0.5114, d0.loss_cls: 0.2246, d0.loss_bbox: 0.6253, d1.loss_cls: 0.1911, d1.loss_bbox: 0.5935, d2.loss_cls: 0.1803, d2.loss_bbox: 0.5473, d3.loss_cls: 0.1686, d3.loss_bbox: 0.5246, d4.loss_cls: 0.1597, d4.loss_bbox: 0.5133, loss: 4.3968, grad_norm: 52.9391
2025-06-20 09:16:39,941 - mmdet - INFO - Epoch [3][1050/7033]	lr: 1.501e-04, eta: 10:09:16, time: 1.390, data_time: 0.064, memory: 18168, loss_cls: 0.1556, loss_bbox: 0.5246, d0.loss_cls: 0.2273, d0.loss_bbox: 0.6400, d1.loss_cls: 0.1895, d1.loss_bbox: 0.6093, d2.loss_cls: 0.1773, d2.loss_bbox: 0.5737, d3.loss_cls: 0.1688, d3.loss_bbox: 0.5408, d4.loss_cls: 0.1586, d4.loss_bbox: 0.5279, loss: 4.4933, grad_norm: 43.9127
2025-06-20 09:17:47,520 - mmdet - INFO - Epoch [3][1100/7033]	lr: 1.501e-04, eta: 10:08:09, time: 1.352, data_time: 0.023, memory: 18168, loss_cls: 0.1552, loss_bbox: 0.5137, d0.loss_cls: 0.2116, d0.loss_bbox: 0.6334, d1.loss_cls: 0.1824, d1.loss_bbox: 0.5942, d2.loss_cls: 0.1736, d2.loss_bbox: 0.5578, d3.loss_cls: 0.1665, d3.loss_bbox: 0.5299, d4.loss_cls: 0.1612, d4.loss_bbox: 0.5161, loss: 4.3954, grad_norm: 37.2709
2025-06-20 09:18:56,208 - mmdet - INFO - Epoch [3][1150/7033]	lr: 1.501e-04, eta: 10:07:03, time: 1.374, data_time: 0.044, memory: 18168, loss_cls: 0.1640, loss_bbox: 0.5537, d0.loss_cls: 0.2272, d0.loss_bbox: 0.6605, d1.loss_cls: 0.1934, d1.loss_bbox: 0.6297, d2.loss_cls: 0.1824, d2.loss_bbox: 0.5959, d3.loss_cls: 0.1789, d3.loss_bbox: 0.5658, d4.loss_cls: 0.1695, d4.loss_bbox: 0.5537, loss: 4.6746, grad_norm: 56.9523
2025-06-20 09:20:03,888 - mmdet - INFO - Epoch [3][1200/7033]	lr: 1.501e-04, eta: 10:05:56, time: 1.354, data_time: 0.024, memory: 18168, loss_cls: 0.1651, loss_bbox: 0.5458, d0.loss_cls: 0.2349, d0.loss_bbox: 0.6655, d1.loss_cls: 0.2010, d1.loss_bbox: 0.6287, d2.loss_cls: 0.1888, d2.loss_bbox: 0.5822, d3.loss_cls: 0.1811, d3.loss_bbox: 0.5552, d4.loss_cls: 0.1727, d4.loss_bbox: 0.5473, loss: 4.6684, grad_norm: 64.8403
2025-06-20 09:21:11,310 - mmdet - INFO - Epoch [3][1250/7033]	lr: 1.501e-04, eta: 10:04:49, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1744, loss_bbox: 0.5247, d0.loss_cls: 0.2368, d0.loss_bbox: 0.6473, d1.loss_cls: 0.2071, d1.loss_bbox: 0.6138, d2.loss_cls: 0.1986, d2.loss_bbox: 0.5681, d3.loss_cls: 0.1901, d3.loss_bbox: 0.5410, d4.loss_cls: 0.1807, d4.loss_bbox: 0.5253, loss: 4.6077, grad_norm: 37.4958
2025-06-20 09:22:18,769 - mmdet - INFO - Epoch [3][1300/7033]	lr: 1.501e-04, eta: 10:03:41, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1715, loss_bbox: 0.5277, d0.loss_cls: 0.2294, d0.loss_bbox: 0.6739, d1.loss_cls: 0.2039, d1.loss_bbox: 0.6299, d2.loss_cls: 0.1959, d2.loss_bbox: 0.5655, d3.loss_cls: 0.1864, d3.loss_bbox: 0.5400, d4.loss_cls: 0.1786, d4.loss_bbox: 0.5293, loss: 4.6320, grad_norm: 30.1874
2025-06-20 09:23:26,463 - mmdet - INFO - Epoch [3][1350/7033]	lr: 1.501e-04, eta: 10:02:34, time: 1.354, data_time: 0.023, memory: 18168, loss_cls: 0.1580, loss_bbox: 0.5309, d0.loss_cls: 0.2264, d0.loss_bbox: 0.6589, d1.loss_cls: 0.1961, d1.loss_bbox: 0.6251, d2.loss_cls: 0.1869, d2.loss_bbox: 0.5738, d3.loss_cls: 0.1717, d3.loss_bbox: 0.5479, d4.loss_cls: 0.1642, d4.loss_bbox: 0.5321, loss: 4.5721, grad_norm: 38.6214
2025-06-20 09:24:34,098 - mmdet - INFO - Epoch [3][1400/7033]	lr: 1.501e-04, eta: 10:01:27, time: 1.353, data_time: 0.022, memory: 18168, loss_cls: 0.1580, loss_bbox: 0.5141, d0.loss_cls: 0.2243, d0.loss_bbox: 0.6201, d1.loss_cls: 0.1886, d1.loss_bbox: 0.5820, d2.loss_cls: 0.1818, d2.loss_bbox: 0.5455, d3.loss_cls: 0.1726, d3.loss_bbox: 0.5281, d4.loss_cls: 0.1641, d4.loss_bbox: 0.5161, loss: 4.3953, grad_norm: 31.3605
2025-06-20 09:25:43,416 - mmdet - INFO - Epoch [3][1450/7033]	lr: 1.501e-04, eta: 10:00:22, time: 1.386, data_time: 0.023, memory: 18168, loss_cls: 0.1615, loss_bbox: 0.5314, d0.loss_cls: 0.2235, d0.loss_bbox: 0.6606, d1.loss_cls: 0.1928, d1.loss_bbox: 0.6271, d2.loss_cls: 0.1844, d2.loss_bbox: 0.5817, d3.loss_cls: 0.1757, d3.loss_bbox: 0.5479, d4.loss_cls: 0.1671, d4.loss_bbox: 0.5369, loss: 4.5906, grad_norm: 40.5242
2025-06-20 09:26:50,762 - mmdet - INFO - Epoch [3][1500/7033]	lr: 1.501e-04, eta: 9:59:15, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1653, loss_bbox: 0.5245, d0.loss_cls: 0.2239, d0.loss_bbox: 0.6289, d1.loss_cls: 0.1921, d1.loss_bbox: 0.6007, d2.loss_cls: 0.1871, d2.loss_bbox: 0.5604, d3.loss_cls: 0.1819, d3.loss_bbox: 0.5359, d4.loss_cls: 0.1718, d4.loss_bbox: 0.5261, loss: 4.4985, grad_norm: 28.2525
2025-06-20 09:27:58,252 - mmdet - INFO - Epoch [3][1550/7033]	lr: 1.501e-04, eta: 9:58:07, time: 1.350, data_time: 0.021, memory: 18168, loss_cls: 0.1603, loss_bbox: 0.5353, d0.loss_cls: 0.2224, d0.loss_bbox: 0.6538, d1.loss_cls: 0.1912, d1.loss_bbox: 0.6116, d2.loss_cls: 0.1855, d2.loss_bbox: 0.5631, d3.loss_cls: 0.1746, d3.loss_bbox: 0.5436, d4.loss_cls: 0.1647, d4.loss_bbox: 0.5343, loss: 4.5401, grad_norm: 43.8308
2025-06-20 09:29:05,784 - mmdet - INFO - Epoch [3][1600/7033]	lr: 1.501e-04, eta: 9:57:00, time: 1.351, data_time: 0.024, memory: 18168, loss_cls: 0.1629, loss_bbox: 0.5215, d0.loss_cls: 0.2297, d0.loss_bbox: 0.6812, d1.loss_cls: 0.1971, d1.loss_bbox: 0.6531, d2.loss_cls: 0.1902, d2.loss_bbox: 0.5741, d3.loss_cls: 0.1776, d3.loss_bbox: 0.5396, d4.loss_cls: 0.1671, d4.loss_bbox: 0.5259, loss: 4.6199, grad_norm: 40.6551
2025-06-20 09:30:13,475 - mmdet - INFO - Epoch [3][1650/7033]	lr: 1.501e-04, eta: 9:55:52, time: 1.354, data_time: 0.021, memory: 18168, loss_cls: 0.1604, loss_bbox: 0.5202, d0.loss_cls: 0.2276, d0.loss_bbox: 0.6534, d1.loss_cls: 0.1962, d1.loss_bbox: 0.6248, d2.loss_cls: 0.1822, d2.loss_bbox: 0.5748, d3.loss_cls: 0.1735, d3.loss_bbox: 0.5393, d4.loss_cls: 0.1667, d4.loss_bbox: 0.5244, loss: 4.5435, grad_norm: 30.2893
2025-06-20 09:31:21,156 - mmdet - INFO - Epoch [3][1700/7033]	lr: 1.501e-04, eta: 9:54:45, time: 1.354, data_time: 0.024, memory: 18168, loss_cls: 0.1502, loss_bbox: 0.5026, d0.loss_cls: 0.2153, d0.loss_bbox: 0.6123, d1.loss_cls: 0.1835, d1.loss_bbox: 0.5763, d2.loss_cls: 0.1735, d2.loss_bbox: 0.5319, d3.loss_cls: 0.1663, d3.loss_bbox: 0.5112, d4.loss_cls: 0.1567, d4.loss_bbox: 0.5039, loss: 4.2839, grad_norm: 37.0249
2025-06-20 09:32:28,696 - mmdet - INFO - Epoch [3][1750/7033]	lr: 1.501e-04, eta: 9:53:38, time: 1.351, data_time: 0.023, memory: 18168, loss_cls: 0.1521, loss_bbox: 0.4950, d0.loss_cls: 0.2111, d0.loss_bbox: 0.6332, d1.loss_cls: 0.1830, d1.loss_bbox: 0.5919, d2.loss_cls: 0.1726, d2.loss_bbox: 0.5407, d3.loss_cls: 0.1665, d3.loss_bbox: 0.5093, d4.loss_cls: 0.1606, d4.loss_bbox: 0.4933, loss: 4.3093, grad_norm: 28.9144
2025-06-20 09:33:57,662 - mmdet - INFO - Epoch [3][1800/7033]	lr: 1.501e-04, eta: 9:53:06, time: 1.779, data_time: 0.452, memory: 18168, loss_cls: 0.1560, loss_bbox: 0.5051, d0.loss_cls: 0.2168, d0.loss_bbox: 0.6322, d1.loss_cls: 0.1886, d1.loss_bbox: 0.5948, d2.loss_cls: 0.1767, d2.loss_bbox: 0.5419, d3.loss_cls: 0.1690, d3.loss_bbox: 0.5191, d4.loss_cls: 0.1620, d4.loss_bbox: 0.5072, loss: 4.3693, grad_norm: 32.1885
2025-06-20 09:35:05,256 - mmdet - INFO - Epoch [3][1850/7033]	lr: 1.501e-04, eta: 9:51:58, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1520, loss_bbox: 0.5171, d0.loss_cls: 0.2092, d0.loss_bbox: 0.6398, d1.loss_cls: 0.1795, d1.loss_bbox: 0.6049, d2.loss_cls: 0.1715, d2.loss_bbox: 0.5637, d3.loss_cls: 0.1662, d3.loss_bbox: 0.5332, d4.loss_cls: 0.1551, d4.loss_bbox: 0.5203, loss: 4.4126, grad_norm: 29.0626
2025-06-20 09:36:12,641 - mmdet - INFO - Epoch [3][1900/7033]	lr: 1.501e-04, eta: 9:50:50, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.1661, loss_bbox: 0.5466, d0.loss_cls: 0.2221, d0.loss_bbox: 0.6759, d1.loss_cls: 0.1971, d1.loss_bbox: 0.6349, d2.loss_cls: 0.1906, d2.loss_bbox: 0.5922, d3.loss_cls: 0.1805, d3.loss_bbox: 0.5646, d4.loss_cls: 0.1704, d4.loss_bbox: 0.5498, loss: 4.6906, grad_norm: 33.6438
2025-06-20 09:37:20,220 - mmdet - INFO - Epoch [3][1950/7033]	lr: 1.501e-04, eta: 9:49:43, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1591, loss_bbox: 0.5144, d0.loss_cls: 0.2132, d0.loss_bbox: 0.6387, d1.loss_cls: 0.1856, d1.loss_bbox: 0.5988, d2.loss_cls: 0.1817, d2.loss_bbox: 0.5583, d3.loss_cls: 0.1711, d3.loss_bbox: 0.5307, d4.loss_cls: 0.1611, d4.loss_bbox: 0.5205, loss: 4.4332, grad_norm: 34.2407
2025-06-20 09:38:27,463 - mmdet - INFO - Epoch [3][2000/7033]	lr: 1.501e-04, eta: 9:48:35, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.1559, loss_bbox: 0.5039, d0.loss_cls: 0.2107, d0.loss_bbox: 0.6293, d1.loss_cls: 0.1803, d1.loss_bbox: 0.5871, d2.loss_cls: 0.1736, d2.loss_bbox: 0.5396, d3.loss_cls: 0.1647, d3.loss_bbox: 0.5149, d4.loss_cls: 0.1597, d4.loss_bbox: 0.5056, loss: 4.3254, grad_norm: 28.6351
2025-06-20 09:39:36,741 - mmdet - INFO - Epoch [3][2050/7033]	lr: 1.501e-04, eta: 9:47:30, time: 1.386, data_time: 0.022, memory: 18168, loss_cls: 0.1591, loss_bbox: 0.5113, d0.loss_cls: 0.2166, d0.loss_bbox: 0.6283, d1.loss_cls: 0.1867, d1.loss_bbox: 0.5894, d2.loss_cls: 0.1794, d2.loss_bbox: 0.5425, d3.loss_cls: 0.1698, d3.loss_bbox: 0.5209, d4.loss_cls: 0.1610, d4.loss_bbox: 0.5130, loss: 4.3779, grad_norm: 35.3541
2025-06-20 09:40:43,988 - mmdet - INFO - Epoch [3][2100/7033]	lr: 1.501e-04, eta: 9:46:22, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.1773, loss_bbox: 0.5523, d0.loss_cls: 0.2335, d0.loss_bbox: 0.6749, d1.loss_cls: 0.2074, d1.loss_bbox: 0.6409, d2.loss_cls: 0.1958, d2.loss_bbox: 0.5983, d3.loss_cls: 0.1863, d3.loss_bbox: 0.5680, d4.loss_cls: 0.1776, d4.loss_bbox: 0.5570, loss: 4.7695, grad_norm: 51.8113
2025-06-20 09:41:51,307 - mmdet - INFO - Epoch [3][2150/7033]	lr: 1.501e-04, eta: 9:45:14, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1486, loss_bbox: 0.5292, d0.loss_cls: 0.2074, d0.loss_bbox: 0.6353, d1.loss_cls: 0.1783, d1.loss_bbox: 0.6049, d2.loss_cls: 0.1665, d2.loss_bbox: 0.5665, d3.loss_cls: 0.1588, d3.loss_bbox: 0.5426, d4.loss_cls: 0.1511, d4.loss_bbox: 0.5335, loss: 4.4229, grad_norm: 31.8722
2025-06-20 09:42:58,907 - mmdet - INFO - Epoch [3][2200/7033]	lr: 1.501e-04, eta: 9:44:06, time: 1.352, data_time: 0.023, memory: 18168, loss_cls: 0.1583, loss_bbox: 0.5136, d0.loss_cls: 0.2148, d0.loss_bbox: 0.6284, d1.loss_cls: 0.1875, d1.loss_bbox: 0.5952, d2.loss_cls: 0.1784, d2.loss_bbox: 0.5510, d3.loss_cls: 0.1696, d3.loss_bbox: 0.5281, d4.loss_cls: 0.1642, d4.loss_bbox: 0.5162, loss: 4.4054, grad_norm: 188.5369
2025-06-20 09:44:06,151 - mmdet - INFO - Epoch [3][2250/7033]	lr: 1.501e-04, eta: 9:42:58, time: 1.345, data_time: 0.021, memory: 18168, loss_cls: 0.1543, loss_bbox: 0.5139, d0.loss_cls: 0.2214, d0.loss_bbox: 0.6299, d1.loss_cls: 0.1876, d1.loss_bbox: 0.5986, d2.loss_cls: 0.1796, d2.loss_bbox: 0.5513, d3.loss_cls: 0.1669, d3.loss_bbox: 0.5292, d4.loss_cls: 0.1610, d4.loss_bbox: 0.5159, loss: 4.4096, grad_norm: 92.2196
2025-06-20 09:45:13,443 - mmdet - INFO - Epoch [3][2300/7033]	lr: 1.501e-04, eta: 9:41:50, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1685, loss_bbox: 0.5075, d0.loss_cls: 0.2279, d0.loss_bbox: 0.6612, d1.loss_cls: 0.1969, d1.loss_bbox: 0.6176, d2.loss_cls: 0.1902, d2.loss_bbox: 0.5434, d3.loss_cls: 0.1781, d3.loss_bbox: 0.5184, d4.loss_cls: 0.1715, d4.loss_bbox: 0.5077, loss: 4.4888, grad_norm: 34.2967
2025-06-20 09:46:20,751 - mmdet - INFO - Epoch [3][2350/7033]	lr: 1.501e-04, eta: 9:40:42, time: 1.346, data_time: 0.020, memory: 18168, loss_cls: 0.1698, loss_bbox: 0.5145, d0.loss_cls: 0.2389, d0.loss_bbox: 0.6511, d1.loss_cls: 0.2058, d1.loss_bbox: 0.6150, d2.loss_cls: 0.1915, d2.loss_bbox: 0.5623, d3.loss_cls: 0.1773, d3.loss_bbox: 0.5336, d4.loss_cls: 0.1739, d4.loss_bbox: 0.5180, loss: 4.5516, grad_norm: 39.1392
2025-06-20 09:47:28,493 - mmdet - INFO - Epoch [3][2400/7033]	lr: 1.501e-04, eta: 9:39:35, time: 1.355, data_time: 0.023, memory: 18168, loss_cls: 0.1630, loss_bbox: 0.5178, d0.loss_cls: 0.2234, d0.loss_bbox: 0.6362, d1.loss_cls: 0.1954, d1.loss_bbox: 0.6020, d2.loss_cls: 0.1836, d2.loss_bbox: 0.5543, d3.loss_cls: 0.1726, d3.loss_bbox: 0.5309, d4.loss_cls: 0.1705, d4.loss_bbox: 0.5170, loss: 4.4667, grad_norm: 52.9892
2025-06-20 09:48:36,073 - mmdet - INFO - Epoch [3][2450/7033]	lr: 1.501e-04, eta: 9:38:27, time: 1.352, data_time: 0.023, memory: 18168, loss_cls: 0.1610, loss_bbox: 0.5221, d0.loss_cls: 0.2305, d0.loss_bbox: 0.6497, d1.loss_cls: 0.1955, d1.loss_bbox: 0.6069, d2.loss_cls: 0.1819, d2.loss_bbox: 0.5591, d3.loss_cls: 0.1701, d3.loss_bbox: 0.5362, d4.loss_cls: 0.1651, d4.loss_bbox: 0.5244, loss: 4.5025, grad_norm: 58.4052
2025-06-20 09:49:43,135 - mmdet - INFO - Epoch [3][2500/7033]	lr: 1.501e-04, eta: 9:37:19, time: 1.341, data_time: 0.022, memory: 18168, loss_cls: 0.1524, loss_bbox: 0.5107, d0.loss_cls: 0.2162, d0.loss_bbox: 0.6106, d1.loss_cls: 0.1912, d1.loss_bbox: 0.5710, d2.loss_cls: 0.1773, d2.loss_bbox: 0.5357, d3.loss_cls: 0.1635, d3.loss_bbox: 0.5233, d4.loss_cls: 0.1541, d4.loss_bbox: 0.5153, loss: 4.3214, grad_norm: 30.8541
2025-06-20 09:50:50,613 - mmdet - INFO - Epoch [3][2550/7033]	lr: 1.501e-04, eta: 9:36:11, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.1553, loss_bbox: 0.5121, d0.loss_cls: 0.2187, d0.loss_bbox: 0.6211, d1.loss_cls: 0.1860, d1.loss_bbox: 0.5897, d2.loss_cls: 0.1759, d2.loss_bbox: 0.5478, d3.loss_cls: 0.1666, d3.loss_bbox: 0.5221, d4.loss_cls: 0.1579, d4.loss_bbox: 0.5118, loss: 4.3652, grad_norm: 34.2554
2025-06-20 09:51:58,105 - mmdet - INFO - Epoch [3][2600/7033]	lr: 1.501e-04, eta: 9:35:04, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.1528, loss_bbox: 0.5283, d0.loss_cls: 0.2230, d0.loss_bbox: 0.6508, d1.loss_cls: 0.1871, d1.loss_bbox: 0.6110, d2.loss_cls: 0.1740, d2.loss_bbox: 0.5634, d3.loss_cls: 0.1627, d3.loss_bbox: 0.5398, d4.loss_cls: 0.1569, d4.loss_bbox: 0.5309, loss: 4.4808, grad_norm: 29.4980
2025-06-20 09:53:05,532 - mmdet - INFO - Epoch [3][2650/7033]	lr: 1.501e-04, eta: 9:33:56, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1483, loss_bbox: 0.4794, d0.loss_cls: 0.2050, d0.loss_bbox: 0.6013, d1.loss_cls: 0.1803, d1.loss_bbox: 0.5603, d2.loss_cls: 0.1703, d2.loss_bbox: 0.5135, d3.loss_cls: 0.1640, d3.loss_bbox: 0.4896, d4.loss_cls: 0.1551, d4.loss_bbox: 0.4799, loss: 4.1468, grad_norm: 28.0462
2025-06-20 09:54:13,138 - mmdet - INFO - Epoch [3][2700/7033]	lr: 1.501e-04, eta: 9:32:48, time: 1.352, data_time: 0.021, memory: 18168, loss_cls: 0.1591, loss_bbox: 0.5193, d0.loss_cls: 0.2157, d0.loss_bbox: 0.6295, d1.loss_cls: 0.1921, d1.loss_bbox: 0.5915, d2.loss_cls: 0.1842, d2.loss_bbox: 0.5569, d3.loss_cls: 0.1718, d3.loss_bbox: 0.5311, d4.loss_cls: 0.1640, d4.loss_bbox: 0.5195, loss: 4.4346, grad_norm: 30.9200
2025-06-20 09:55:20,686 - mmdet - INFO - Epoch [3][2750/7033]	lr: 1.501e-04, eta: 9:31:41, time: 1.351, data_time: 0.022, memory: 18168, loss_cls: 0.1573, loss_bbox: 0.4855, d0.loss_cls: 0.2236, d0.loss_bbox: 0.5918, d1.loss_cls: 0.1889, d1.loss_bbox: 0.5580, d2.loss_cls: 0.1760, d2.loss_bbox: 0.5239, d3.loss_cls: 0.1650, d3.loss_bbox: 0.5044, d4.loss_cls: 0.1590, d4.loss_bbox: 0.4896, loss: 4.2231, grad_norm: 32.0157
2025-06-20 09:56:28,742 - mmdet - INFO - Epoch [3][2800/7033]	lr: 1.501e-04, eta: 9:30:34, time: 1.361, data_time: 0.032, memory: 18168, loss_cls: 0.1664, loss_bbox: 0.5471, d0.loss_cls: 0.2189, d0.loss_bbox: 0.6549, d1.loss_cls: 0.1943, d1.loss_bbox: 0.6210, d2.loss_cls: 0.1837, d2.loss_bbox: 0.5872, d3.loss_cls: 0.1728, d3.loss_bbox: 0.5684, d4.loss_cls: 0.1697, d4.loss_bbox: 0.5505, loss: 4.6349, grad_norm: 34.6688
2025-06-20 09:57:35,911 - mmdet - INFO - Epoch [3][2850/7033]	lr: 1.501e-04, eta: 9:29:26, time: 1.343, data_time: 0.021, memory: 18168, loss_cls: 0.1628, loss_bbox: 0.5223, d0.loss_cls: 0.2236, d0.loss_bbox: 0.6328, d1.loss_cls: 0.1942, d1.loss_bbox: 0.5972, d2.loss_cls: 0.1831, d2.loss_bbox: 0.5548, d3.loss_cls: 0.1720, d3.loss_bbox: 0.5346, d4.loss_cls: 0.1680, d4.loss_bbox: 0.5251, loss: 4.4704, grad_norm: 32.5657
2025-06-20 09:58:43,266 - mmdet - INFO - Epoch [3][2900/7033]	lr: 1.501e-04, eta: 9:28:18, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1552, loss_bbox: 0.5285, d0.loss_cls: 0.2200, d0.loss_bbox: 0.6395, d1.loss_cls: 0.1877, d1.loss_bbox: 0.5987, d2.loss_cls: 0.1754, d2.loss_bbox: 0.5555, d3.loss_cls: 0.1691, d3.loss_bbox: 0.5363, d4.loss_cls: 0.1596, d4.loss_bbox: 0.5277, loss: 4.4531, grad_norm: 41.8396
2025-06-20 09:59:50,775 - mmdet - INFO - Epoch [3][2950/7033]	lr: 1.501e-04, eta: 9:27:10, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1502, loss_bbox: 0.4995, d0.loss_cls: 0.2169, d0.loss_bbox: 0.6149, d1.loss_cls: 0.1811, d1.loss_bbox: 0.5924, d2.loss_cls: 0.1702, d2.loss_bbox: 0.5374, d3.loss_cls: 0.1592, d3.loss_bbox: 0.5153, d4.loss_cls: 0.1541, d4.loss_bbox: 0.5022, loss: 4.2934, grad_norm: 32.5572
2025-06-20 10:00:58,276 - mmdet - INFO - Epoch [3][3000/7033]	lr: 1.501e-04, eta: 9:26:02, time: 1.350, data_time: 0.023, memory: 18168, loss_cls: 0.1500, loss_bbox: 0.5127, d0.loss_cls: 0.2106, d0.loss_bbox: 0.6279, d1.loss_cls: 0.1803, d1.loss_bbox: 0.5973, d2.loss_cls: 0.1729, d2.loss_bbox: 0.5368, d3.loss_cls: 0.1615, d3.loss_bbox: 0.5258, d4.loss_cls: 0.1557, d4.loss_bbox: 0.5133, loss: 4.3447, grad_norm: 49.2034
2025-06-20 10:02:06,022 - mmdet - INFO - Epoch [3][3050/7033]	lr: 1.501e-04, eta: 9:24:55, time: 1.355, data_time: 0.024, memory: 18168, loss_cls: 0.1577, loss_bbox: 0.5372, d0.loss_cls: 0.2236, d0.loss_bbox: 0.6676, d1.loss_cls: 0.1876, d1.loss_bbox: 0.6306, d2.loss_cls: 0.1815, d2.loss_bbox: 0.5758, d3.loss_cls: 0.1711, d3.loss_bbox: 0.5496, d4.loss_cls: 0.1627, d4.loss_bbox: 0.5379, loss: 4.5828, grad_norm: 61.7374
2025-06-20 10:03:13,497 - mmdet - INFO - Epoch [3][3100/7033]	lr: 1.501e-04, eta: 9:23:47, time: 1.349, data_time: 0.022, memory: 18168, loss_cls: 0.1595, loss_bbox: 0.5098, d0.loss_cls: 0.2237, d0.loss_bbox: 0.6456, d1.loss_cls: 0.1978, d1.loss_bbox: 0.5974, d2.loss_cls: 0.1892, d2.loss_bbox: 0.5477, d3.loss_cls: 0.1774, d3.loss_bbox: 0.5196, d4.loss_cls: 0.1674, d4.loss_bbox: 0.5111, loss: 4.4462, grad_norm: 37.3263
2025-06-20 10:04:22,776 - mmdet - INFO - Epoch [3][3150/7033]	lr: 1.501e-04, eta: 9:22:42, time: 1.386, data_time: 0.024, memory: 18168, loss_cls: 0.1500, loss_bbox: 0.5049, d0.loss_cls: 0.2091, d0.loss_bbox: 0.6597, d1.loss_cls: 0.1796, d1.loss_bbox: 0.6178, d2.loss_cls: 0.1721, d2.loss_bbox: 0.5558, d3.loss_cls: 0.1591, d3.loss_bbox: 0.5237, d4.loss_cls: 0.1545, d4.loss_bbox: 0.5066, loss: 4.3929, grad_norm: 32.7597
2025-06-20 10:05:30,125 - mmdet - INFO - Epoch [3][3200/7033]	lr: 1.501e-04, eta: 9:21:34, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1580, loss_bbox: 0.5180, d0.loss_cls: 0.2171, d0.loss_bbox: 0.6260, d1.loss_cls: 0.1871, d1.loss_bbox: 0.5923, d2.loss_cls: 0.1781, d2.loss_bbox: 0.5441, d3.loss_cls: 0.1685, d3.loss_bbox: 0.5247, d4.loss_cls: 0.1645, d4.loss_bbox: 0.5180, loss: 4.3964, grad_norm: 37.6199
2025-06-20 10:06:37,787 - mmdet - INFO - Epoch [3][3250/7033]	lr: 1.501e-04, eta: 9:20:27, time: 1.353, data_time: 0.024, memory: 18168, loss_cls: 0.1545, loss_bbox: 0.5016, d0.loss_cls: 0.2215, d0.loss_bbox: 0.6477, d1.loss_cls: 0.1878, d1.loss_bbox: 0.6075, d2.loss_cls: 0.1816, d2.loss_bbox: 0.5380, d3.loss_cls: 0.1675, d3.loss_bbox: 0.5131, d4.loss_cls: 0.1604, d4.loss_bbox: 0.5019, loss: 4.3833, grad_norm: 32.1747
2025-06-20 10:07:45,155 - mmdet - INFO - Epoch [3][3300/7033]	lr: 1.501e-04, eta: 9:19:19, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1645, loss_bbox: 0.5245, d0.loss_cls: 0.2251, d0.loss_bbox: 0.6531, d1.loss_cls: 0.1912, d1.loss_bbox: 0.6118, d2.loss_cls: 0.1843, d2.loss_bbox: 0.5610, d3.loss_cls: 0.1748, d3.loss_bbox: 0.5389, d4.loss_cls: 0.1678, d4.loss_bbox: 0.5280, loss: 4.5249, grad_norm: 32.0652
2025-06-20 10:08:52,794 - mmdet - INFO - Epoch [3][3350/7033]	lr: 1.501e-04, eta: 9:18:12, time: 1.353, data_time: 0.022, memory: 18168, loss_cls: 0.1593, loss_bbox: 0.5170, d0.loss_cls: 0.2205, d0.loss_bbox: 0.6454, d1.loss_cls: 0.1892, d1.loss_bbox: 0.6101, d2.loss_cls: 0.1816, d2.loss_bbox: 0.5591, d3.loss_cls: 0.1714, d3.loss_bbox: 0.5310, d4.loss_cls: 0.1626, d4.loss_bbox: 0.5194, loss: 4.4666, grad_norm: 39.9220
2025-06-20 10:10:00,516 - mmdet - INFO - Epoch [3][3400/7033]	lr: 1.501e-04, eta: 9:17:04, time: 1.354, data_time: 0.023, memory: 18168, loss_cls: 0.1652, loss_bbox: 0.5335, d0.loss_cls: 0.2214, d0.loss_bbox: 0.6566, d1.loss_cls: 0.1907, d1.loss_bbox: 0.6044, d2.loss_cls: 0.1851, d2.loss_bbox: 0.5642, d3.loss_cls: 0.1784, d3.loss_bbox: 0.5385, d4.loss_cls: 0.1704, d4.loss_bbox: 0.5304, loss: 4.5387, grad_norm: 37.7185
2025-06-20 10:11:08,043 - mmdet - INFO - Epoch [3][3450/7033]	lr: 1.501e-04, eta: 9:15:57, time: 1.351, data_time: 0.023, memory: 18168, loss_cls: 0.1533, loss_bbox: 0.5254, d0.loss_cls: 0.2161, d0.loss_bbox: 0.6260, d1.loss_cls: 0.1835, d1.loss_bbox: 0.5935, d2.loss_cls: 0.1709, d2.loss_bbox: 0.5588, d3.loss_cls: 0.1666, d3.loss_bbox: 0.5338, d4.loss_cls: 0.1593, d4.loss_bbox: 0.5265, loss: 4.4139, grad_norm: 64.0831
2025-06-20 10:12:15,713 - mmdet - INFO - Epoch [3][3500/7033]	lr: 1.501e-04, eta: 9:14:49, time: 1.353, data_time: 0.025, memory: 18168, loss_cls: 0.1529, loss_bbox: 0.5128, d0.loss_cls: 0.2169, d0.loss_bbox: 0.6473, d1.loss_cls: 0.1887, d1.loss_bbox: 0.6048, d2.loss_cls: 0.1768, d2.loss_bbox: 0.5518, d3.loss_cls: 0.1684, d3.loss_bbox: 0.5244, d4.loss_cls: 0.1587, d4.loss_bbox: 0.5128, loss: 4.4162, grad_norm: 31.0365
2025-06-20 10:13:23,226 - mmdet - INFO - Epoch [3][3550/7033]	lr: 1.501e-04, eta: 9:13:41, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.1466, loss_bbox: 0.5102, d0.loss_cls: 0.2076, d0.loss_bbox: 0.6261, d1.loss_cls: 0.1781, d1.loss_bbox: 0.5847, d2.loss_cls: 0.1691, d2.loss_bbox: 0.5380, d3.loss_cls: 0.1588, d3.loss_bbox: 0.5168, d4.loss_cls: 0.1546, d4.loss_bbox: 0.5088, loss: 4.2994, grad_norm: 28.2700
2025-06-20 10:14:30,651 - mmdet - INFO - Epoch [3][3600/7033]	lr: 1.501e-04, eta: 9:12:34, time: 1.349, data_time: 0.024, memory: 18168, loss_cls: 0.1520, loss_bbox: 0.5113, d0.loss_cls: 0.2142, d0.loss_bbox: 0.6234, d1.loss_cls: 0.1815, d1.loss_bbox: 0.5871, d2.loss_cls: 0.1725, d2.loss_bbox: 0.5411, d3.loss_cls: 0.1622, d3.loss_bbox: 0.5194, d4.loss_cls: 0.1578, d4.loss_bbox: 0.5110, loss: 4.3336, grad_norm: 60.6165
2025-06-20 10:15:37,899 - mmdet - INFO - Epoch [3][3650/7033]	lr: 1.501e-04, eta: 9:11:26, time: 1.345, data_time: 0.023, memory: 18168, loss_cls: 0.1592, loss_bbox: 0.5257, d0.loss_cls: 0.2235, d0.loss_bbox: 0.6567, d1.loss_cls: 0.1946, d1.loss_bbox: 0.6132, d2.loss_cls: 0.1810, d2.loss_bbox: 0.5661, d3.loss_cls: 0.1721, d3.loss_bbox: 0.5401, d4.loss_cls: 0.1652, d4.loss_bbox: 0.5274, loss: 4.5248, grad_norm: 34.7343
2025-06-20 10:16:45,814 - mmdet - INFO - Epoch [3][3700/7033]	lr: 1.501e-04, eta: 9:10:19, time: 1.358, data_time: 0.022, memory: 18168, loss_cls: 0.1806, loss_bbox: 0.5278, d0.loss_cls: 0.2421, d0.loss_bbox: 0.6546, d1.loss_cls: 0.2130, d1.loss_bbox: 0.6171, d2.loss_cls: 0.2006, d2.loss_bbox: 0.5635, d3.loss_cls: 0.1912, d3.loss_bbox: 0.5388, d4.loss_cls: 0.1874, d4.loss_bbox: 0.5265, loss: 4.6432, grad_norm: 41.8310
2025-06-20 10:17:54,788 - mmdet - INFO - Epoch [3][3750/7033]	lr: 1.501e-04, eta: 9:09:13, time: 1.379, data_time: 0.020, memory: 18168, loss_cls: 0.1467, loss_bbox: 0.5340, d0.loss_cls: 0.2164, d0.loss_bbox: 0.6411, d1.loss_cls: 0.1839, d1.loss_bbox: 0.6059, d2.loss_cls: 0.1726, d2.loss_bbox: 0.5665, d3.loss_cls: 0.1614, d3.loss_bbox: 0.5434, d4.loss_cls: 0.1547, d4.loss_bbox: 0.5345, loss: 4.4612, grad_norm: 35.3100
2025-06-20 10:19:02,528 - mmdet - INFO - Epoch [3][3800/7033]	lr: 1.501e-04, eta: 9:08:06, time: 1.355, data_time: 0.022, memory: 18168, loss_cls: 0.1544, loss_bbox: 0.5145, d0.loss_cls: 0.2212, d0.loss_bbox: 0.6185, d1.loss_cls: 0.1919, d1.loss_bbox: 0.5830, d2.loss_cls: 0.1797, d2.loss_bbox: 0.5462, d3.loss_cls: 0.1701, d3.loss_bbox: 0.5242, d4.loss_cls: 0.1614, d4.loss_bbox: 0.5150, loss: 4.3800, grad_norm: 32.3104
2025-06-20 10:20:09,847 - mmdet - INFO - Epoch [3][3850/7033]	lr: 1.501e-04, eta: 9:06:58, time: 1.346, data_time: 0.023, memory: 18168, loss_cls: 0.1702, loss_bbox: 0.5379, d0.loss_cls: 0.2257, d0.loss_bbox: 0.6336, d1.loss_cls: 0.1980, d1.loss_bbox: 0.5988, d2.loss_cls: 0.1923, d2.loss_bbox: 0.5617, d3.loss_cls: 0.1818, d3.loss_bbox: 0.5426, d4.loss_cls: 0.1793, d4.loss_bbox: 0.5336, loss: 4.5555, grad_norm: 30.1411
2025-06-20 10:21:17,158 - mmdet - INFO - Epoch [3][3900/7033]	lr: 1.501e-04, eta: 9:05:50, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1634, loss_bbox: 0.5408, d0.loss_cls: 0.2261, d0.loss_bbox: 0.6294, d1.loss_cls: 0.1915, d1.loss_bbox: 0.5936, d2.loss_cls: 0.1820, d2.loss_bbox: 0.5640, d3.loss_cls: 0.1744, d3.loss_bbox: 0.5455, d4.loss_cls: 0.1638, d4.loss_bbox: 0.5394, loss: 4.5139, grad_norm: 45.1985
2025-06-20 10:22:24,747 - mmdet - INFO - Epoch [3][3950/7033]	lr: 1.501e-04, eta: 9:04:42, time: 1.352, data_time: 0.022, memory: 18168, loss_cls: 0.1563, loss_bbox: 0.5145, d0.loss_cls: 0.2156, d0.loss_bbox: 0.6390, d1.loss_cls: 0.1838, d1.loss_bbox: 0.6037, d2.loss_cls: 0.1770, d2.loss_bbox: 0.5513, d3.loss_cls: 0.1661, d3.loss_bbox: 0.5263, d4.loss_cls: 0.1603, d4.loss_bbox: 0.5136, loss: 4.4073, grad_norm: 32.5222
2025-06-20 10:23:32,100 - mmdet - INFO - Epoch [3][4000/7033]	lr: 1.501e-04, eta: 9:03:34, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1495, loss_bbox: 0.4910, d0.loss_cls: 0.2103, d0.loss_bbox: 0.6185, d1.loss_cls: 0.1830, d1.loss_bbox: 0.5713, d2.loss_cls: 0.1706, d2.loss_bbox: 0.5318, d3.loss_cls: 0.1643, d3.loss_bbox: 0.5008, d4.loss_cls: 0.1552, d4.loss_bbox: 0.4905, loss: 4.2369, grad_norm: 200.5918
2025-06-20 10:24:39,754 - mmdet - INFO - Epoch [3][4050/7033]	lr: 1.501e-04, eta: 9:02:27, time: 1.353, data_time: 0.023, memory: 18168, loss_cls: 0.1520, loss_bbox: 0.4944, d0.loss_cls: 0.2170, d0.loss_bbox: 0.6196, d1.loss_cls: 0.1824, d1.loss_bbox: 0.5776, d2.loss_cls: 0.1724, d2.loss_bbox: 0.5324, d3.loss_cls: 0.1631, d3.loss_bbox: 0.5100, d4.loss_cls: 0.1551, d4.loss_bbox: 0.4989, loss: 4.2749, grad_norm: 33.8353
2025-06-20 10:25:47,344 - mmdet - INFO - Epoch [3][4100/7033]	lr: 1.501e-04, eta: 9:01:19, time: 1.352, data_time: 0.022, memory: 18168, loss_cls: 0.1541, loss_bbox: 0.5079, d0.loss_cls: 0.2107, d0.loss_bbox: 0.6175, d1.loss_cls: 0.1763, d1.loss_bbox: 0.5807, d2.loss_cls: 0.1672, d2.loss_bbox: 0.5376, d3.loss_cls: 0.1632, d3.loss_bbox: 0.5151, d4.loss_cls: 0.1579, d4.loss_bbox: 0.5085, loss: 4.2967, grad_norm: 64.5523
2025-06-20 10:26:54,687 - mmdet - INFO - Epoch [3][4150/7033]	lr: 1.501e-04, eta: 9:00:11, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1505, loss_bbox: 0.5189, d0.loss_cls: 0.2085, d0.loss_bbox: 0.6050, d1.loss_cls: 0.1778, d1.loss_bbox: 0.5679, d2.loss_cls: 0.1705, d2.loss_bbox: 0.5383, d3.loss_cls: 0.1647, d3.loss_bbox: 0.5174, d4.loss_cls: 0.1540, d4.loss_bbox: 0.5156, loss: 4.2891, grad_norm: 58.1213
2025-06-20 10:28:01,974 - mmdet - INFO - Epoch [3][4200/7033]	lr: 1.501e-04, eta: 8:59:03, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1602, loss_bbox: 0.5140, d0.loss_cls: 0.2148, d0.loss_bbox: 0.6493, d1.loss_cls: 0.1847, d1.loss_bbox: 0.5984, d2.loss_cls: 0.1787, d2.loss_bbox: 0.5490, d3.loss_cls: 0.1748, d3.loss_bbox: 0.5201, d4.loss_cls: 0.1654, d4.loss_bbox: 0.5128, loss: 4.4220, grad_norm: 96.5954
2025-06-20 10:29:09,636 - mmdet - INFO - Epoch [3][4250/7033]	lr: 1.501e-04, eta: 8:57:56, time: 1.353, data_time: 0.021, memory: 18168, loss_cls: 0.1646, loss_bbox: 0.5189, d0.loss_cls: 0.2213, d0.loss_bbox: 0.6450, d1.loss_cls: 0.1879, d1.loss_bbox: 0.6035, d2.loss_cls: 0.1784, d2.loss_bbox: 0.5593, d3.loss_cls: 0.1760, d3.loss_bbox: 0.5303, d4.loss_cls: 0.1674, d4.loss_bbox: 0.5227, loss: 4.4752, grad_norm: 34.1155
2025-06-20 10:30:17,210 - mmdet - INFO - Epoch [3][4300/7033]	lr: 1.501e-04, eta: 8:56:48, time: 1.352, data_time: 0.021, memory: 18168, loss_cls: 0.1525, loss_bbox: 0.5243, d0.loss_cls: 0.2099, d0.loss_bbox: 0.6212, d1.loss_cls: 0.1794, d1.loss_bbox: 0.5812, d2.loss_cls: 0.1713, d2.loss_bbox: 0.5532, d3.loss_cls: 0.1629, d3.loss_bbox: 0.5337, d4.loss_cls: 0.1556, d4.loss_bbox: 0.5271, loss: 4.3724, grad_norm: 43.2840
2025-06-20 10:31:24,741 - mmdet - INFO - Epoch [3][4350/7033]	lr: 1.501e-04, eta: 8:55:41, time: 1.351, data_time: 0.021, memory: 18168, loss_cls: 0.1684, loss_bbox: 0.5197, d0.loss_cls: 0.2298, d0.loss_bbox: 0.6323, d1.loss_cls: 0.1986, d1.loss_bbox: 0.5905, d2.loss_cls: 0.1881, d2.loss_bbox: 0.5543, d3.loss_cls: 0.1795, d3.loss_bbox: 0.5320, d4.loss_cls: 0.1727, d4.loss_bbox: 0.5206, loss: 4.4865, grad_norm: 35.9543
2025-06-20 10:32:32,127 - mmdet - INFO - Epoch [3][4400/7033]	lr: 1.501e-04, eta: 8:54:33, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.1559, loss_bbox: 0.4997, d0.loss_cls: 0.2189, d0.loss_bbox: 0.6100, d1.loss_cls: 0.1858, d1.loss_bbox: 0.5718, d2.loss_cls: 0.1741, d2.loss_bbox: 0.5356, d3.loss_cls: 0.1660, d3.loss_bbox: 0.5135, d4.loss_cls: 0.1599, d4.loss_bbox: 0.4997, loss: 4.2908, grad_norm: 53.2654
2025-06-20 10:33:39,544 - mmdet - INFO - Epoch [3][4450/7033]	lr: 1.501e-04, eta: 8:53:25, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1435, loss_bbox: 0.4963, d0.loss_cls: 0.2025, d0.loss_bbox: 0.6003, d1.loss_cls: 0.1704, d1.loss_bbox: 0.5558, d2.loss_cls: 0.1610, d2.loss_bbox: 0.5203, d3.loss_cls: 0.1535, d3.loss_bbox: 0.5041, d4.loss_cls: 0.1466, d4.loss_bbox: 0.4945, loss: 4.1490, grad_norm: 42.5839
2025-06-20 10:34:46,992 - mmdet - INFO - Epoch [3][4500/7033]	lr: 1.501e-04, eta: 8:52:17, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1569, loss_bbox: 0.5003, d0.loss_cls: 0.2115, d0.loss_bbox: 0.6065, d1.loss_cls: 0.1793, d1.loss_bbox: 0.5698, d2.loss_cls: 0.1740, d2.loss_bbox: 0.5333, d3.loss_cls: 0.1688, d3.loss_bbox: 0.5118, d4.loss_cls: 0.1604, d4.loss_bbox: 0.5027, loss: 4.2753, grad_norm: 49.3266
2025-06-20 10:35:54,478 - mmdet - INFO - Epoch [3][4550/7033]	lr: 1.501e-04, eta: 8:51:10, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1599, loss_bbox: 0.5202, d0.loss_cls: 0.2174, d0.loss_bbox: 0.6295, d1.loss_cls: 0.1851, d1.loss_bbox: 0.5918, d2.loss_cls: 0.1761, d2.loss_bbox: 0.5578, d3.loss_cls: 0.1707, d3.loss_bbox: 0.5319, d4.loss_cls: 0.1653, d4.loss_bbox: 0.5240, loss: 4.4297, grad_norm: 35.2423
2025-06-20 10:37:02,068 - mmdet - INFO - Epoch [3][4600/7033]	lr: 1.501e-04, eta: 8:50:02, time: 1.352, data_time: 0.024, memory: 18168, loss_cls: 0.1508, loss_bbox: 0.4996, d0.loss_cls: 0.2114, d0.loss_bbox: 0.6143, d1.loss_cls: 0.1804, d1.loss_bbox: 0.5786, d2.loss_cls: 0.1664, d2.loss_bbox: 0.5395, d3.loss_cls: 0.1598, d3.loss_bbox: 0.5098, d4.loss_cls: 0.1561, d4.loss_bbox: 0.4995, loss: 4.2663, grad_norm: 49.0660
2025-06-20 10:38:10,639 - mmdet - INFO - Epoch [3][4650/7033]	lr: 1.501e-04, eta: 8:48:56, time: 1.371, data_time: 0.044, memory: 18168, loss_cls: 0.1507, loss_bbox: 0.5093, d0.loss_cls: 0.2042, d0.loss_bbox: 0.6138, d1.loss_cls: 0.1749, d1.loss_bbox: 0.5743, d2.loss_cls: 0.1681, d2.loss_bbox: 0.5424, d3.loss_cls: 0.1631, d3.loss_bbox: 0.5209, d4.loss_cls: 0.1551, d4.loss_bbox: 0.5124, loss: 4.2892, grad_norm: 33.2692
2025-06-20 10:39:18,068 - mmdet - INFO - Epoch [3][4700/7033]	lr: 1.501e-04, eta: 8:47:48, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1565, loss_bbox: 0.5215, d0.loss_cls: 0.2138, d0.loss_bbox: 0.6386, d1.loss_cls: 0.1798, d1.loss_bbox: 0.6048, d2.loss_cls: 0.1718, d2.loss_bbox: 0.5662, d3.loss_cls: 0.1667, d3.loss_bbox: 0.5367, d4.loss_cls: 0.1582, d4.loss_bbox: 0.5280, loss: 4.4425, grad_norm: 72.1408
2025-06-20 10:40:25,356 - mmdet - INFO - Epoch [3][4750/7033]	lr: 1.501e-04, eta: 8:46:40, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1631, loss_bbox: 0.4981, d0.loss_cls: 0.2177, d0.loss_bbox: 0.5992, d1.loss_cls: 0.1825, d1.loss_bbox: 0.5700, d2.loss_cls: 0.1758, d2.loss_bbox: 0.5310, d3.loss_cls: 0.1703, d3.loss_bbox: 0.5066, d4.loss_cls: 0.1637, d4.loss_bbox: 0.5004, loss: 4.2786, grad_norm: 41.5043
2025-06-20 10:41:32,752 - mmdet - INFO - Epoch [3][4800/7033]	lr: 1.501e-04, eta: 8:45:32, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.1560, loss_bbox: 0.5122, d0.loss_cls: 0.2174, d0.loss_bbox: 0.6237, d1.loss_cls: 0.1858, d1.loss_bbox: 0.5828, d2.loss_cls: 0.1740, d2.loss_bbox: 0.5479, d3.loss_cls: 0.1686, d3.loss_bbox: 0.5218, d4.loss_cls: 0.1610, d4.loss_bbox: 0.5144, loss: 4.3655, grad_norm: 54.1666
2025-06-20 10:42:41,743 - mmdet - INFO - Epoch [3][4850/7033]	lr: 1.501e-04, eta: 8:44:27, time: 1.380, data_time: 0.021, memory: 18168, loss_cls: 0.1484, loss_bbox: 0.5112, d0.loss_cls: 0.2103, d0.loss_bbox: 0.6072, d1.loss_cls: 0.1833, d1.loss_bbox: 0.5738, d2.loss_cls: 0.1711, d2.loss_bbox: 0.5385, d3.loss_cls: 0.1599, d3.loss_bbox: 0.5196, d4.loss_cls: 0.1523, d4.loss_bbox: 0.5117, loss: 4.2873, grad_norm: 35.7071
2025-06-20 10:43:56,263 - mmdet - INFO - Epoch [3][4900/7033]	lr: 1.501e-04, eta: 8:43:27, time: 1.490, data_time: 0.022, memory: 18168, loss_cls: 0.1527, loss_bbox: 0.5295, d0.loss_cls: 0.2110, d0.loss_bbox: 0.6061, d1.loss_cls: 0.1831, d1.loss_bbox: 0.5783, d2.loss_cls: 0.1751, d2.loss_bbox: 0.5523, d3.loss_cls: 0.1655, d3.loss_bbox: 0.5374, d4.loss_cls: 0.1564, d4.loss_bbox: 0.5319, loss: 4.3793, grad_norm: 36.6503
2025-06-20 10:45:03,838 - mmdet - INFO - Epoch [3][4950/7033]	lr: 1.501e-04, eta: 8:42:20, time: 1.351, data_time: 0.025, memory: 18168, loss_cls: 0.1457, loss_bbox: 0.5013, d0.loss_cls: 0.2115, d0.loss_bbox: 0.6327, d1.loss_cls: 0.1758, d1.loss_bbox: 0.5882, d2.loss_cls: 0.1667, d2.loss_bbox: 0.5395, d3.loss_cls: 0.1591, d3.loss_bbox: 0.5126, d4.loss_cls: 0.1505, d4.loss_bbox: 0.5005, loss: 4.2842, grad_norm: 34.3783
2025-06-20 10:46:11,049 - mmdet - INFO - Epoch [3][5000/7033]	lr: 1.501e-04, eta: 8:41:12, time: 1.344, data_time: 0.021, memory: 18168, loss_cls: 0.1561, loss_bbox: 0.5232, d0.loss_cls: 0.2186, d0.loss_bbox: 0.6419, d1.loss_cls: 0.1815, d1.loss_bbox: 0.6011, d2.loss_cls: 0.1730, d2.loss_bbox: 0.5515, d3.loss_cls: 0.1677, d3.loss_bbox: 0.5304, d4.loss_cls: 0.1626, d4.loss_bbox: 0.5233, loss: 4.4309, grad_norm: 46.7480
2025-06-20 10:47:18,439 - mmdet - INFO - Epoch [3][5050/7033]	lr: 1.501e-04, eta: 8:40:04, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.1567, loss_bbox: 0.5139, d0.loss_cls: 0.2144, d0.loss_bbox: 0.6259, d1.loss_cls: 0.1781, d1.loss_bbox: 0.5871, d2.loss_cls: 0.1709, d2.loss_bbox: 0.5472, d3.loss_cls: 0.1659, d3.loss_bbox: 0.5267, d4.loss_cls: 0.1601, d4.loss_bbox: 0.5164, loss: 4.3633, grad_norm: 33.1634
2025-06-20 10:48:25,842 - mmdet - INFO - Epoch [3][5100/7033]	lr: 1.501e-04, eta: 8:38:56, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1465, loss_bbox: 0.5112, d0.loss_cls: 0.2083, d0.loss_bbox: 0.6178, d1.loss_cls: 0.1744, d1.loss_bbox: 0.5791, d2.loss_cls: 0.1626, d2.loss_bbox: 0.5401, d3.loss_cls: 0.1551, d3.loss_bbox: 0.5201, d4.loss_cls: 0.1510, d4.loss_bbox: 0.5122, loss: 4.2782, grad_norm: 54.9406
2025-06-20 10:49:33,194 - mmdet - INFO - Epoch [3][5150/7033]	lr: 1.501e-04, eta: 8:37:48, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1480, loss_bbox: 0.5324, d0.loss_cls: 0.2079, d0.loss_bbox: 0.6308, d1.loss_cls: 0.1749, d1.loss_bbox: 0.5919, d2.loss_cls: 0.1678, d2.loss_bbox: 0.5586, d3.loss_cls: 0.1587, d3.loss_bbox: 0.5402, d4.loss_cls: 0.1541, d4.loss_bbox: 0.5325, loss: 4.3977, grad_norm: 608.5185
2025-06-20 10:50:40,576 - mmdet - INFO - Epoch [3][5200/7033]	lr: 1.501e-04, eta: 8:36:40, time: 1.348, data_time: 0.023, memory: 18168, loss_cls: 0.1534, loss_bbox: 0.4993, d0.loss_cls: 0.2063, d0.loss_bbox: 0.6015, d1.loss_cls: 0.1758, d1.loss_bbox: 0.5597, d2.loss_cls: 0.1654, d2.loss_bbox: 0.5277, d3.loss_cls: 0.1589, d3.loss_bbox: 0.5058, d4.loss_cls: 0.1552, d4.loss_bbox: 0.4988, loss: 4.2077, grad_norm: 50.8759
2025-06-20 10:51:47,893 - mmdet - INFO - Epoch [3][5250/7033]	lr: 1.501e-04, eta: 8:35:32, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1505, loss_bbox: 0.5099, d0.loss_cls: 0.2120, d0.loss_bbox: 0.6213, d1.loss_cls: 0.1793, d1.loss_bbox: 0.5776, d2.loss_cls: 0.1691, d2.loss_bbox: 0.5366, d3.loss_cls: 0.1607, d3.loss_bbox: 0.5170, d4.loss_cls: 0.1545, d4.loss_bbox: 0.5104, loss: 4.2990, grad_norm: 55.0142
2025-06-20 10:52:55,286 - mmdet - INFO - Epoch [3][5300/7033]	lr: 1.501e-04, eta: 8:34:25, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.1575, loss_bbox: 0.5097, d0.loss_cls: 0.2173, d0.loss_bbox: 0.6246, d1.loss_cls: 0.1851, d1.loss_bbox: 0.5760, d2.loss_cls: 0.1729, d2.loss_bbox: 0.5462, d3.loss_cls: 0.1676, d3.loss_bbox: 0.5219, d4.loss_cls: 0.1636, d4.loss_bbox: 0.5098, loss: 4.3523, grad_norm: 34.9520
2025-06-20 10:54:02,843 - mmdet - INFO - Epoch [3][5350/7033]	lr: 1.501e-04, eta: 8:33:17, time: 1.351, data_time: 0.024, memory: 18168, loss_cls: 0.1516, loss_bbox: 0.5054, d0.loss_cls: 0.2169, d0.loss_bbox: 0.6064, d1.loss_cls: 0.1832, d1.loss_bbox: 0.5763, d2.loss_cls: 0.1739, d2.loss_bbox: 0.5396, d3.loss_cls: 0.1683, d3.loss_bbox: 0.5113, d4.loss_cls: 0.1588, d4.loss_bbox: 0.5053, loss: 4.2969, grad_norm: 46.6635
2025-06-20 10:55:10,133 - mmdet - INFO - Epoch [3][5400/7033]	lr: 1.501e-04, eta: 8:32:09, time: 1.346, data_time: 0.025, memory: 18168, loss_cls: 0.1608, loss_bbox: 0.4979, d0.loss_cls: 0.2243, d0.loss_bbox: 0.6125, d1.loss_cls: 0.1923, d1.loss_bbox: 0.5723, d2.loss_cls: 0.1798, d2.loss_bbox: 0.5332, d3.loss_cls: 0.1711, d3.loss_bbox: 0.5111, d4.loss_cls: 0.1638, d4.loss_bbox: 0.4987, loss: 4.3180, grad_norm: 30.7123
2025-06-20 10:56:19,086 - mmdet - INFO - Epoch [3][5450/7033]	lr: 1.501e-04, eta: 8:31:03, time: 1.379, data_time: 0.023, memory: 18168, loss_cls: 0.1653, loss_bbox: 0.5127, d0.loss_cls: 0.2217, d0.loss_bbox: 0.6213, d1.loss_cls: 0.1891, d1.loss_bbox: 0.5787, d2.loss_cls: 0.1792, d2.loss_bbox: 0.5412, d3.loss_cls: 0.1766, d3.loss_bbox: 0.5212, d4.loss_cls: 0.1707, d4.loss_bbox: 0.5114, loss: 4.3892, grad_norm: 33.0497
2025-06-20 10:57:26,265 - mmdet - INFO - Epoch [3][5500/7033]	lr: 1.501e-04, eta: 8:29:55, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.1585, loss_bbox: 0.5161, d0.loss_cls: 0.2141, d0.loss_bbox: 0.6083, d1.loss_cls: 0.1797, d1.loss_bbox: 0.5740, d2.loss_cls: 0.1712, d2.loss_bbox: 0.5421, d3.loss_cls: 0.1642, d3.loss_bbox: 0.5281, d4.loss_cls: 0.1602, d4.loss_bbox: 0.5181, loss: 4.3345, grad_norm: 36.4519
2025-06-20 10:58:33,683 - mmdet - INFO - Epoch [3][5550/7033]	lr: 1.501e-04, eta: 8:28:47, time: 1.348, data_time: 0.024, memory: 18168, loss_cls: 0.1464, loss_bbox: 0.4885, d0.loss_cls: 0.2073, d0.loss_bbox: 0.6033, d1.loss_cls: 0.1703, d1.loss_bbox: 0.5539, d2.loss_cls: 0.1613, d2.loss_bbox: 0.5160, d3.loss_cls: 0.1555, d3.loss_bbox: 0.4968, d4.loss_cls: 0.1474, d4.loss_bbox: 0.4910, loss: 4.1376, grad_norm: 34.3338
2025-06-20 10:59:41,219 - mmdet - INFO - Epoch [3][5600/7033]	lr: 1.501e-04, eta: 8:27:40, time: 1.351, data_time: 0.024, memory: 18168, loss_cls: 0.1482, loss_bbox: 0.4898, d0.loss_cls: 0.2017, d0.loss_bbox: 0.6092, d1.loss_cls: 0.1743, d1.loss_bbox: 0.5683, d2.loss_cls: 0.1639, d2.loss_bbox: 0.5261, d3.loss_cls: 0.1587, d3.loss_bbox: 0.5027, d4.loss_cls: 0.1517, d4.loss_bbox: 0.4928, loss: 4.1872, grad_norm: 53.8089
2025-06-20 11:00:50,274 - mmdet - INFO - Epoch [3][5650/7033]	lr: 1.501e-04, eta: 8:26:34, time: 1.381, data_time: 0.021, memory: 18168, loss_cls: 0.1428, loss_bbox: 0.5165, d0.loss_cls: 0.2004, d0.loss_bbox: 0.6299, d1.loss_cls: 0.1714, d1.loss_bbox: 0.5782, d2.loss_cls: 0.1638, d2.loss_bbox: 0.5390, d3.loss_cls: 0.1535, d3.loss_bbox: 0.5248, d4.loss_cls: 0.1468, d4.loss_bbox: 0.5157, loss: 4.2828, grad_norm: 104.4922
2025-06-20 11:01:57,493 - mmdet - INFO - Epoch [3][5700/7033]	lr: 1.501e-04, eta: 8:25:26, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.1514, loss_bbox: 0.5053, d0.loss_cls: 0.2129, d0.loss_bbox: 0.6229, d1.loss_cls: 0.1782, d1.loss_bbox: 0.5831, d2.loss_cls: 0.1713, d2.loss_bbox: 0.5382, d3.loss_cls: 0.1621, d3.loss_bbox: 0.5155, d4.loss_cls: 0.1557, d4.loss_bbox: 0.5047, loss: 4.3012, grad_norm: 28.8645
2025-06-20 11:03:04,802 - mmdet - INFO - Epoch [3][5750/7033]	lr: 1.501e-04, eta: 8:24:18, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1545, loss_bbox: 0.5087, d0.loss_cls: 0.2114, d0.loss_bbox: 0.6323, d1.loss_cls: 0.1809, d1.loss_bbox: 0.5883, d2.loss_cls: 0.1725, d2.loss_bbox: 0.5447, d3.loss_cls: 0.1643, d3.loss_bbox: 0.5193, d4.loss_cls: 0.1584, d4.loss_bbox: 0.5093, loss: 4.3446, grad_norm: 62.3079
2025-06-20 11:04:12,109 - mmdet - INFO - Epoch [3][5800/7033]	lr: 1.501e-04, eta: 8:23:10, time: 1.346, data_time: 0.024, memory: 18168, loss_cls: 0.1553, loss_bbox: 0.5217, d0.loss_cls: 0.2109, d0.loss_bbox: 0.6339, d1.loss_cls: 0.1846, d1.loss_bbox: 0.5888, d2.loss_cls: 0.1765, d2.loss_bbox: 0.5470, d3.loss_cls: 0.1674, d3.loss_bbox: 0.5271, d4.loss_cls: 0.1592, d4.loss_bbox: 0.5231, loss: 4.3955, grad_norm: 30.7770
2025-06-20 11:05:19,516 - mmdet - INFO - Epoch [3][5850/7033]	lr: 1.501e-04, eta: 8:22:02, time: 1.348, data_time: 0.021, memory: 18168, loss_cls: 0.1557, loss_bbox: 0.5189, d0.loss_cls: 0.2122, d0.loss_bbox: 0.6276, d1.loss_cls: 0.1826, d1.loss_bbox: 0.5944, d2.loss_cls: 0.1769, d2.loss_bbox: 0.5548, d3.loss_cls: 0.1658, d3.loss_bbox: 0.5325, d4.loss_cls: 0.1586, d4.loss_bbox: 0.5206, loss: 4.4006, grad_norm: 49.1167
2025-06-20 11:06:26,995 - mmdet - INFO - Epoch [3][5900/7033]	lr: 1.501e-04, eta: 8:20:54, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1630, loss_bbox: 0.5230, d0.loss_cls: 0.2176, d0.loss_bbox: 0.6246, d1.loss_cls: 0.1885, d1.loss_bbox: 0.5845, d2.loss_cls: 0.1789, d2.loss_bbox: 0.5504, d3.loss_cls: 0.1706, d3.loss_bbox: 0.5311, d4.loss_cls: 0.1657, d4.loss_bbox: 0.5229, loss: 4.4209, grad_norm: 53.6993
2025-06-20 11:07:34,452 - mmdet - INFO - Epoch [3][5950/7033]	lr: 1.501e-04, eta: 8:19:46, time: 1.349, data_time: 0.022, memory: 18168, loss_cls: 0.1521, loss_bbox: 0.5109, d0.loss_cls: 0.2124, d0.loss_bbox: 0.6061, d1.loss_cls: 0.1824, d1.loss_bbox: 0.5677, d2.loss_cls: 0.1696, d2.loss_bbox: 0.5293, d3.loss_cls: 0.1625, d3.loss_bbox: 0.5165, d4.loss_cls: 0.1553, d4.loss_bbox: 0.5102, loss: 4.2750, grad_norm: 70.5758
2025-06-20 11:08:41,955 - mmdet - INFO - Epoch [3][6000/7033]	lr: 1.501e-04, eta: 8:18:39, time: 1.350, data_time: 0.024, memory: 18168, loss_cls: 0.1523, loss_bbox: 0.5108, d0.loss_cls: 0.2111, d0.loss_bbox: 0.6012, d1.loss_cls: 0.1792, d1.loss_bbox: 0.5671, d2.loss_cls: 0.1705, d2.loss_bbox: 0.5369, d3.loss_cls: 0.1617, d3.loss_bbox: 0.5194, d4.loss_cls: 0.1544, d4.loss_bbox: 0.5124, loss: 4.2768, grad_norm: 44.5396
2025-06-20 11:09:49,321 - mmdet - INFO - Epoch [3][6050/7033]	lr: 1.501e-04, eta: 8:17:31, time: 1.347, data_time: 0.023, memory: 18168, loss_cls: 0.1456, loss_bbox: 0.4934, d0.loss_cls: 0.1997, d0.loss_bbox: 0.5891, d1.loss_cls: 0.1694, d1.loss_bbox: 0.5523, d2.loss_cls: 0.1598, d2.loss_bbox: 0.5193, d3.loss_cls: 0.1522, d3.loss_bbox: 0.5032, d4.loss_cls: 0.1482, d4.loss_bbox: 0.4960, loss: 4.1283, grad_norm: 39.3732
2025-06-20 11:10:56,622 - mmdet - INFO - Epoch [3][6100/7033]	lr: 1.501e-04, eta: 8:16:23, time: 1.346, data_time: 0.022, memory: 18168, loss_cls: 0.1500, loss_bbox: 0.5005, d0.loss_cls: 0.2089, d0.loss_bbox: 0.5882, d1.loss_cls: 0.1768, d1.loss_bbox: 0.5531, d2.loss_cls: 0.1668, d2.loss_bbox: 0.5205, d3.loss_cls: 0.1621, d3.loss_bbox: 0.5055, d4.loss_cls: 0.1537, d4.loss_bbox: 0.5007, loss: 4.1867, grad_norm: 31.7837
2025-06-20 11:12:03,802 - mmdet - INFO - Epoch [3][6150/7033]	lr: 1.501e-04, eta: 8:15:15, time: 1.344, data_time: 0.021, memory: 18168, loss_cls: 0.1574, loss_bbox: 0.5073, d0.loss_cls: 0.2103, d0.loss_bbox: 0.6145, d1.loss_cls: 0.1807, d1.loss_bbox: 0.5763, d2.loss_cls: 0.1707, d2.loss_bbox: 0.5356, d3.loss_cls: 0.1665, d3.loss_bbox: 0.5159, d4.loss_cls: 0.1592, d4.loss_bbox: 0.5096, loss: 4.3040, grad_norm: 43.8098
2025-06-20 11:13:10,920 - mmdet - INFO - Epoch [3][6200/7033]	lr: 1.501e-04, eta: 8:14:07, time: 1.342, data_time: 0.022, memory: 18168, loss_cls: 0.1601, loss_bbox: 0.4929, d0.loss_cls: 0.2171, d0.loss_bbox: 0.6126, d1.loss_cls: 0.1869, d1.loss_bbox: 0.5680, d2.loss_cls: 0.1783, d2.loss_bbox: 0.5213, d3.loss_cls: 0.1681, d3.loss_bbox: 0.5051, d4.loss_cls: 0.1620, d4.loss_bbox: 0.4953, loss: 4.2677, grad_norm: 34.4610
2025-06-20 11:14:18,378 - mmdet - INFO - Epoch [3][6250/7033]	lr: 1.501e-04, eta: 8:12:59, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1601, loss_bbox: 0.5254, d0.loss_cls: 0.2161, d0.loss_bbox: 0.6134, d1.loss_cls: 0.1860, d1.loss_bbox: 0.5831, d2.loss_cls: 0.1801, d2.loss_bbox: 0.5505, d3.loss_cls: 0.1706, d3.loss_bbox: 0.5345, d4.loss_cls: 0.1643, d4.loss_bbox: 0.5263, loss: 4.4103, grad_norm: 32.8862
2025-06-20 11:15:25,628 - mmdet - INFO - Epoch [3][6300/7033]	lr: 1.501e-04, eta: 8:11:51, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.1469, loss_bbox: 0.5037, d0.loss_cls: 0.2073, d0.loss_bbox: 0.6143, d1.loss_cls: 0.1750, d1.loss_bbox: 0.5686, d2.loss_cls: 0.1650, d2.loss_bbox: 0.5321, d3.loss_cls: 0.1576, d3.loss_bbox: 0.5126, d4.loss_cls: 0.1503, d4.loss_bbox: 0.5047, loss: 4.2383, grad_norm: 33.4424
2025-06-20 11:16:32,988 - mmdet - INFO - Epoch [3][6350/7033]	lr: 1.501e-04, eta: 8:10:43, time: 1.347, data_time: 0.022, memory: 18168, loss_cls: 0.1624, loss_bbox: 0.5317, d0.loss_cls: 0.2236, d0.loss_bbox: 0.6359, d1.loss_cls: 0.1904, d1.loss_bbox: 0.5977, d2.loss_cls: 0.1823, d2.loss_bbox: 0.5573, d3.loss_cls: 0.1716, d3.loss_bbox: 0.5428, d4.loss_cls: 0.1665, d4.loss_bbox: 0.5320, loss: 4.4943, grad_norm: 53.6205
2025-06-20 11:17:40,594 - mmdet - INFO - Epoch [3][6400/7033]	lr: 1.501e-04, eta: 8:09:36, time: 1.352, data_time: 0.025, memory: 18168, loss_cls: 0.1563, loss_bbox: 0.4999, d0.loss_cls: 0.2157, d0.loss_bbox: 0.6093, d1.loss_cls: 0.1811, d1.loss_bbox: 0.5735, d2.loss_cls: 0.1727, d2.loss_bbox: 0.5373, d3.loss_cls: 0.1659, d3.loss_bbox: 0.5134, d4.loss_cls: 0.1579, d4.loss_bbox: 0.5039, loss: 4.2870, grad_norm: 64.7401
2025-06-20 11:18:48,069 - mmdet - INFO - Epoch [3][6450/7033]	lr: 1.501e-04, eta: 8:08:28, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1609, loss_bbox: 0.4988, d0.loss_cls: 0.2159, d0.loss_bbox: 0.6167, d1.loss_cls: 0.1874, d1.loss_bbox: 0.5766, d2.loss_cls: 0.1785, d2.loss_bbox: 0.5324, d3.loss_cls: 0.1710, d3.loss_bbox: 0.5112, d4.loss_cls: 0.1633, d4.loss_bbox: 0.5023, loss: 4.3151, grad_norm: 131.8478
2025-06-20 11:19:55,279 - mmdet - INFO - Epoch [3][6500/7033]	lr: 1.501e-04, eta: 8:07:20, time: 1.344, data_time: 0.022, memory: 18168, loss_cls: 0.1551, loss_bbox: 0.5247, d0.loss_cls: 0.2103, d0.loss_bbox: 0.6310, d1.loss_cls: 0.1849, d1.loss_bbox: 0.5888, d2.loss_cls: 0.1753, d2.loss_bbox: 0.5484, d3.loss_cls: 0.1645, d3.loss_bbox: 0.5352, d4.loss_cls: 0.1577, d4.loss_bbox: 0.5253, loss: 4.4010, grad_norm: 30.8981
2025-06-20 11:21:02,602 - mmdet - INFO - Epoch [3][6550/7033]	lr: 1.501e-04, eta: 8:06:12, time: 1.346, data_time: 0.023, memory: 18168, loss_cls: 0.1574, loss_bbox: 0.5180, d0.loss_cls: 0.2158, d0.loss_bbox: 0.6280, d1.loss_cls: 0.1861, d1.loss_bbox: 0.5876, d2.loss_cls: 0.1765, d2.loss_bbox: 0.5485, d3.loss_cls: 0.1708, d3.loss_bbox: 0.5265, d4.loss_cls: 0.1613, d4.loss_bbox: 0.5194, loss: 4.3958, grad_norm: 37.4787
2025-06-20 11:22:12,721 - mmdet - INFO - Epoch [3][6600/7033]	lr: 1.501e-04, eta: 8:05:07, time: 1.402, data_time: 0.044, memory: 18168, loss_cls: 0.1533, loss_bbox: 0.5059, d0.loss_cls: 0.2204, d0.loss_bbox: 0.6026, d1.loss_cls: 0.1853, d1.loss_bbox: 0.5629, d2.loss_cls: 0.1705, d2.loss_bbox: 0.5338, d3.loss_cls: 0.1645, d3.loss_bbox: 0.5127, d4.loss_cls: 0.1559, d4.loss_bbox: 0.5057, loss: 4.2735, grad_norm: 41.0477
2025-06-20 11:23:20,223 - mmdet - INFO - Epoch [3][6650/7033]	lr: 1.501e-04, eta: 8:04:00, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.1497, loss_bbox: 0.5181, d0.loss_cls: 0.2168, d0.loss_bbox: 0.6028, d1.loss_cls: 0.1850, d1.loss_bbox: 0.5749, d2.loss_cls: 0.1687, d2.loss_bbox: 0.5446, d3.loss_cls: 0.1647, d3.loss_bbox: 0.5291, d4.loss_cls: 0.1558, d4.loss_bbox: 0.5168, loss: 4.3269, grad_norm: 40.9969
2025-06-20 11:24:27,524 - mmdet - INFO - Epoch [3][6700/7033]	lr: 1.501e-04, eta: 8:02:52, time: 1.346, data_time: 0.021, memory: 18168, loss_cls: 0.1458, loss_bbox: 0.5010, d0.loss_cls: 0.2097, d0.loss_bbox: 0.6011, d1.loss_cls: 0.1776, d1.loss_bbox: 0.5680, d2.loss_cls: 0.1662, d2.loss_bbox: 0.5297, d3.loss_cls: 0.1586, d3.loss_bbox: 0.5110, d4.loss_cls: 0.1508, d4.loss_bbox: 0.5019, loss: 4.2216, grad_norm: 50.2795
2025-06-20 11:25:34,792 - mmdet - INFO - Epoch [3][6750/7033]	lr: 1.501e-04, eta: 8:01:44, time: 1.345, data_time: 0.022, memory: 18168, loss_cls: 0.1576, loss_bbox: 0.4888, d0.loss_cls: 0.2176, d0.loss_bbox: 0.6122, d1.loss_cls: 0.1863, d1.loss_bbox: 0.5617, d2.loss_cls: 0.1763, d2.loss_bbox: 0.5219, d3.loss_cls: 0.1658, d3.loss_bbox: 0.5023, d4.loss_cls: 0.1600, d4.loss_bbox: 0.4897, loss: 4.2401, grad_norm: 31.3673
2025-06-20 11:26:42,240 - mmdet - INFO - Epoch [3][6800/7033]	lr: 1.501e-04, eta: 8:00:36, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1526, loss_bbox: 0.5023, d0.loss_cls: 0.2114, d0.loss_bbox: 0.5975, d1.loss_cls: 0.1811, d1.loss_bbox: 0.5630, d2.loss_cls: 0.1689, d2.loss_bbox: 0.5366, d3.loss_cls: 0.1624, d3.loss_bbox: 0.5136, d4.loss_cls: 0.1551, d4.loss_bbox: 0.5028, loss: 4.2472, grad_norm: 36.8175
2025-06-20 11:27:49,684 - mmdet - INFO - Epoch [3][6850/7033]	lr: 1.501e-04, eta: 7:59:28, time: 1.349, data_time: 0.023, memory: 18168, loss_cls: 0.1634, loss_bbox: 0.5308, d0.loss_cls: 0.2231, d0.loss_bbox: 0.6359, d1.loss_cls: 0.1876, d1.loss_bbox: 0.5901, d2.loss_cls: 0.1798, d2.loss_bbox: 0.5598, d3.loss_cls: 0.1775, d3.loss_bbox: 0.5397, d4.loss_cls: 0.1678, d4.loss_bbox: 0.5334, loss: 4.4890, grad_norm: 92.7876
2025-06-20 11:28:57,524 - mmdet - INFO - Epoch [3][6900/7033]	lr: 1.501e-04, eta: 7:58:21, time: 1.357, data_time: 0.024, memory: 18168, loss_cls: 0.1627, loss_bbox: 0.4950, d0.loss_cls: 0.2253, d0.loss_bbox: 0.6119, d1.loss_cls: 0.1937, d1.loss_bbox: 0.5637, d2.loss_cls: 0.1823, d2.loss_bbox: 0.5296, d3.loss_cls: 0.1731, d3.loss_bbox: 0.5090, d4.loss_cls: 0.1679, d4.loss_bbox: 0.4987, loss: 4.3129, grad_norm: 39.8830
2025-06-20 11:30:05,085 - mmdet - INFO - Epoch [3][6950/7033]	lr: 1.501e-04, eta: 7:57:13, time: 1.351, data_time: 0.024, memory: 18168, loss_cls: 0.1534, loss_bbox: 0.4997, d0.loss_cls: 0.2101, d0.loss_bbox: 0.6134, d1.loss_cls: 0.1798, d1.loss_bbox: 0.5750, d2.loss_cls: 0.1701, d2.loss_bbox: 0.5319, d3.loss_cls: 0.1621, d3.loss_bbox: 0.5119, d4.loss_cls: 0.1569, d4.loss_bbox: 0.5005, loss: 4.2649, grad_norm: 215.1007
2025-06-20 11:31:12,627 - mmdet - INFO - Epoch [3][7000/7033]	lr: 1.501e-04, eta: 7:56:06, time: 1.351, data_time: 0.023, memory: 18168, loss_cls: 0.1507, loss_bbox: 0.5040, d0.loss_cls: 0.2110, d0.loss_bbox: 0.6141, d1.loss_cls: 0.1845, d1.loss_bbox: 0.5667, d2.loss_cls: 0.1723, d2.loss_bbox: 0.5310, d3.loss_cls: 0.1620, d3.loss_bbox: 0.5115, d4.loss_cls: 0.1555, d4.loss_bbox: 0.5046, loss: 4.2678, grad_norm: 38.6031
2025-06-20 11:31:57,593 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-06-20 11:57:48,648 - mmdet - INFO - Exp name: lidar_0075v_900q_enhance_petr_vov_1600.py
2025-06-20 11:57:48,648 - mmdet - INFO - Epoch(val) [3][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.6609, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8698, pts_bbox_NuScenes/car_AP_dist_2.0: 0.9172, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9310, pts_bbox_NuScenes/car_trans_err: 0.2567, pts_bbox_NuScenes/car_scale_err: 0.1514, pts_bbox_NuScenes/car_orient_err: 0.0757, pts_bbox_NuScenes/car_vel_err: 0.2312, pts_bbox_NuScenes/car_attr_err: 0.1885, pts_bbox_NuScenes/mATE: 0.4173, pts_bbox_NuScenes/mASE: 0.2667, pts_bbox_NuScenes/mAOE: 0.2732, pts_bbox_NuScenes/mAVE: 0.2532, pts_bbox_NuScenes/mAAE: 0.1865, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.2690, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5755, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7045, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7649, pts_bbox_NuScenes/truck_trans_err: 0.4614, pts_bbox_NuScenes/truck_scale_err: 0.2057, pts_bbox_NuScenes/truck_orient_err: 0.0899, pts_bbox_NuScenes/truck_vel_err: 0.2329, pts_bbox_NuScenes/truck_attr_err: 0.2335, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0511, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.2032, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4201, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.5089, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.6973, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4351, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.8612, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1179, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3000, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.2539, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7062, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8809, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.9117, pts_bbox_NuScenes/bus_trans_err: 0.4844, pts_bbox_NuScenes/bus_scale_err: 0.2292, pts_bbox_NuScenes/bus_orient_err: 0.0386, pts_bbox_NuScenes/bus_vel_err: 0.4721, pts_bbox_NuScenes/bus_attr_err: 0.2455, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0696, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.4146, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.6168, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6989, pts_bbox_NuScenes/trailer_trans_err: 0.6100, pts_bbox_NuScenes/trailer_scale_err: 0.2501, pts_bbox_NuScenes/trailer_orient_err: 0.4142, pts_bbox_NuScenes/trailer_vel_err: 0.2000, pts_bbox_NuScenes/trailer_attr_err: 0.1707, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.2464, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.5905, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.6740, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7026, pts_bbox_NuScenes/barrier_trans_err: 0.4888, pts_bbox_NuScenes/barrier_scale_err: 0.2910, pts_bbox_NuScenes/barrier_orient_err: 0.0630, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.4613, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7223, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7848, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7912, pts_bbox_NuScenes/motorcycle_trans_err: 0.3296, pts_bbox_NuScenes/motorcycle_scale_err: 0.2425, pts_bbox_NuScenes/motorcycle_orient_err: 0.2081, pts_bbox_NuScenes/motorcycle_vel_err: 0.3254, pts_bbox_NuScenes/motorcycle_attr_err: 0.2354, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.4669, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.6054, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6208, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6277, pts_bbox_NuScenes/bicycle_trans_err: 0.2685, pts_bbox_NuScenes/bicycle_scale_err: 0.2605, pts_bbox_NuScenes/bicycle_orient_err: 0.3397, pts_bbox_NuScenes/bicycle_vel_err: 0.2267, pts_bbox_NuScenes/bicycle_attr_err: 0.0124, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.6043, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8197, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8733, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8908, pts_bbox_NuScenes/pedestrian_trans_err: 0.3241, pts_bbox_NuScenes/pedestrian_scale_err: 0.2756, pts_bbox_NuScenes/pedestrian_orient_err: 0.3688, pts_bbox_NuScenes/pedestrian_vel_err: 0.2192, pts_bbox_NuScenes/pedestrian_attr_err: 0.1063, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6178, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7392, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7804, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.8136, pts_bbox_NuScenes/traffic_cone_trans_err: 0.2522, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3263, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6711, pts_bbox_NuScenes/mAP: 0.6215
2025-06-20 11:59:04,312 - mmdet - INFO - Epoch [4][50/7033]	lr: 1.001e-04, eta: 7:53:33, time: 1.430, data_time: 0.107, memory: 18168, loss_cls: 0.1497, loss_bbox: 0.4822, d0.loss_cls: 0.2115, d0.loss_bbox: 0.5908, d1.loss_cls: 0.1776, d1.loss_bbox: 0.5473, d2.loss_cls: 0.1647, d2.loss_bbox: 0.5078, d3.loss_cls: 0.1570, d3.loss_bbox: 0.4921, d4.loss_cls: 0.1529, d4.loss_bbox: 0.4846, loss: 4.1183, grad_norm: 33.2212
2025-06-20 12:00:11,601 - mmdet - INFO - Epoch [4][100/7033]	lr: 1.001e-04, eta: 7:52:25, time: 1.346, data_time: 0.020, memory: 18168, loss_cls: 0.1446, loss_bbox: 0.4724, d0.loss_cls: 0.2105, d0.loss_bbox: 0.5694, d1.loss_cls: 0.1741, d1.loss_bbox: 0.5338, d2.loss_cls: 0.1640, d2.loss_bbox: 0.4986, d3.loss_cls: 0.1552, d3.loss_bbox: 0.4841, d4.loss_cls: 0.1485, d4.loss_bbox: 0.4775, loss: 4.0328, grad_norm: 45.0899
2025-06-20 12:01:18,988 - mmdet - INFO - Epoch [4][150/7033]	lr: 1.001e-04, eta: 7:51:18, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1430, loss_bbox: 0.4832, d0.loss_cls: 0.2062, d0.loss_bbox: 0.5942, d1.loss_cls: 0.1738, d1.loss_bbox: 0.5537, d2.loss_cls: 0.1626, d2.loss_bbox: 0.5148, d3.loss_cls: 0.1551, d3.loss_bbox: 0.4936, d4.loss_cls: 0.1480, d4.loss_bbox: 0.4845, loss: 4.1125, grad_norm: 32.0820
2025-06-20 12:02:28,290 - mmdet - INFO - Epoch [4][200/7033]	lr: 1.001e-04, eta: 7:50:12, time: 1.386, data_time: 0.022, memory: 18168, loss_cls: 0.1433, loss_bbox: 0.4922, d0.loss_cls: 0.2073, d0.loss_bbox: 0.5841, d1.loss_cls: 0.1738, d1.loss_bbox: 0.5467, d2.loss_cls: 0.1615, d2.loss_bbox: 0.5218, d3.loss_cls: 0.1524, d3.loss_bbox: 0.5016, d4.loss_cls: 0.1458, d4.loss_bbox: 0.4932, loss: 4.1237, grad_norm: 39.7082
2025-06-20 12:03:35,710 - mmdet - INFO - Epoch [4][250/7033]	lr: 1.001e-04, eta: 7:49:04, time: 1.348, data_time: 0.020, memory: 18168, loss_cls: 0.1494, loss_bbox: 0.4850, d0.loss_cls: 0.2069, d0.loss_bbox: 0.5950, d1.loss_cls: 0.1782, d1.loss_bbox: 0.5489, d2.loss_cls: 0.1624, d2.loss_bbox: 0.5231, d3.loss_cls: 0.1546, d3.loss_bbox: 0.5029, d4.loss_cls: 0.1513, d4.loss_bbox: 0.4907, loss: 4.1484, grad_norm: 411.7727
2025-06-20 12:04:42,990 - mmdet - INFO - Epoch [4][300/7033]	lr: 1.001e-04, eta: 7:47:57, time: 1.346, data_time: 0.020, memory: 18168, loss_cls: 0.1417, loss_bbox: 0.4765, d0.loss_cls: 0.2010, d0.loss_bbox: 0.5807, d1.loss_cls: 0.1702, d1.loss_bbox: 0.5352, d2.loss_cls: 0.1586, d2.loss_bbox: 0.5045, d3.loss_cls: 0.1530, d3.loss_bbox: 0.4887, d4.loss_cls: 0.1469, d4.loss_bbox: 0.4789, loss: 4.0360, grad_norm: 29.4647
2025-06-20 12:05:50,384 - mmdet - INFO - Epoch [4][350/7033]	lr: 1.001e-04, eta: 7:46:49, time: 1.348, data_time: 0.022, memory: 18168, loss_cls: 0.1435, loss_bbox: 0.4956, d0.loss_cls: 0.2020, d0.loss_bbox: 0.5847, d1.loss_cls: 0.1707, d1.loss_bbox: 0.5482, d2.loss_cls: 0.1600, d2.loss_bbox: 0.5214, d3.loss_cls: 0.1525, d3.loss_bbox: 0.5063, d4.loss_cls: 0.1482, d4.loss_bbox: 0.4962, loss: 4.1294, grad_norm: 41.5875
2025-06-20 12:06:57,836 - mmdet - INFO - Epoch [4][400/7033]	lr: 1.001e-04, eta: 7:45:42, time: 1.349, data_time: 0.020, memory: 18168, loss_cls: 0.1536, loss_bbox: 0.5026, d0.loss_cls: 0.2186, d0.loss_bbox: 0.6151, d1.loss_cls: 0.1878, d1.loss_bbox: 0.5700, d2.loss_cls: 0.1743, d2.loss_bbox: 0.5349, d3.loss_cls: 0.1638, d3.loss_bbox: 0.5146, d4.loss_cls: 0.1579, d4.loss_bbox: 0.5043, loss: 4.2975, grad_norm: 43.8053
2025-06-20 12:08:05,273 - mmdet - INFO - Epoch [4][450/7033]	lr: 1.001e-04, eta: 7:44:34, time: 1.349, data_time: 0.019, memory: 18168, loss_cls: 0.1469, loss_bbox: 0.4745, d0.loss_cls: 0.2169, d0.loss_bbox: 0.5923, d1.loss_cls: 0.1787, d1.loss_bbox: 0.5442, d2.loss_cls: 0.1651, d2.loss_bbox: 0.5068, d3.loss_cls: 0.1553, d3.loss_bbox: 0.4858, d4.loss_cls: 0.1509, d4.loss_bbox: 0.4753, loss: 4.0927, grad_norm: 38.3193
2025-06-20 12:09:12,652 - mmdet - INFO - Epoch [4][500/7033]	lr: 1.001e-04, eta: 7:43:26, time: 1.348, data_time: 0.019, memory: 18168, loss_cls: 0.1535, loss_bbox: 0.4880, d0.loss_cls: 0.2131, d0.loss_bbox: 0.5958, d1.loss_cls: 0.1798, d1.loss_bbox: 0.5554, d2.loss_cls: 0.1729, d2.loss_bbox: 0.5175, d3.loss_cls: 0.1653, d3.loss_bbox: 0.4963, d4.loss_cls: 0.1586, d4.loss_bbox: 0.4877, loss: 4.1839, grad_norm: 51.1424
2025-06-20 12:10:19,754 - mmdet - INFO - Epoch [4][550/7033]	lr: 1.001e-04, eta: 7:42:19, time: 1.342, data_time: 0.018, memory: 18168, loss_cls: 0.1465, loss_bbox: 0.5044, d0.loss_cls: 0.2067, d0.loss_bbox: 0.5932, d1.loss_cls: 0.1745, d1.loss_bbox: 0.5530, d2.loss_cls: 0.1625, d2.loss_bbox: 0.5280, d3.loss_cls: 0.1549, d3.loss_bbox: 0.5154, d4.loss_cls: 0.1488, d4.loss_bbox: 0.5084, loss: 4.1964, grad_norm: 30.5327
2025-06-20 12:11:26,785 - mmdet - INFO - Epoch [4][600/7033]	lr: 1.001e-04, eta: 7:41:11, time: 1.341, data_time: 0.019, memory: 18168, loss_cls: 0.1509, loss_bbox: 0.4907, d0.loss_cls: 0.2169, d0.loss_bbox: 0.5996, d1.loss_cls: 0.1828, d1.loss_bbox: 0.5530, d2.loss_cls: 0.1656, d2.loss_bbox: 0.5203, d3.loss_cls: 0.1592, d3.loss_bbox: 0.5054, d4.loss_cls: 0.1533, d4.loss_bbox: 0.4938, loss: 4.1915, grad_norm: 72.0255
2025-06-20 12:12:34,321 - mmdet - INFO - Epoch [4][650/7033]	lr: 1.001e-04, eta: 7:40:03, time: 1.351, data_time: 0.021, memory: 18168, loss_cls: 0.1490, loss_bbox: 0.4878, d0.loss_cls: 0.2060, d0.loss_bbox: 0.5810, d1.loss_cls: 0.1747, d1.loss_bbox: 0.5470, d2.loss_cls: 0.1667, d2.loss_bbox: 0.5184, d3.loss_cls: 0.1596, d3.loss_bbox: 0.4973, d4.loss_cls: 0.1540, d4.loss_bbox: 0.4883, loss: 4.1298, grad_norm: 33.0599
2025-06-20 12:13:41,780 - mmdet - INFO - Epoch [4][700/7033]	lr: 1.001e-04, eta: 7:38:56, time: 1.349, data_time: 0.021, memory: 18168, loss_cls: 0.1499, loss_bbox: 0.4915, d0.loss_cls: 0.2124, d0.loss_bbox: 0.6057, d1.loss_cls: 0.1778, d1.loss_bbox: 0.5680, d2.loss_cls: 0.1711, d2.loss_bbox: 0.5256, d3.loss_cls: 0.1626, d3.loss_bbox: 0.5030, d4.loss_cls: 0.1557, d4.loss_bbox: 0.4940, loss: 4.2173, grad_norm: 34.3036
2025-06-20 12:14:49,127 - mmdet - INFO - Epoch [4][750/7033]	lr: 1.001e-04, eta: 7:37:48, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1363, loss_bbox: 0.4862, d0.loss_cls: 0.1980, d0.loss_bbox: 0.5710, d1.loss_cls: 0.1668, d1.loss_bbox: 0.5358, d2.loss_cls: 0.1546, d2.loss_bbox: 0.5064, d3.loss_cls: 0.1470, d3.loss_bbox: 0.4936, d4.loss_cls: 0.1418, d4.loss_bbox: 0.4866, loss: 4.0242, grad_norm: 148.8237
2025-06-20 12:15:58,329 - mmdet - INFO - Epoch [4][800/7033]	lr: 1.001e-04, eta: 7:36:42, time: 1.384, data_time: 0.022, memory: 18168, loss_cls: 0.1455, loss_bbox: 0.4860, d0.loss_cls: 0.1999, d0.loss_bbox: 0.5839, d1.loss_cls: 0.1684, d1.loss_bbox: 0.5420, d2.loss_cls: 0.1605, d2.loss_bbox: 0.5116, d3.loss_cls: 0.1528, d3.loss_bbox: 0.4962, d4.loss_cls: 0.1497, d4.loss_bbox: 0.4848, loss: 4.0814, grad_norm: 43.2803
2025-06-20 12:17:05,731 - mmdet - INFO - Epoch [4][850/7033]	lr: 1.001e-04, eta: 7:35:35, time: 1.348, data_time: 0.020, memory: 18168, loss_cls: 0.1456, loss_bbox: 0.4894, d0.loss_cls: 0.1989, d0.loss_bbox: 0.5705, d1.loss_cls: 0.1750, d1.loss_bbox: 0.5290, d2.loss_cls: 0.1646, d2.loss_bbox: 0.5066, d3.loss_cls: 0.1594, d3.loss_bbox: 0.4959, d4.loss_cls: 0.1496, d4.loss_bbox: 0.4902, loss: 4.0747, grad_norm: 32.8149
2025-06-20 12:18:13,150 - mmdet - INFO - Epoch [4][900/7033]	lr: 1.001e-04, eta: 7:34:27, time: 1.348, data_time: 0.020, memory: 18168, loss_cls: 0.1432, loss_bbox: 0.4833, d0.loss_cls: 0.1981, d0.loss_bbox: 0.5691, d1.loss_cls: 0.1691, d1.loss_bbox: 0.5307, d2.loss_cls: 0.1597, d2.loss_bbox: 0.5056, d3.loss_cls: 0.1525, d3.loss_bbox: 0.4917, d4.loss_cls: 0.1472, d4.loss_bbox: 0.4859, loss: 4.0361, grad_norm: 29.5741
2025-06-20 12:19:20,591 - mmdet - INFO - Epoch [4][950/7033]	lr: 1.001e-04, eta: 7:33:19, time: 1.349, data_time: 0.020, memory: 18168, loss_cls: 0.1498, loss_bbox: 0.4939, d0.loss_cls: 0.2077, d0.loss_bbox: 0.6014, d1.loss_cls: 0.1745, d1.loss_bbox: 0.5599, d2.loss_cls: 0.1646, d2.loss_bbox: 0.5215, d3.loss_cls: 0.1600, d3.loss_bbox: 0.5041, d4.loss_cls: 0.1532, d4.loss_bbox: 0.4962, loss: 4.1867, grad_norm: 34.7102
2025-06-20 12:20:27,929 - mmdet - INFO - Epoch [4][1000/7033]	lr: 1.001e-04, eta: 7:32:12, time: 1.347, data_time: 0.021, memory: 18168, loss_cls: 0.1468, loss_bbox: 0.4704, d0.loss_cls: 0.2054, d0.loss_bbox: 0.5611, d1.loss_cls: 0.1713, d1.loss_bbox: 0.5174, d2.loss_cls: 0.1612, d2.loss_bbox: 0.4935, d3.loss_cls: 0.1560, d3.loss_bbox: 0.4802, d4.loss_cls: 0.1503, d4.loss_bbox: 0.4728, loss: 3.9863, grad_norm: 29.6192
2025-06-20 12:21:35,848 - mmdet - INFO - Epoch [4][1050/7033]	lr: 1.001e-04, eta: 7:31:05, time: 1.358, data_time: 0.032, memory: 18168, loss_cls: 0.1321, loss_bbox: 0.4652, d0.loss_cls: 0.1910, d0.loss_bbox: 0.5532, d1.loss_cls: 0.1593, d1.loss_bbox: 0.5230, d2.loss_cls: 0.1484, d2.loss_bbox: 0.4908, d3.loss_cls: 0.1428, d3.loss_bbox: 0.4733, d4.loss_cls: 0.1369, d4.loss_bbox: 0.4668, loss: 3.8830, grad_norm: 28.8474
2025-06-20 12:22:43,295 - mmdet - INFO - Epoch [4][1100/7033]	lr: 1.001e-04, eta: 7:29:57, time: 1.349, data_time: 0.019, memory: 18168, loss_cls: 0.1426, loss_bbox: 0.4726, d0.loss_cls: 0.1989, d0.loss_bbox: 0.5710, d1.loss_cls: 0.1679, d1.loss_bbox: 0.5315, d2.loss_cls: 0.1577, d2.loss_bbox: 0.5002, d3.loss_cls: 0.1506, d3.loss_bbox: 0.4844, d4.loss_cls: 0.1468, d4.loss_bbox: 0.4751, loss: 3.9993, grad_norm: 62.7896
2025-06-20 12:23:50,674 - mmdet - INFO - Epoch [4][1150/7033]	lr: 1.001e-04, eta: 7:28:49, time: 1.348, data_time: 0.020, memory: 18168, loss_cls: 0.1425, loss_bbox: 0.4925, d0.loss_cls: 0.1989, d0.loss_bbox: 0.5828, d1.loss_cls: 0.1722, d1.loss_bbox: 0.5434, d2.loss_cls: 0.1581, d2.loss_bbox: 0.5178, d3.loss_cls: 0.1531, d3.loss_bbox: 0.5035, d4.loss_cls: 0.1463, d4.loss_bbox: 0.4939, loss: 4.1050, grad_norm: 32.2362
2025-06-20 12:24:58,249 - mmdet - INFO - Epoch [4][1200/7033]	lr: 1.001e-04, eta: 7:27:42, time: 1.351, data_time: 0.021, memory: 18168, loss_cls: 0.1431, loss_bbox: 0.4917, d0.loss_cls: 0.2000, d0.loss_bbox: 0.5827, d1.loss_cls: 0.1679, d1.loss_bbox: 0.5453, d2.loss_cls: 0.1575, d2.loss_bbox: 0.5182, d3.loss_cls: 0.1518, d3.loss_bbox: 0.5001, d4.loss_cls: 0.1453, d4.loss_bbox: 0.4945, loss: 4.0980, grad_norm: 34.3685
2025-06-20 12:26:05,677 - mmdet - INFO - Epoch [4][1250/7033]	lr: 1.001e-04, eta: 7:26:35, time: 1.349, data_time: 0.022, memory: 18168, loss_cls: 0.1520, loss_bbox: 0.4829, d0.loss_cls: 0.2134, d0.loss_bbox: 0.6016, d1.loss_cls: 0.1799, d1.loss_bbox: 0.5503, d2.loss_cls: 0.1672, d2.loss_bbox: 0.5148, d3.loss_cls: 0.1589, d3.loss_bbox: 0.4978, d4.loss_cls: 0.1547, d4.loss_bbox: 0.4865, loss: 4.1599, grad_norm: 39.1310
2025-06-20 12:27:13,095 - mmdet - INFO - Epoch [4][1300/7033]	lr: 1.001e-04, eta: 7:25:27, time: 1.348, data_time: 0.019, memory: 18168, loss_cls: 0.1487, loss_bbox: 0.4948, d0.loss_cls: 0.2174, d0.loss_bbox: 0.6119, d1.loss_cls: 0.1792, d1.loss_bbox: 0.5558, d2.loss_cls: 0.1681, d2.loss_bbox: 0.5187, d3.loss_cls: 0.1598, d3.loss_bbox: 0.5030, d4.loss_cls: 0.1526, d4.loss_bbox: 0.4973, loss: 4.2072, grad_norm: 40.7603
2025-06-20 12:28:20,616 - mmdet - INFO - Epoch [4][1350/7033]	lr: 1.001e-04, eta: 7:24:19, time: 1.350, data_time: 0.022, memory: 18168, loss_cls: 0.1487, loss_bbox: 0.4892, d0.loss_cls: 0.2117, d0.loss_bbox: 0.5949, d1.loss_cls: 0.1754, d1.loss_bbox: 0.5606, d2.loss_cls: 0.1635, d2.loss_bbox: 0.5240, d3.loss_cls: 0.1558, d3.loss_bbox: 0.5027, d4.loss_cls: 0.1511, d4.loss_bbox: 0.4926, loss: 4.1701, grad_norm: 34.6279
2025-06-20 12:29:28,008 - mmdet - INFO - Epoch [4][1400/7033]	lr: 1.001e-04, eta: 7:23:12, time: 1.348, data_time: 0.020, memory: 18168, loss_cls: 0.1442, loss_bbox: 0.4808, d0.loss_cls: 0.2020, d0.loss_bbox: 0.5735, d1.loss_cls: 0.1724, d1.loss_bbox: 0.5291, d2.loss_cls: 0.1617, d2.loss_bbox: 0.5066, d3.loss_cls: 0.1554, d3.loss_bbox: 0.4899, d4.loss_cls: 0.1476, d4.loss_bbox: 0.4832, loss: 4.0465, grad_norm: 38.4691
2025-06-20 12:30:35,474 - mmdet - INFO - Epoch [4][1450/7033]	lr: 1.001e-04, eta: 7:22:04, time: 1.349, data_time: 0.019, memory: 18168, loss_cls: 0.1518, loss_bbox: 0.5042, d0.loss_cls: 0.2154, d0.loss_bbox: 0.6072, d1.loss_cls: 0.1867, d1.loss_bbox: 0.5677, d2.loss_cls: 0.1718, d2.loss_bbox: 0.5316, d3.loss_cls: 0.1636, d3.loss_bbox: 0.5159, d4.loss_cls: 0.1577, d4.loss_bbox: 0.5055, loss: 4.2791, grad_norm: 54.5933
