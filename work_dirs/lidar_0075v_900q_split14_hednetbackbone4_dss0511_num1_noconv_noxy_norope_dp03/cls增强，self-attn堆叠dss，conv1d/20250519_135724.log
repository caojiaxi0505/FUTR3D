2025-05-19 13:57:24,994 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:52:49) [GCC 13.3.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090 D
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.6, V11.6.55
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.1-Product Build 20220311 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+52a0242
spconv2.0: True
------------------------------------------------------------

2025-05-19 13:57:25,818 - mmdet - INFO - 分布式训练: True
2025-05-19 13:57:26,611 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=False,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='ObjectSample',
        db_sampler=dict(
            data_root='data/nuscenes/',
            info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
            rate=1.0,
            prepare=dict(
                filter_by_difficulty=[-1],
                filter_by_min_points=dict(
                    car=5,
                    truck=5,
                    bus=5,
                    trailer=5,
                    construction_vehicle=5,
                    traffic_cone=5,
                    barrier=5,
                    motorcycle=5,
                    bicycle=5,
                    pedestrian=5)),
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            sample_groups=dict(
                car=2,
                truck=3,
                construction_vehicle=7,
                bus=4,
                trailer=6,
                barrier=2,
                motorcycle=6,
                bicycle=6,
                pedestrian=2,
                traffic_cone=2),
            points_loader=dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk')))),
    dict(
        type='GlobalRotScaleTrans',
        rot_range=[-0.785, 0.785],
        scale_ratio_range=[0.9, 1.1],
        translation_std=[0.5, 0.5, 0.5]),
    dict(
        type='RandomFlip3D',
        sync_2d=False,
        flip_ratio_bev_horizontal=0.5,
        flip_ratio_bev_vertical=0.5),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='CBGSDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=10,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[-0.3925, 0.3925],
                scale_ratio_range=[0.95, 1.05],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D', flip_ratio_bev_horizontal=0.5),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ]),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        split=14,
        dataset=dict(
            type='NuScenesDataset',
            data_root='data/nuscenes/',
            ann_file='data/nuscenes/nuscenes_infos_train.pkl',
            pipeline=[
                dict(
                    type='LoadPointsFromFile',
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=5,
                    file_client_args=dict(backend='disk')),
                dict(
                    type='LoadPointsFromMultiSweeps',
                    sweeps_num=9,
                    use_dim=[0, 1, 2, 3, 4],
                    file_client_args=dict(backend='disk'),
                    pad_empty_sweeps=True,
                    remove_close=True),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox_3d=True,
                    with_label_3d=True),
                dict(
                    type='ObjectSample',
                    db_sampler=dict(
                        data_root='data/nuscenes/',
                        info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
                        rate=1.0,
                        prepare=dict(
                            filter_by_difficulty=[-1],
                            filter_by_min_points=dict(
                                car=5,
                                truck=5,
                                bus=5,
                                trailer=5,
                                construction_vehicle=5,
                                traffic_cone=5,
                                barrier=5,
                                motorcycle=5,
                                bicycle=5,
                                pedestrian=5)),
                        classes=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        sample_groups=dict(
                            car=2,
                            truck=3,
                            construction_vehicle=7,
                            bus=4,
                            trailer=6,
                            barrier=2,
                            motorcycle=6,
                            bicycle=6,
                            pedestrian=2,
                            traffic_cone=2),
                        points_loader=dict(
                            type='LoadPointsFromFile',
                            coord_type='LIDAR',
                            load_dim=5,
                            use_dim=[0, 1, 2, 3, 4],
                            file_client_args=dict(backend='disk')))),
                dict(
                    type='GlobalRotScaleTrans',
                    rot_range=[-0.785, 0.785],
                    scale_ratio_range=[0.9, 1.1],
                    translation_std=[0.5, 0.5, 0.5]),
                dict(
                    type='RandomFlip3D',
                    sync_2d=False,
                    flip_ratio_bev_horizontal=0.5,
                    flip_ratio_bev_vertical=0.5),
                dict(
                    type='PointsRangeFilter',
                    point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                dict(
                    type='ObjectNameFilter',
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(type='PointShuffle'),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='Collect3D',
                    keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
            ],
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            test_mode=False,
            use_valid_flag=True,
            box_type_3d='LiDAR')),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='Collect3D',
                        keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='Collect3D',
                        keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=5,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
optimizer = dict(type='AdamW', lr=1.25e-05, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='cyclic',
    target_ratio=(10, 0.0001),
    cyclic_times=1,
    step_ratio_up=0.4)
momentum_config = dict(
    policy='cyclic',
    target_ratio=(0.8947368421052632, 1),
    cyclic_times=1,
    step_ratio_up=0.4)
runner = dict(type='EpochBasedRunner', max_epochs=20)
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/lidar_0075v_900q_split14_hednetbackbone4_dss0511_num1_noconv_noxy_norope_dp03/cls增强，self-attn堆叠dss，conv1d'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    aux_weight=0.5,
    pts_voxel_layer=dict(
        max_num_points=10,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(120000, 160000),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),
    pts_middle_encoder=dict(
        type='SparseEncoder',
        in_channels=5,
        sparse_shape=[41, 1440, 1440],
        output_channels=128,
        order=('conv', 'norm', 'act'),
        encoder_channels=((16, 16, 32), (32, 32, 64), (64, 64, 128), (128,
                                                                      128)),
        encoder_paddings=((0, 0, 1), (0, 0, 1), (0, 0, [0, 1, 1]), (0, 0)),
        block_type='basicblock'),
    pts_backbone=dict(
        type='CascadeDEDBackbone',
        in_channels=256,
        model_cfg=dict(
            USE_SECONDMAMBA=False,
            FEATURE_DIM=256,
            NUM_LAYERS=4,
            NUM_SBB=[2, 1, 1],
            DOWN_STRIDES=[1, 2, 2])),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        dss_drop_prob=0.3,
        dss_mamba_version='DSSMamba_Pico',
        dss_num_layers=1,
        dss_use_morton=True,
        dss_use_conv=False,
        dss_use_xy=False,
        dss_use_rope=False,
        anchor_size=3,
        use_aux=True,
        aux_head=dict(
            type='CenterHead',
            in_channels=512,
            tasks=[
                dict(num_class=1, class_names=['car']),
                dict(
                    num_class=2, class_names=['truck',
                                              'construction_vehicle']),
                dict(num_class=2, class_names=['bus', 'trailer']),
                dict(num_class=1, class_names=['barrier']),
                dict(num_class=2, class_names=['motorcycle', 'bicycle']),
                dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
            ],
            common_heads=dict(
                reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
            share_conv_channel=64,
            bbox_coder=dict(
                type='CenterPointBBoxCoder',
                pc_range=[-54, -54],
                post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
                max_num=500,
                score_threshold=0.1,
                out_size_factor=8,
                voxel_size=[0.075, 0.075],
                code_size=9),
            separate_head=dict(
                type='SeparateHead', init_bias=-2.19, final_kernel=3),
            loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
            loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
            norm_bbox=True),
        mix_selection=False,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(type='FUTR3DAttention', embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
db_sampler = dict(
    data_root='data/nuscenes/',
    info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
    rate=1.0,
    prepare=dict(
        filter_by_difficulty=[-1],
        filter_by_min_points=dict(
            car=5,
            truck=5,
            bus=5,
            trailer=5,
            construction_vehicle=5,
            traffic_cone=5,
            barrier=5,
            motorcycle=5,
            bicycle=5,
            pedestrian=5)),
    classes=[
        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
    ],
    sample_groups=dict(
        car=2,
        truck=3,
        construction_vehicle=7,
        bus=4,
        trailer=6,
        barrier=2,
        motorcycle=6,
        bicycle=6,
        pedestrian=2,
        traffic_cone=2),
    points_loader=dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk')))
find_unused_parameters = True
custom_hooks = [dict(type='FadeOjectSampleHook', num_last_epochs=5)]
gpu_ids = range(0, 2)

2025-05-19 13:57:26,612 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-05-19 13:57:26,891 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_middle_encoder.conv_input.0.weight - torch.Size([16, 3, 3, 3, 5]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_input.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_input.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.0.weight - torch.Size([32, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.0.weight - torch.Size([64, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.0.weight - torch.Size([128, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.0.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.1.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.2.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.0.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.1.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.0.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.0.downsample_layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.encoder.2.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.layers.3.decoder_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm_before.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_f - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.A_log_b - torch.Size([256, 1]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_f.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.x_proj_b.weight - torch.Size([18, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.out_proj.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mamba.global_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.gate_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.up_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.2.layers.0.mlp.down_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.gate_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.up_proj.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.weight - torch.Size([10, 1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.down_proj.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.conv.weight - torch.Size([64, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-05-19 13:57:26,940 - mmdet - INFO - Model:
FUTR3D(
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=10, max_voxels=(120000, 160000), deterministic=True)
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseEncoder(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (encoder_layers): SparseSequential(
      (encoder_layer1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer2): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer3): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer4): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (pts_backbone): CascadeDEDBackbone(
    (layers): ModuleList(
      (0): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (1): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (2): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (3): DEDBackbone(
        (encoder): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
              (downsample_layer): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu1): ReLU()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu2): ReLU()
            )
          )
        )
        (decoder): ModuleList(
          (0): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Sequential(
            (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (2): ReLU()
          )
        )
        (decoder_norm): ModuleList(
          (0): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): ModuleList(
                (0): MultiheadAttention(
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (dropout_layer): Dropout(p=0.1, inplace=False)
                )
                (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (2): DSS(
                  (layers): ModuleList(
                    (0): ModuleDict(
                      (norm_before): RMSNorm()
                      (mamba): DSSMamba(
                        (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (act): SiLU()
                        (x_proj_f): Linear(in_features=256, out_features=18, bias=False)
                        (x_proj_b): Linear(in_features=256, out_features=18, bias=False)
                        (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                        (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                        (out_proj): Linear(in_features=512, out_features=256, bias=False)
                        (global_proj): Linear(in_features=512, out_features=512, bias=True)
                      )
                      (dropout): Identity()
                      (norm): RMSNorm()
                      (mlp): MLP(
                        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
                        (down_proj): Linear(in_features=1024, out_features=256, bias=False)
                        (act_fn): SiLU()
                      )
                      (mlp_norm): Identity()
                    )
                  )
                  (rope): Identity()
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (1): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (2): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (3): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (4): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
      (5): MLP(
        (gate_proj): Linear(in_features=256, out_features=1024, bias=False)
        (up_proj): Linear(in_features=256, out_features=1024, bias=False)
        (act_fn): SiLU()
        (down_proj): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
    (aux_head): CenterHead(
      (loss_cls): GaussianFocalLoss()
      (loss_bbox): L1Loss()
      (shared_conv): ConvModule(
        (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (task_heads): ModuleList(
        (0): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (1): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (2): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (3): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (4): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (5): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
      )
    )
  )
)
2025-05-19 13:57:54,457 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /home/ubuntu/jxcao/hdd/jxc/FUTR3D/work_dirs/lidar_0075v_900q_split14_hednetbackbone4_dss0511_num1_noconv_noxy_norope_dp03/cls增强，self-attn堆叠dss，conv1d
2025-05-19 13:57:54,457 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) FadeOjectSampleHook                
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-19 13:57:54,457 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs
2025-05-19 13:57:54,457 - mmdet - INFO - Checkpoints will be saved to /home/ubuntu/jxcao/hdd/jxc/FUTR3D/work_dirs/lidar_0075v_900q_split14_hednetbackbone4_dss0511_num1_noconv_noxy_norope_dp03/cls增强，self-attn堆叠dss，conv1d by HardDiskBackend.
2025-05-19 13:58:49,030 - mmdet - INFO - Epoch [1][50/2207]	lr: 1.250e-05, eta: 13:20:07, time: 1.089, data_time: 0.078, memory: 11107, loss_cls: 2.0142, loss_bbox: 2.2388, d0.loss_cls: 2.2149, d0.loss_bbox: 4.3818, d1.loss_cls: 2.1591, d1.loss_bbox: 2.2507, d2.loss_cls: 2.0961, d2.loss_bbox: 2.2473, d3.loss_cls: 2.0488, d3.loss_bbox: 2.2446, d4.loss_cls: 2.0535, d4.loss_bbox: 2.2417, aux_task0.loss_heatmap: 309.4999, aux_task0.loss_bbox: 0.8898, aux_task1.loss_heatmap: 665.4126, aux_task1.loss_bbox: 1.0596, aux_task2.loss_heatmap: 818.4660, aux_task2.loss_bbox: 1.1476, aux_task3.loss_heatmap: 816.4473, aux_task3.loss_bbox: 0.8835, aux_task4.loss_heatmap: 627.4421, aux_task4.loss_bbox: 0.7695, aux_task5.loss_heatmap: 753.5848, aux_task5.loss_bbox: 0.7813, loss: 4024.5755, grad_norm: 19213.2034
2025-05-19 13:59:31,701 - mmdet - INFO - Epoch [1][100/2207]	lr: 1.251e-05, eta: 11:52:48, time: 0.853, data_time: 0.007, memory: 11107, loss_cls: 1.5255, loss_bbox: 2.1412, d0.loss_cls: 2.0065, d0.loss_bbox: 4.2405, d1.loss_cls: 1.7125, d1.loss_bbox: 2.1971, d2.loss_cls: 1.5938, d2.loss_bbox: 2.1821, d3.loss_cls: 1.5253, d3.loss_bbox: 2.1693, d4.loss_cls: 1.5657, d4.loss_bbox: 2.1546, aux_task0.loss_heatmap: 201.8087, aux_task0.loss_bbox: 0.7883, aux_task1.loss_heatmap: 445.9381, aux_task1.loss_bbox: 0.9580, aux_task2.loss_heatmap: 520.9981, aux_task2.loss_bbox: 1.0150, aux_task3.loss_heatmap: 329.0602, aux_task3.loss_bbox: 0.7394, aux_task4.loss_heatmap: 412.8325, aux_task4.loss_bbox: 0.6453, aux_task5.loss_heatmap: 440.0699, aux_task5.loss_bbox: 0.6676, loss: 2380.5352, grad_norm: 11841.2915
2025-05-19 14:00:14,246 - mmdet - INFO - Epoch [1][150/2207]	lr: 1.252e-05, eta: 11:22:37, time: 0.851, data_time: 0.006, memory: 11107, loss_cls: 1.2286, loss_bbox: 1.9390, d0.loss_cls: 1.4464, d0.loss_bbox: 4.0402, d1.loss_cls: 1.2599, d1.loss_bbox: 2.1052, d2.loss_cls: 1.2388, d2.loss_bbox: 2.0542, d3.loss_cls: 1.2188, d3.loss_bbox: 2.0092, d4.loss_cls: 1.2367, d4.loss_bbox: 1.9709, aux_task0.loss_heatmap: 117.6648, aux_task0.loss_bbox: 0.6713, aux_task1.loss_heatmap: 254.4079, aux_task1.loss_bbox: 0.7784, aux_task2.loss_heatmap: 318.1454, aux_task2.loss_bbox: 0.8628, aux_task3.loss_heatmap: 226.8814, aux_task3.loss_bbox: 0.6130, aux_task4.loss_heatmap: 257.3658, aux_task4.loss_bbox: 0.5386, aux_task5.loss_heatmap: 310.3600, aux_task5.loss_bbox: 0.5768, loss: 1510.6142, grad_norm: 8463.1686
2025-05-19 14:00:56,718 - mmdet - INFO - Epoch [1][200/2207]	lr: 1.254e-05, eta: 11:06:53, time: 0.849, data_time: 0.006, memory: 11133, loss_cls: 1.1723, loss_bbox: 1.8663, d0.loss_cls: 1.1969, d0.loss_bbox: 3.1606, d1.loss_cls: 1.1736, d1.loss_bbox: 1.8738, d2.loss_cls: 1.1743, d2.loss_bbox: 1.8291, d3.loss_cls: 1.1720, d3.loss_bbox: 1.8150, d4.loss_cls: 1.1728, d4.loss_bbox: 1.8363, aux_task0.loss_heatmap: 86.0308, aux_task0.loss_bbox: 0.5687, aux_task1.loss_heatmap: 173.9173, aux_task1.loss_bbox: 0.7045, aux_task2.loss_heatmap: 195.1630, aux_task2.loss_bbox: 0.7937, aux_task3.loss_heatmap: 141.6320, aux_task3.loss_bbox: 0.5144, aux_task4.loss_heatmap: 168.1875, aux_task4.loss_bbox: 0.5012, aux_task5.loss_heatmap: 204.7096, aux_task5.loss_bbox: 0.5342, loss: 992.7002, grad_norm: 6101.2303
2025-05-19 14:01:39,215 - mmdet - INFO - Epoch [1][250/2207]	lr: 1.256e-05, eta: 10:57:15, time: 0.850, data_time: 0.005, memory: 11133, loss_cls: 1.1195, loss_bbox: 1.9285, d0.loss_cls: 1.1526, d0.loss_bbox: 2.0261, d1.loss_cls: 1.1448, d1.loss_bbox: 1.7596, d2.loss_cls: 1.1404, d2.loss_bbox: 1.8013, d3.loss_cls: 1.1317, d3.loss_bbox: 1.8500, d4.loss_cls: 1.1244, d4.loss_bbox: 1.8955, aux_task0.loss_heatmap: 39.9171, aux_task0.loss_bbox: 0.5137, aux_task1.loss_heatmap: 111.1034, aux_task1.loss_bbox: 0.6227, aux_task2.loss_heatmap: 132.6128, aux_task2.loss_bbox: 0.7203, aux_task3.loss_heatmap: 72.8480, aux_task3.loss_bbox: 0.5086, aux_task4.loss_heatmap: 114.7091, aux_task4.loss_bbox: 0.4709, aux_task5.loss_heatmap: 112.2702, aux_task5.loss_bbox: 0.5102, loss: 604.8813, grad_norm: 3894.4381
2025-05-19 14:02:21,651 - mmdet - INFO - Epoch [1][300/2207]	lr: 1.258e-05, eta: 10:50:26, time: 0.849, data_time: 0.005, memory: 11133, loss_cls: 1.0888, loss_bbox: 1.8203, d0.loss_cls: 1.1532, d0.loss_bbox: 1.7441, d1.loss_cls: 1.1472, d1.loss_bbox: 1.7429, d2.loss_cls: 1.1342, d2.loss_bbox: 1.7753, d3.loss_cls: 1.1117, d3.loss_bbox: 1.7976, d4.loss_cls: 1.0963, d4.loss_bbox: 1.8148, aux_task0.loss_heatmap: 26.8088, aux_task0.loss_bbox: 0.4731, aux_task1.loss_heatmap: 74.5900, aux_task1.loss_bbox: 0.5759, aux_task2.loss_heatmap: 87.9666, aux_task2.loss_bbox: 0.6555, aux_task3.loss_heatmap: 55.3380, aux_task3.loss_bbox: 0.4637, aux_task4.loss_heatmap: 73.3776, aux_task4.loss_bbox: 0.4557, aux_task5.loss_heatmap: 87.9858, aux_task5.loss_bbox: 0.4822, loss: 426.5993, grad_norm: 2866.1138
2025-05-19 14:03:04,258 - mmdet - INFO - Epoch [1][350/2207]	lr: 1.261e-05, eta: 10:45:44, time: 0.852, data_time: 0.006, memory: 11133, loss_cls: 1.1226, loss_bbox: 1.7572, d0.loss_cls: 1.1677, d0.loss_bbox: 1.7329, d1.loss_cls: 1.1611, d1.loss_bbox: 1.7341, d2.loss_cls: 1.1442, d2.loss_bbox: 1.7453, d3.loss_cls: 1.1303, d3.loss_bbox: 1.7550, d4.loss_cls: 1.1241, d4.loss_bbox: 1.7616, aux_task0.loss_heatmap: 24.6632, aux_task0.loss_bbox: 0.4669, aux_task1.loss_heatmap: 49.7871, aux_task1.loss_bbox: 0.5456, aux_task2.loss_heatmap: 64.0756, aux_task2.loss_bbox: 0.6060, aux_task3.loss_heatmap: 39.7782, aux_task3.loss_bbox: 0.4429, aux_task4.loss_heatmap: 50.5295, aux_task4.loss_bbox: 0.4402, aux_task5.loss_heatmap: 60.7088, aux_task5.loss_bbox: 0.4753, loss: 309.8554, grad_norm: 2157.4586
2025-05-19 14:03:46,709 - mmdet - INFO - Epoch [1][400/2207]	lr: 1.264e-05, eta: 10:41:44, time: 0.849, data_time: 0.006, memory: 11133, loss_cls: 1.1125, loss_bbox: 1.7375, d0.loss_cls: 1.1448, d0.loss_bbox: 1.7303, d1.loss_cls: 1.1405, d1.loss_bbox: 1.7276, d2.loss_cls: 1.1260, d2.loss_bbox: 1.7325, d3.loss_cls: 1.1161, d3.loss_bbox: 1.7374, d4.loss_cls: 1.1106, d4.loss_bbox: 1.7385, aux_task0.loss_heatmap: 12.7704, aux_task0.loss_bbox: 0.4487, aux_task1.loss_heatmap: 34.3464, aux_task1.loss_bbox: 0.5336, aux_task2.loss_heatmap: 43.9666, aux_task2.loss_bbox: 0.5750, aux_task3.loss_heatmap: 29.0387, aux_task3.loss_bbox: 0.4460, aux_task4.loss_heatmap: 35.0947, aux_task4.loss_bbox: 0.4402, aux_task5.loss_heatmap: 38.8940, aux_task5.loss_bbox: 0.4758, loss: 214.1844, grad_norm: 1504.7274
2025-05-19 14:04:29,653 - mmdet - INFO - Epoch [1][450/2207]	lr: 1.268e-05, eta: 10:39:16, time: 0.859, data_time: 0.006, memory: 11133, loss_cls: 1.1123, loss_bbox: 1.7258, d0.loss_cls: 1.1473, d0.loss_bbox: 1.7430, d1.loss_cls: 1.1402, d1.loss_bbox: 1.7345, d2.loss_cls: 1.1291, d2.loss_bbox: 1.7319, d3.loss_cls: 1.1214, d3.loss_bbox: 1.7346, d4.loss_cls: 1.1161, d4.loss_bbox: 1.7308, aux_task0.loss_heatmap: 12.0816, aux_task0.loss_bbox: 0.4395, aux_task1.loss_heatmap: 22.9169, aux_task1.loss_bbox: 0.5035, aux_task2.loss_heatmap: 27.4592, aux_task2.loss_bbox: 0.5378, aux_task3.loss_heatmap: 16.2196, aux_task3.loss_bbox: 0.4335, aux_task4.loss_heatmap: 23.4939, aux_task4.loss_bbox: 0.4386, aux_task5.loss_heatmap: 25.3597, aux_task5.loss_bbox: 0.4627, loss: 147.5134, grad_norm: 993.9739
2025-05-19 14:05:12,080 - mmdet - INFO - Epoch [1][500/2207]	lr: 1.272e-05, eta: 10:36:24, time: 0.849, data_time: 0.006, memory: 11133, loss_cls: 1.0875, loss_bbox: 1.7048, d0.loss_cls: 1.1420, d0.loss_bbox: 1.7323, d1.loss_cls: 1.1349, d1.loss_bbox: 1.7207, d2.loss_cls: 1.1221, d2.loss_bbox: 1.7285, d3.loss_cls: 1.1102, d3.loss_bbox: 1.7274, d4.loss_cls: 1.0935, d4.loss_bbox: 1.7152, aux_task0.loss_heatmap: 7.0571, aux_task0.loss_bbox: 0.4454, aux_task1.loss_heatmap: 15.8547, aux_task1.loss_bbox: 0.5016, aux_task2.loss_heatmap: 21.2531, aux_task2.loss_bbox: 0.5215, aux_task3.loss_heatmap: 11.4762, aux_task3.loss_bbox: 0.4181, aux_task4.loss_heatmap: 15.7402, aux_task4.loss_bbox: 0.4397, aux_task5.loss_heatmap: 18.3273, aux_task5.loss_bbox: 0.4728, loss: 109.5268, grad_norm: 725.4339
2025-05-19 14:05:54,541 - mmdet - INFO - Epoch [1][550/2207]	lr: 1.277e-05, eta: 10:33:58, time: 0.849, data_time: 0.005, memory: 11133, loss_cls: 1.0539, loss_bbox: 1.7161, d0.loss_cls: 1.1296, d0.loss_bbox: 1.7386, d1.loss_cls: 1.1209, d1.loss_bbox: 1.7207, d2.loss_cls: 1.1053, d2.loss_bbox: 1.7195, d3.loss_cls: 1.0872, d3.loss_bbox: 1.7154, d4.loss_cls: 1.0599, d4.loss_bbox: 1.7103, aux_task0.loss_heatmap: 5.5890, aux_task0.loss_bbox: 0.4428, aux_task1.loss_heatmap: 10.2229, aux_task1.loss_bbox: 0.4940, aux_task2.loss_heatmap: 12.6594, aux_task2.loss_bbox: 0.5161, aux_task3.loss_heatmap: 8.5473, aux_task3.loss_bbox: 0.4195, aux_task4.loss_heatmap: 10.7954, aux_task4.loss_bbox: 0.4202, aux_task5.loss_heatmap: 12.0450, aux_task5.loss_bbox: 0.4647, loss: 79.4939, grad_norm: 483.4457
2025-05-19 14:06:38,890 - mmdet - INFO - Epoch [1][600/2207]	lr: 1.282e-05, eta: 10:34:06, time: 0.887, data_time: 0.006, memory: 11194, loss_cls: 1.0593, loss_bbox: 1.6948, d0.loss_cls: 1.1383, d0.loss_bbox: 1.7275, d1.loss_cls: 1.1241, d1.loss_bbox: 1.7147, d2.loss_cls: 1.0977, d2.loss_bbox: 1.7138, d3.loss_cls: 1.0775, d3.loss_bbox: 1.6947, d4.loss_cls: 1.0596, d4.loss_bbox: 1.6997, aux_task0.loss_heatmap: 4.3231, aux_task0.loss_bbox: 0.4464, aux_task1.loss_heatmap: 7.1288, aux_task1.loss_bbox: 0.4909, aux_task2.loss_heatmap: 8.5319, aux_task2.loss_bbox: 0.5177, aux_task3.loss_heatmap: 7.2760, aux_task3.loss_bbox: 0.4132, aux_task4.loss_heatmap: 7.3302, aux_task4.loss_bbox: 0.4295, aux_task5.loss_heatmap: 8.7444, aux_task5.loss_bbox: 0.4610, loss: 62.8950, grad_norm: 343.9378
2025-05-19 14:07:21,197 - mmdet - INFO - Epoch [1][650/2207]	lr: 1.287e-05, eta: 10:31:50, time: 0.846, data_time: 0.007, memory: 11194, loss_cls: 1.0489, loss_bbox: 1.6965, d0.loss_cls: 1.1252, d0.loss_bbox: 1.7483, d1.loss_cls: 1.1095, d1.loss_bbox: 1.7304, d2.loss_cls: 1.0733, d2.loss_bbox: 1.7161, d3.loss_cls: 1.0538, d3.loss_bbox: 1.7059, d4.loss_cls: 1.0451, d4.loss_bbox: 1.7069, aux_task0.loss_heatmap: 3.4199, aux_task0.loss_bbox: 0.4514, aux_task1.loss_heatmap: 5.0782, aux_task1.loss_bbox: 0.4987, aux_task2.loss_heatmap: 5.7731, aux_task2.loss_bbox: 0.5205, aux_task3.loss_heatmap: 4.7241, aux_task3.loss_bbox: 0.4215, aux_task4.loss_heatmap: 5.1297, aux_task4.loss_bbox: 0.4347, aux_task5.loss_heatmap: 5.9658, aux_task5.loss_bbox: 0.4586, loss: 49.6362, grad_norm: 224.3480
2025-05-19 14:08:03,537 - mmdet - INFO - Epoch [1][700/2207]	lr: 1.293e-05, eta: 10:29:49, time: 0.847, data_time: 0.006, memory: 11194, loss_cls: 1.0361, loss_bbox: 1.6558, d0.loss_cls: 1.1086, d0.loss_bbox: 1.7308, d1.loss_cls: 1.1001, d1.loss_bbox: 1.7085, d2.loss_cls: 1.0474, d2.loss_bbox: 1.6842, d3.loss_cls: 1.0372, d3.loss_bbox: 1.6728, d4.loss_cls: 1.0329, d4.loss_bbox: 1.6620, aux_task0.loss_heatmap: 2.5222, aux_task0.loss_bbox: 0.4379, aux_task1.loss_heatmap: 3.6812, aux_task1.loss_bbox: 0.5001, aux_task2.loss_heatmap: 4.2937, aux_task2.loss_bbox: 0.4870, aux_task3.loss_heatmap: 3.9200, aux_task3.loss_bbox: 0.4089, aux_task4.loss_heatmap: 3.8134, aux_task4.loss_bbox: 0.4268, aux_task5.loss_heatmap: 4.1912, aux_task5.loss_bbox: 0.4504, loss: 41.6092, grad_norm: 155.7169
2025-05-19 14:08:46,110 - mmdet - INFO - Epoch [1][750/2207]	lr: 1.300e-05, eta: 10:28:12, time: 0.851, data_time: 0.005, memory: 11194, loss_cls: 1.0283, loss_bbox: 1.6563, d0.loss_cls: 1.0880, d0.loss_bbox: 1.7399, d1.loss_cls: 1.0752, d1.loss_bbox: 1.7082, d2.loss_cls: 1.0283, d2.loss_bbox: 1.6833, d3.loss_cls: 1.0258, d3.loss_bbox: 1.6684, d4.loss_cls: 1.0233, d4.loss_bbox: 1.6603, aux_task0.loss_heatmap: 2.1687, aux_task0.loss_bbox: 0.4267, aux_task1.loss_heatmap: 2.8230, aux_task1.loss_bbox: 0.4878, aux_task2.loss_heatmap: 3.1980, aux_task2.loss_bbox: 0.4764, aux_task3.loss_heatmap: 2.6925, aux_task3.loss_bbox: 0.4082, aux_task4.loss_heatmap: 2.8745, aux_task4.loss_bbox: 0.4323, aux_task5.loss_heatmap: 3.2316, aux_task5.loss_bbox: 0.4524, loss: 36.0572, grad_norm: 98.3735
2025-05-19 14:09:28,700 - mmdet - INFO - Epoch [1][800/2207]	lr: 1.307e-05, eta: 10:26:43, time: 0.852, data_time: 0.006, memory: 11194, loss_cls: 1.0153, loss_bbox: 1.6007, d0.loss_cls: 1.0762, d0.loss_bbox: 1.7035, d1.loss_cls: 1.0518, d1.loss_bbox: 1.6720, d2.loss_cls: 1.0011, d2.loss_bbox: 1.6527, d3.loss_cls: 1.0050, d3.loss_bbox: 1.6274, d4.loss_cls: 1.0107, d4.loss_bbox: 1.6118, aux_task0.loss_heatmap: 1.7787, aux_task0.loss_bbox: 0.4357, aux_task1.loss_heatmap: 2.2688, aux_task1.loss_bbox: 0.4777, aux_task2.loss_heatmap: 2.5936, aux_task2.loss_bbox: 0.4804, aux_task3.loss_heatmap: 2.4764, aux_task3.loss_bbox: 0.3949, aux_task4.loss_heatmap: 2.3434, aux_task4.loss_bbox: 0.4249, aux_task5.loss_heatmap: 2.5424, aux_task5.loss_bbox: 0.4435, loss: 32.6886, grad_norm: 71.6630
2025-05-19 14:10:11,433 - mmdet - INFO - Epoch [1][850/2207]	lr: 1.314e-05, eta: 10:25:26, time: 0.855, data_time: 0.007, memory: 11194, loss_cls: 1.0416, loss_bbox: 1.6195, d0.loss_cls: 1.0864, d0.loss_bbox: 1.7271, d1.loss_cls: 1.0542, d1.loss_bbox: 1.6733, d2.loss_cls: 1.0243, d2.loss_bbox: 1.6503, d3.loss_cls: 1.0318, d3.loss_bbox: 1.6283, d4.loss_cls: 1.0368, d4.loss_bbox: 1.6276, aux_task0.loss_heatmap: 1.7196, aux_task0.loss_bbox: 0.4161, aux_task1.loss_heatmap: 2.0216, aux_task1.loss_bbox: 0.4829, aux_task2.loss_heatmap: 2.1790, aux_task2.loss_bbox: 0.4887, aux_task3.loss_heatmap: 2.0466, aux_task3.loss_bbox: 0.3963, aux_task4.loss_heatmap: 2.0018, aux_task4.loss_bbox: 0.4239, aux_task5.loss_heatmap: 2.2653, aux_task5.loss_bbox: 0.4508, loss: 31.0937, grad_norm: 54.6090
2025-05-19 14:10:53,972 - mmdet - INFO - Epoch [1][900/2207]	lr: 1.322e-05, eta: 10:24:04, time: 0.851, data_time: 0.006, memory: 11194, loss_cls: 1.0395, loss_bbox: 1.6059, d0.loss_cls: 1.0752, d0.loss_bbox: 1.7391, d1.loss_cls: 1.0319, d1.loss_bbox: 1.6791, d2.loss_cls: 1.0129, d2.loss_bbox: 1.6560, d3.loss_cls: 1.0231, d3.loss_bbox: 1.6321, d4.loss_cls: 1.0290, d4.loss_bbox: 1.6236, aux_task0.loss_heatmap: 1.5911, aux_task0.loss_bbox: 0.4268, aux_task1.loss_heatmap: 1.8756, aux_task1.loss_bbox: 0.4889, aux_task2.loss_heatmap: 2.0334, aux_task2.loss_bbox: 0.4889, aux_task3.loss_heatmap: 1.9260, aux_task3.loss_bbox: 0.3969, aux_task4.loss_heatmap: 1.8189, aux_task4.loss_bbox: 0.4239, aux_task5.loss_heatmap: 1.9233, aux_task5.loss_bbox: 0.4486, loss: 29.9898, grad_norm: 45.2957
2025-05-19 14:11:36,606 - mmdet - INFO - Epoch [1][950/2207]	lr: 1.330e-05, eta: 10:22:51, time: 0.853, data_time: 0.006, memory: 11204, loss_cls: 1.0037, loss_bbox: 1.6092, d0.loss_cls: 1.0481, d0.loss_bbox: 1.7413, d1.loss_cls: 0.9959, d1.loss_bbox: 1.6596, d2.loss_cls: 0.9888, d2.loss_bbox: 1.6290, d3.loss_cls: 0.9950, d3.loss_bbox: 1.6181, d4.loss_cls: 0.9968, d4.loss_bbox: 1.6139, aux_task0.loss_heatmap: 1.5212, aux_task0.loss_bbox: 0.4311, aux_task1.loss_heatmap: 1.7489, aux_task1.loss_bbox: 0.4784, aux_task2.loss_heatmap: 1.8437, aux_task2.loss_bbox: 0.4638, aux_task3.loss_heatmap: 1.7138, aux_task3.loss_bbox: 0.3928, aux_task4.loss_heatmap: 1.6662, aux_task4.loss_bbox: 0.4162, aux_task5.loss_heatmap: 1.7276, aux_task5.loss_bbox: 0.4415, loss: 28.7445, grad_norm: 36.2386
2025-05-19 14:12:19,214 - mmdet - INFO - Exp name: lidar_0075v_900q_split14_hednetbackbone4_dss0511_num1_noconv_noxy_norope_dp03.py
2025-05-19 14:12:19,214 - mmdet - INFO - Epoch [1][1000/2207]	lr: 1.339e-05, eta: 10:21:39, time: 0.852, data_time: 0.006, memory: 11204, loss_cls: 1.0054, loss_bbox: 1.5633, d0.loss_cls: 1.0555, d0.loss_bbox: 1.6929, d1.loss_cls: 1.0042, d1.loss_bbox: 1.6088, d2.loss_cls: 0.9973, d2.loss_bbox: 1.5856, d3.loss_cls: 0.9997, d3.loss_bbox: 1.5762, d4.loss_cls: 1.0015, d4.loss_bbox: 1.5677, aux_task0.loss_heatmap: 1.5280, aux_task0.loss_bbox: 0.4222, aux_task1.loss_heatmap: 1.6654, aux_task1.loss_bbox: 0.4558, aux_task2.loss_heatmap: 1.8566, aux_task2.loss_bbox: 0.4666, aux_task3.loss_heatmap: 1.7143, aux_task3.loss_bbox: 0.3963, aux_task4.loss_heatmap: 1.5821, aux_task4.loss_bbox: 0.4152, aux_task5.loss_heatmap: 1.6980, aux_task5.loss_bbox: 0.4397, loss: 28.2982, grad_norm: 36.8455
2025-05-19 14:13:01,831 - mmdet - INFO - Epoch [1][1050/2207]	lr: 1.348e-05, eta: 10:20:31, time: 0.852, data_time: 0.005, memory: 11204, loss_cls: 0.9780, loss_bbox: 1.6001, d0.loss_cls: 1.0316, d0.loss_bbox: 1.7299, d1.loss_cls: 0.9828, d1.loss_bbox: 1.6304, d2.loss_cls: 0.9786, d2.loss_bbox: 1.6162, d3.loss_cls: 0.9804, d3.loss_bbox: 1.6066, d4.loss_cls: 0.9779, d4.loss_bbox: 1.6031, aux_task0.loss_heatmap: 1.4372, aux_task0.loss_bbox: 0.4274, aux_task1.loss_heatmap: 1.6067, aux_task1.loss_bbox: 0.4674, aux_task2.loss_heatmap: 1.7849, aux_task2.loss_bbox: 0.4771, aux_task3.loss_heatmap: 1.5742, aux_task3.loss_bbox: 0.3946, aux_task4.loss_heatmap: 1.5059, aux_task4.loss_bbox: 0.4243, aux_task5.loss_heatmap: 1.6283, aux_task5.loss_bbox: 0.4443, loss: 27.8879, grad_norm: 32.6095
2025-05-19 14:13:44,268 - mmdet - INFO - Epoch [1][1100/2207]	lr: 1.357e-05, eta: 10:19:18, time: 0.849, data_time: 0.006, memory: 11204, loss_cls: 0.9534, loss_bbox: 1.5746, d0.loss_cls: 1.0113, d0.loss_bbox: 1.7139, d1.loss_cls: 0.9627, d1.loss_bbox: 1.6040, d2.loss_cls: 0.9583, d2.loss_bbox: 1.5898, d3.loss_cls: 0.9567, d3.loss_bbox: 1.5756, d4.loss_cls: 0.9521, d4.loss_bbox: 1.5743, aux_task0.loss_heatmap: 1.4139, aux_task0.loss_bbox: 0.4183, aux_task1.loss_heatmap: 1.5939, aux_task1.loss_bbox: 0.4701, aux_task2.loss_heatmap: 1.7933, aux_task2.loss_bbox: 0.4702, aux_task3.loss_heatmap: 1.5285, aux_task3.loss_bbox: 0.4033, aux_task4.loss_heatmap: 1.3990, aux_task4.loss_bbox: 0.4157, aux_task5.loss_heatmap: 1.5257, aux_task5.loss_bbox: 0.4332, loss: 27.2919, grad_norm: 32.6690
2025-05-19 14:14:26,854 - mmdet - INFO - Epoch [1][1150/2207]	lr: 1.367e-05, eta: 10:18:13, time: 0.852, data_time: 0.007, memory: 11204, loss_cls: 0.9442, loss_bbox: 1.5631, d0.loss_cls: 0.9974, d0.loss_bbox: 1.6957, d1.loss_cls: 0.9566, d1.loss_bbox: 1.5864, d2.loss_cls: 0.9510, d2.loss_bbox: 1.5730, d3.loss_cls: 0.9509, d3.loss_bbox: 1.5606, d4.loss_cls: 0.9447, d4.loss_bbox: 1.5612, aux_task0.loss_heatmap: 1.3769, aux_task0.loss_bbox: 0.4071, aux_task1.loss_heatmap: 1.5825, aux_task1.loss_bbox: 0.4503, aux_task2.loss_heatmap: 1.7687, aux_task2.loss_bbox: 0.4770, aux_task3.loss_heatmap: 1.5005, aux_task3.loss_bbox: 0.3951, aux_task4.loss_heatmap: 1.3339, aux_task4.loss_bbox: 0.4105, aux_task5.loss_heatmap: 1.5136, aux_task5.loss_bbox: 0.4304, loss: 26.9311, grad_norm: 33.9688
2025-05-19 14:15:11,325 - mmdet - INFO - Epoch [1][1200/2207]	lr: 1.378e-05, eta: 10:18:17, time: 0.889, data_time: 0.006, memory: 11204, loss_cls: 0.9286, loss_bbox: 1.5445, d0.loss_cls: 0.9825, d0.loss_bbox: 1.6797, d1.loss_cls: 0.9415, d1.loss_bbox: 1.5713, d2.loss_cls: 0.9337, d2.loss_bbox: 1.5578, d3.loss_cls: 0.9329, d3.loss_bbox: 1.5478, d4.loss_cls: 0.9276, d4.loss_bbox: 1.5461, aux_task0.loss_heatmap: 1.3349, aux_task0.loss_bbox: 0.4053, aux_task1.loss_heatmap: 1.5733, aux_task1.loss_bbox: 0.4445, aux_task2.loss_heatmap: 1.7557, aux_task2.loss_bbox: 0.4680, aux_task3.loss_heatmap: 1.4612, aux_task3.loss_bbox: 0.3882, aux_task4.loss_heatmap: 1.2571, aux_task4.loss_bbox: 0.4118, aux_task5.loss_heatmap: 1.4636, aux_task5.loss_bbox: 0.4329, loss: 26.4905, grad_norm: 34.2502
2025-05-19 14:15:54,271 - mmdet - INFO - Epoch [1][1250/2207]	lr: 1.388e-05, eta: 10:17:25, time: 0.859, data_time: 0.007, memory: 11204, loss_cls: 0.9413, loss_bbox: 1.5556, d0.loss_cls: 0.9953, d0.loss_bbox: 1.6789, d1.loss_cls: 0.9529, d1.loss_bbox: 1.5809, d2.loss_cls: 0.9444, d2.loss_bbox: 1.5718, d3.loss_cls: 0.9424, d3.loss_bbox: 1.5606, d4.loss_cls: 0.9366, d4.loss_bbox: 1.5583, aux_task0.loss_heatmap: 1.4109, aux_task0.loss_bbox: 0.4216, aux_task1.loss_heatmap: 1.5215, aux_task1.loss_bbox: 0.4501, aux_task2.loss_heatmap: 1.7398, aux_task2.loss_bbox: 0.4651, aux_task3.loss_heatmap: 1.4772, aux_task3.loss_bbox: 0.3832, aux_task4.loss_heatmap: 1.2409, aux_task4.loss_bbox: 0.4190, aux_task5.loss_heatmap: 1.4574, aux_task5.loss_bbox: 0.4313, loss: 26.6368, grad_norm: 35.5685
2025-05-19 14:16:36,726 - mmdet - INFO - Epoch [1][1300/2207]	lr: 1.400e-05, eta: 10:16:18, time: 0.849, data_time: 0.007, memory: 11204, loss_cls: 0.9234, loss_bbox: 1.5358, d0.loss_cls: 0.9678, d0.loss_bbox: 1.6645, d1.loss_cls: 0.9347, d1.loss_bbox: 1.5636, d2.loss_cls: 0.9267, d2.loss_bbox: 1.5528, d3.loss_cls: 0.9239, d3.loss_bbox: 1.5434, d4.loss_cls: 0.9199, d4.loss_bbox: 1.5391, aux_task0.loss_heatmap: 1.3357, aux_task0.loss_bbox: 0.4046, aux_task1.loss_heatmap: 1.5059, aux_task1.loss_bbox: 0.4552, aux_task2.loss_heatmap: 1.7463, aux_task2.loss_bbox: 0.4793, aux_task3.loss_heatmap: 1.4685, aux_task3.loss_bbox: 0.3876, aux_task4.loss_heatmap: 1.2043, aux_task4.loss_bbox: 0.4059, aux_task5.loss_heatmap: 1.3948, aux_task5.loss_bbox: 0.4265, loss: 26.2102, grad_norm: 35.1248
2025-05-19 14:17:19,426 - mmdet - INFO - Epoch [1][1350/2207]	lr: 1.411e-05, eta: 10:15:20, time: 0.854, data_time: 0.008, memory: 11204, loss_cls: 0.9135, loss_bbox: 1.5344, d0.loss_cls: 0.9580, d0.loss_bbox: 1.6655, d1.loss_cls: 0.9251, d1.loss_bbox: 1.5666, d2.loss_cls: 0.9147, d2.loss_bbox: 1.5552, d3.loss_cls: 0.9136, d3.loss_bbox: 1.5426, d4.loss_cls: 0.9122, d4.loss_bbox: 1.5372, aux_task0.loss_heatmap: 1.3117, aux_task0.loss_bbox: 0.4143, aux_task1.loss_heatmap: 1.4991, aux_task1.loss_bbox: 0.4443, aux_task2.loss_heatmap: 1.7193, aux_task2.loss_bbox: 0.4745, aux_task3.loss_heatmap: 1.3972, aux_task3.loss_bbox: 0.3810, aux_task4.loss_heatmap: 1.1501, aux_task4.loss_bbox: 0.4003, aux_task5.loss_heatmap: 1.3690, aux_task5.loss_bbox: 0.4216, loss: 25.9209, grad_norm: 33.4506
2025-05-19 14:18:02,264 - mmdet - INFO - Epoch [1][1400/2207]	lr: 1.423e-05, eta: 10:14:28, time: 0.857, data_time: 0.006, memory: 11204, loss_cls: 0.9254, loss_bbox: 1.5244, d0.loss_cls: 0.9624, d0.loss_bbox: 1.6615, d1.loss_cls: 0.9343, d1.loss_bbox: 1.5658, d2.loss_cls: 0.9241, d2.loss_bbox: 1.5515, d3.loss_cls: 0.9244, d3.loss_bbox: 1.5351, d4.loss_cls: 0.9217, d4.loss_bbox: 1.5292, aux_task0.loss_heatmap: 1.3401, aux_task0.loss_bbox: 0.4103, aux_task1.loss_heatmap: 1.4852, aux_task1.loss_bbox: 0.4288, aux_task2.loss_heatmap: 1.7258, aux_task2.loss_bbox: 0.4668, aux_task3.loss_heatmap: 1.4094, aux_task3.loss_bbox: 0.3795, aux_task4.loss_heatmap: 1.1205, aux_task4.loss_bbox: 0.3995, aux_task5.loss_heatmap: 1.3348, aux_task5.loss_bbox: 0.4109, loss: 25.8715, grad_norm: 34.5176
2025-05-19 14:18:44,817 - mmdet - INFO - Epoch [1][1450/2207]	lr: 1.436e-05, eta: 10:13:28, time: 0.851, data_time: 0.006, memory: 11204, loss_cls: 0.9201, loss_bbox: 1.5040, d0.loss_cls: 0.9532, d0.loss_bbox: 1.6440, d1.loss_cls: 0.9277, d1.loss_bbox: 1.5442, d2.loss_cls: 0.9170, d2.loss_bbox: 1.5279, d3.loss_cls: 0.9169, d3.loss_bbox: 1.5152, d4.loss_cls: 0.9174, d4.loss_bbox: 1.5084, aux_task0.loss_heatmap: 1.3109, aux_task0.loss_bbox: 0.3988, aux_task1.loss_heatmap: 1.5024, aux_task1.loss_bbox: 0.4291, aux_task2.loss_heatmap: 1.7090, aux_task2.loss_bbox: 0.4684, aux_task3.loss_heatmap: 1.3589, aux_task3.loss_bbox: 0.3767, aux_task4.loss_heatmap: 1.1144, aux_task4.loss_bbox: 0.3940, aux_task5.loss_heatmap: 1.3408, aux_task5.loss_bbox: 0.4189, loss: 25.6185, grad_norm: 34.1824
2025-05-19 14:19:27,533 - mmdet - INFO - Epoch [1][1500/2207]	lr: 1.449e-05, eta: 10:12:33, time: 0.854, data_time: 0.006, memory: 11205, loss_cls: 0.9111, loss_bbox: 1.5083, d0.loss_cls: 0.9447, d0.loss_bbox: 1.6399, d1.loss_cls: 0.9165, d1.loss_bbox: 1.5482, d2.loss_cls: 0.9088, d2.loss_bbox: 1.5308, d3.loss_cls: 0.9089, d3.loss_bbox: 1.5177, d4.loss_cls: 0.9090, d4.loss_bbox: 1.5118, aux_task0.loss_heatmap: 1.3170, aux_task0.loss_bbox: 0.3864, aux_task1.loss_heatmap: 1.4804, aux_task1.loss_bbox: 0.4289, aux_task2.loss_heatmap: 1.7237, aux_task2.loss_bbox: 0.4490, aux_task3.loss_heatmap: 1.3700, aux_task3.loss_bbox: 0.3753, aux_task4.loss_heatmap: 1.0970, aux_task4.loss_bbox: 0.3987, aux_task5.loss_heatmap: 1.3476, aux_task5.loss_bbox: 0.4122, loss: 25.5418, grad_norm: 36.4970
2025-05-19 14:20:09,894 - mmdet - INFO - Epoch [1][1550/2207]	lr: 1.462e-05, eta: 10:11:30, time: 0.847, data_time: 0.006, memory: 11205, loss_cls: 0.9224, loss_bbox: 1.4822, d0.loss_cls: 0.9473, d0.loss_bbox: 1.6391, d1.loss_cls: 0.9270, d1.loss_bbox: 1.5365, d2.loss_cls: 0.9199, d2.loss_bbox: 1.5170, d3.loss_cls: 0.9230, d3.loss_bbox: 1.4984, d4.loss_cls: 0.9204, d4.loss_bbox: 1.4887, aux_task0.loss_heatmap: 1.2596, aux_task0.loss_bbox: 0.3911, aux_task1.loss_heatmap: 1.4901, aux_task1.loss_bbox: 0.4246, aux_task2.loss_heatmap: 1.7191, aux_task2.loss_bbox: 0.4537, aux_task3.loss_heatmap: 1.3346, aux_task3.loss_bbox: 0.3734, aux_task4.loss_heatmap: 1.0417, aux_task4.loss_bbox: 0.3758, aux_task5.loss_heatmap: 1.2830, aux_task5.loss_bbox: 0.3986, loss: 25.2673, grad_norm: 34.9131
2025-05-19 14:20:52,441 - mmdet - INFO - Epoch [1][1600/2207]	lr: 1.476e-05, eta: 10:10:33, time: 0.851, data_time: 0.006, memory: 11205, loss_cls: 0.9040, loss_bbox: 1.4625, d0.loss_cls: 0.9333, d0.loss_bbox: 1.6178, d1.loss_cls: 0.9133, d1.loss_bbox: 1.5189, d2.loss_cls: 0.9052, d2.loss_bbox: 1.4931, d3.loss_cls: 0.9027, d3.loss_bbox: 1.4782, d4.loss_cls: 0.9025, d4.loss_bbox: 1.4683, aux_task0.loss_heatmap: 1.2527, aux_task0.loss_bbox: 0.3935, aux_task1.loss_heatmap: 1.4696, aux_task1.loss_bbox: 0.4165, aux_task2.loss_heatmap: 1.7145, aux_task2.loss_bbox: 0.4534, aux_task3.loss_heatmap: 1.3292, aux_task3.loss_bbox: 0.3646, aux_task4.loss_heatmap: 1.0442, aux_task4.loss_bbox: 0.3829, aux_task5.loss_heatmap: 1.2573, aux_task5.loss_bbox: 0.3996, loss: 24.9779, grad_norm: 35.7169
2025-05-19 14:21:34,987 - mmdet - INFO - Epoch [1][1650/2207]	lr: 1.490e-05, eta: 10:09:37, time: 0.851, data_time: 0.007, memory: 11205, loss_cls: 0.9084, loss_bbox: 1.4564, d0.loss_cls: 0.9392, d0.loss_bbox: 1.6107, d1.loss_cls: 0.9166, d1.loss_bbox: 1.5108, d2.loss_cls: 0.9093, d2.loss_bbox: 1.4873, d3.loss_cls: 0.9095, d3.loss_bbox: 1.4699, d4.loss_cls: 0.9077, d4.loss_bbox: 1.4623, aux_task0.loss_heatmap: 1.2204, aux_task0.loss_bbox: 0.3778, aux_task1.loss_heatmap: 1.4492, aux_task1.loss_bbox: 0.4272, aux_task2.loss_heatmap: 1.6899, aux_task2.loss_bbox: 0.4619, aux_task3.loss_heatmap: 1.3777, aux_task3.loss_bbox: 0.3645, aux_task4.loss_heatmap: 1.0164, aux_task4.loss_bbox: 0.3805, aux_task5.loss_heatmap: 1.2502, aux_task5.loss_bbox: 0.3995, loss: 24.9032, grad_norm: 36.7518
2025-05-19 14:22:17,435 - mmdet - INFO - Epoch [1][1700/2207]	lr: 1.505e-05, eta: 10:08:39, time: 0.849, data_time: 0.006, memory: 11205, loss_cls: 0.9007, loss_bbox: 1.4425, d0.loss_cls: 0.9307, d0.loss_bbox: 1.6103, d1.loss_cls: 0.9095, d1.loss_bbox: 1.5069, d2.loss_cls: 0.9040, d2.loss_bbox: 1.4780, d3.loss_cls: 0.9015, d3.loss_bbox: 1.4611, d4.loss_cls: 0.8997, d4.loss_bbox: 1.4492, aux_task0.loss_heatmap: 1.2275, aux_task0.loss_bbox: 0.3848, aux_task1.loss_heatmap: 1.4442, aux_task1.loss_bbox: 0.4214, aux_task2.loss_heatmap: 1.6834, aux_task2.loss_bbox: 0.4585, aux_task3.loss_heatmap: 1.3306, aux_task3.loss_bbox: 0.3581, aux_task4.loss_heatmap: 0.9998, aux_task4.loss_bbox: 0.3714, aux_task5.loss_heatmap: 1.2305, aux_task5.loss_bbox: 0.3967, loss: 24.7011, grad_norm: 36.7949
2025-05-19 14:23:00,346 - mmdet - INFO - Epoch [1][1750/2207]	lr: 1.520e-05, eta: 10:07:53, time: 0.858, data_time: 0.008, memory: 11268, loss_cls: 0.9055, loss_bbox: 1.4380, d0.loss_cls: 0.9346, d0.loss_bbox: 1.6079, d1.loss_cls: 0.9143, d1.loss_bbox: 1.4962, d2.loss_cls: 0.9065, d2.loss_bbox: 1.4728, d3.loss_cls: 0.9053, d3.loss_bbox: 1.4552, d4.loss_cls: 0.9061, d4.loss_bbox: 1.4446, aux_task0.loss_heatmap: 1.2091, aux_task0.loss_bbox: 0.3808, aux_task1.loss_heatmap: 1.4490, aux_task1.loss_bbox: 0.4057, aux_task2.loss_heatmap: 1.6859, aux_task2.loss_bbox: 0.4658, aux_task3.loss_heatmap: 1.3113, aux_task3.loss_bbox: 0.3665, aux_task4.loss_heatmap: 0.9914, aux_task4.loss_bbox: 0.3706, aux_task5.loss_heatmap: 1.2436, aux_task5.loss_bbox: 0.4006, loss: 24.6674, grad_norm: 36.5578
2025-05-19 14:23:42,929 - mmdet - INFO - Epoch [1][1800/2207]	lr: 1.536e-05, eta: 10:07:00, time: 0.852, data_time: 0.009, memory: 11268, loss_cls: 0.9114, loss_bbox: 1.4348, d0.loss_cls: 0.9382, d0.loss_bbox: 1.6150, d1.loss_cls: 0.9175, d1.loss_bbox: 1.4962, d2.loss_cls: 0.9100, d2.loss_bbox: 1.4715, d3.loss_cls: 0.9106, d3.loss_bbox: 1.4557, d4.loss_cls: 0.9099, d4.loss_bbox: 1.4439, aux_task0.loss_heatmap: 1.2361, aux_task0.loss_bbox: 0.3844, aux_task1.loss_heatmap: 1.4349, aux_task1.loss_bbox: 0.4185, aux_task2.loss_heatmap: 1.6796, aux_task2.loss_bbox: 0.4586, aux_task3.loss_heatmap: 1.3399, aux_task3.loss_bbox: 0.3600, aux_task4.loss_heatmap: 1.0125, aux_task4.loss_bbox: 0.3732, aux_task5.loss_heatmap: 1.2317, aux_task5.loss_bbox: 0.3958, loss: 24.7399, grad_norm: 39.6345
2025-05-19 14:24:25,374 - mmdet - INFO - Epoch [1][1850/2207]	lr: 1.552e-05, eta: 10:06:04, time: 0.849, data_time: 0.007, memory: 11268, loss_cls: 0.8914, loss_bbox: 1.4242, d0.loss_cls: 0.9207, d0.loss_bbox: 1.6055, d1.loss_cls: 0.9002, d1.loss_bbox: 1.4887, d2.loss_cls: 0.8929, d2.loss_bbox: 1.4642, d3.loss_cls: 0.8915, d3.loss_bbox: 1.4451, d4.loss_cls: 0.8880, d4.loss_bbox: 1.4333, aux_task0.loss_heatmap: 1.1930, aux_task0.loss_bbox: 0.3861, aux_task1.loss_heatmap: 1.4557, aux_task1.loss_bbox: 0.4148, aux_task2.loss_heatmap: 1.6848, aux_task2.loss_bbox: 0.4576, aux_task3.loss_heatmap: 1.2844, aux_task3.loss_bbox: 0.3577, aux_task4.loss_heatmap: 0.9515, aux_task4.loss_bbox: 0.3732, aux_task5.loss_heatmap: 1.2055, aux_task5.loss_bbox: 0.3888, loss: 24.3988, grad_norm: 37.4915
2025-05-19 14:25:07,682 - mmdet - INFO - Epoch [1][1900/2207]	lr: 1.568e-05, eta: 10:05:06, time: 0.846, data_time: 0.006, memory: 11268, loss_cls: 0.8918, loss_bbox: 1.3915, d0.loss_cls: 0.9224, d0.loss_bbox: 1.5782, d1.loss_cls: 0.9018, d1.loss_bbox: 1.4585, d2.loss_cls: 0.8946, d2.loss_bbox: 1.4315, d3.loss_cls: 0.8932, d3.loss_bbox: 1.4162, d4.loss_cls: 0.8916, d4.loss_bbox: 1.4013, aux_task0.loss_heatmap: 1.1988, aux_task0.loss_bbox: 0.3806, aux_task1.loss_heatmap: 1.4044, aux_task1.loss_bbox: 0.4086, aux_task2.loss_heatmap: 1.6785, aux_task2.loss_bbox: 0.4453, aux_task3.loss_heatmap: 1.2805, aux_task3.loss_bbox: 0.3650, aux_task4.loss_heatmap: 0.9450, aux_task4.loss_bbox: 0.3661, aux_task5.loss_heatmap: 1.2009, aux_task5.loss_bbox: 0.3836, loss: 24.1298, grad_norm: 39.6278
2025-05-19 14:25:50,100 - mmdet - INFO - Epoch [1][1950/2207]	lr: 1.585e-05, eta: 10:04:11, time: 0.848, data_time: 0.006, memory: 11268, loss_cls: 0.8835, loss_bbox: 1.3879, d0.loss_cls: 0.9141, d0.loss_bbox: 1.5882, d1.loss_cls: 0.8898, d1.loss_bbox: 1.4633, d2.loss_cls: 0.8819, d2.loss_bbox: 1.4375, d3.loss_cls: 0.8819, d3.loss_bbox: 1.4174, d4.loss_cls: 0.8815, d4.loss_bbox: 1.3982, aux_task0.loss_heatmap: 1.1791, aux_task0.loss_bbox: 0.3778, aux_task1.loss_heatmap: 1.3949, aux_task1.loss_bbox: 0.4128, aux_task2.loss_heatmap: 1.6969, aux_task2.loss_bbox: 0.4518, aux_task3.loss_heatmap: 1.2865, aux_task3.loss_bbox: 0.3529, aux_task4.loss_heatmap: 0.9500, aux_task4.loss_bbox: 0.3704, aux_task5.loss_heatmap: 1.1793, aux_task5.loss_bbox: 0.3839, loss: 24.0614, grad_norm: 40.2021
2025-05-19 14:26:32,754 - mmdet - INFO - Exp name: lidar_0075v_900q_split14_hednetbackbone4_dss0511_num1_noconv_noxy_norope_dp03.py
2025-05-19 14:26:32,754 - mmdet - INFO - Epoch [1][2000/2207]	lr: 1.602e-05, eta: 10:03:21, time: 0.853, data_time: 0.008, memory: 11268, loss_cls: 0.8789, loss_bbox: 1.3691, d0.loss_cls: 0.9065, d0.loss_bbox: 1.5700, d1.loss_cls: 0.8830, d1.loss_bbox: 1.4452, d2.loss_cls: 0.8762, d2.loss_bbox: 1.4190, d3.loss_cls: 0.8784, d3.loss_bbox: 1.3985, d4.loss_cls: 0.8774, d4.loss_bbox: 1.3794, aux_task0.loss_heatmap: 1.1762, aux_task0.loss_bbox: 0.3746, aux_task1.loss_heatmap: 1.4074, aux_task1.loss_bbox: 0.4139, aux_task2.loss_heatmap: 1.6288, aux_task2.loss_bbox: 0.4483, aux_task3.loss_heatmap: 1.2520, aux_task3.loss_bbox: 0.3465, aux_task4.loss_heatmap: 0.9321, aux_task4.loss_bbox: 0.3692, aux_task5.loss_heatmap: 1.1547, aux_task5.loss_bbox: 0.3798, loss: 23.7652, grad_norm: 39.6344
2025-05-19 14:27:15,214 - mmdet - INFO - Epoch [1][2050/2207]	lr: 1.620e-05, eta: 10:02:28, time: 0.849, data_time: 0.007, memory: 11268, loss_cls: 0.8682, loss_bbox: 1.3099, d0.loss_cls: 0.8891, d0.loss_bbox: 1.5319, d1.loss_cls: 0.8699, d1.loss_bbox: 1.4026, d2.loss_cls: 0.8625, d2.loss_bbox: 1.3704, d3.loss_cls: 0.8663, d3.loss_bbox: 1.3479, d4.loss_cls: 0.8656, d4.loss_bbox: 1.3231, aux_task0.loss_heatmap: 1.1401, aux_task0.loss_bbox: 0.3582, aux_task1.loss_heatmap: 1.3796, aux_task1.loss_bbox: 0.4023, aux_task2.loss_heatmap: 1.6600, aux_task2.loss_bbox: 0.4436, aux_task3.loss_heatmap: 1.2679, aux_task3.loss_bbox: 0.3545, aux_task4.loss_heatmap: 0.9232, aux_task4.loss_bbox: 0.3599, aux_task5.loss_heatmap: 1.1434, aux_task5.loss_bbox: 0.3720, loss: 23.3121, grad_norm: 39.7923
2025-05-19 14:27:57,762 - mmdet - INFO - Epoch [1][2100/2207]	lr: 1.638e-05, eta: 10:01:37, time: 0.851, data_time: 0.006, memory: 11268, loss_cls: 0.8615, loss_bbox: 1.3300, d0.loss_cls: 0.8881, d0.loss_bbox: 1.5658, d1.loss_cls: 0.8687, d1.loss_bbox: 1.4325, d2.loss_cls: 0.8596, d2.loss_bbox: 1.3981, d3.loss_cls: 0.8598, d3.loss_bbox: 1.3729, d4.loss_cls: 0.8598, d4.loss_bbox: 1.3445, aux_task0.loss_heatmap: 1.1303, aux_task0.loss_bbox: 0.3806, aux_task1.loss_heatmap: 1.3930, aux_task1.loss_bbox: 0.4218, aux_task2.loss_heatmap: 1.6480, aux_task2.loss_bbox: 0.4394, aux_task3.loss_heatmap: 1.2572, aux_task3.loss_bbox: 0.3488, aux_task4.loss_heatmap: 0.9327, aux_task4.loss_bbox: 0.3700, aux_task5.loss_heatmap: 1.1149, aux_task5.loss_bbox: 0.3740, loss: 23.4521, grad_norm: 38.8949
2025-05-19 14:28:40,589 - mmdet - INFO - Epoch [1][2150/2207]	lr: 1.656e-05, eta: 10:00:52, time: 0.857, data_time: 0.007, memory: 11268, loss_cls: 0.8670, loss_bbox: 1.3314, d0.loss_cls: 0.8916, d0.loss_bbox: 1.5719, d1.loss_cls: 0.8697, d1.loss_bbox: 1.4328, d2.loss_cls: 0.8648, d2.loss_bbox: 1.3933, d3.loss_cls: 0.8630, d3.loss_bbox: 1.3705, d4.loss_cls: 0.8645, d4.loss_bbox: 1.3445, aux_task0.loss_heatmap: 1.1447, aux_task0.loss_bbox: 0.3770, aux_task1.loss_heatmap: 1.3698, aux_task1.loss_bbox: 0.4129, aux_task2.loss_heatmap: 1.6532, aux_task2.loss_bbox: 0.4513, aux_task3.loss_heatmap: 1.2410, aux_task3.loss_bbox: 0.3465, aux_task4.loss_heatmap: 0.9028, aux_task4.loss_bbox: 0.3676, aux_task5.loss_heatmap: 1.1186, aux_task5.loss_bbox: 0.3717, loss: 23.4222, grad_norm: 40.2713
2025-05-19 14:29:23,296 - mmdet - INFO - Epoch [1][2200/2207]	lr: 1.675e-05, eta: 10:00:05, time: 0.854, data_time: 0.006, memory: 11268, loss_cls: 0.8762, loss_bbox: 1.3274, d0.loss_cls: 0.8901, d0.loss_bbox: 1.5668, d1.loss_cls: 0.8736, d1.loss_bbox: 1.4288, d2.loss_cls: 0.8685, d2.loss_bbox: 1.3886, d3.loss_cls: 0.8692, d3.loss_bbox: 1.3648, d4.loss_cls: 0.8728, d4.loss_bbox: 1.3381, aux_task0.loss_heatmap: 1.1864, aux_task0.loss_bbox: 0.3739, aux_task1.loss_heatmap: 1.3775, aux_task1.loss_bbox: 0.4110, aux_task2.loss_heatmap: 1.6486, aux_task2.loss_bbox: 0.4506, aux_task3.loss_heatmap: 1.2196, aux_task3.loss_bbox: 0.3506, aux_task4.loss_heatmap: 0.9572, aux_task4.loss_bbox: 0.3746, aux_task5.loss_heatmap: 1.1016, aux_task5.loss_bbox: 0.3737, loss: 23.4901, grad_norm: 41.4014
2025-05-19 14:29:29,496 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-05-19 14:30:22,354 - mmdet - INFO - Epoch [2][50/2207]	lr: 1.697e-05, eta: 9:58:18, time: 0.917, data_time: 0.071, memory: 11268, loss_cls: 0.8661, loss_bbox: 1.2896, d0.loss_cls: 0.8867, d0.loss_bbox: 1.5425, d1.loss_cls: 0.8717, d1.loss_bbox: 1.3998, d2.loss_cls: 0.8618, d2.loss_bbox: 1.3505, d3.loss_cls: 0.8626, d3.loss_bbox: 1.3299, d4.loss_cls: 0.8640, d4.loss_bbox: 1.3032, aux_task0.loss_heatmap: 1.1255, aux_task0.loss_bbox: 0.3607, aux_task1.loss_heatmap: 1.3672, aux_task1.loss_bbox: 0.4071, aux_task2.loss_heatmap: 1.6575, aux_task2.loss_bbox: 0.4447, aux_task3.loss_heatmap: 1.2254, aux_task3.loss_bbox: 0.3454, aux_task4.loss_heatmap: 0.9102, aux_task4.loss_bbox: 0.3650, aux_task5.loss_heatmap: 1.1026, aux_task5.loss_bbox: 0.3785, loss: 23.1185, grad_norm: 42.9893
2025-05-19 14:31:04,928 - mmdet - INFO - Epoch [2][100/2207]	lr: 1.717e-05, eta: 9:57:30, time: 0.851, data_time: 0.006, memory: 11268, loss_cls: 0.8711, loss_bbox: 1.2747, d0.loss_cls: 0.8881, d0.loss_bbox: 1.5209, d1.loss_cls: 0.8706, d1.loss_bbox: 1.3863, d2.loss_cls: 0.8659, d2.loss_bbox: 1.3381, d3.loss_cls: 0.8654, d3.loss_bbox: 1.3144, d4.loss_cls: 0.8680, d4.loss_bbox: 1.2867, aux_task0.loss_heatmap: 1.1246, aux_task0.loss_bbox: 0.3635, aux_task1.loss_heatmap: 1.3560, aux_task1.loss_bbox: 0.4030, aux_task2.loss_heatmap: 1.6491, aux_task2.loss_bbox: 0.4540, aux_task3.loss_heatmap: 1.2126, aux_task3.loss_bbox: 0.3429, aux_task4.loss_heatmap: 0.9413, aux_task4.loss_bbox: 0.3633, aux_task5.loss_heatmap: 1.0880, aux_task5.loss_bbox: 0.3695, loss: 23.0179, grad_norm: 42.0140
2025-05-19 14:31:47,604 - mmdet - INFO - Epoch [2][150/2207]	lr: 1.737e-05, eta: 9:56:45, time: 0.853, data_time: 0.006, memory: 11268, loss_cls: 0.8733, loss_bbox: 1.2570, d0.loss_cls: 0.8857, d0.loss_bbox: 1.4924, d1.loss_cls: 0.8714, d1.loss_bbox: 1.3580, d2.loss_cls: 0.8677, d2.loss_bbox: 1.3107, d3.loss_cls: 0.8701, d3.loss_bbox: 1.2915, d4.loss_cls: 0.8711, d4.loss_bbox: 1.2684, aux_task0.loss_heatmap: 1.0966, aux_task0.loss_bbox: 0.3694, aux_task1.loss_heatmap: 1.3561, aux_task1.loss_bbox: 0.3988, aux_task2.loss_heatmap: 1.6176, aux_task2.loss_bbox: 0.4278, aux_task3.loss_heatmap: 1.2170, aux_task3.loss_bbox: 0.3521, aux_task4.loss_heatmap: 0.9051, aux_task4.loss_bbox: 0.3642, aux_task5.loss_heatmap: 1.1040, aux_task5.loss_bbox: 0.3765, loss: 22.8026, grad_norm: 49.0850
2025-05-19 14:32:30,283 - mmdet - INFO - Epoch [2][200/2207]	lr: 1.758e-05, eta: 9:55:59, time: 0.854, data_time: 0.009, memory: 11268, loss_cls: 0.8591, loss_bbox: 1.2742, d0.loss_cls: 0.8775, d0.loss_bbox: 1.5324, d1.loss_cls: 0.8595, d1.loss_bbox: 1.3908, d2.loss_cls: 0.8563, d2.loss_bbox: 1.3373, d3.loss_cls: 0.8573, d3.loss_bbox: 1.3114, d4.loss_cls: 0.8582, d4.loss_bbox: 1.2862, aux_task0.loss_heatmap: 1.1382, aux_task0.loss_bbox: 0.3756, aux_task1.loss_heatmap: 1.3684, aux_task1.loss_bbox: 0.4013, aux_task2.loss_heatmap: 1.6490, aux_task2.loss_bbox: 0.4459, aux_task3.loss_heatmap: 1.2163, aux_task3.loss_bbox: 0.3545, aux_task4.loss_heatmap: 0.8867, aux_task4.loss_bbox: 0.3653, aux_task5.loss_heatmap: 1.0814, aux_task5.loss_bbox: 0.3660, loss: 22.9487, grad_norm: 44.7688
2025-05-19 14:33:12,968 - mmdet - INFO - Epoch [2][250/2207]	lr: 1.779e-05, eta: 9:55:13, time: 0.854, data_time: 0.006, memory: 11268, loss_cls: 0.8600, loss_bbox: 1.2548, d0.loss_cls: 0.8739, d0.loss_bbox: 1.5042, d1.loss_cls: 0.8584, d1.loss_bbox: 1.3683, d2.loss_cls: 0.8547, d2.loss_bbox: 1.3119, d3.loss_cls: 0.8574, d3.loss_bbox: 1.2869, d4.loss_cls: 0.8574, d4.loss_bbox: 1.2643, aux_task0.loss_heatmap: 1.1488, aux_task0.loss_bbox: 0.3682, aux_task1.loss_heatmap: 1.3397, aux_task1.loss_bbox: 0.4093, aux_task2.loss_heatmap: 1.6429, aux_task2.loss_bbox: 0.4340, aux_task3.loss_heatmap: 1.2018, aux_task3.loss_bbox: 0.3568, aux_task4.loss_heatmap: 0.9086, aux_task4.loss_bbox: 0.3683, aux_task5.loss_heatmap: 1.0651, aux_task5.loss_bbox: 0.3666, loss: 22.7624, grad_norm: 44.2309
2025-05-19 14:33:55,475 - mmdet - INFO - Epoch [2][300/2207]	lr: 1.800e-05, eta: 9:54:25, time: 0.850, data_time: 0.008, memory: 11268, loss_cls: 0.8463, loss_bbox: 1.2476, d0.loss_cls: 0.8668, d0.loss_bbox: 1.4876, d1.loss_cls: 0.8473, d1.loss_bbox: 1.3577, d2.loss_cls: 0.8425, d2.loss_bbox: 1.3031, d3.loss_cls: 0.8422, d3.loss_bbox: 1.2823, d4.loss_cls: 0.8450, d4.loss_bbox: 1.2589, aux_task0.loss_heatmap: 1.0952, aux_task0.loss_bbox: 0.3611, aux_task1.loss_heatmap: 1.3498, aux_task1.loss_bbox: 0.4009, aux_task2.loss_heatmap: 1.6265, aux_task2.loss_bbox: 0.4454, aux_task3.loss_heatmap: 1.1850, aux_task3.loss_bbox: 0.3469, aux_task4.loss_heatmap: 0.8748, aux_task4.loss_bbox: 0.3553, aux_task5.loss_heatmap: 1.0435, aux_task5.loss_bbox: 0.3711, loss: 22.4829, grad_norm: 42.7435
2025-05-19 14:34:38,125 - mmdet - INFO - Epoch [2][350/2207]	lr: 1.822e-05, eta: 9:53:39, time: 0.853, data_time: 0.008, memory: 11268, loss_cls: 0.8611, loss_bbox: 1.2304, d0.loss_cls: 0.8706, d0.loss_bbox: 1.4749, d1.loss_cls: 0.8550, d1.loss_bbox: 1.3362, d2.loss_cls: 0.8494, d2.loss_bbox: 1.2818, d3.loss_cls: 0.8556, d3.loss_bbox: 1.2639, d4.loss_cls: 0.8567, d4.loss_bbox: 1.2450, aux_task0.loss_heatmap: 1.0995, aux_task0.loss_bbox: 0.3647, aux_task1.loss_heatmap: 1.3222, aux_task1.loss_bbox: 0.3958, aux_task2.loss_heatmap: 1.6286, aux_task2.loss_bbox: 0.4318, aux_task3.loss_heatmap: 1.2446, aux_task3.loss_bbox: 0.3479, aux_task4.loss_heatmap: 0.8830, aux_task4.loss_bbox: 0.3511, aux_task5.loss_heatmap: 1.0442, aux_task5.loss_bbox: 0.3643, loss: 22.4582, grad_norm: 47.7244
2025-05-19 14:35:20,539 - mmdet - INFO - Epoch [2][400/2207]	lr: 1.844e-05, eta: 9:52:50, time: 0.848, data_time: 0.006, memory: 11268, loss_cls: 0.8658, loss_bbox: 1.2474, d0.loss_cls: 0.8746, d0.loss_bbox: 1.4879, d1.loss_cls: 0.8606, d1.loss_bbox: 1.3474, d2.loss_cls: 0.8574, d2.loss_bbox: 1.2942, d3.loss_cls: 0.8602, d3.loss_bbox: 1.2731, d4.loss_cls: 0.8618, d4.loss_bbox: 1.2561, aux_task0.loss_heatmap: 1.1047, aux_task0.loss_bbox: 0.3635, aux_task1.loss_heatmap: 1.3226, aux_task1.loss_bbox: 0.4128, aux_task2.loss_heatmap: 1.6230, aux_task2.loss_bbox: 0.4484, aux_task3.loss_heatmap: 1.1916, aux_task3.loss_bbox: 0.3401, aux_task4.loss_heatmap: 0.8713, aux_task4.loss_bbox: 0.3587, aux_task5.loss_heatmap: 1.0874, aux_task5.loss_bbox: 0.3739, loss: 22.5844, grad_norm: 46.9438
2025-05-19 14:36:02,914 - mmdet - INFO - Epoch [2][450/2207]	lr: 1.867e-05, eta: 9:52:00, time: 0.848, data_time: 0.006, memory: 11268, loss_cls: 0.8576, loss_bbox: 1.2303, d0.loss_cls: 0.8715, d0.loss_bbox: 1.4647, d1.loss_cls: 0.8569, d1.loss_bbox: 1.3342, d2.loss_cls: 0.8527, d2.loss_bbox: 1.2802, d3.loss_cls: 0.8550, d3.loss_bbox: 1.2613, d4.loss_cls: 0.8560, d4.loss_bbox: 1.2435, aux_task0.loss_heatmap: 1.1083, aux_task0.loss_bbox: 0.3722, aux_task1.loss_heatmap: 1.3125, aux_task1.loss_bbox: 0.4085, aux_task2.loss_heatmap: 1.6100, aux_task2.loss_bbox: 0.4303, aux_task3.loss_heatmap: 1.1548, aux_task3.loss_bbox: 0.3393, aux_task4.loss_heatmap: 0.8975, aux_task4.loss_bbox: 0.3643, aux_task5.loss_heatmap: 1.0709, aux_task5.loss_bbox: 0.3653, loss: 22.3979, grad_norm: 44.5198
2025-05-19 14:36:45,221 - mmdet - INFO - Epoch [2][500/2207]	lr: 1.890e-05, eta: 9:51:09, time: 0.846, data_time: 0.006, memory: 11268, loss_cls: 0.8481, loss_bbox: 1.2292, d0.loss_cls: 0.8639, d0.loss_bbox: 1.4699, d1.loss_cls: 0.8501, d1.loss_bbox: 1.3313, d2.loss_cls: 0.8433, d2.loss_bbox: 1.2792, d3.loss_cls: 0.8468, d3.loss_bbox: 1.2578, d4.loss_cls: 0.8457, d4.loss_bbox: 1.2389, aux_task0.loss_heatmap: 1.1054, aux_task0.loss_bbox: 0.3585, aux_task1.loss_heatmap: 1.3421, aux_task1.loss_bbox: 0.4071, aux_task2.loss_heatmap: 1.6440, aux_task2.loss_bbox: 0.4430, aux_task3.loss_heatmap: 1.1757, aux_task3.loss_bbox: 0.3501, aux_task4.loss_heatmap: 0.8684, aux_task4.loss_bbox: 0.3625, aux_task5.loss_heatmap: 1.0508, aux_task5.loss_bbox: 0.3653, loss: 22.3773, grad_norm: 44.9185
2025-05-19 14:37:27,817 - mmdet - INFO - Epoch [2][550/2207]	lr: 1.913e-05, eta: 9:50:23, time: 0.852, data_time: 0.008, memory: 11268, loss_cls: 0.8474, loss_bbox: 1.2299, d0.loss_cls: 0.8642, d0.loss_bbox: 1.4617, d1.loss_cls: 0.8478, d1.loss_bbox: 1.3320, d2.loss_cls: 0.8436, d2.loss_bbox: 1.2766, d3.loss_cls: 0.8452, d3.loss_bbox: 1.2584, d4.loss_cls: 0.8470, d4.loss_bbox: 1.2407, aux_task0.loss_heatmap: 1.0875, aux_task0.loss_bbox: 0.3722, aux_task1.loss_heatmap: 1.3206, aux_task1.loss_bbox: 0.3996, aux_task2.loss_heatmap: 1.6455, aux_task2.loss_bbox: 0.4500, aux_task3.loss_heatmap: 1.1230, aux_task3.loss_bbox: 0.3328, aux_task4.loss_heatmap: 0.8626, aux_task4.loss_bbox: 0.3429, aux_task5.loss_heatmap: 1.0256, aux_task5.loss_bbox: 0.3588, loss: 22.2154, grad_norm: 45.1870
2025-05-19 14:38:10,479 - mmdet - INFO - Epoch [2][600/2207]	lr: 1.937e-05, eta: 9:49:38, time: 0.853, data_time: 0.006, memory: 11268, loss_cls: 0.8345, loss_bbox: 1.2110, d0.loss_cls: 0.8539, d0.loss_bbox: 1.4442, d1.loss_cls: 0.8327, d1.loss_bbox: 1.3040, d2.loss_cls: 0.8276, d2.loss_bbox: 1.2548, d3.loss_cls: 0.8303, d3.loss_bbox: 1.2365, d4.loss_cls: 0.8330, d4.loss_bbox: 1.2200, aux_task0.loss_heatmap: 1.0365, aux_task0.loss_bbox: 0.3638, aux_task1.loss_heatmap: 1.3278, aux_task1.loss_bbox: 0.3961, aux_task2.loss_heatmap: 1.5779, aux_task2.loss_bbox: 0.4412, aux_task3.loss_heatmap: 1.1795, aux_task3.loss_bbox: 0.3478, aux_task4.loss_heatmap: 0.8621, aux_task4.loss_bbox: 0.3507, aux_task5.loss_heatmap: 1.0176, aux_task5.loss_bbox: 0.3669, loss: 21.9505, grad_norm: 43.2053
2025-05-19 14:38:52,693 - mmdet - INFO - Epoch [2][650/2207]	lr: 1.961e-05, eta: 9:48:47, time: 0.844, data_time: 0.006, memory: 11268, loss_cls: 0.8387, loss_bbox: 1.2070, d0.loss_cls: 0.8596, d0.loss_bbox: 1.4429, d1.loss_cls: 0.8348, d1.loss_bbox: 1.3082, d2.loss_cls: 0.8320, d2.loss_bbox: 1.2532, d3.loss_cls: 0.8328, d3.loss_bbox: 1.2364, d4.loss_cls: 0.8353, d4.loss_bbox: 1.2184, aux_task0.loss_heatmap: 1.0642, aux_task0.loss_bbox: 0.3564, aux_task1.loss_heatmap: 1.3382, aux_task1.loss_bbox: 0.4017, aux_task2.loss_heatmap: 1.6034, aux_task2.loss_bbox: 0.4468, aux_task3.loss_heatmap: 1.1815, aux_task3.loss_bbox: 0.3422, aux_task4.loss_heatmap: 0.8475, aux_task4.loss_bbox: 0.3561, aux_task5.loss_heatmap: 1.0175, aux_task5.loss_bbox: 0.3576, loss: 22.0122, grad_norm: 46.0033
2025-05-19 14:39:35,382 - mmdet - INFO - Epoch [2][700/2207]	lr: 1.985e-05, eta: 9:48:03, time: 0.854, data_time: 0.009, memory: 11268, loss_cls: 0.8463, loss_bbox: 1.2115, d0.loss_cls: 0.8620, d0.loss_bbox: 1.4381, d1.loss_cls: 0.8441, d1.loss_bbox: 1.3081, d2.loss_cls: 0.8420, d2.loss_bbox: 1.2513, d3.loss_cls: 0.8438, d3.loss_bbox: 1.2331, d4.loss_cls: 0.8455, d4.loss_bbox: 1.2185, aux_task0.loss_heatmap: 1.0889, aux_task0.loss_bbox: 0.3665, aux_task1.loss_heatmap: 1.2944, aux_task1.loss_bbox: 0.3962, aux_task2.loss_heatmap: 1.6155, aux_task2.loss_bbox: 0.4300, aux_task3.loss_heatmap: 1.1625, aux_task3.loss_bbox: 0.3506, aux_task4.loss_heatmap: 0.8734, aux_task4.loss_bbox: 0.3520, aux_task5.loss_heatmap: 1.0232, aux_task5.loss_bbox: 0.3580, loss: 22.0556, grad_norm: 45.0215
2025-05-19 14:40:18,460 - mmdet - INFO - Epoch [2][750/2207]	lr: 2.010e-05, eta: 9:47:24, time: 0.862, data_time: 0.006, memory: 11268, loss_cls: 0.8347, loss_bbox: 1.1885, d0.loss_cls: 0.8514, d0.loss_bbox: 1.4162, d1.loss_cls: 0.8333, d1.loss_bbox: 1.2860, d2.loss_cls: 0.8299, d2.loss_bbox: 1.2356, d3.loss_cls: 0.8299, d3.loss_bbox: 1.2168, d4.loss_cls: 0.8329, d4.loss_bbox: 1.1995, aux_task0.loss_heatmap: 1.0803, aux_task0.loss_bbox: 0.3735, aux_task1.loss_heatmap: 1.2987, aux_task1.loss_bbox: 0.4003, aux_task2.loss_heatmap: 1.6184, aux_task2.loss_bbox: 0.4263, aux_task3.loss_heatmap: 1.1563, aux_task3.loss_bbox: 0.3463, aux_task4.loss_heatmap: 0.8579, aux_task4.loss_bbox: 0.3572, aux_task5.loss_heatmap: 0.9912, aux_task5.loss_bbox: 0.3568, loss: 21.8180, grad_norm: 45.2196
2025-05-19 14:41:01,110 - mmdet - INFO - Epoch [2][800/2207]	lr: 2.036e-05, eta: 9:46:40, time: 0.853, data_time: 0.008, memory: 11268, loss_cls: 0.8376, loss_bbox: 1.1866, d0.loss_cls: 0.8577, d0.loss_bbox: 1.4155, d1.loss_cls: 0.8385, d1.loss_bbox: 1.2785, d2.loss_cls: 0.8347, d2.loss_bbox: 1.2277, d3.loss_cls: 0.8335, d3.loss_bbox: 1.2110, d4.loss_cls: 0.8361, d4.loss_bbox: 1.1948, aux_task0.loss_heatmap: 1.0490, aux_task0.loss_bbox: 0.3730, aux_task1.loss_heatmap: 1.2783, aux_task1.loss_bbox: 0.4040, aux_task2.loss_heatmap: 1.5864, aux_task2.loss_bbox: 0.4337, aux_task3.loss_heatmap: 1.0981, aux_task3.loss_bbox: 0.3429, aux_task4.loss_heatmap: 0.8265, aux_task4.loss_bbox: 0.3486, aux_task5.loss_heatmap: 1.0079, aux_task5.loss_bbox: 0.3614, loss: 21.6621, grad_norm: 46.2173
2025-05-19 14:41:43,764 - mmdet - INFO - Epoch [2][850/2207]	lr: 2.061e-05, eta: 9:45:55, time: 0.853, data_time: 0.008, memory: 11268, loss_cls: 0.8310, loss_bbox: 1.1820, d0.loss_cls: 0.8554, d0.loss_bbox: 1.4088, d1.loss_cls: 0.8315, d1.loss_bbox: 1.2731, d2.loss_cls: 0.8258, d2.loss_bbox: 1.2246, d3.loss_cls: 0.8263, d3.loss_bbox: 1.2070, d4.loss_cls: 0.8289, d4.loss_bbox: 1.1920, aux_task0.loss_heatmap: 1.0548, aux_task0.loss_bbox: 0.3581, aux_task1.loss_heatmap: 1.2843, aux_task1.loss_bbox: 0.3976, aux_task2.loss_heatmap: 1.5738, aux_task2.loss_bbox: 0.4270, aux_task3.loss_heatmap: 1.1688, aux_task3.loss_bbox: 0.3423, aux_task4.loss_heatmap: 0.8602, aux_task4.loss_bbox: 0.3513, aux_task5.loss_heatmap: 1.0098, aux_task5.loss_bbox: 0.3591, loss: 21.6734, grad_norm: 46.7106
2025-05-19 14:42:28,127 - mmdet - INFO - Epoch [2][900/2207]	lr: 2.087e-05, eta: 9:45:33, time: 0.887, data_time: 0.006, memory: 11268, loss_cls: 0.8358, loss_bbox: 1.1877, d0.loss_cls: 0.8575, d0.loss_bbox: 1.4134, d1.loss_cls: 0.8386, d1.loss_bbox: 1.2810, d2.loss_cls: 0.8353, d2.loss_bbox: 1.2299, d3.loss_cls: 0.8340, d3.loss_bbox: 1.2137, d4.loss_cls: 0.8360, d4.loss_bbox: 1.1972, aux_task0.loss_heatmap: 1.0734, aux_task0.loss_bbox: 0.3631, aux_task1.loss_heatmap: 1.2861, aux_task1.loss_bbox: 0.3956, aux_task2.loss_heatmap: 1.5839, aux_task2.loss_bbox: 0.4377, aux_task3.loss_heatmap: 1.1058, aux_task3.loss_bbox: 0.3304, aux_task4.loss_heatmap: 0.8635, aux_task4.loss_bbox: 0.3555, aux_task5.loss_heatmap: 1.0016, aux_task5.loss_bbox: 0.3575, loss: 21.7141, grad_norm: 45.8178
2025-05-19 14:43:10,621 - mmdet - INFO - Epoch [2][950/2207]	lr: 2.114e-05, eta: 9:44:46, time: 0.850, data_time: 0.006, memory: 11268, loss_cls: 0.8285, loss_bbox: 1.1723, d0.loss_cls: 0.8469, d0.loss_bbox: 1.4023, d1.loss_cls: 0.8289, d1.loss_bbox: 1.2658, d2.loss_cls: 0.8245, d2.loss_bbox: 1.2144, d3.loss_cls: 0.8236, d3.loss_bbox: 1.1963, d4.loss_cls: 0.8262, d4.loss_bbox: 1.1829, aux_task0.loss_heatmap: 1.0778, aux_task0.loss_bbox: 0.3641, aux_task1.loss_heatmap: 1.3189, aux_task1.loss_bbox: 0.4018, aux_task2.loss_heatmap: 1.5415, aux_task2.loss_bbox: 0.4234, aux_task3.loss_heatmap: 1.1472, aux_task3.loss_bbox: 0.3358, aux_task4.loss_heatmap: 0.8131, aux_task4.loss_bbox: 0.3495, aux_task5.loss_heatmap: 0.9832, aux_task5.loss_bbox: 0.3566, loss: 21.5255, grad_norm: 45.1351
2025-05-19 14:43:53,091 - mmdet - INFO - Epoch [2][1000/2207]	lr: 2.141e-05, eta: 9:43:59, time: 0.849, data_time: 0.006, memory: 11268, loss_cls: 0.8092, loss_bbox: 1.1542, d0.loss_cls: 0.8340, d0.loss_bbox: 1.3857, d1.loss_cls: 0.8180, d1.loss_bbox: 1.2480, d2.loss_cls: 0.8115, d2.loss_bbox: 1.1967, d3.loss_cls: 0.8094, d3.loss_bbox: 1.1780, d4.loss_cls: 0.8095, d4.loss_bbox: 1.1642, aux_task0.loss_heatmap: 1.0445, aux_task0.loss_bbox: 0.3561, aux_task1.loss_heatmap: 1.2612, aux_task1.loss_bbox: 0.3890, aux_task2.loss_heatmap: 1.5695, aux_task2.loss_bbox: 0.4328, aux_task3.loss_heatmap: 1.1073, aux_task3.loss_bbox: 0.3329, aux_task4.loss_heatmap: 0.8372, aux_task4.loss_bbox: 0.3543, aux_task5.loss_heatmap: 0.9464, aux_task5.loss_bbox: 0.3508, loss: 21.2004, grad_norm: 46.5528
2025-05-19 14:44:35,584 - mmdet - INFO - Epoch [2][1050/2207]	lr: 2.168e-05, eta: 9:43:12, time: 0.850, data_time: 0.006, memory: 11268, loss_cls: 0.8140, loss_bbox: 1.1870, d0.loss_cls: 0.8407, d0.loss_bbox: 1.4061, d1.loss_cls: 0.8200, d1.loss_bbox: 1.2710, d2.loss_cls: 0.8147, d2.loss_bbox: 1.2200, d3.loss_cls: 0.8141, d3.loss_bbox: 1.2044, d4.loss_cls: 0.8131, d4.loss_bbox: 1.1946, aux_task0.loss_heatmap: 1.0495, aux_task0.loss_bbox: 0.3665, aux_task1.loss_heatmap: 1.2477, aux_task1.loss_bbox: 0.3923, aux_task2.loss_heatmap: 1.5839, aux_task2.loss_bbox: 0.4267, aux_task3.loss_heatmap: 1.1392, aux_task3.loss_bbox: 0.3290, aux_task4.loss_heatmap: 0.8278, aux_task4.loss_bbox: 0.3565, aux_task5.loss_heatmap: 0.9730, aux_task5.loss_bbox: 0.3555, loss: 21.4472, grad_norm: 48.3667
2025-05-19 14:45:18,015 - mmdet - INFO - Epoch [2][1100/2207]	lr: 2.195e-05, eta: 9:42:25, time: 0.849, data_time: 0.010, memory: 11268, loss_cls: 0.8021, loss_bbox: 1.1665, d0.loss_cls: 0.8336, d0.loss_bbox: 1.3893, d1.loss_cls: 0.8089, d1.loss_bbox: 1.2505, d2.loss_cls: 0.8006, d2.loss_bbox: 1.2023, d3.loss_cls: 0.8016, d3.loss_bbox: 1.1852, d4.loss_cls: 0.8019, d4.loss_bbox: 1.1750, aux_task0.loss_heatmap: 1.0372, aux_task0.loss_bbox: 0.3637, aux_task1.loss_heatmap: 1.2586, aux_task1.loss_bbox: 0.3958, aux_task2.loss_heatmap: 1.5791, aux_task2.loss_bbox: 0.4349, aux_task3.loss_heatmap: 1.1840, aux_task3.loss_bbox: 0.3325, aux_task4.loss_heatmap: 0.7817, aux_task4.loss_bbox: 0.3507, aux_task5.loss_heatmap: 0.9497, aux_task5.loss_bbox: 0.3518, loss: 21.2372, grad_norm: 49.2964
2025-05-19 14:46:00,546 - mmdet - INFO - Epoch [2][1150/2207]	lr: 2.223e-05, eta: 9:41:39, time: 0.851, data_time: 0.008, memory: 11268, loss_cls: 0.8004, loss_bbox: 1.1560, d0.loss_cls: 0.8292, d0.loss_bbox: 1.3738, d1.loss_cls: 0.8100, d1.loss_bbox: 1.2391, d2.loss_cls: 0.8002, d2.loss_bbox: 1.1903, d3.loss_cls: 0.8000, d3.loss_bbox: 1.1735, d4.loss_cls: 0.7996, d4.loss_bbox: 1.1644, aux_task0.loss_heatmap: 1.0310, aux_task0.loss_bbox: 0.3520, aux_task1.loss_heatmap: 1.2656, aux_task1.loss_bbox: 0.3933, aux_task2.loss_heatmap: 1.5750, aux_task2.loss_bbox: 0.4384, aux_task3.loss_heatmap: 1.1320, aux_task3.loss_bbox: 0.3386, aux_task4.loss_heatmap: 0.7953, aux_task4.loss_bbox: 0.3462, aux_task5.loss_heatmap: 0.9657, aux_task5.loss_bbox: 0.3577, loss: 21.1274, grad_norm: 50.2526
2025-05-19 14:46:43,237 - mmdet - INFO - Epoch [2][1200/2207]	lr: 2.252e-05, eta: 9:40:55, time: 0.854, data_time: 0.007, memory: 11268, loss_cls: 0.8063, loss_bbox: 1.1538, d0.loss_cls: 0.8321, d0.loss_bbox: 1.3638, d1.loss_cls: 0.8085, d1.loss_bbox: 1.2323, d2.loss_cls: 0.8049, d2.loss_bbox: 1.1884, d3.loss_cls: 0.8042, d3.loss_bbox: 1.1740, d4.loss_cls: 0.8052, d4.loss_bbox: 1.1614, aux_task0.loss_heatmap: 1.0500, aux_task0.loss_bbox: 0.3565, aux_task1.loss_heatmap: 1.2951, aux_task1.loss_bbox: 0.3969, aux_task2.loss_heatmap: 1.5478, aux_task2.loss_bbox: 0.4382, aux_task3.loss_heatmap: 1.0887, aux_task3.loss_bbox: 0.3413, aux_task4.loss_heatmap: 0.8002, aux_task4.loss_bbox: 0.3460, aux_task5.loss_heatmap: 0.9359, aux_task5.loss_bbox: 0.3542, loss: 21.0857, grad_norm: 50.4077
2025-05-19 14:47:26,011 - mmdet - INFO - Epoch [2][1250/2207]	lr: 2.280e-05, eta: 9:40:12, time: 0.855, data_time: 0.007, memory: 11268, loss_cls: 0.8054, loss_bbox: 1.1500, d0.loss_cls: 0.8270, d0.loss_bbox: 1.3741, d1.loss_cls: 0.8084, d1.loss_bbox: 1.2392, d2.loss_cls: 0.8042, d2.loss_bbox: 1.1931, d3.loss_cls: 0.8056, d3.loss_bbox: 1.1742, d4.loss_cls: 0.8043, d4.loss_bbox: 1.1599, aux_task0.loss_heatmap: 1.0221, aux_task0.loss_bbox: 0.3550, aux_task1.loss_heatmap: 1.2090, aux_task1.loss_bbox: 0.3894, aux_task2.loss_heatmap: 1.5602, aux_task2.loss_bbox: 0.4348, aux_task3.loss_heatmap: 1.1868, aux_task3.loss_bbox: 0.3335, aux_task4.loss_heatmap: 0.8712, aux_task4.loss_bbox: 0.3538, aux_task5.loss_heatmap: 0.9307, aux_task5.loss_bbox: 0.3483, loss: 21.1402, grad_norm: 45.9979
2025-05-19 14:48:08,734 - mmdet - INFO - Epoch [2][1300/2207]	lr: 2.310e-05, eta: 9:39:29, time: 0.854, data_time: 0.007, memory: 11268, loss_cls: 0.8041, loss_bbox: 1.1593, d0.loss_cls: 0.8309, d0.loss_bbox: 1.3829, d1.loss_cls: 0.8112, d1.loss_bbox: 1.2413, d2.loss_cls: 0.8059, d2.loss_bbox: 1.1952, d3.loss_cls: 0.8047, d3.loss_bbox: 1.1795, d4.loss_cls: 0.8014, d4.loss_bbox: 1.1685, aux_task0.loss_heatmap: 1.0482, aux_task0.loss_bbox: 0.3688, aux_task1.loss_heatmap: 1.2380, aux_task1.loss_bbox: 0.4032, aux_task2.loss_heatmap: 1.5618, aux_task2.loss_bbox: 0.4431, aux_task3.loss_heatmap: 1.1700, aux_task3.loss_bbox: 0.3393, aux_task4.loss_heatmap: 0.8530, aux_task4.loss_bbox: 0.3522, aux_task5.loss_heatmap: 0.9581, aux_task5.loss_bbox: 0.3483, loss: 21.2689, grad_norm: 46.3807
2025-05-19 14:48:51,266 - mmdet - INFO - Epoch [2][1350/2207]	lr: 2.339e-05, eta: 9:38:43, time: 0.851, data_time: 0.007, memory: 11268, loss_cls: 0.7894, loss_bbox: 1.1203, d0.loss_cls: 0.8154, d0.loss_bbox: 1.3468, d1.loss_cls: 0.7951, d1.loss_bbox: 1.2055, d2.loss_cls: 0.7894, d2.loss_bbox: 1.1591, d3.loss_cls: 0.7899, d3.loss_bbox: 1.1432, d4.loss_cls: 0.7876, d4.loss_bbox: 1.1338, aux_task0.loss_heatmap: 0.9871, aux_task0.loss_bbox: 0.3544, aux_task1.loss_heatmap: 1.2410, aux_task1.loss_bbox: 0.3965, aux_task2.loss_heatmap: 1.5256, aux_task2.loss_bbox: 0.4280, aux_task3.loss_heatmap: 1.1945, aux_task3.loss_bbox: 0.3430, aux_task4.loss_heatmap: 0.8009, aux_task4.loss_bbox: 0.3476, aux_task5.loss_heatmap: 0.9282, aux_task5.loss_bbox: 0.3466, loss: 20.7687, grad_norm: 46.9684
2025-05-19 14:49:35,524 - mmdet - INFO - Epoch [2][1400/2207]	lr: 2.369e-05, eta: 9:38:17, time: 0.885, data_time: 0.007, memory: 11268, loss_cls: 0.7881, loss_bbox: 1.1281, d0.loss_cls: 0.8177, d0.loss_bbox: 1.3403, d1.loss_cls: 0.7929, d1.loss_bbox: 1.2152, d2.loss_cls: 0.7873, d2.loss_bbox: 1.1685, d3.loss_cls: 0.7886, d3.loss_bbox: 1.1526, d4.loss_cls: 0.7849, d4.loss_bbox: 1.1407, aux_task0.loss_heatmap: 1.0156, aux_task0.loss_bbox: 0.3504, aux_task1.loss_heatmap: 1.2352, aux_task1.loss_bbox: 0.3810, aux_task2.loss_heatmap: 1.5190, aux_task2.loss_bbox: 0.4269, aux_task3.loss_heatmap: 1.0937, aux_task3.loss_bbox: 0.3320, aux_task4.loss_heatmap: 0.7836, aux_task4.loss_bbox: 0.3502, aux_task5.loss_heatmap: 0.9341, aux_task5.loss_bbox: 0.3451, loss: 20.6715, grad_norm: 50.8784
2025-05-19 14:50:18,181 - mmdet - INFO - Epoch [2][1450/2207]	lr: 2.399e-05, eta: 9:37:32, time: 0.853, data_time: 0.007, memory: 11268, loss_cls: 0.7873, loss_bbox: 1.1253, d0.loss_cls: 0.8135, d0.loss_bbox: 1.3358, d1.loss_cls: 0.7936, d1.loss_bbox: 1.2037, d2.loss_cls: 0.7879, d2.loss_bbox: 1.1585, d3.loss_cls: 0.7875, d3.loss_bbox: 1.1448, d4.loss_cls: 0.7859, d4.loss_bbox: 1.1346, aux_task0.loss_heatmap: 0.9981, aux_task0.loss_bbox: 0.3471, aux_task1.loss_heatmap: 1.2644, aux_task1.loss_bbox: 0.3890, aux_task2.loss_heatmap: 1.5211, aux_task2.loss_bbox: 0.4346, aux_task3.loss_heatmap: 1.1092, aux_task3.loss_bbox: 0.3334, aux_task4.loss_heatmap: 0.7912, aux_task4.loss_bbox: 0.3495, aux_task5.loss_heatmap: 0.8944, aux_task5.loss_bbox: 0.3420, loss: 20.6321, grad_norm: 49.1921
2025-05-19 14:51:00,926 - mmdet - INFO - Epoch [2][1500/2207]	lr: 2.429e-05, eta: 9:36:49, time: 0.855, data_time: 0.008, memory: 11268, loss_cls: 0.7767, loss_bbox: 1.1201, d0.loss_cls: 0.8078, d0.loss_bbox: 1.3230, d1.loss_cls: 0.7800, d1.loss_bbox: 1.1954, d2.loss_cls: 0.7725, d2.loss_bbox: 1.1535, d3.loss_cls: 0.7719, d3.loss_bbox: 1.1408, d4.loss_cls: 0.7739, d4.loss_bbox: 1.1297, aux_task0.loss_heatmap: 0.9961, aux_task0.loss_bbox: 0.3467, aux_task1.loss_heatmap: 1.2416, aux_task1.loss_bbox: 0.3922, aux_task2.loss_heatmap: 1.5287, aux_task2.loss_bbox: 0.4258, aux_task3.loss_heatmap: 1.1041, aux_task3.loss_bbox: 0.3351, aux_task4.loss_heatmap: 0.8125, aux_task4.loss_bbox: 0.3528, aux_task5.loss_heatmap: 0.8899, aux_task5.loss_bbox: 0.3461, loss: 20.5171, grad_norm: 49.0186
2025-05-19 14:51:43,504 - mmdet - INFO - Epoch [2][1550/2207]	lr: 2.460e-05, eta: 9:36:04, time: 0.852, data_time: 0.007, memory: 11268, loss_cls: 0.7917, loss_bbox: 1.1309, d0.loss_cls: 0.8152, d0.loss_bbox: 1.3431, d1.loss_cls: 0.7950, d1.loss_bbox: 1.2128, d2.loss_cls: 0.7908, d2.loss_bbox: 1.1666, d3.loss_cls: 0.7885, d3.loss_bbox: 1.1529, d4.loss_cls: 0.7892, d4.loss_bbox: 1.1412, aux_task0.loss_heatmap: 0.9943, aux_task0.loss_bbox: 0.3465, aux_task1.loss_heatmap: 1.2563, aux_task1.loss_bbox: 0.3889, aux_task2.loss_heatmap: 1.5374, aux_task2.loss_bbox: 0.4262, aux_task3.loss_heatmap: 1.0773, aux_task3.loss_bbox: 0.3322, aux_task4.loss_heatmap: 0.8078, aux_task4.loss_bbox: 0.3402, aux_task5.loss_heatmap: 0.9055, aux_task5.loss_bbox: 0.3449, loss: 20.6754, grad_norm: 48.2030
2025-05-19 14:52:26,079 - mmdet - INFO - Epoch [2][1600/2207]	lr: 2.491e-05, eta: 9:35:19, time: 0.851, data_time: 0.007, memory: 11268, loss_cls: 0.7785, loss_bbox: 1.1262, d0.loss_cls: 0.8101, d0.loss_bbox: 1.3310, d1.loss_cls: 0.7840, d1.loss_bbox: 1.2014, d2.loss_cls: 0.7782, d2.loss_bbox: 1.1572, d3.loss_cls: 0.7768, d3.loss_bbox: 1.1433, d4.loss_cls: 0.7774, d4.loss_bbox: 1.1322, aux_task0.loss_heatmap: 1.0068, aux_task0.loss_bbox: 0.3549, aux_task1.loss_heatmap: 1.2137, aux_task1.loss_bbox: 0.3865, aux_task2.loss_heatmap: 1.5080, aux_task2.loss_bbox: 0.4133, aux_task3.loss_heatmap: 1.1179, aux_task3.loss_bbox: 0.3281, aux_task4.loss_heatmap: 0.7887, aux_task4.loss_bbox: 0.3444, aux_task5.loss_heatmap: 0.9075, aux_task5.loss_bbox: 0.3494, loss: 20.5156, grad_norm: 52.0407
2025-05-19 14:53:08,290 - mmdet - INFO - Epoch [2][1650/2207]	lr: 2.523e-05, eta: 9:34:30, time: 0.844, data_time: 0.006, memory: 11268, loss_cls: 0.7731, loss_bbox: 1.1173, d0.loss_cls: 0.7998, d0.loss_bbox: 1.3275, d1.loss_cls: 0.7773, d1.loss_bbox: 1.1968, d2.loss_cls: 0.7724, d2.loss_bbox: 1.1547, d3.loss_cls: 0.7735, d3.loss_bbox: 1.1405, d4.loss_cls: 0.7722, d4.loss_bbox: 1.1287, aux_task0.loss_heatmap: 0.9723, aux_task0.loss_bbox: 0.3526, aux_task1.loss_heatmap: 1.2430, aux_task1.loss_bbox: 0.3926, aux_task2.loss_heatmap: 1.4623, aux_task2.loss_bbox: 0.4290, aux_task3.loss_heatmap: 1.0867, aux_task3.loss_bbox: 0.3304, aux_task4.loss_heatmap: 0.7993, aux_task4.loss_bbox: 0.3449, aux_task5.loss_heatmap: 0.8482, aux_task5.loss_bbox: 0.3451, loss: 20.3401, grad_norm: 49.5524
2025-05-19 14:53:50,722 - mmdet - INFO - Epoch [2][1700/2207]	lr: 2.555e-05, eta: 9:33:43, time: 0.849, data_time: 0.006, memory: 11268, loss_cls: 0.7708, loss_bbox: 1.1175, d0.loss_cls: 0.8034, d0.loss_bbox: 1.3164, d1.loss_cls: 0.7793, d1.loss_bbox: 1.1922, d2.loss_cls: 0.7730, d2.loss_bbox: 1.1493, d3.loss_cls: 0.7709, d3.loss_bbox: 1.1361, d4.loss_cls: 0.7701, d4.loss_bbox: 1.1277, aux_task0.loss_heatmap: 1.0088, aux_task0.loss_bbox: 0.3526, aux_task1.loss_heatmap: 1.2430, aux_task1.loss_bbox: 0.3872, aux_task2.loss_heatmap: 1.5029, aux_task2.loss_bbox: 0.4289, aux_task3.loss_heatmap: 1.1049, aux_task3.loss_bbox: 0.3304, aux_task4.loss_heatmap: 0.7697, aux_task4.loss_bbox: 0.3348, aux_task5.loss_heatmap: 0.8930, aux_task5.loss_bbox: 0.3453, loss: 20.4079, grad_norm: 50.3971
2025-05-19 14:54:33,414 - mmdet - INFO - Epoch [2][1750/2207]	lr: 2.587e-05, eta: 9:33:00, time: 0.854, data_time: 0.006, memory: 11268, loss_cls: 0.7668, loss_bbox: 1.1166, d0.loss_cls: 0.7906, d0.loss_bbox: 1.3300, d1.loss_cls: 0.7704, d1.loss_bbox: 1.1977, d2.loss_cls: 0.7642, d2.loss_bbox: 1.1517, d3.loss_cls: 0.7628, d3.loss_bbox: 1.1367, d4.loss_cls: 0.7644, d4.loss_bbox: 1.1250, aux_task0.loss_heatmap: 0.9949, aux_task0.loss_bbox: 0.3523, aux_task1.loss_heatmap: 1.2441, aux_task1.loss_bbox: 0.3851, aux_task2.loss_heatmap: 1.5057, aux_task2.loss_bbox: 0.4266, aux_task3.loss_heatmap: 1.0832, aux_task3.loss_bbox: 0.3378, aux_task4.loss_heatmap: 0.8058, aux_task4.loss_bbox: 0.3377, aux_task5.loss_heatmap: 0.8399, aux_task5.loss_bbox: 0.3462, loss: 20.3360, grad_norm: 45.7370
2025-05-19 14:55:16,063 - mmdet - INFO - Epoch [2][1800/2207]	lr: 2.620e-05, eta: 9:32:16, time: 0.853, data_time: 0.006, memory: 11268, loss_cls: 0.7740, loss_bbox: 1.1171, d0.loss_cls: 0.8075, d0.loss_bbox: 1.3234, d1.loss_cls: 0.7786, d1.loss_bbox: 1.1976, d2.loss_cls: 0.7733, d2.loss_bbox: 1.1556, d3.loss_cls: 0.7727, d3.loss_bbox: 1.1420, d4.loss_cls: 0.7718, d4.loss_bbox: 1.1297, aux_task0.loss_heatmap: 0.9640, aux_task0.loss_bbox: 0.3456, aux_task1.loss_heatmap: 1.2306, aux_task1.loss_bbox: 0.3881, aux_task2.loss_heatmap: 1.4824, aux_task2.loss_bbox: 0.4285, aux_task3.loss_heatmap: 1.0830, aux_task3.loss_bbox: 0.3272, aux_task4.loss_heatmap: 0.8143, aux_task4.loss_bbox: 0.3421, aux_task5.loss_heatmap: 0.8794, aux_task5.loss_bbox: 0.3470, loss: 20.3757, grad_norm: 48.7960
2025-05-19 14:55:58,448 - mmdet - INFO - Epoch [2][1850/2207]	lr: 2.652e-05, eta: 9:31:29, time: 0.848, data_time: 0.007, memory: 11268, loss_cls: 0.7850, loss_bbox: 1.1246, d0.loss_cls: 0.8129, d0.loss_bbox: 1.3288, d1.loss_cls: 0.7926, d1.loss_bbox: 1.2023, d2.loss_cls: 0.7852, d2.loss_bbox: 1.1580, d3.loss_cls: 0.7824, d3.loss_bbox: 1.1434, d4.loss_cls: 0.7804, d4.loss_bbox: 1.1327, aux_task0.loss_heatmap: 1.0328, aux_task0.loss_bbox: 0.3595, aux_task1.loss_heatmap: 1.2860, aux_task1.loss_bbox: 0.3923, aux_task2.loss_heatmap: 1.4785, aux_task2.loss_bbox: 0.4251, aux_task3.loss_heatmap: 1.0982, aux_task3.loss_bbox: 0.3323, aux_task4.loss_heatmap: 0.7481, aux_task4.loss_bbox: 0.3457, aux_task5.loss_heatmap: 0.8660, aux_task5.loss_bbox: 0.3405, loss: 20.5333, grad_norm: 47.8131
2025-05-19 14:56:41,178 - mmdet - INFO - Epoch [2][1900/2207]	lr: 2.686e-05, eta: 9:30:46, time: 0.855, data_time: 0.006, memory: 11268, loss_cls: 0.7516, loss_bbox: 1.0980, d0.loss_cls: 0.7859, d0.loss_bbox: 1.2959, d1.loss_cls: 0.7597, d1.loss_bbox: 1.1767, d2.loss_cls: 0.7522, d2.loss_bbox: 1.1353, d3.loss_cls: 0.7496, d3.loss_bbox: 1.1222, d4.loss_cls: 0.7486, d4.loss_bbox: 1.1116, aux_task0.loss_heatmap: 0.9882, aux_task0.loss_bbox: 0.3491, aux_task1.loss_heatmap: 1.2062, aux_task1.loss_bbox: 0.3836, aux_task2.loss_heatmap: 1.4519, aux_task2.loss_bbox: 0.4159, aux_task3.loss_heatmap: 1.0540, aux_task3.loss_bbox: 0.3355, aux_task4.loss_heatmap: 0.7920, aux_task4.loss_bbox: 0.3427, aux_task5.loss_heatmap: 0.8353, aux_task5.loss_bbox: 0.3450, loss: 19.9865, grad_norm: 47.4464
2025-05-19 14:57:23,658 - mmdet - INFO - Epoch [2][1950/2207]	lr: 2.719e-05, eta: 9:30:00, time: 0.850, data_time: 0.007, memory: 11268, loss_cls: 0.7658, loss_bbox: 1.0992, d0.loss_cls: 0.7980, d0.loss_bbox: 1.2978, d1.loss_cls: 0.7698, d1.loss_bbox: 1.1774, d2.loss_cls: 0.7653, d2.loss_bbox: 1.1345, d3.loss_cls: 0.7632, d3.loss_bbox: 1.1199, d4.loss_cls: 0.7622, d4.loss_bbox: 1.1084, aux_task0.loss_heatmap: 0.9780, aux_task0.loss_bbox: 0.3513, aux_task1.loss_heatmap: 1.2376, aux_task1.loss_bbox: 0.3881, aux_task2.loss_heatmap: 1.4750, aux_task2.loss_bbox: 0.4214, aux_task3.loss_heatmap: 1.0637, aux_task3.loss_bbox: 0.3334, aux_task4.loss_heatmap: 0.7734, aux_task4.loss_bbox: 0.3442, aux_task5.loss_heatmap: 0.8430, aux_task5.loss_bbox: 0.3404, loss: 20.1110, grad_norm: 50.6044
2025-05-19 14:58:06,178 - mmdet - INFO - Epoch [2][2000/2207]	lr: 2.753e-05, eta: 9:29:15, time: 0.850, data_time: 0.009, memory: 11317, loss_cls: 0.7570, loss_bbox: 1.1019, d0.loss_cls: 0.7890, d0.loss_bbox: 1.2925, d1.loss_cls: 0.7675, d1.loss_bbox: 1.1734, d2.loss_cls: 0.7590, d2.loss_bbox: 1.1323, d3.loss_cls: 0.7577, d3.loss_bbox: 1.1186, d4.loss_cls: 0.7558, d4.loss_bbox: 1.1092, aux_task0.loss_heatmap: 0.9561, aux_task0.loss_bbox: 0.3377, aux_task1.loss_heatmap: 1.2448, aux_task1.loss_bbox: 0.3854, aux_task2.loss_heatmap: 1.4501, aux_task2.loss_bbox: 0.4299, aux_task3.loss_heatmap: 1.0667, aux_task3.loss_bbox: 0.3305, aux_task4.loss_heatmap: 0.7695, aux_task4.loss_bbox: 0.3421, aux_task5.loss_heatmap: 0.8519, aux_task5.loss_bbox: 0.3443, loss: 20.0229, grad_norm: 50.2816
2025-05-19 14:58:48,751 - mmdet - INFO - Epoch [2][2050/2207]	lr: 2.787e-05, eta: 9:28:31, time: 0.851, data_time: 0.007, memory: 11317, loss_cls: 0.7499, loss_bbox: 1.0880, d0.loss_cls: 0.7794, d0.loss_bbox: 1.2904, d1.loss_cls: 0.7592, d1.loss_bbox: 1.1645, d2.loss_cls: 0.7526, d2.loss_bbox: 1.1218, d3.loss_cls: 0.7494, d3.loss_bbox: 1.1098, d4.loss_cls: 0.7473, d4.loss_bbox: 1.0991, aux_task0.loss_heatmap: 0.9584, aux_task0.loss_bbox: 0.3401, aux_task1.loss_heatmap: 1.2210, aux_task1.loss_bbox: 0.3835, aux_task2.loss_heatmap: 1.4551, aux_task2.loss_bbox: 0.4128, aux_task3.loss_heatmap: 1.0577, aux_task3.loss_bbox: 0.3283, aux_task4.loss_heatmap: 0.7700, aux_task4.loss_bbox: 0.3377, aux_task5.loss_heatmap: 0.8107, aux_task5.loss_bbox: 0.3396, loss: 19.8264, grad_norm: 49.2039
2025-05-19 14:59:31,549 - mmdet - INFO - Epoch [2][2100/2207]	lr: 2.822e-05, eta: 9:27:48, time: 0.856, data_time: 0.006, memory: 11317, loss_cls: 0.7509, loss_bbox: 1.0901, d0.loss_cls: 0.7855, d0.loss_bbox: 1.2930, d1.loss_cls: 0.7610, d1.loss_bbox: 1.1659, d2.loss_cls: 0.7535, d2.loss_bbox: 1.1250, d3.loss_cls: 0.7514, d3.loss_bbox: 1.1127, d4.loss_cls: 0.7513, d4.loss_bbox: 1.0998, aux_task0.loss_heatmap: 0.9639, aux_task0.loss_bbox: 0.3385, aux_task1.loss_heatmap: 1.2420, aux_task1.loss_bbox: 0.3908, aux_task2.loss_heatmap: 1.4275, aux_task2.loss_bbox: 0.4149, aux_task3.loss_heatmap: 1.0680, aux_task3.loss_bbox: 0.3229, aux_task4.loss_heatmap: 0.7693, aux_task4.loss_bbox: 0.3385, aux_task5.loss_heatmap: 0.8256, aux_task5.loss_bbox: 0.3349, loss: 19.8770, grad_norm: 48.4978
2025-05-19 15:00:14,381 - mmdet - INFO - Epoch [2][2150/2207]	lr: 2.857e-05, eta: 9:27:06, time: 0.857, data_time: 0.006, memory: 11317, loss_cls: 0.7380, loss_bbox: 1.0874, d0.loss_cls: 0.7710, d0.loss_bbox: 1.2823, d1.loss_cls: 0.7454, d1.loss_bbox: 1.1625, d2.loss_cls: 0.7412, d2.loss_bbox: 1.1209, d3.loss_cls: 0.7370, d3.loss_bbox: 1.1084, d4.loss_cls: 0.7373, d4.loss_bbox: 1.0967, aux_task0.loss_heatmap: 0.9364, aux_task0.loss_bbox: 0.3406, aux_task1.loss_heatmap: 1.2189, aux_task1.loss_bbox: 0.3850, aux_task2.loss_heatmap: 1.4261, aux_task2.loss_bbox: 0.4217, aux_task3.loss_heatmap: 1.0450, aux_task3.loss_bbox: 0.3269, aux_task4.loss_heatmap: 0.7522, aux_task4.loss_bbox: 0.3432, aux_task5.loss_heatmap: 0.8251, aux_task5.loss_bbox: 0.3373, loss: 19.6868, grad_norm: 48.3236
2025-05-19 15:00:57,090 - mmdet - INFO - Epoch [2][2200/2207]	lr: 2.892e-05, eta: 9:26:23, time: 0.854, data_time: 0.006, memory: 11317, loss_cls: 0.7464, loss_bbox: 1.1011, d0.loss_cls: 0.7759, d0.loss_bbox: 1.2995, d1.loss_cls: 0.7550, d1.loss_bbox: 1.1774, d2.loss_cls: 0.7489, d2.loss_bbox: 1.1341, d3.loss_cls: 0.7473, d3.loss_bbox: 1.1200, d4.loss_cls: 0.7463, d4.loss_bbox: 1.1105, aux_task0.loss_heatmap: 0.9706, aux_task0.loss_bbox: 0.3484, aux_task1.loss_heatmap: 1.2311, aux_task1.loss_bbox: 0.3874, aux_task2.loss_heatmap: 1.4191, aux_task2.loss_bbox: 0.4278, aux_task3.loss_heatmap: 1.0033, aux_task3.loss_bbox: 0.3299, aux_task4.loss_heatmap: 0.7849, aux_task4.loss_bbox: 0.3533, aux_task5.loss_heatmap: 0.8019, aux_task5.loss_bbox: 0.3415, loss: 19.8617, grad_norm: 46.7652
2025-05-19 15:01:03,415 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-05-19 15:01:56,859 - mmdet - INFO - Epoch [3][50/2207]	lr: 2.932e-05, eta: 9:25:08, time: 0.916, data_time: 0.071, memory: 11317, loss_cls: 0.7536, loss_bbox: 1.1021, d0.loss_cls: 0.7873, d0.loss_bbox: 1.2913, d1.loss_cls: 0.7630, d1.loss_bbox: 1.1718, d2.loss_cls: 0.7568, d2.loss_bbox: 1.1288, d3.loss_cls: 0.7545, d3.loss_bbox: 1.1173, d4.loss_cls: 0.7522, d4.loss_bbox: 1.1103, aux_task0.loss_heatmap: 1.0018, aux_task0.loss_bbox: 0.3525, aux_task1.loss_heatmap: 1.2271, aux_task1.loss_bbox: 0.3837, aux_task2.loss_heatmap: 1.4643, aux_task2.loss_bbox: 0.4217, aux_task3.loss_heatmap: 1.0605, aux_task3.loss_bbox: 0.3300, aux_task4.loss_heatmap: 0.7672, aux_task4.loss_bbox: 0.3445, aux_task5.loss_heatmap: 0.8095, aux_task5.loss_bbox: 0.3405, loss: 19.9922, grad_norm: 50.6684
2025-05-19 15:02:39,566 - mmdet - INFO - Epoch [3][100/2207]	lr: 2.968e-05, eta: 9:24:25, time: 0.854, data_time: 0.006, memory: 11317, loss_cls: 0.7525, loss_bbox: 1.0971, d0.loss_cls: 0.7856, d0.loss_bbox: 1.2878, d1.loss_cls: 0.7575, d1.loss_bbox: 1.1740, d2.loss_cls: 0.7551, d2.loss_bbox: 1.1303, d3.loss_cls: 0.7535, d3.loss_bbox: 1.1178, d4.loss_cls: 0.7506, d4.loss_bbox: 1.1069, aux_task0.loss_heatmap: 0.9789, aux_task0.loss_bbox: 0.3542, aux_task1.loss_heatmap: 1.1897, aux_task1.loss_bbox: 0.3796, aux_task2.loss_heatmap: 1.3967, aux_task2.loss_bbox: 0.4266, aux_task3.loss_heatmap: 0.9773, aux_task3.loss_bbox: 0.3300, aux_task4.loss_heatmap: 0.7572, aux_task4.loss_bbox: 0.3440, aux_task5.loss_heatmap: 0.8317, aux_task5.loss_bbox: 0.3378, loss: 19.7723, grad_norm: 46.7110
2025-05-19 15:03:22,427 - mmdet - INFO - Epoch [3][150/2207]	lr: 3.004e-05, eta: 9:23:43, time: 0.857, data_time: 0.007, memory: 11317, loss_cls: 0.7292, loss_bbox: 1.0695, d0.loss_cls: 0.7653, d0.loss_bbox: 1.2618, d1.loss_cls: 0.7385, d1.loss_bbox: 1.1444, d2.loss_cls: 0.7355, d2.loss_bbox: 1.0994, d3.loss_cls: 0.7279, d3.loss_bbox: 1.0890, d4.loss_cls: 0.7272, d4.loss_bbox: 1.0771, aux_task0.loss_heatmap: 0.9269, aux_task0.loss_bbox: 0.3448, aux_task1.loss_heatmap: 1.2017, aux_task1.loss_bbox: 0.3776, aux_task2.loss_heatmap: 1.3610, aux_task2.loss_bbox: 0.4046, aux_task3.loss_heatmap: 1.0003, aux_task3.loss_bbox: 0.3231, aux_task4.loss_heatmap: 0.7250, aux_task4.loss_bbox: 0.3450, aux_task5.loss_heatmap: 0.8282, aux_task5.loss_bbox: 0.3441, loss: 19.3471, grad_norm: 47.8494
2025-05-19 15:04:04,832 - mmdet - INFO - Epoch [3][200/2207]	lr: 3.041e-05, eta: 9:22:58, time: 0.848, data_time: 0.006, memory: 11317, loss_cls: 0.7317, loss_bbox: 1.0815, d0.loss_cls: 0.7700, d0.loss_bbox: 1.2843, d1.loss_cls: 0.7430, d1.loss_bbox: 1.1587, d2.loss_cls: 0.7359, d2.loss_bbox: 1.1153, d3.loss_cls: 0.7316, d3.loss_bbox: 1.1043, d4.loss_cls: 0.7304, d4.loss_bbox: 1.0947, aux_task0.loss_heatmap: 0.9465, aux_task0.loss_bbox: 0.3436, aux_task1.loss_heatmap: 1.2200, aux_task1.loss_bbox: 0.3820, aux_task2.loss_heatmap: 1.4080, aux_task2.loss_bbox: 0.4178, aux_task3.loss_heatmap: 1.0220, aux_task3.loss_bbox: 0.3346, aux_task4.loss_heatmap: 0.7745, aux_task4.loss_bbox: 0.3438, aux_task5.loss_heatmap: 0.7913, aux_task5.loss_bbox: 0.3363, loss: 19.6021, grad_norm: 46.6573
2025-05-19 15:04:49,175 - mmdet - INFO - Epoch [3][250/2207]	lr: 3.078e-05, eta: 9:22:29, time: 0.887, data_time: 0.007, memory: 11317, loss_cls: 0.7232, loss_bbox: 1.0717, d0.loss_cls: 0.7554, d0.loss_bbox: 1.2663, d1.loss_cls: 0.7343, d1.loss_bbox: 1.1490, d2.loss_cls: 0.7279, d2.loss_bbox: 1.1051, d3.loss_cls: 0.7239, d3.loss_bbox: 1.0918, d4.loss_cls: 0.7230, d4.loss_bbox: 1.0821, aux_task0.loss_heatmap: 0.9330, aux_task0.loss_bbox: 0.3445, aux_task1.loss_heatmap: 1.1825, aux_task1.loss_bbox: 0.3800, aux_task2.loss_heatmap: 1.3877, aux_task2.loss_bbox: 0.4137, aux_task3.loss_heatmap: 1.0508, aux_task3.loss_bbox: 0.3329, aux_task4.loss_heatmap: 0.7648, aux_task4.loss_bbox: 0.3429, aux_task5.loss_heatmap: 0.7401, aux_task5.loss_bbox: 0.3339, loss: 19.3605, grad_norm: 50.3380
2025-05-19 15:05:31,741 - mmdet - INFO - Epoch [3][300/2207]	lr: 3.115e-05, eta: 9:21:44, time: 0.851, data_time: 0.009, memory: 11317, loss_cls: 0.7274, loss_bbox: 1.0628, d0.loss_cls: 0.7670, d0.loss_bbox: 1.2657, d1.loss_cls: 0.7436, d1.loss_bbox: 1.1416, d2.loss_cls: 0.7326, d2.loss_bbox: 1.0994, d3.loss_cls: 0.7275, d3.loss_bbox: 1.0867, d4.loss_cls: 0.7258, d4.loss_bbox: 1.0748, aux_task0.loss_heatmap: 0.9120, aux_task0.loss_bbox: 0.3404, aux_task1.loss_heatmap: 1.1940, aux_task1.loss_bbox: 0.3797, aux_task2.loss_heatmap: 1.3645, aux_task2.loss_bbox: 0.4165, aux_task3.loss_heatmap: 1.0266, aux_task3.loss_bbox: 0.3374, aux_task4.loss_heatmap: 0.7289, aux_task4.loss_bbox: 0.3356, aux_task5.loss_heatmap: 0.7772, aux_task5.loss_bbox: 0.3390, loss: 19.3067, grad_norm: 46.4507
2025-05-19 15:06:14,229 - mmdet - INFO - Epoch [3][350/2207]	lr: 3.152e-05, eta: 9:21:00, time: 0.850, data_time: 0.007, memory: 11317, loss_cls: 0.7135, loss_bbox: 1.0608, d0.loss_cls: 0.7468, d0.loss_bbox: 1.2597, d1.loss_cls: 0.7283, d1.loss_bbox: 1.1362, d2.loss_cls: 0.7208, d2.loss_bbox: 1.0956, d3.loss_cls: 0.7144, d3.loss_bbox: 1.0845, d4.loss_cls: 0.7118, d4.loss_bbox: 1.0731, aux_task0.loss_heatmap: 0.8790, aux_task0.loss_bbox: 0.3396, aux_task1.loss_heatmap: 1.1707, aux_task1.loss_bbox: 0.3810, aux_task2.loss_heatmap: 1.3683, aux_task2.loss_bbox: 0.4170, aux_task3.loss_heatmap: 0.9424, aux_task3.loss_bbox: 0.3194, aux_task4.loss_heatmap: 0.7187, aux_task4.loss_bbox: 0.3315, aux_task5.loss_heatmap: 0.7999, aux_task5.loss_bbox: 0.3421, loss: 19.0552, grad_norm: 52.5486
2025-05-19 15:06:56,621 - mmdet - INFO - Epoch [3][400/2207]	lr: 3.190e-05, eta: 9:20:14, time: 0.848, data_time: 0.008, memory: 11317, loss_cls: 0.7395, loss_bbox: 1.0648, d0.loss_cls: 0.7733, d0.loss_bbox: 1.2631, d1.loss_cls: 0.7500, d1.loss_bbox: 1.1414, d2.loss_cls: 0.7427, d2.loss_bbox: 1.0964, d3.loss_cls: 0.7370, d3.loss_bbox: 1.0836, d4.loss_cls: 0.7360, d4.loss_bbox: 1.0747, aux_task0.loss_heatmap: 0.9377, aux_task0.loss_bbox: 0.3469, aux_task1.loss_heatmap: 1.1904, aux_task1.loss_bbox: 0.3863, aux_task2.loss_heatmap: 1.3531, aux_task2.loss_bbox: 0.4151, aux_task3.loss_heatmap: 1.0328, aux_task3.loss_bbox: 0.3291, aux_task4.loss_heatmap: 0.7021, aux_task4.loss_bbox: 0.3383, aux_task5.loss_heatmap: 0.8001, aux_task5.loss_bbox: 0.3426, loss: 19.3768, grad_norm: 54.8149
2025-05-19 15:07:39,354 - mmdet - INFO - Epoch [3][450/2207]	lr: 3.228e-05, eta: 9:19:31, time: 0.855, data_time: 0.006, memory: 11317, loss_cls: 0.7160, loss_bbox: 1.0539, d0.loss_cls: 0.7522, d0.loss_bbox: 1.2521, d1.loss_cls: 0.7260, d1.loss_bbox: 1.1306, d2.loss_cls: 0.7219, d2.loss_bbox: 1.0870, d3.loss_cls: 0.7200, d3.loss_bbox: 1.0737, d4.loss_cls: 0.7157, d4.loss_bbox: 1.0651, aux_task0.loss_heatmap: 0.9204, aux_task0.loss_bbox: 0.3433, aux_task1.loss_heatmap: 1.1545, aux_task1.loss_bbox: 0.3848, aux_task2.loss_heatmap: 1.3087, aux_task2.loss_bbox: 0.4094, aux_task3.loss_heatmap: 0.9556, aux_task3.loss_bbox: 0.3219, aux_task4.loss_heatmap: 0.7620, aux_task4.loss_bbox: 0.3442, aux_task5.loss_heatmap: 0.7917, aux_task5.loss_bbox: 0.3385, loss: 19.0491, grad_norm: 48.7263
2025-05-19 15:08:21,728 - mmdet - INFO - Epoch [3][500/2207]	lr: 3.266e-05, eta: 9:18:45, time: 0.847, data_time: 0.006, memory: 11317, loss_cls: 0.7210, loss_bbox: 1.0616, d0.loss_cls: 0.7597, d0.loss_bbox: 1.2436, d1.loss_cls: 0.7336, d1.loss_bbox: 1.1350, d2.loss_cls: 0.7280, d2.loss_bbox: 1.0943, d3.loss_cls: 0.7221, d3.loss_bbox: 1.0815, d4.loss_cls: 0.7199, d4.loss_bbox: 1.0732, aux_task0.loss_heatmap: 0.9474, aux_task0.loss_bbox: 0.3515, aux_task1.loss_heatmap: 1.1762, aux_task1.loss_bbox: 0.3881, aux_task2.loss_heatmap: 1.3804, aux_task2.loss_bbox: 0.4210, aux_task3.loss_heatmap: 1.0116, aux_task3.loss_bbox: 0.3191, aux_task4.loss_heatmap: 0.7630, aux_task4.loss_bbox: 0.3419, aux_task5.loss_heatmap: 0.7781, aux_task5.loss_bbox: 0.3381, loss: 19.2899, grad_norm: 50.1301
2025-05-19 15:09:04,330 - mmdet - INFO - Epoch [3][550/2207]	lr: 3.304e-05, eta: 9:18:02, time: 0.852, data_time: 0.006, memory: 11317, loss_cls: 0.7023, loss_bbox: 1.0305, d0.loss_cls: 0.7414, d0.loss_bbox: 1.2297, d1.loss_cls: 0.7164, d1.loss_bbox: 1.1120, d2.loss_cls: 0.7114, d2.loss_bbox: 1.0687, d3.loss_cls: 0.7047, d3.loss_bbox: 1.0532, d4.loss_cls: 0.7020, d4.loss_bbox: 1.0421, aux_task0.loss_heatmap: 0.8858, aux_task0.loss_bbox: 0.3286, aux_task1.loss_heatmap: 1.1530, aux_task1.loss_bbox: 0.3748, aux_task2.loss_heatmap: 1.3840, aux_task2.loss_bbox: 0.4191, aux_task3.loss_heatmap: 0.9768, aux_task3.loss_bbox: 0.3220, aux_task4.loss_heatmap: 0.7358, aux_task4.loss_bbox: 0.3274, aux_task5.loss_heatmap: 0.7544, aux_task5.loss_bbox: 0.3312, loss: 18.8074, grad_norm: 49.0754
2025-05-19 15:09:46,808 - mmdet - INFO - Epoch [3][600/2207]	lr: 3.343e-05, eta: 9:17:17, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.7069, loss_bbox: 1.0558, d0.loss_cls: 0.7427, d0.loss_bbox: 1.2472, d1.loss_cls: 0.7183, d1.loss_bbox: 1.1333, d2.loss_cls: 0.7143, d2.loss_bbox: 1.0912, d3.loss_cls: 0.7054, d3.loss_bbox: 1.0808, d4.loss_cls: 0.7039, d4.loss_bbox: 1.0689, aux_task0.loss_heatmap: 0.9031, aux_task0.loss_bbox: 0.3370, aux_task1.loss_heatmap: 1.1777, aux_task1.loss_bbox: 0.3838, aux_task2.loss_heatmap: 1.2909, aux_task2.loss_bbox: 0.4115, aux_task3.loss_heatmap: 0.9874, aux_task3.loss_bbox: 0.3239, aux_task4.loss_heatmap: 0.7504, aux_task4.loss_bbox: 0.3366, aux_task5.loss_heatmap: 0.7576, aux_task5.loss_bbox: 0.3343, loss: 18.9628, grad_norm: 52.0941
2025-05-19 15:10:29,453 - mmdet - INFO - Epoch [3][650/2207]	lr: 3.382e-05, eta: 9:16:34, time: 0.853, data_time: 0.007, memory: 11317, loss_cls: 0.7113, loss_bbox: 1.0425, d0.loss_cls: 0.7544, d0.loss_bbox: 1.2480, d1.loss_cls: 0.7265, d1.loss_bbox: 1.1280, d2.loss_cls: 0.7192, d2.loss_bbox: 1.0821, d3.loss_cls: 0.7128, d3.loss_bbox: 1.0701, d4.loss_cls: 0.7096, d4.loss_bbox: 1.0548, aux_task0.loss_heatmap: 0.9289, aux_task0.loss_bbox: 0.3336, aux_task1.loss_heatmap: 1.2141, aux_task1.loss_bbox: 0.3814, aux_task2.loss_heatmap: 1.3244, aux_task2.loss_bbox: 0.4235, aux_task3.loss_heatmap: 0.9634, aux_task3.loss_bbox: 0.3217, aux_task4.loss_heatmap: 0.7387, aux_task4.loss_bbox: 0.3423, aux_task5.loss_heatmap: 0.7542, aux_task5.loss_bbox: 0.3317, loss: 19.0172, grad_norm: 45.9131
2025-05-19 15:11:12,252 - mmdet - INFO - Epoch [3][700/2207]	lr: 3.422e-05, eta: 9:15:51, time: 0.856, data_time: 0.006, memory: 11317, loss_cls: 0.7020, loss_bbox: 1.0454, d0.loss_cls: 0.7407, d0.loss_bbox: 1.2492, d1.loss_cls: 0.7140, d1.loss_bbox: 1.1285, d2.loss_cls: 0.7103, d2.loss_bbox: 1.0822, d3.loss_cls: 0.7041, d3.loss_bbox: 1.0682, d4.loss_cls: 0.7001, d4.loss_bbox: 1.0553, aux_task0.loss_heatmap: 0.8670, aux_task0.loss_bbox: 0.3337, aux_task1.loss_heatmap: 1.1395, aux_task1.loss_bbox: 0.3786, aux_task2.loss_heatmap: 1.3466, aux_task2.loss_bbox: 0.4081, aux_task3.loss_heatmap: 1.0005, aux_task3.loss_bbox: 0.3293, aux_task4.loss_heatmap: 0.7684, aux_task4.loss_bbox: 0.3436, aux_task5.loss_heatmap: 0.7489, aux_task5.loss_bbox: 0.3329, loss: 18.8971, grad_norm: 49.0305
2025-05-19 15:11:54,766 - mmdet - INFO - Epoch [3][750/2207]	lr: 3.461e-05, eta: 9:15:07, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.6967, loss_bbox: 1.0211, d0.loss_cls: 0.7410, d0.loss_bbox: 1.2180, d1.loss_cls: 0.7112, d1.loss_bbox: 1.0998, d2.loss_cls: 0.7068, d2.loss_bbox: 1.0523, d3.loss_cls: 0.6977, d3.loss_bbox: 1.0417, d4.loss_cls: 0.6947, d4.loss_bbox: 1.0321, aux_task0.loss_heatmap: 0.8817, aux_task0.loss_bbox: 0.3344, aux_task1.loss_heatmap: 1.1611, aux_task1.loss_bbox: 0.3745, aux_task2.loss_heatmap: 1.3389, aux_task2.loss_bbox: 0.3965, aux_task3.loss_heatmap: 0.9337, aux_task3.loss_bbox: 0.3198, aux_task4.loss_heatmap: 0.6937, aux_task4.loss_bbox: 0.3346, aux_task5.loss_heatmap: 0.7643, aux_task5.loss_bbox: 0.3319, loss: 18.5783, grad_norm: 49.0176
2025-05-19 15:12:37,596 - mmdet - INFO - Epoch [3][800/2207]	lr: 3.501e-05, eta: 9:14:25, time: 0.857, data_time: 0.006, memory: 11317, loss_cls: 0.6943, loss_bbox: 1.0211, d0.loss_cls: 0.7306, d0.loss_bbox: 1.2252, d1.loss_cls: 0.7102, d1.loss_bbox: 1.1043, d2.loss_cls: 0.7041, d2.loss_bbox: 1.0552, d3.loss_cls: 0.6975, d3.loss_bbox: 1.0402, d4.loss_cls: 0.6938, d4.loss_bbox: 1.0297, aux_task0.loss_heatmap: 0.8934, aux_task0.loss_bbox: 0.3385, aux_task1.loss_heatmap: 1.1210, aux_task1.loss_bbox: 0.3769, aux_task2.loss_heatmap: 1.3280, aux_task2.loss_bbox: 0.4023, aux_task3.loss_heatmap: 0.9159, aux_task3.loss_bbox: 0.3285, aux_task4.loss_heatmap: 0.7102, aux_task4.loss_bbox: 0.3369, aux_task5.loss_heatmap: 0.7384, aux_task5.loss_bbox: 0.3232, loss: 18.5194, grad_norm: 49.0287
2025-05-19 15:13:20,273 - mmdet - INFO - Epoch [3][850/2207]	lr: 3.541e-05, eta: 9:13:42, time: 0.854, data_time: 0.006, memory: 11317, loss_cls: 0.6847, loss_bbox: 1.0085, d0.loss_cls: 0.7240, d0.loss_bbox: 1.2026, d1.loss_cls: 0.6983, d1.loss_bbox: 1.0915, d2.loss_cls: 0.6917, d2.loss_bbox: 1.0469, d3.loss_cls: 0.6849, d3.loss_bbox: 1.0311, d4.loss_cls: 0.6827, d4.loss_bbox: 1.0173, aux_task0.loss_heatmap: 0.8822, aux_task0.loss_bbox: 0.3312, aux_task1.loss_heatmap: 1.1276, aux_task1.loss_bbox: 0.3770, aux_task2.loss_heatmap: 1.3115, aux_task2.loss_bbox: 0.3989, aux_task3.loss_heatmap: 0.9359, aux_task3.loss_bbox: 0.3163, aux_task4.loss_heatmap: 0.7356, aux_task4.loss_bbox: 0.3350, aux_task5.loss_heatmap: 0.7165, aux_task5.loss_bbox: 0.3277, loss: 18.3593, grad_norm: 47.8789
2025-05-19 15:14:03,080 - mmdet - INFO - Epoch [3][900/2207]	lr: 3.582e-05, eta: 9:13:00, time: 0.856, data_time: 0.007, memory: 11317, loss_cls: 0.6991, loss_bbox: 1.0215, d0.loss_cls: 0.7375, d0.loss_bbox: 1.2194, d1.loss_cls: 0.7159, d1.loss_bbox: 1.0989, d2.loss_cls: 0.7083, d2.loss_bbox: 1.0537, d3.loss_cls: 0.7016, d3.loss_bbox: 1.0399, d4.loss_cls: 0.6972, d4.loss_bbox: 1.0317, aux_task0.loss_heatmap: 0.8807, aux_task0.loss_bbox: 0.3334, aux_task1.loss_heatmap: 1.1273, aux_task1.loss_bbox: 0.3718, aux_task2.loss_heatmap: 1.2987, aux_task2.loss_bbox: 0.4097, aux_task3.loss_heatmap: 0.9729, aux_task3.loss_bbox: 0.3178, aux_task4.loss_heatmap: 0.7479, aux_task4.loss_bbox: 0.3411, aux_task5.loss_heatmap: 0.7541, aux_task5.loss_bbox: 0.3320, loss: 18.6123, grad_norm: 54.2719
2025-05-19 15:14:45,491 - mmdet - INFO - Epoch [3][950/2207]	lr: 3.623e-05, eta: 9:12:15, time: 0.848, data_time: 0.006, memory: 11317, loss_cls: 0.6880, loss_bbox: 1.0216, d0.loss_cls: 0.7307, d0.loss_bbox: 1.2220, d1.loss_cls: 0.7057, d1.loss_bbox: 1.0998, d2.loss_cls: 0.7005, d2.loss_bbox: 1.0517, d3.loss_cls: 0.6912, d3.loss_bbox: 1.0386, d4.loss_cls: 0.6891, d4.loss_bbox: 1.0275, aux_task0.loss_heatmap: 0.8618, aux_task0.loss_bbox: 0.3259, aux_task1.loss_heatmap: 1.1803, aux_task1.loss_bbox: 0.3728, aux_task2.loss_heatmap: 1.2677, aux_task2.loss_bbox: 0.3963, aux_task3.loss_heatmap: 1.0038, aux_task3.loss_bbox: 0.3171, aux_task4.loss_heatmap: 0.7059, aux_task4.loss_bbox: 0.3306, aux_task5.loss_heatmap: 0.7253, aux_task5.loss_bbox: 0.3303, loss: 18.4843, grad_norm: 49.7741
2025-05-19 15:15:28,061 - mmdet - INFO - Epoch [3][1000/2207]	lr: 3.663e-05, eta: 9:11:31, time: 0.851, data_time: 0.007, memory: 11317, loss_cls: 0.6839, loss_bbox: 1.0135, d0.loss_cls: 0.7272, d0.loss_bbox: 1.2032, d1.loss_cls: 0.7040, d1.loss_bbox: 1.0852, d2.loss_cls: 0.6969, d2.loss_bbox: 1.0420, d3.loss_cls: 0.6865, d3.loss_bbox: 1.0304, d4.loss_cls: 0.6830, d4.loss_bbox: 1.0223, aux_task0.loss_heatmap: 0.8980, aux_task0.loss_bbox: 0.3319, aux_task1.loss_heatmap: 1.1067, aux_task1.loss_bbox: 0.3712, aux_task2.loss_heatmap: 1.2521, aux_task2.loss_bbox: 0.4063, aux_task3.loss_heatmap: 0.9475, aux_task3.loss_bbox: 0.3123, aux_task4.loss_heatmap: 0.7223, aux_task4.loss_bbox: 0.3375, aux_task5.loss_heatmap: 0.7226, aux_task5.loss_bbox: 0.3293, loss: 18.3160, grad_norm: 51.6020
2025-05-19 15:16:10,732 - mmdet - INFO - Epoch [3][1050/2207]	lr: 3.705e-05, eta: 9:10:48, time: 0.853, data_time: 0.007, memory: 11317, loss_cls: 0.6873, loss_bbox: 1.0170, d0.loss_cls: 0.7267, d0.loss_bbox: 1.2203, d1.loss_cls: 0.7037, d1.loss_bbox: 1.0986, d2.loss_cls: 0.6997, d2.loss_bbox: 1.0492, d3.loss_cls: 0.6931, d3.loss_bbox: 1.0359, d4.loss_cls: 0.6873, d4.loss_bbox: 1.0250, aux_task0.loss_heatmap: 0.8870, aux_task0.loss_bbox: 0.3362, aux_task1.loss_heatmap: 1.1101, aux_task1.loss_bbox: 0.3742, aux_task2.loss_heatmap: 1.3078, aux_task2.loss_bbox: 0.4078, aux_task3.loss_heatmap: 0.9584, aux_task3.loss_bbox: 0.3201, aux_task4.loss_heatmap: 0.7116, aux_task4.loss_bbox: 0.3356, aux_task5.loss_heatmap: 0.7620, aux_task5.loss_bbox: 0.3294, loss: 18.4841, grad_norm: 46.5713
2025-05-19 15:16:53,153 - mmdet - INFO - Epoch [3][1100/2207]	lr: 3.746e-05, eta: 9:10:03, time: 0.848, data_time: 0.006, memory: 11317, loss_cls: 0.6898, loss_bbox: 1.0143, d0.loss_cls: 0.7298, d0.loss_bbox: 1.2132, d1.loss_cls: 0.7058, d1.loss_bbox: 1.0949, d2.loss_cls: 0.6972, d2.loss_bbox: 1.0475, d3.loss_cls: 0.6906, d3.loss_bbox: 1.0336, d4.loss_cls: 0.6874, d4.loss_bbox: 1.0231, aux_task0.loss_heatmap: 0.8915, aux_task0.loss_bbox: 0.3368, aux_task1.loss_heatmap: 1.1112, aux_task1.loss_bbox: 0.3738, aux_task2.loss_heatmap: 1.3011, aux_task2.loss_bbox: 0.4101, aux_task3.loss_heatmap: 0.9577, aux_task3.loss_bbox: 0.3217, aux_task4.loss_heatmap: 0.6824, aux_task4.loss_bbox: 0.3361, aux_task5.loss_heatmap: 0.7152, aux_task5.loss_bbox: 0.3249, loss: 18.3898, grad_norm: 46.0674
2025-05-19 15:17:35,451 - mmdet - INFO - Epoch [3][1150/2207]	lr: 3.788e-05, eta: 9:09:17, time: 0.846, data_time: 0.006, memory: 11317, loss_cls: 0.6826, loss_bbox: 1.0028, d0.loss_cls: 0.7218, d0.loss_bbox: 1.1898, d1.loss_cls: 0.7029, d1.loss_bbox: 1.0742, d2.loss_cls: 0.6940, d2.loss_bbox: 1.0285, d3.loss_cls: 0.6858, d3.loss_bbox: 1.0181, d4.loss_cls: 0.6806, d4.loss_bbox: 1.0093, aux_task0.loss_heatmap: 0.9151, aux_task0.loss_bbox: 0.3369, aux_task1.loss_heatmap: 1.1155, aux_task1.loss_bbox: 0.3762, aux_task2.loss_heatmap: 1.2865, aux_task2.loss_bbox: 0.4116, aux_task3.loss_heatmap: 0.9704, aux_task3.loss_bbox: 0.3227, aux_task4.loss_heatmap: 0.6653, aux_task4.loss_bbox: 0.3263, aux_task5.loss_heatmap: 0.7027, aux_task5.loss_bbox: 0.3255, loss: 18.2453, grad_norm: 49.0511
2025-05-19 15:18:17,905 - mmdet - INFO - Epoch [3][1200/2207]	lr: 3.830e-05, eta: 9:08:33, time: 0.849, data_time: 0.006, memory: 11317, loss_cls: 0.6760, loss_bbox: 1.0101, d0.loss_cls: 0.7136, d0.loss_bbox: 1.1980, d1.loss_cls: 0.6913, d1.loss_bbox: 1.0824, d2.loss_cls: 0.6843, d2.loss_bbox: 1.0381, d3.loss_cls: 0.6784, d3.loss_bbox: 1.0268, d4.loss_cls: 0.6729, d4.loss_bbox: 1.0200, aux_task0.loss_heatmap: 0.8643, aux_task0.loss_bbox: 0.3217, aux_task1.loss_heatmap: 1.1440, aux_task1.loss_bbox: 0.3744, aux_task2.loss_heatmap: 1.2718, aux_task2.loss_bbox: 0.4085, aux_task3.loss_heatmap: 0.9594, aux_task3.loss_bbox: 0.3231, aux_task4.loss_heatmap: 0.6719, aux_task4.loss_bbox: 0.3302, aux_task5.loss_heatmap: 0.7236, aux_task5.loss_bbox: 0.3262, loss: 18.2108, grad_norm: 48.3107
2025-05-19 15:19:00,705 - mmdet - INFO - Epoch [3][1250/2207]	lr: 3.872e-05, eta: 9:07:51, time: 0.856, data_time: 0.006, memory: 11317, loss_cls: 0.6714, loss_bbox: 1.0096, d0.loss_cls: 0.7185, d0.loss_bbox: 1.2024, d1.loss_cls: 0.6872, d1.loss_bbox: 1.0856, d2.loss_cls: 0.6825, d2.loss_bbox: 1.0414, d3.loss_cls: 0.6757, d3.loss_bbox: 1.0276, d4.loss_cls: 0.6709, d4.loss_bbox: 1.0182, aux_task0.loss_heatmap: 0.8352, aux_task0.loss_bbox: 0.3188, aux_task1.loss_heatmap: 1.0520, aux_task1.loss_bbox: 0.3692, aux_task2.loss_heatmap: 1.2664, aux_task2.loss_bbox: 0.4024, aux_task3.loss_heatmap: 0.9625, aux_task3.loss_bbox: 0.3218, aux_task4.loss_heatmap: 0.7294, aux_task4.loss_bbox: 0.3386, aux_task5.loss_heatmap: 0.7279, aux_task5.loss_bbox: 0.3234, loss: 18.1386, grad_norm: 48.3073
2025-05-19 15:19:43,103 - mmdet - INFO - Epoch [3][1300/2207]	lr: 3.914e-05, eta: 9:07:06, time: 0.848, data_time: 0.007, memory: 11317, loss_cls: 0.6773, loss_bbox: 1.0163, d0.loss_cls: 0.7250, d0.loss_bbox: 1.2077, d1.loss_cls: 0.6971, d1.loss_bbox: 1.0929, d2.loss_cls: 0.6901, d2.loss_bbox: 1.0429, d3.loss_cls: 0.6822, d3.loss_bbox: 1.0322, d4.loss_cls: 0.6761, d4.loss_bbox: 1.0251, aux_task0.loss_heatmap: 0.8817, aux_task0.loss_bbox: 0.3366, aux_task1.loss_heatmap: 1.0683, aux_task1.loss_bbox: 0.3812, aux_task2.loss_heatmap: 1.2811, aux_task2.loss_bbox: 0.4121, aux_task3.loss_heatmap: 0.9489, aux_task3.loss_bbox: 0.3227, aux_task4.loss_heatmap: 0.7273, aux_task4.loss_bbox: 0.3329, aux_task5.loss_heatmap: 0.6972, aux_task5.loss_bbox: 0.3233, loss: 18.2783, grad_norm: 48.8314
2025-05-19 15:20:25,933 - mmdet - INFO - Epoch [3][1350/2207]	lr: 3.957e-05, eta: 9:06:24, time: 0.857, data_time: 0.007, memory: 11317, loss_cls: 0.6624, loss_bbox: 0.9863, d0.loss_cls: 0.7047, d0.loss_bbox: 1.1790, d1.loss_cls: 0.6814, d1.loss_bbox: 1.0578, d2.loss_cls: 0.6701, d2.loss_bbox: 1.0171, d3.loss_cls: 0.6656, d3.loss_bbox: 1.0020, d4.loss_cls: 0.6596, d4.loss_bbox: 0.9941, aux_task0.loss_heatmap: 0.8645, aux_task0.loss_bbox: 0.3254, aux_task1.loss_heatmap: 1.0963, aux_task1.loss_bbox: 0.3778, aux_task2.loss_heatmap: 1.2586, aux_task2.loss_bbox: 0.4021, aux_task3.loss_heatmap: 0.9173, aux_task3.loss_bbox: 0.3135, aux_task4.loss_heatmap: 0.6800, aux_task4.loss_bbox: 0.3334, aux_task5.loss_heatmap: 0.7089, aux_task5.loss_bbox: 0.3288, loss: 17.8865, grad_norm: 46.1585
2025-05-19 15:21:08,456 - mmdet - INFO - Epoch [3][1400/2207]	lr: 4.000e-05, eta: 9:05:40, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.6623, loss_bbox: 0.9953, d0.loss_cls: 0.7072, d0.loss_bbox: 1.1900, d1.loss_cls: 0.6818, d1.loss_bbox: 1.0691, d2.loss_cls: 0.6738, d2.loss_bbox: 1.0254, d3.loss_cls: 0.6681, d3.loss_bbox: 1.0123, d4.loss_cls: 0.6641, d4.loss_bbox: 1.0032, aux_task0.loss_heatmap: 0.8593, aux_task0.loss_bbox: 0.3219, aux_task1.loss_heatmap: 1.0689, aux_task1.loss_bbox: 0.3625, aux_task2.loss_heatmap: 1.2533, aux_task2.loss_bbox: 0.4073, aux_task3.loss_heatmap: 0.9489, aux_task3.loss_bbox: 0.3096, aux_task4.loss_heatmap: 0.7085, aux_task4.loss_bbox: 0.3328, aux_task5.loss_heatmap: 0.7083, aux_task5.loss_bbox: 0.3254, loss: 17.9594, grad_norm: 51.6527
2025-05-19 15:21:51,162 - mmdet - INFO - Epoch [3][1450/2207]	lr: 4.043e-05, eta: 9:04:57, time: 0.854, data_time: 0.007, memory: 11317, loss_cls: 0.6651, loss_bbox: 0.9958, d0.loss_cls: 0.7057, d0.loss_bbox: 1.1785, d1.loss_cls: 0.6805, d1.loss_bbox: 1.0622, d2.loss_cls: 0.6753, d2.loss_bbox: 1.0211, d3.loss_cls: 0.6694, d3.loss_bbox: 1.0085, d4.loss_cls: 0.6633, d4.loss_bbox: 1.0035, aux_task0.loss_heatmap: 0.8660, aux_task0.loss_bbox: 0.3242, aux_task1.loss_heatmap: 1.1177, aux_task1.loss_bbox: 0.3652, aux_task2.loss_heatmap: 1.2283, aux_task2.loss_bbox: 0.4057, aux_task3.loss_heatmap: 0.9151, aux_task3.loss_bbox: 0.3125, aux_task4.loss_heatmap: 0.6910, aux_task4.loss_bbox: 0.3344, aux_task5.loss_heatmap: 0.7044, aux_task5.loss_bbox: 0.3267, loss: 17.9205, grad_norm: 54.7831
2025-05-19 15:22:33,678 - mmdet - INFO - Epoch [3][1500/2207]	lr: 4.087e-05, eta: 9:04:13, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.6601, loss_bbox: 1.0028, d0.loss_cls: 0.7045, d0.loss_bbox: 1.1948, d1.loss_cls: 0.6797, d1.loss_bbox: 1.0724, d2.loss_cls: 0.6728, d2.loss_bbox: 1.0278, d3.loss_cls: 0.6655, d3.loss_bbox: 1.0162, d4.loss_cls: 0.6599, d4.loss_bbox: 1.0097, aux_task0.loss_heatmap: 0.8679, aux_task0.loss_bbox: 0.3322, aux_task1.loss_heatmap: 1.1025, aux_task1.loss_bbox: 0.3757, aux_task2.loss_heatmap: 1.1702, aux_task2.loss_bbox: 0.3969, aux_task3.loss_heatmap: 0.9038, aux_task3.loss_bbox: 0.3165, aux_task4.loss_heatmap: 0.6847, aux_task4.loss_bbox: 0.3338, aux_task5.loss_heatmap: 0.7062, aux_task5.loss_bbox: 0.3299, loss: 17.8868, grad_norm: 47.5677
2025-05-19 15:23:16,012 - mmdet - INFO - Epoch [3][1550/2207]	lr: 4.130e-05, eta: 9:03:28, time: 0.847, data_time: 0.007, memory: 11317, loss_cls: 0.6708, loss_bbox: 1.0005, d0.loss_cls: 0.7106, d0.loss_bbox: 1.1904, d1.loss_cls: 0.6872, d1.loss_bbox: 1.0666, d2.loss_cls: 0.6822, d2.loss_bbox: 1.0250, d3.loss_cls: 0.6728, d3.loss_bbox: 1.0140, d4.loss_cls: 0.6679, d4.loss_bbox: 1.0079, aux_task0.loss_heatmap: 0.8554, aux_task0.loss_bbox: 0.3347, aux_task1.loss_heatmap: 1.1155, aux_task1.loss_bbox: 0.3743, aux_task2.loss_heatmap: 1.2648, aux_task2.loss_bbox: 0.4065, aux_task3.loss_heatmap: 0.9286, aux_task3.loss_bbox: 0.3183, aux_task4.loss_heatmap: 0.6742, aux_task4.loss_bbox: 0.3236, aux_task5.loss_heatmap: 0.6938, aux_task5.loss_bbox: 0.3268, loss: 18.0122, grad_norm: 47.6522
2025-05-19 15:23:58,555 - mmdet - INFO - Epoch [3][1600/2207]	lr: 4.174e-05, eta: 9:02:44, time: 0.851, data_time: 0.007, memory: 11317, loss_cls: 0.6524, loss_bbox: 0.9856, d0.loss_cls: 0.6955, d0.loss_bbox: 1.1682, d1.loss_cls: 0.6747, d1.loss_bbox: 1.0500, d2.loss_cls: 0.6682, d2.loss_bbox: 1.0109, d3.loss_cls: 0.6576, d3.loss_bbox: 1.0016, d4.loss_cls: 0.6514, d4.loss_bbox: 0.9942, aux_task0.loss_heatmap: 0.8690, aux_task0.loss_bbox: 0.3294, aux_task1.loss_heatmap: 1.0701, aux_task1.loss_bbox: 0.3625, aux_task2.loss_heatmap: 1.2228, aux_task2.loss_bbox: 0.3976, aux_task3.loss_heatmap: 0.8830, aux_task3.loss_bbox: 0.3167, aux_task4.loss_heatmap: 0.7034, aux_task4.loss_bbox: 0.3328, aux_task5.loss_heatmap: 0.6496, aux_task5.loss_bbox: 0.3178, loss: 17.6648, grad_norm: 49.2044
2025-05-19 15:24:41,197 - mmdet - INFO - Epoch [3][1650/2207]	lr: 4.218e-05, eta: 9:02:01, time: 0.853, data_time: 0.006, memory: 11317, loss_cls: 0.6537, loss_bbox: 1.0011, d0.loss_cls: 0.6937, d0.loss_bbox: 1.1751, d1.loss_cls: 0.6714, d1.loss_bbox: 1.0588, d2.loss_cls: 0.6628, d2.loss_bbox: 1.0257, d3.loss_cls: 0.6569, d3.loss_bbox: 1.0138, d4.loss_cls: 0.6522, d4.loss_bbox: 1.0066, aux_task0.loss_heatmap: 0.8590, aux_task0.loss_bbox: 0.3268, aux_task1.loss_heatmap: 1.0889, aux_task1.loss_bbox: 0.3802, aux_task2.loss_heatmap: 1.1794, aux_task2.loss_bbox: 0.4008, aux_task3.loss_heatmap: 0.8999, aux_task3.loss_bbox: 0.3112, aux_task4.loss_heatmap: 0.7026, aux_task4.loss_bbox: 0.3341, aux_task5.loss_heatmap: 0.6813, aux_task5.loss_bbox: 0.3210, loss: 17.7571, grad_norm: 48.3000
2025-05-19 15:25:23,654 - mmdet - INFO - Epoch [3][1700/2207]	lr: 4.262e-05, eta: 9:01:17, time: 0.849, data_time: 0.006, memory: 11317, loss_cls: 0.6602, loss_bbox: 0.9860, d0.loss_cls: 0.7053, d0.loss_bbox: 1.1753, d1.loss_cls: 0.6822, d1.loss_bbox: 1.0479, d2.loss_cls: 0.6724, d2.loss_bbox: 1.0094, d3.loss_cls: 0.6659, d3.loss_bbox: 0.9983, d4.loss_cls: 0.6591, d4.loss_bbox: 0.9930, aux_task0.loss_heatmap: 0.8774, aux_task0.loss_bbox: 0.3308, aux_task1.loss_heatmap: 1.1097, aux_task1.loss_bbox: 0.3777, aux_task2.loss_heatmap: 1.2547, aux_task2.loss_bbox: 0.4138, aux_task3.loss_heatmap: 0.9203, aux_task3.loss_bbox: 0.3118, aux_task4.loss_heatmap: 0.6541, aux_task4.loss_bbox: 0.3226, aux_task5.loss_heatmap: 0.6943, aux_task5.loss_bbox: 0.3248, loss: 17.8468, grad_norm: 50.6035
2025-05-19 15:26:06,270 - mmdet - INFO - Epoch [3][1750/2207]	lr: 4.307e-05, eta: 9:00:34, time: 0.852, data_time: 0.006, memory: 11317, loss_cls: 0.6517, loss_bbox: 0.9844, d0.loss_cls: 0.6945, d0.loss_bbox: 1.1666, d1.loss_cls: 0.6700, d1.loss_bbox: 1.0496, d2.loss_cls: 0.6640, d2.loss_bbox: 1.0127, d3.loss_cls: 0.6586, d3.loss_bbox: 0.9996, d4.loss_cls: 0.6515, d4.loss_bbox: 0.9927, aux_task0.loss_heatmap: 0.8396, aux_task0.loss_bbox: 0.3258, aux_task1.loss_heatmap: 1.0966, aux_task1.loss_bbox: 0.3708, aux_task2.loss_heatmap: 1.2527, aux_task2.loss_bbox: 0.4107, aux_task3.loss_heatmap: 0.8789, aux_task3.loss_bbox: 0.3164, aux_task4.loss_heatmap: 0.6935, aux_task4.loss_bbox: 0.3250, aux_task5.loss_heatmap: 0.6772, aux_task5.loss_bbox: 0.3258, loss: 17.7088, grad_norm: 45.9016
2025-05-19 15:26:48,853 - mmdet - INFO - Epoch [3][1800/2207]	lr: 4.351e-05, eta: 8:59:50, time: 0.852, data_time: 0.006, memory: 11317, loss_cls: 0.6594, loss_bbox: 0.9897, d0.loss_cls: 0.7058, d0.loss_bbox: 1.1661, d1.loss_cls: 0.6801, d1.loss_bbox: 1.0456, d2.loss_cls: 0.6729, d2.loss_bbox: 1.0095, d3.loss_cls: 0.6645, d3.loss_bbox: 1.0001, d4.loss_cls: 0.6583, d4.loss_bbox: 0.9958, aux_task0.loss_heatmap: 0.8315, aux_task0.loss_bbox: 0.3230, aux_task1.loss_heatmap: 1.0721, aux_task1.loss_bbox: 0.3667, aux_task2.loss_heatmap: 1.1953, aux_task2.loss_bbox: 0.4011, aux_task3.loss_heatmap: 0.9501, aux_task3.loss_bbox: 0.3278, aux_task4.loss_heatmap: 0.6955, aux_task4.loss_bbox: 0.3227, aux_task5.loss_heatmap: 0.7040, aux_task5.loss_bbox: 0.3209, loss: 17.7585, grad_norm: 48.9165
2025-05-19 15:27:31,583 - mmdet - INFO - Epoch [3][1850/2207]	lr: 4.396e-05, eta: 8:59:08, time: 0.855, data_time: 0.007, memory: 11317, loss_cls: 0.6495, loss_bbox: 0.9883, d0.loss_cls: 0.6942, d0.loss_bbox: 1.1758, d1.loss_cls: 0.6709, d1.loss_bbox: 1.0517, d2.loss_cls: 0.6645, d2.loss_bbox: 1.0103, d3.loss_cls: 0.6554, d3.loss_bbox: 0.9997, d4.loss_cls: 0.6507, d4.loss_bbox: 0.9939, aux_task0.loss_heatmap: 0.8653, aux_task0.loss_bbox: 0.3260, aux_task1.loss_heatmap: 1.1054, aux_task1.loss_bbox: 0.3741, aux_task2.loss_heatmap: 1.1951, aux_task2.loss_bbox: 0.3998, aux_task3.loss_heatmap: 0.8873, aux_task3.loss_bbox: 0.3112, aux_task4.loss_heatmap: 0.6545, aux_task4.loss_bbox: 0.3291, aux_task5.loss_heatmap: 0.6649, aux_task5.loss_bbox: 0.3171, loss: 17.6347, grad_norm: 50.6714
2025-05-19 15:28:14,079 - mmdet - INFO - Epoch [3][1900/2207]	lr: 4.441e-05, eta: 8:58:24, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.6457, loss_bbox: 0.9889, d0.loss_cls: 0.6910, d0.loss_bbox: 1.1750, d1.loss_cls: 0.6664, d1.loss_bbox: 1.0529, d2.loss_cls: 0.6609, d2.loss_bbox: 1.0151, d3.loss_cls: 0.6525, d3.loss_bbox: 1.0020, d4.loss_cls: 0.6445, d4.loss_bbox: 0.9965, aux_task0.loss_heatmap: 0.8260, aux_task0.loss_bbox: 0.3330, aux_task1.loss_heatmap: 1.0859, aux_task1.loss_bbox: 0.3734, aux_task2.loss_heatmap: 1.2019, aux_task2.loss_bbox: 0.3958, aux_task3.loss_heatmap: 0.9527, aux_task3.loss_bbox: 0.3197, aux_task4.loss_heatmap: 0.6805, aux_task4.loss_bbox: 0.3274, aux_task5.loss_heatmap: 0.6608, aux_task5.loss_bbox: 0.3220, loss: 17.6705, grad_norm: 46.9917
2025-05-19 15:28:56,797 - mmdet - INFO - Epoch [3][1950/2207]	lr: 4.486e-05, eta: 8:57:41, time: 0.854, data_time: 0.008, memory: 11317, loss_cls: 0.6424, loss_bbox: 0.9779, d0.loss_cls: 0.6917, d0.loss_bbox: 1.1566, d1.loss_cls: 0.6660, d1.loss_bbox: 1.0379, d2.loss_cls: 0.6600, d2.loss_bbox: 0.9967, d3.loss_cls: 0.6478, d3.loss_bbox: 0.9871, d4.loss_cls: 0.6410, d4.loss_bbox: 0.9840, aux_task0.loss_heatmap: 0.8387, aux_task0.loss_bbox: 0.3290, aux_task1.loss_heatmap: 1.1073, aux_task1.loss_bbox: 0.3684, aux_task2.loss_heatmap: 1.2328, aux_task2.loss_bbox: 0.3982, aux_task3.loss_heatmap: 0.8894, aux_task3.loss_bbox: 0.3180, aux_task4.loss_heatmap: 0.6651, aux_task4.loss_bbox: 0.3226, aux_task5.loss_heatmap: 0.6626, aux_task5.loss_bbox: 0.3216, loss: 17.5429, grad_norm: 53.4337
2025-05-19 15:29:39,387 - mmdet - INFO - Epoch [3][2000/2207]	lr: 4.532e-05, eta: 8:56:58, time: 0.852, data_time: 0.005, memory: 11317, loss_cls: 0.6410, loss_bbox: 0.9712, d0.loss_cls: 0.6867, d0.loss_bbox: 1.1613, d1.loss_cls: 0.6643, d1.loss_bbox: 1.0341, d2.loss_cls: 0.6560, d2.loss_bbox: 0.9950, d3.loss_cls: 0.6490, d3.loss_bbox: 0.9821, d4.loss_cls: 0.6419, d4.loss_bbox: 0.9773, aux_task0.loss_heatmap: 0.8430, aux_task0.loss_bbox: 0.3201, aux_task1.loss_heatmap: 1.0865, aux_task1.loss_bbox: 0.3711, aux_task2.loss_heatmap: 1.1301, aux_task2.loss_bbox: 0.3998, aux_task3.loss_heatmap: 0.8701, aux_task3.loss_bbox: 0.3210, aux_task4.loss_heatmap: 0.6668, aux_task4.loss_bbox: 0.3261, aux_task5.loss_heatmap: 0.6525, aux_task5.loss_bbox: 0.3200, loss: 17.3669, grad_norm: 52.3060
2025-05-19 15:30:21,876 - mmdet - INFO - Epoch [3][2050/2207]	lr: 4.577e-05, eta: 8:56:14, time: 0.850, data_time: 0.006, memory: 11317, loss_cls: 0.6372, loss_bbox: 0.9666, d0.loss_cls: 0.6883, d0.loss_bbox: 1.1470, d1.loss_cls: 0.6645, d1.loss_bbox: 1.0232, d2.loss_cls: 0.6509, d2.loss_bbox: 0.9872, d3.loss_cls: 0.6436, d3.loss_bbox: 0.9752, d4.loss_cls: 0.6368, d4.loss_bbox: 0.9711, aux_task0.loss_heatmap: 0.8248, aux_task0.loss_bbox: 0.3190, aux_task1.loss_heatmap: 1.0753, aux_task1.loss_bbox: 0.3671, aux_task2.loss_heatmap: 1.1379, aux_task2.loss_bbox: 0.3892, aux_task3.loss_heatmap: 0.8803, aux_task3.loss_bbox: 0.3124, aux_task4.loss_heatmap: 0.6832, aux_task4.loss_bbox: 0.3248, aux_task5.loss_heatmap: 0.6768, aux_task5.loss_bbox: 0.3203, loss: 17.3027, grad_norm: 46.5233
2025-05-19 15:31:06,067 - mmdet - INFO - Epoch [3][2100/2207]	lr: 4.623e-05, eta: 8:55:40, time: 0.884, data_time: 0.006, memory: 11317, loss_cls: 0.6526, loss_bbox: 0.9871, d0.loss_cls: 0.6977, d0.loss_bbox: 1.1626, d1.loss_cls: 0.6778, d1.loss_bbox: 1.0403, d2.loss_cls: 0.6712, d2.loss_bbox: 1.0043, d3.loss_cls: 0.6587, d3.loss_bbox: 0.9974, d4.loss_cls: 0.6527, d4.loss_bbox: 0.9925, aux_task0.loss_heatmap: 0.8475, aux_task0.loss_bbox: 0.3274, aux_task1.loss_heatmap: 1.0881, aux_task1.loss_bbox: 0.3786, aux_task2.loss_heatmap: 1.1306, aux_task2.loss_bbox: 0.3890, aux_task3.loss_heatmap: 0.9267, aux_task3.loss_bbox: 0.3192, aux_task4.loss_heatmap: 0.6929, aux_task4.loss_bbox: 0.3312, aux_task5.loss_heatmap: 0.6602, aux_task5.loss_bbox: 0.3216, loss: 17.6080, grad_norm: 47.1822
2025-05-19 15:31:48,762 - mmdet - INFO - Epoch [3][2150/2207]	lr: 4.669e-05, eta: 8:54:57, time: 0.854, data_time: 0.005, memory: 11317, loss_cls: 0.6531, loss_bbox: 0.9721, d0.loss_cls: 0.6987, d0.loss_bbox: 1.1593, d1.loss_cls: 0.6762, d1.loss_bbox: 1.0324, d2.loss_cls: 0.6705, d2.loss_bbox: 0.9958, d3.loss_cls: 0.6591, d3.loss_bbox: 0.9851, d4.loss_cls: 0.6522, d4.loss_bbox: 0.9789, aux_task0.loss_heatmap: 0.8520, aux_task0.loss_bbox: 0.3316, aux_task1.loss_heatmap: 1.0558, aux_task1.loss_bbox: 0.3677, aux_task2.loss_heatmap: 1.1960, aux_task2.loss_bbox: 0.4027, aux_task3.loss_heatmap: 0.8811, aux_task3.loss_bbox: 0.3143, aux_task4.loss_heatmap: 0.6541, aux_task4.loss_bbox: 0.3281, aux_task5.loss_heatmap: 0.6980, aux_task5.loss_bbox: 0.3208, loss: 17.5357, grad_norm: 45.3094
2025-05-19 15:32:31,310 - mmdet - INFO - Epoch [3][2200/2207]	lr: 4.715e-05, eta: 8:54:13, time: 0.851, data_time: 0.006, memory: 11317, loss_cls: 0.6359, loss_bbox: 0.9848, d0.loss_cls: 0.6796, d0.loss_bbox: 1.1623, d1.loss_cls: 0.6588, d1.loss_bbox: 1.0419, d2.loss_cls: 0.6508, d2.loss_bbox: 1.0052, d3.loss_cls: 0.6414, d3.loss_bbox: 0.9957, d4.loss_cls: 0.6350, d4.loss_bbox: 0.9908, aux_task0.loss_heatmap: 0.8327, aux_task0.loss_bbox: 0.3282, aux_task1.loss_heatmap: 1.0845, aux_task1.loss_bbox: 0.3732, aux_task2.loss_heatmap: 1.1626, aux_task2.loss_bbox: 0.4042, aux_task3.loss_heatmap: 0.8632, aux_task3.loss_bbox: 0.3101, aux_task4.loss_heatmap: 0.6805, aux_task4.loss_bbox: 0.3310, aux_task5.loss_heatmap: 0.6521, aux_task5.loss_bbox: 0.3210, loss: 17.4256, grad_norm: 43.8364
2025-05-19 15:32:39,125 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-05-19 15:33:32,162 - mmdet - INFO - Epoch [4][50/2207]	lr: 4.768e-05, eta: 8:53:10, time: 0.920, data_time: 0.071, memory: 11317, loss_cls: 0.6490, loss_bbox: 0.9616, d0.loss_cls: 0.6937, d0.loss_bbox: 1.1368, d1.loss_cls: 0.6733, d1.loss_bbox: 1.0125, d2.loss_cls: 0.6626, d2.loss_bbox: 0.9803, d3.loss_cls: 0.6553, d3.loss_bbox: 0.9711, d4.loss_cls: 0.6464, d4.loss_bbox: 0.9680, aux_task0.loss_heatmap: 0.8517, aux_task0.loss_bbox: 0.3276, aux_task1.loss_heatmap: 1.0699, aux_task1.loss_bbox: 0.3644, aux_task2.loss_heatmap: 1.2434, aux_task2.loss_bbox: 0.3924, aux_task3.loss_heatmap: 0.8408, aux_task3.loss_bbox: 0.3114, aux_task4.loss_heatmap: 0.6791, aux_task4.loss_bbox: 0.3282, aux_task5.loss_heatmap: 0.6657, aux_task5.loss_bbox: 0.3241, loss: 17.4092, grad_norm: 47.7118
2025-05-19 15:34:14,814 - mmdet - INFO - Epoch [4][100/2207]	lr: 4.814e-05, eta: 8:52:27, time: 0.853, data_time: 0.007, memory: 11317, loss_cls: 0.6416, loss_bbox: 0.9583, d0.loss_cls: 0.6855, d0.loss_bbox: 1.1331, d1.loss_cls: 0.6611, d1.loss_bbox: 1.0198, d2.loss_cls: 0.6535, d2.loss_bbox: 0.9833, d3.loss_cls: 0.6473, d3.loss_bbox: 0.9740, d4.loss_cls: 0.6406, d4.loss_bbox: 0.9670, aux_task0.loss_heatmap: 0.7793, aux_task0.loss_bbox: 0.3250, aux_task1.loss_heatmap: 1.0597, aux_task1.loss_bbox: 0.3579, aux_task2.loss_heatmap: 1.1485, aux_task2.loss_bbox: 0.3998, aux_task3.loss_heatmap: 0.8653, aux_task3.loss_bbox: 0.3125, aux_task4.loss_heatmap: 0.6790, aux_task4.loss_bbox: 0.3285, aux_task5.loss_heatmap: 0.6353, aux_task5.loss_bbox: 0.3202, loss: 17.1762, grad_norm: 48.4311
2025-05-19 15:34:57,687 - mmdet - INFO - Epoch [4][150/2207]	lr: 4.861e-05, eta: 8:51:45, time: 0.857, data_time: 0.007, memory: 11317, loss_cls: 0.6365, loss_bbox: 0.9588, d0.loss_cls: 0.6848, d0.loss_bbox: 1.1391, d1.loss_cls: 0.6639, d1.loss_bbox: 1.0141, d2.loss_cls: 0.6574, d2.loss_bbox: 0.9793, d3.loss_cls: 0.6451, d3.loss_bbox: 0.9697, d4.loss_cls: 0.6372, d4.loss_bbox: 0.9648, aux_task0.loss_heatmap: 0.8149, aux_task0.loss_bbox: 0.3202, aux_task1.loss_heatmap: 1.0798, aux_task1.loss_bbox: 0.3652, aux_task2.loss_heatmap: 1.0916, aux_task2.loss_bbox: 0.3812, aux_task3.loss_heatmap: 0.9071, aux_task3.loss_bbox: 0.3157, aux_task4.loss_heatmap: 0.6547, aux_task4.loss_bbox: 0.3291, aux_task5.loss_heatmap: 0.6817, aux_task5.loss_bbox: 0.3222, loss: 17.2139, grad_norm: 43.9797
2025-05-19 15:35:39,970 - mmdet - INFO - Epoch [4][200/2207]	lr: 4.908e-05, eta: 8:51:00, time: 0.846, data_time: 0.006, memory: 11317, loss_cls: 0.6357, loss_bbox: 0.9567, d0.loss_cls: 0.6747, d0.loss_bbox: 1.1346, d1.loss_cls: 0.6552, d1.loss_bbox: 1.0158, d2.loss_cls: 0.6504, d2.loss_bbox: 0.9793, d3.loss_cls: 0.6397, d3.loss_bbox: 0.9676, d4.loss_cls: 0.6349, d4.loss_bbox: 0.9617, aux_task0.loss_heatmap: 0.7777, aux_task0.loss_bbox: 0.3182, aux_task1.loss_heatmap: 1.0889, aux_task1.loss_bbox: 0.3742, aux_task2.loss_heatmap: 1.1762, aux_task2.loss_bbox: 0.3934, aux_task3.loss_heatmap: 0.8675, aux_task3.loss_bbox: 0.3153, aux_task4.loss_heatmap: 0.6632, aux_task4.loss_bbox: 0.3311, aux_task5.loss_heatmap: 0.6325, aux_task5.loss_bbox: 0.3079, loss: 17.1523, grad_norm: 48.1420
2025-05-19 15:36:22,557 - mmdet - INFO - Epoch [4][250/2207]	lr: 4.955e-05, eta: 8:50:17, time: 0.852, data_time: 0.006, memory: 11317, loss_cls: 0.6364, loss_bbox: 0.9737, d0.loss_cls: 0.6845, d0.loss_bbox: 1.1545, d1.loss_cls: 0.6643, d1.loss_bbox: 1.0276, d2.loss_cls: 0.6545, d2.loss_bbox: 0.9919, d3.loss_cls: 0.6442, d3.loss_bbox: 0.9839, d4.loss_cls: 0.6350, d4.loss_bbox: 0.9799, aux_task0.loss_heatmap: 0.7959, aux_task0.loss_bbox: 0.3157, aux_task1.loss_heatmap: 1.0356, aux_task1.loss_bbox: 0.3690, aux_task2.loss_heatmap: 1.1651, aux_task2.loss_bbox: 0.3886, aux_task3.loss_heatmap: 0.9228, aux_task3.loss_bbox: 0.3178, aux_task4.loss_heatmap: 0.6541, aux_task4.loss_bbox: 0.3274, aux_task5.loss_heatmap: 0.6676, aux_task5.loss_bbox: 0.3229, loss: 17.3132, grad_norm: 44.9435
2025-05-19 15:37:04,879 - mmdet - INFO - Epoch [4][300/2207]	lr: 5.002e-05, eta: 8:49:32, time: 0.846, data_time: 0.006, memory: 11317, loss_cls: 0.6358, loss_bbox: 0.9580, d0.loss_cls: 0.6792, d0.loss_bbox: 1.1328, d1.loss_cls: 0.6607, d1.loss_bbox: 1.0115, d2.loss_cls: 0.6542, d2.loss_bbox: 0.9772, d3.loss_cls: 0.6419, d3.loss_bbox: 0.9681, d4.loss_cls: 0.6341, d4.loss_bbox: 0.9627, aux_task0.loss_heatmap: 0.8382, aux_task0.loss_bbox: 0.3265, aux_task1.loss_heatmap: 1.0719, aux_task1.loss_bbox: 0.3688, aux_task2.loss_heatmap: 1.1150, aux_task2.loss_bbox: 0.3957, aux_task3.loss_heatmap: 0.9162, aux_task3.loss_bbox: 0.3170, aux_task4.loss_heatmap: 0.6365, aux_task4.loss_bbox: 0.3250, aux_task5.loss_heatmap: 0.6336, aux_task5.loss_bbox: 0.3165, loss: 17.1774, grad_norm: 44.6063
2025-05-19 15:37:47,425 - mmdet - INFO - Epoch [4][350/2207]	lr: 5.049e-05, eta: 8:48:49, time: 0.851, data_time: 0.006, memory: 11317, loss_cls: 0.6146, loss_bbox: 0.9498, d0.loss_cls: 0.6682, d0.loss_bbox: 1.1279, d1.loss_cls: 0.6443, d1.loss_bbox: 1.0022, d2.loss_cls: 0.6353, d2.loss_bbox: 0.9705, d3.loss_cls: 0.6224, d3.loss_bbox: 0.9614, d4.loss_cls: 0.6142, d4.loss_bbox: 0.9560, aux_task0.loss_heatmap: 0.8020, aux_task0.loss_bbox: 0.3173, aux_task1.loss_heatmap: 1.0321, aux_task1.loss_bbox: 0.3626, aux_task2.loss_heatmap: 1.1208, aux_task2.loss_bbox: 0.3901, aux_task3.loss_heatmap: 0.8665, aux_task3.loss_bbox: 0.3163, aux_task4.loss_heatmap: 0.6407, aux_task4.loss_bbox: 0.3159, aux_task5.loss_heatmap: 0.6505, aux_task5.loss_bbox: 0.3199, loss: 16.9017, grad_norm: 48.7594
2025-05-19 15:38:29,973 - mmdet - INFO - Epoch [4][400/2207]	lr: 5.096e-05, eta: 8:48:05, time: 0.851, data_time: 0.007, memory: 11317, loss_cls: 0.6229, loss_bbox: 0.9579, d0.loss_cls: 0.6697, d0.loss_bbox: 1.1320, d1.loss_cls: 0.6499, d1.loss_bbox: 1.0133, d2.loss_cls: 0.6460, d2.loss_bbox: 0.9771, d3.loss_cls: 0.6309, d3.loss_bbox: 0.9682, d4.loss_cls: 0.6239, d4.loss_bbox: 0.9632, aux_task0.loss_heatmap: 0.8044, aux_task0.loss_bbox: 0.3261, aux_task1.loss_heatmap: 1.0562, aux_task1.loss_bbox: 0.3687, aux_task2.loss_heatmap: 1.1258, aux_task2.loss_bbox: 0.3943, aux_task3.loss_heatmap: 0.8512, aux_task3.loss_bbox: 0.3154, aux_task4.loss_heatmap: 0.6327, aux_task4.loss_bbox: 0.3253, aux_task5.loss_heatmap: 0.6553, aux_task5.loss_bbox: 0.3194, loss: 17.0297, grad_norm: 48.1485
2025-05-19 15:39:12,621 - mmdet - INFO - Epoch [4][450/2207]	lr: 5.144e-05, eta: 8:47:23, time: 0.853, data_time: 0.006, memory: 11317, loss_cls: 0.6142, loss_bbox: 0.9433, d0.loss_cls: 0.6609, d0.loss_bbox: 1.1129, d1.loss_cls: 0.6426, d1.loss_bbox: 0.9952, d2.loss_cls: 0.6332, d2.loss_bbox: 0.9615, d3.loss_cls: 0.6217, d3.loss_bbox: 0.9520, d4.loss_cls: 0.6121, d4.loss_bbox: 0.9488, aux_task0.loss_heatmap: 0.7773, aux_task0.loss_bbox: 0.3142, aux_task1.loss_heatmap: 1.0227, aux_task1.loss_bbox: 0.3617, aux_task2.loss_heatmap: 1.1032, aux_task2.loss_bbox: 0.3771, aux_task3.loss_heatmap: 0.8122, aux_task3.loss_bbox: 0.3041, aux_task4.loss_heatmap: 0.6588, aux_task4.loss_bbox: 0.3260, aux_task5.loss_heatmap: 0.6731, aux_task5.loss_bbox: 0.3229, loss: 16.7518, grad_norm: 50.9887
2025-05-19 15:39:55,327 - mmdet - INFO - Epoch [4][500/2207]	lr: 5.192e-05, eta: 8:46:40, time: 0.854, data_time: 0.013, memory: 11317, loss_cls: 0.6228, loss_bbox: 0.9527, d0.loss_cls: 0.6652, d0.loss_bbox: 1.1220, d1.loss_cls: 0.6482, d1.loss_bbox: 1.0061, d2.loss_cls: 0.6420, d2.loss_bbox: 0.9695, d3.loss_cls: 0.6325, d3.loss_bbox: 0.9610, d4.loss_cls: 0.6205, d4.loss_bbox: 0.9587, aux_task0.loss_heatmap: 0.7859, aux_task0.loss_bbox: 0.3164, aux_task1.loss_heatmap: 1.0647, aux_task1.loss_bbox: 0.3752, aux_task2.loss_heatmap: 1.1619, aux_task2.loss_bbox: 0.3941, aux_task3.loss_heatmap: 0.8484, aux_task3.loss_bbox: 0.3092, aux_task4.loss_heatmap: 0.6737, aux_task4.loss_bbox: 0.3254, aux_task5.loss_heatmap: 0.6449, aux_task5.loss_bbox: 0.3137, loss: 17.0150, grad_norm: 48.6915
2025-05-19 15:40:38,015 - mmdet - INFO - Epoch [4][550/2207]	lr: 5.240e-05, eta: 8:45:57, time: 0.854, data_time: 0.006, memory: 11317, loss_cls: 0.6176, loss_bbox: 0.9348, d0.loss_cls: 0.6633, d0.loss_bbox: 1.1073, d1.loss_cls: 0.6446, d1.loss_bbox: 0.9869, d2.loss_cls: 0.6364, d2.loss_bbox: 0.9540, d3.loss_cls: 0.6238, d3.loss_bbox: 0.9434, d4.loss_cls: 0.6160, d4.loss_bbox: 0.9384, aux_task0.loss_heatmap: 0.7961, aux_task0.loss_bbox: 0.3183, aux_task1.loss_heatmap: 1.0285, aux_task1.loss_bbox: 0.3615, aux_task2.loss_heatmap: 1.1635, aux_task2.loss_bbox: 0.4016, aux_task3.loss_heatmap: 0.7811, aux_task3.loss_bbox: 0.3072, aux_task4.loss_heatmap: 0.6584, aux_task4.loss_bbox: 0.3142, aux_task5.loss_heatmap: 0.6347, aux_task5.loss_bbox: 0.3147, loss: 16.7464, grad_norm: 48.7784
2025-05-19 15:41:20,851 - mmdet - INFO - Epoch [4][600/2207]	lr: 5.287e-05, eta: 8:45:15, time: 0.857, data_time: 0.006, memory: 11317, loss_cls: 0.6163, loss_bbox: 0.9484, d0.loss_cls: 0.6627, d0.loss_bbox: 1.1244, d1.loss_cls: 0.6417, d1.loss_bbox: 1.0048, d2.loss_cls: 0.6344, d2.loss_bbox: 0.9686, d3.loss_cls: 0.6253, d3.loss_bbox: 0.9593, d4.loss_cls: 0.6160, d4.loss_bbox: 0.9539, aux_task0.loss_heatmap: 0.7997, aux_task0.loss_bbox: 0.3203, aux_task1.loss_heatmap: 1.0624, aux_task1.loss_bbox: 0.3736, aux_task2.loss_heatmap: 1.0323, aux_task2.loss_bbox: 0.3892, aux_task3.loss_heatmap: 0.8779, aux_task3.loss_bbox: 0.3081, aux_task4.loss_heatmap: 0.6552, aux_task4.loss_bbox: 0.3220, aux_task5.loss_heatmap: 0.6584, aux_task5.loss_bbox: 0.3181, loss: 16.8732, grad_norm: 43.3466
2025-05-19 15:42:03,504 - mmdet - INFO - Epoch [4][650/2207]	lr: 5.336e-05, eta: 8:44:33, time: 0.853, data_time: 0.006, memory: 11317, loss_cls: 0.6252, loss_bbox: 0.9604, d0.loss_cls: 0.6716, d0.loss_bbox: 1.1278, d1.loss_cls: 0.6523, d1.loss_bbox: 1.0119, d2.loss_cls: 0.6428, d2.loss_bbox: 0.9777, d3.loss_cls: 0.6301, d3.loss_bbox: 0.9706, d4.loss_cls: 0.6249, d4.loss_bbox: 0.9666, aux_task0.loss_heatmap: 0.8120, aux_task0.loss_bbox: 0.3187, aux_task1.loss_heatmap: 1.0898, aux_task1.loss_bbox: 0.3722, aux_task2.loss_heatmap: 1.1367, aux_task2.loss_bbox: 0.4017, aux_task3.loss_heatmap: 0.8701, aux_task3.loss_bbox: 0.3197, aux_task4.loss_heatmap: 0.6553, aux_task4.loss_bbox: 0.3257, aux_task5.loss_heatmap: 0.6422, aux_task5.loss_bbox: 0.3178, loss: 17.1238, grad_norm: 48.2076
2025-05-19 15:42:45,870 - mmdet - INFO - Epoch [4][700/2207]	lr: 5.384e-05, eta: 8:43:48, time: 0.847, data_time: 0.006, memory: 11317, loss_cls: 0.6136, loss_bbox: 0.9387, d0.loss_cls: 0.6680, d0.loss_bbox: 1.1110, d1.loss_cls: 0.6450, d1.loss_bbox: 0.9909, d2.loss_cls: 0.6358, d2.loss_bbox: 0.9574, d3.loss_cls: 0.6209, d3.loss_bbox: 0.9480, d4.loss_cls: 0.6138, d4.loss_bbox: 0.9432, aux_task0.loss_heatmap: 0.8061, aux_task0.loss_bbox: 0.3167, aux_task1.loss_heatmap: 1.0323, aux_task1.loss_bbox: 0.3653, aux_task2.loss_heatmap: 1.1609, aux_task2.loss_bbox: 0.3885, aux_task3.loss_heatmap: 0.8391, aux_task3.loss_bbox: 0.3116, aux_task4.loss_heatmap: 0.6530, aux_task4.loss_bbox: 0.3224, aux_task5.loss_heatmap: 0.6082, aux_task5.loss_bbox: 0.3118, loss: 16.8021, grad_norm: 46.4940
2025-05-19 15:43:28,440 - mmdet - INFO - Epoch [4][750/2207]	lr: 5.432e-05, eta: 8:43:05, time: 0.851, data_time: 0.006, memory: 11317, loss_cls: 0.6126, loss_bbox: 0.9377, d0.loss_cls: 0.6614, d0.loss_bbox: 1.1053, d1.loss_cls: 0.6391, d1.loss_bbox: 0.9874, d2.loss_cls: 0.6319, d2.loss_bbox: 0.9532, d3.loss_cls: 0.6204, d3.loss_bbox: 0.9461, d4.loss_cls: 0.6133, d4.loss_bbox: 0.9421, aux_task0.loss_heatmap: 0.7773, aux_task0.loss_bbox: 0.3161, aux_task1.loss_heatmap: 1.0430, aux_task1.loss_bbox: 0.3639, aux_task2.loss_heatmap: 1.1359, aux_task2.loss_bbox: 0.3774, aux_task3.loss_heatmap: 0.8125, aux_task3.loss_bbox: 0.3114, aux_task4.loss_heatmap: 0.6313, aux_task4.loss_bbox: 0.3251, aux_task5.loss_heatmap: 0.6387, aux_task5.loss_bbox: 0.3191, loss: 16.7022, grad_norm: 45.0848
2025-05-19 15:44:11,311 - mmdet - INFO - Epoch [4][800/2207]	lr: 5.480e-05, eta: 8:42:23, time: 0.857, data_time: 0.007, memory: 11317, loss_cls: 0.5961, loss_bbox: 0.9384, d0.loss_cls: 0.6459, d0.loss_bbox: 1.0972, d1.loss_cls: 0.6256, d1.loss_bbox: 0.9861, d2.loss_cls: 0.6171, d2.loss_bbox: 0.9570, d3.loss_cls: 0.6056, d3.loss_bbox: 0.9489, d4.loss_cls: 0.5985, d4.loss_bbox: 0.9427, aux_task0.loss_heatmap: 0.7746, aux_task0.loss_bbox: 0.3202, aux_task1.loss_heatmap: 0.9804, aux_task1.loss_bbox: 0.3592, aux_task2.loss_heatmap: 1.1524, aux_task2.loss_bbox: 0.3905, aux_task3.loss_heatmap: 0.8076, aux_task3.loss_bbox: 0.3155, aux_task4.loss_heatmap: 0.6207, aux_task4.loss_bbox: 0.3226, aux_task5.loss_heatmap: 0.6302, aux_task5.loss_bbox: 0.3158, loss: 16.5487, grad_norm: 45.3784
2025-05-19 15:44:53,955 - mmdet - INFO - Epoch [4][850/2207]	lr: 5.529e-05, eta: 8:41:40, time: 0.853, data_time: 0.006, memory: 11317, loss_cls: 0.6035, loss_bbox: 0.9367, d0.loss_cls: 0.6538, d0.loss_bbox: 1.0986, d1.loss_cls: 0.6292, d1.loss_bbox: 0.9812, d2.loss_cls: 0.6226, d2.loss_bbox: 0.9519, d3.loss_cls: 0.6095, d3.loss_bbox: 0.9469, d4.loss_cls: 0.6028, d4.loss_bbox: 0.9426, aux_task0.loss_heatmap: 0.7550, aux_task0.loss_bbox: 0.3182, aux_task1.loss_heatmap: 1.0070, aux_task1.loss_bbox: 0.3568, aux_task2.loss_heatmap: 1.1266, aux_task2.loss_bbox: 0.3901, aux_task3.loss_heatmap: 0.8398, aux_task3.loss_bbox: 0.3117, aux_task4.loss_heatmap: 0.6440, aux_task4.loss_bbox: 0.3194, aux_task5.loss_heatmap: 0.6162, aux_task5.loss_bbox: 0.3166, loss: 16.5804, grad_norm: 46.5484
2025-05-19 15:45:36,703 - mmdet - INFO - Epoch [4][900/2207]	lr: 5.578e-05, eta: 8:40:58, time: 0.855, data_time: 0.008, memory: 11317, loss_cls: 0.6169, loss_bbox: 0.9331, d0.loss_cls: 0.6688, d0.loss_bbox: 1.1007, d1.loss_cls: 0.6458, d1.loss_bbox: 0.9885, d2.loss_cls: 0.6352, d2.loss_bbox: 0.9573, d3.loss_cls: 0.6232, d3.loss_bbox: 0.9457, d4.loss_cls: 0.6155, d4.loss_bbox: 0.9391, aux_task0.loss_heatmap: 0.8004, aux_task0.loss_bbox: 0.3082, aux_task1.loss_heatmap: 0.9894, aux_task1.loss_bbox: 0.3591, aux_task2.loss_heatmap: 1.1244, aux_task2.loss_bbox: 0.3888, aux_task3.loss_heatmap: 0.8776, aux_task3.loss_bbox: 0.3047, aux_task4.loss_heatmap: 0.6657, aux_task4.loss_bbox: 0.3250, aux_task5.loss_heatmap: 0.6423, aux_task5.loss_bbox: 0.3129, loss: 16.7683, grad_norm: 47.7985
2025-05-19 15:46:19,345 - mmdet - INFO - Epoch [4][950/2207]	lr: 5.626e-05, eta: 8:40:15, time: 0.853, data_time: 0.009, memory: 11317, loss_cls: 0.6100, loss_bbox: 0.9398, d0.loss_cls: 0.6606, d0.loss_bbox: 1.1132, d1.loss_cls: 0.6425, d1.loss_bbox: 0.9939, d2.loss_cls: 0.6333, d2.loss_bbox: 0.9599, d3.loss_cls: 0.6186, d3.loss_bbox: 0.9509, d4.loss_cls: 0.6099, d4.loss_bbox: 0.9462, aux_task0.loss_heatmap: 0.7970, aux_task0.loss_bbox: 0.3186, aux_task1.loss_heatmap: 1.0643, aux_task1.loss_bbox: 0.3642, aux_task2.loss_heatmap: 1.0716, aux_task2.loss_bbox: 0.3797, aux_task3.loss_heatmap: 0.8271, aux_task3.loss_bbox: 0.3007, aux_task4.loss_heatmap: 0.6332, aux_task4.loss_bbox: 0.3192, aux_task5.loss_heatmap: 0.6297, aux_task5.loss_bbox: 0.3126, loss: 16.6968, grad_norm: 45.8453
2025-05-19 15:47:01,878 - mmdet - INFO - Epoch [4][1000/2207]	lr: 5.675e-05, eta: 8:39:32, time: 0.851, data_time: 0.006, memory: 11317, loss_cls: 0.5947, loss_bbox: 0.9301, d0.loss_cls: 0.6475, d0.loss_bbox: 1.0998, d1.loss_cls: 0.6297, d1.loss_bbox: 0.9814, d2.loss_cls: 0.6184, d2.loss_bbox: 0.9475, d3.loss_cls: 0.6033, d3.loss_bbox: 0.9367, d4.loss_cls: 0.5956, d4.loss_bbox: 0.9338, aux_task0.loss_heatmap: 0.8159, aux_task0.loss_bbox: 0.3168, aux_task1.loss_heatmap: 1.0247, aux_task1.loss_bbox: 0.3612, aux_task2.loss_heatmap: 1.0861, aux_task2.loss_bbox: 0.3872, aux_task3.loss_heatmap: 0.8322, aux_task3.loss_bbox: 0.3040, aux_task4.loss_heatmap: 0.6186, aux_task4.loss_bbox: 0.3245, aux_task5.loss_heatmap: 0.6305, aux_task5.loss_bbox: 0.3164, loss: 16.5365, grad_norm: 45.1211
2025-05-19 15:47:44,507 - mmdet - INFO - Epoch [4][1050/2207]	lr: 5.724e-05, eta: 8:38:49, time: 0.853, data_time: 0.007, memory: 11317, loss_cls: 0.6062, loss_bbox: 0.9471, d0.loss_cls: 0.6582, d0.loss_bbox: 1.1119, d1.loss_cls: 0.6374, d1.loss_bbox: 0.9949, d2.loss_cls: 0.6298, d2.loss_bbox: 0.9620, d3.loss_cls: 0.6155, d3.loss_bbox: 0.9545, d4.loss_cls: 0.6072, d4.loss_bbox: 0.9523, aux_task0.loss_heatmap: 0.8127, aux_task0.loss_bbox: 0.3196, aux_task1.loss_heatmap: 0.9729, aux_task1.loss_bbox: 0.3548, aux_task2.loss_heatmap: 1.1027, aux_task2.loss_bbox: 0.3829, aux_task3.loss_heatmap: 0.8341, aux_task3.loss_bbox: 0.3163, aux_task4.loss_heatmap: 0.6317, aux_task4.loss_bbox: 0.3231, aux_task5.loss_heatmap: 0.6090, aux_task5.loss_bbox: 0.3149, loss: 16.6520, grad_norm: 48.0595
2025-05-19 15:48:26,970 - mmdet - INFO - Epoch [4][1100/2207]	lr: 5.773e-05, eta: 8:38:05, time: 0.849, data_time: 0.006, memory: 11317, loss_cls: 0.6010, loss_bbox: 0.9192, d0.loss_cls: 0.6511, d0.loss_bbox: 1.0892, d1.loss_cls: 0.6274, d1.loss_bbox: 0.9758, d2.loss_cls: 0.6182, d2.loss_bbox: 0.9413, d3.loss_cls: 0.6061, d3.loss_bbox: 0.9312, d4.loss_cls: 0.5994, d4.loss_bbox: 0.9266, aux_task0.loss_heatmap: 0.7835, aux_task0.loss_bbox: 0.3189, aux_task1.loss_heatmap: 0.9974, aux_task1.loss_bbox: 0.3558, aux_task2.loss_heatmap: 1.0837, aux_task2.loss_bbox: 0.3855, aux_task3.loss_heatmap: 0.8683, aux_task3.loss_bbox: 0.3115, aux_task4.loss_heatmap: 0.6043, aux_task4.loss_bbox: 0.3186, aux_task5.loss_heatmap: 0.6313, aux_task5.loss_bbox: 0.3076, loss: 16.4528, grad_norm: 44.1614
2025-05-19 15:49:09,893 - mmdet - INFO - Epoch [4][1150/2207]	lr: 5.822e-05, eta: 8:37:24, time: 0.858, data_time: 0.008, memory: 11317, loss_cls: 0.6107, loss_bbox: 0.9419, d0.loss_cls: 0.6506, d0.loss_bbox: 1.0964, d1.loss_cls: 0.6351, d1.loss_bbox: 0.9896, d2.loss_cls: 0.6299, d2.loss_bbox: 0.9606, d3.loss_cls: 0.6177, d3.loss_bbox: 0.9509, d4.loss_cls: 0.6082, d4.loss_bbox: 0.9476, aux_task0.loss_heatmap: 0.8139, aux_task0.loss_bbox: 0.3130, aux_task1.loss_heatmap: 1.0176, aux_task1.loss_bbox: 0.3619, aux_task2.loss_heatmap: 1.1102, aux_task2.loss_bbox: 0.3919, aux_task3.loss_heatmap: 0.8775, aux_task3.loss_bbox: 0.3055, aux_task4.loss_heatmap: 0.6414, aux_task4.loss_bbox: 0.3163, aux_task5.loss_heatmap: 0.6228, aux_task5.loss_bbox: 0.3113, loss: 16.7224, grad_norm: 42.6219
2025-05-19 15:49:52,422 - mmdet - INFO - Epoch [4][1200/2207]	lr: 5.872e-05, eta: 8:36:40, time: 0.851, data_time: 0.006, memory: 11317, loss_cls: 0.5995, loss_bbox: 0.9371, d0.loss_cls: 0.6512, d0.loss_bbox: 1.0922, d1.loss_cls: 0.6313, d1.loss_bbox: 0.9809, d2.loss_cls: 0.6223, d2.loss_bbox: 0.9539, d3.loss_cls: 0.6082, d3.loss_bbox: 0.9460, d4.loss_cls: 0.5991, d4.loss_bbox: 0.9428, aux_task0.loss_heatmap: 0.8088, aux_task0.loss_bbox: 0.3228, aux_task1.loss_heatmap: 1.0320, aux_task1.loss_bbox: 0.3620, aux_task2.loss_heatmap: 1.0664, aux_task2.loss_bbox: 0.3900, aux_task3.loss_heatmap: 0.8686, aux_task3.loss_bbox: 0.3052, aux_task4.loss_heatmap: 0.6102, aux_task4.loss_bbox: 0.3223, aux_task5.loss_heatmap: 0.6396, aux_task5.loss_bbox: 0.3163, loss: 16.6087, grad_norm: 46.6636
2025-05-19 15:50:35,196 - mmdet - INFO - Epoch [4][1250/2207]	lr: 5.921e-05, eta: 8:35:58, time: 0.855, data_time: 0.006, memory: 11397, loss_cls: 0.5966, loss_bbox: 0.9264, d0.loss_cls: 0.6477, d0.loss_bbox: 1.0872, d1.loss_cls: 0.6307, d1.loss_bbox: 0.9715, d2.loss_cls: 0.6147, d2.loss_bbox: 0.9474, d3.loss_cls: 0.6053, d3.loss_bbox: 0.9371, d4.loss_cls: 0.5951, d4.loss_bbox: 0.9326, aux_task0.loss_heatmap: 0.7769, aux_task0.loss_bbox: 0.3060, aux_task1.loss_heatmap: 0.9460, aux_task1.loss_bbox: 0.3549, aux_task2.loss_heatmap: 1.1010, aux_task2.loss_bbox: 0.3905, aux_task3.loss_heatmap: 0.8625, aux_task3.loss_bbox: 0.3090, aux_task4.loss_heatmap: 0.6487, aux_task4.loss_bbox: 0.3221, aux_task5.loss_heatmap: 0.6063, aux_task5.loss_bbox: 0.3114, loss: 16.4276, grad_norm: 46.4929
2025-05-19 15:51:17,518 - mmdet - INFO - Epoch [4][1300/2207]	lr: 5.970e-05, eta: 8:35:14, time: 0.846, data_time: 0.006, memory: 11397, loss_cls: 0.6017, loss_bbox: 0.9162, d0.loss_cls: 0.6514, d0.loss_bbox: 1.0749, d1.loss_cls: 0.6304, d1.loss_bbox: 0.9652, d2.loss_cls: 0.6219, d2.loss_bbox: 0.9367, d3.loss_cls: 0.6080, d3.loss_bbox: 0.9271, d4.loss_cls: 0.6006, d4.loss_bbox: 0.9243, aux_task0.loss_heatmap: 0.7768, aux_task0.loss_bbox: 0.3061, aux_task1.loss_heatmap: 0.9728, aux_task1.loss_bbox: 0.3604, aux_task2.loss_heatmap: 1.0856, aux_task2.loss_bbox: 0.3945, aux_task3.loss_heatmap: 0.8499, aux_task3.loss_bbox: 0.3014, aux_task4.loss_heatmap: 0.6385, aux_task4.loss_bbox: 0.3173, aux_task5.loss_heatmap: 0.6016, aux_task5.loss_bbox: 0.3114, loss: 16.3745, grad_norm: 43.7280
2025-05-19 15:52:00,201 - mmdet - INFO - Epoch [4][1350/2207]	lr: 6.020e-05, eta: 8:34:31, time: 0.854, data_time: 0.006, memory: 11397, loss_cls: 0.5823, loss_bbox: 0.9174, d0.loss_cls: 0.6395, d0.loss_bbox: 1.0805, d1.loss_cls: 0.6196, d1.loss_bbox: 0.9634, d2.loss_cls: 0.6081, d2.loss_bbox: 0.9316, d3.loss_cls: 0.5907, d3.loss_bbox: 0.9261, d4.loss_cls: 0.5823, d4.loss_bbox: 0.9225, aux_task0.loss_heatmap: 0.7541, aux_task0.loss_bbox: 0.3130, aux_task1.loss_heatmap: 1.0079, aux_task1.loss_bbox: 0.3604, aux_task2.loss_heatmap: 1.0865, aux_task2.loss_bbox: 0.3771, aux_task3.loss_heatmap: 0.8214, aux_task3.loss_bbox: 0.3134, aux_task4.loss_heatmap: 0.5871, aux_task4.loss_bbox: 0.3184, aux_task5.loss_heatmap: 0.6179, aux_task5.loss_bbox: 0.3137, loss: 16.2347, grad_norm: 48.7166
2025-05-19 15:52:42,700 - mmdet - INFO - Epoch [4][1400/2207]	lr: 6.069e-05, eta: 8:33:48, time: 0.850, data_time: 0.007, memory: 11397, loss_cls: 0.5810, loss_bbox: 0.9150, d0.loss_cls: 0.6380, d0.loss_bbox: 1.0768, d1.loss_cls: 0.6154, d1.loss_bbox: 0.9639, d2.loss_cls: 0.6057, d2.loss_bbox: 0.9346, d3.loss_cls: 0.5902, d3.loss_bbox: 0.9235, d4.loss_cls: 0.5828, d4.loss_bbox: 0.9184, aux_task0.loss_heatmap: 0.7573, aux_task0.loss_bbox: 0.3142, aux_task1.loss_heatmap: 0.9769, aux_task1.loss_bbox: 0.3501, aux_task2.loss_heatmap: 1.0682, aux_task2.loss_bbox: 0.3864, aux_task3.loss_heatmap: 0.8255, aux_task3.loss_bbox: 0.3085, aux_task4.loss_heatmap: 0.6240, aux_task4.loss_bbox: 0.3241, aux_task5.loss_heatmap: 0.6063, aux_task5.loss_bbox: 0.3077, loss: 16.1945, grad_norm: 41.2390
2025-05-19 15:53:25,278 - mmdet - INFO - Epoch [4][1450/2207]	lr: 6.119e-05, eta: 8:33:05, time: 0.852, data_time: 0.006, memory: 11397, loss_cls: 0.5800, loss_bbox: 0.9112, d0.loss_cls: 0.6329, d0.loss_bbox: 1.0723, d1.loss_cls: 0.6147, d1.loss_bbox: 0.9575, d2.loss_cls: 0.6044, d2.loss_bbox: 0.9270, d3.loss_cls: 0.5892, d3.loss_bbox: 0.9207, d4.loss_cls: 0.5811, d4.loss_bbox: 0.9159, aux_task0.loss_heatmap: 0.7381, aux_task0.loss_bbox: 0.3094, aux_task1.loss_heatmap: 0.9852, aux_task1.loss_bbox: 0.3531, aux_task2.loss_heatmap: 1.0582, aux_task2.loss_bbox: 0.3847, aux_task3.loss_heatmap: 0.8576, aux_task3.loss_bbox: 0.3144, aux_task4.loss_heatmap: 0.6277, aux_task4.loss_bbox: 0.3202, aux_task5.loss_heatmap: 0.6004, aux_task5.loss_bbox: 0.3145, loss: 16.1702, grad_norm: 45.8305
2025-05-19 15:54:08,101 - mmdet - INFO - Epoch [4][1500/2207]	lr: 6.168e-05, eta: 8:32:23, time: 0.856, data_time: 0.006, memory: 11397, loss_cls: 0.5953, loss_bbox: 0.9323, d0.loss_cls: 0.6506, d0.loss_bbox: 1.1024, d1.loss_cls: 0.6296, d1.loss_bbox: 0.9810, d2.loss_cls: 0.6177, d2.loss_bbox: 0.9522, d3.loss_cls: 0.6071, d3.loss_bbox: 0.9398, d4.loss_cls: 0.5960, d4.loss_bbox: 0.9364, aux_task0.loss_heatmap: 0.7741, aux_task0.loss_bbox: 0.3160, aux_task1.loss_heatmap: 1.0035, aux_task1.loss_bbox: 0.3601, aux_task2.loss_heatmap: 1.0484, aux_task2.loss_bbox: 0.3815, aux_task3.loss_heatmap: 0.8533, aux_task3.loss_bbox: 0.3014, aux_task4.loss_heatmap: 0.6600, aux_task4.loss_bbox: 0.3290, aux_task5.loss_heatmap: 0.6078, aux_task5.loss_bbox: 0.3100, loss: 16.4854, grad_norm: 46.8111
2025-05-19 15:54:50,842 - mmdet - INFO - Epoch [4][1550/2207]	lr: 6.218e-05, eta: 8:31:40, time: 0.855, data_time: 0.008, memory: 11397, loss_cls: 0.5846, loss_bbox: 0.9187, d0.loss_cls: 0.6320, d0.loss_bbox: 1.0818, d1.loss_cls: 0.6148, d1.loss_bbox: 0.9692, d2.loss_cls: 0.6061, d2.loss_bbox: 0.9369, d3.loss_cls: 0.5900, d3.loss_bbox: 0.9288, d4.loss_cls: 0.5821, d4.loss_bbox: 0.9245, aux_task0.loss_heatmap: 0.7259, aux_task0.loss_bbox: 0.3130, aux_task1.loss_heatmap: 1.0462, aux_task1.loss_bbox: 0.3630, aux_task2.loss_heatmap: 1.1003, aux_task2.loss_bbox: 0.3850, aux_task3.loss_heatmap: 0.7977, aux_task3.loss_bbox: 0.3056, aux_task4.loss_heatmap: 0.6053, aux_task4.loss_bbox: 0.3146, aux_task5.loss_heatmap: 0.6035, aux_task5.loss_bbox: 0.3107, loss: 16.2403, grad_norm: 46.8110
2025-05-19 15:55:33,277 - mmdet - INFO - Epoch [4][1600/2207]	lr: 6.268e-05, eta: 8:30:56, time: 0.849, data_time: 0.006, memory: 11397, loss_cls: 0.5829, loss_bbox: 0.9122, d0.loss_cls: 0.6367, d0.loss_bbox: 1.0783, d1.loss_cls: 0.6123, d1.loss_bbox: 0.9620, d2.loss_cls: 0.6061, d2.loss_bbox: 0.9281, d3.loss_cls: 0.5915, d3.loss_bbox: 0.9208, d4.loss_cls: 0.5830, d4.loss_bbox: 0.9157, aux_task0.loss_heatmap: 0.7141, aux_task0.loss_bbox: 0.3078, aux_task1.loss_heatmap: 0.9478, aux_task1.loss_bbox: 0.3530, aux_task2.loss_heatmap: 1.0406, aux_task2.loss_bbox: 0.3805, aux_task3.loss_heatmap: 0.8019, aux_task3.loss_bbox: 0.3047, aux_task4.loss_heatmap: 0.6262, aux_task4.loss_bbox: 0.3226, aux_task5.loss_heatmap: 0.6147, aux_task5.loss_bbox: 0.3095, loss: 16.0530, grad_norm: 44.5193
2025-05-19 15:56:15,839 - mmdet - INFO - Epoch [4][1650/2207]	lr: 6.317e-05, eta: 8:30:13, time: 0.851, data_time: 0.006, memory: 11397, loss_cls: 0.5742, loss_bbox: 0.9099, d0.loss_cls: 0.6263, d0.loss_bbox: 1.0644, d1.loss_cls: 0.6070, d1.loss_bbox: 0.9550, d2.loss_cls: 0.5971, d2.loss_bbox: 0.9263, d3.loss_cls: 0.5842, d3.loss_bbox: 0.9198, d4.loss_cls: 0.5741, d4.loss_bbox: 0.9159, aux_task0.loss_heatmap: 0.7548, aux_task0.loss_bbox: 0.3095, aux_task1.loss_heatmap: 0.9734, aux_task1.loss_bbox: 0.3562, aux_task2.loss_heatmap: 1.0422, aux_task2.loss_bbox: 0.3842, aux_task3.loss_heatmap: 0.8012, aux_task3.loss_bbox: 0.3047, aux_task4.loss_heatmap: 0.6198, aux_task4.loss_bbox: 0.3217, aux_task5.loss_heatmap: 0.5763, aux_task5.loss_bbox: 0.3070, loss: 16.0054, grad_norm: 44.8745
2025-05-19 15:56:58,235 - mmdet - INFO - Epoch [4][1700/2207]	lr: 6.367e-05, eta: 8:29:29, time: 0.848, data_time: 0.006, memory: 11397, loss_cls: 0.5868, loss_bbox: 0.9208, d0.loss_cls: 0.6385, d0.loss_bbox: 1.0808, d1.loss_cls: 0.6214, d1.loss_bbox: 0.9615, d2.loss_cls: 0.6097, d2.loss_bbox: 0.9328, d3.loss_cls: 0.5937, d3.loss_bbox: 0.9271, d4.loss_cls: 0.5855, d4.loss_bbox: 0.9234, aux_task0.loss_heatmap: 0.7712, aux_task0.loss_bbox: 0.3172, aux_task1.loss_heatmap: 0.9686, aux_task1.loss_bbox: 0.3594, aux_task2.loss_heatmap: 1.1025, aux_task2.loss_bbox: 0.3896, aux_task3.loss_heatmap: 0.7862, aux_task3.loss_bbox: 0.3064, aux_task4.loss_heatmap: 0.5640, aux_task4.loss_bbox: 0.3111, aux_task5.loss_heatmap: 0.6103, aux_task5.loss_bbox: 0.3103, loss: 16.1788, grad_norm: 43.5161
2025-05-19 15:57:41,518 - mmdet - INFO - Epoch [4][1750/2207]	lr: 6.417e-05, eta: 8:28:49, time: 0.866, data_time: 0.017, memory: 11397, loss_cls: 0.5882, loss_bbox: 0.9233, d0.loss_cls: 0.6390, d0.loss_bbox: 1.0808, d1.loss_cls: 0.6212, d1.loss_bbox: 0.9649, d2.loss_cls: 0.6107, d2.loss_bbox: 0.9366, d3.loss_cls: 0.5972, d3.loss_bbox: 0.9295, d4.loss_cls: 0.5871, d4.loss_bbox: 0.9286, aux_task0.loss_heatmap: 0.7475, aux_task0.loss_bbox: 0.3004, aux_task1.loss_heatmap: 0.9914, aux_task1.loss_bbox: 0.3495, aux_task2.loss_heatmap: 1.0716, aux_task2.loss_bbox: 0.3887, aux_task3.loss_heatmap: 0.8277, aux_task3.loss_bbox: 0.3148, aux_task4.loss_heatmap: 0.6210, aux_task4.loss_bbox: 0.3102, aux_task5.loss_heatmap: 0.6180, aux_task5.loss_bbox: 0.3129, loss: 16.2605, grad_norm: 45.0465
2025-05-19 15:58:24,238 - mmdet - INFO - Epoch [4][1800/2207]	lr: 6.467e-05, eta: 8:28:07, time: 0.854, data_time: 0.007, memory: 11397, loss_cls: 0.5786, loss_bbox: 0.9088, d0.loss_cls: 0.6331, d0.loss_bbox: 1.0683, d1.loss_cls: 0.6106, d1.loss_bbox: 0.9573, d2.loss_cls: 0.6007, d2.loss_bbox: 0.9267, d3.loss_cls: 0.5865, d3.loss_bbox: 0.9175, d4.loss_cls: 0.5779, d4.loss_bbox: 0.9135, aux_task0.loss_heatmap: 0.7361, aux_task0.loss_bbox: 0.3132, aux_task1.loss_heatmap: 1.0044, aux_task1.loss_bbox: 0.3595, aux_task2.loss_heatmap: 1.0275, aux_task2.loss_bbox: 0.3778, aux_task3.loss_heatmap: 0.7987, aux_task3.loss_bbox: 0.3153, aux_task4.loss_heatmap: 0.6217, aux_task4.loss_bbox: 0.3142, aux_task5.loss_heatmap: 0.5783, aux_task5.loss_bbox: 0.3103, loss: 16.0365, grad_norm: 41.2498
2025-05-19 15:59:06,684 - mmdet - INFO - Epoch [4][1850/2207]	lr: 6.517e-05, eta: 8:27:23, time: 0.849, data_time: 0.007, memory: 11397, loss_cls: 0.5873, loss_bbox: 0.9196, d0.loss_cls: 0.6377, d0.loss_bbox: 1.0798, d1.loss_cls: 0.6201, d1.loss_bbox: 0.9649, d2.loss_cls: 0.6113, d2.loss_bbox: 0.9352, d3.loss_cls: 0.5950, d3.loss_bbox: 0.9284, d4.loss_cls: 0.5847, d4.loss_bbox: 0.9242, aux_task0.loss_heatmap: 0.7358, aux_task0.loss_bbox: 0.3112, aux_task1.loss_heatmap: 1.0282, aux_task1.loss_bbox: 0.3636, aux_task2.loss_heatmap: 1.0124, aux_task2.loss_bbox: 0.3841, aux_task3.loss_heatmap: 0.8140, aux_task3.loss_bbox: 0.3039, aux_task4.loss_heatmap: 0.6000, aux_task4.loss_bbox: 0.3170, aux_task5.loss_heatmap: 0.5743, aux_task5.loss_bbox: 0.3086, loss: 16.1414, grad_norm: 40.9722
2025-05-19 15:59:49,297 - mmdet - INFO - Epoch [4][1900/2207]	lr: 6.567e-05, eta: 8:26:40, time: 0.852, data_time: 0.006, memory: 11397, loss_cls: 0.5855, loss_bbox: 0.9185, d0.loss_cls: 0.6421, d0.loss_bbox: 1.0762, d1.loss_cls: 0.6218, d1.loss_bbox: 0.9649, d2.loss_cls: 0.6076, d2.loss_bbox: 0.9351, d3.loss_cls: 0.5925, d3.loss_bbox: 0.9281, d4.loss_cls: 0.5854, d4.loss_bbox: 0.9226, aux_task0.loss_heatmap: 0.7698, aux_task0.loss_bbox: 0.3108, aux_task1.loss_heatmap: 0.9783, aux_task1.loss_bbox: 0.3527, aux_task2.loss_heatmap: 1.0933, aux_task2.loss_bbox: 0.3759, aux_task3.loss_heatmap: 0.8014, aux_task3.loss_bbox: 0.3042, aux_task4.loss_heatmap: 0.5925, aux_task4.loss_bbox: 0.3122, aux_task5.loss_heatmap: 0.6045, aux_task5.loss_bbox: 0.3047, loss: 16.1806, grad_norm: 42.3774
2025-05-19 16:00:31,731 - mmdet - INFO - Epoch [4][1950/2207]	lr: 6.617e-05, eta: 8:25:57, time: 0.849, data_time: 0.006, memory: 11397, loss_cls: 0.5776, loss_bbox: 0.9150, d0.loss_cls: 0.6368, d0.loss_bbox: 1.0707, d1.loss_cls: 0.6175, d1.loss_bbox: 0.9578, d2.loss_cls: 0.6032, d2.loss_bbox: 0.9283, d3.loss_cls: 0.5862, d3.loss_bbox: 0.9210, d4.loss_cls: 0.5760, d4.loss_bbox: 0.9199, aux_task0.loss_heatmap: 0.7443, aux_task0.loss_bbox: 0.3049, aux_task1.loss_heatmap: 1.0273, aux_task1.loss_bbox: 0.3553, aux_task2.loss_heatmap: 1.0723, aux_task2.loss_bbox: 0.3845, aux_task3.loss_heatmap: 0.8038, aux_task3.loss_bbox: 0.3072, aux_task4.loss_heatmap: 0.5959, aux_task4.loss_bbox: 0.3111, aux_task5.loss_heatmap: 0.5977, aux_task5.loss_bbox: 0.3097, loss: 16.1240, grad_norm: 47.1967
2025-05-19 16:01:14,033 - mmdet - INFO - Epoch [4][2000/2207]	lr: 6.667e-05, eta: 8:25:12, time: 0.846, data_time: 0.006, memory: 11397, loss_cls: 0.5760, loss_bbox: 0.9032, d0.loss_cls: 0.6411, d0.loss_bbox: 1.0659, d1.loss_cls: 0.6126, d1.loss_bbox: 0.9500, d2.loss_cls: 0.6003, d2.loss_bbox: 0.9192, d3.loss_cls: 0.5866, d3.loss_bbox: 0.9107, d4.loss_cls: 0.5800, d4.loss_bbox: 0.9063, aux_task0.loss_heatmap: 0.7262, aux_task0.loss_bbox: 0.3009, aux_task1.loss_heatmap: 0.9924, aux_task1.loss_bbox: 0.3536, aux_task2.loss_heatmap: 1.0067, aux_task2.loss_bbox: 0.3795, aux_task3.loss_heatmap: 0.7850, aux_task3.loss_bbox: 0.2913, aux_task4.loss_heatmap: 0.5861, aux_task4.loss_bbox: 0.3160, aux_task5.loss_heatmap: 0.6041, aux_task5.loss_bbox: 0.3081, loss: 15.9018, grad_norm: 45.3045
2025-05-19 16:01:56,469 - mmdet - INFO - Epoch [4][2050/2207]	lr: 6.717e-05, eta: 8:24:29, time: 0.849, data_time: 0.006, memory: 11397, loss_cls: 0.5862, loss_bbox: 0.9070, d0.loss_cls: 0.6431, d0.loss_bbox: 1.0608, d1.loss_cls: 0.6236, d1.loss_bbox: 0.9514, d2.loss_cls: 0.6124, d2.loss_bbox: 0.9222, d3.loss_cls: 0.5969, d3.loss_bbox: 0.9136, d4.loss_cls: 0.5860, d4.loss_bbox: 0.9101, aux_task0.loss_heatmap: 0.7593, aux_task0.loss_bbox: 0.3074, aux_task1.loss_heatmap: 1.0085, aux_task1.loss_bbox: 0.3559, aux_task2.loss_heatmap: 1.0159, aux_task2.loss_bbox: 0.3733, aux_task3.loss_heatmap: 0.8302, aux_task3.loss_bbox: 0.3003, aux_task4.loss_heatmap: 0.6114, aux_task4.loss_bbox: 0.3101, aux_task5.loss_heatmap: 0.5741, aux_task5.loss_bbox: 0.3064, loss: 16.0662, grad_norm: 41.9467
2025-05-19 16:02:39,246 - mmdet - INFO - Epoch [4][2100/2207]	lr: 6.767e-05, eta: 8:23:46, time: 0.856, data_time: 0.010, memory: 11397, loss_cls: 0.5731, loss_bbox: 0.9049, d0.loss_cls: 0.6261, d0.loss_bbox: 1.0564, d1.loss_cls: 0.6072, d1.loss_bbox: 0.9478, d2.loss_cls: 0.5975, d2.loss_bbox: 0.9216, d3.loss_cls: 0.5813, d3.loss_bbox: 0.9140, d4.loss_cls: 0.5757, d4.loss_bbox: 0.9085, aux_task0.loss_heatmap: 0.7457, aux_task0.loss_bbox: 0.3123, aux_task1.loss_heatmap: 0.9888, aux_task1.loss_bbox: 0.3634, aux_task2.loss_heatmap: 1.0092, aux_task2.loss_bbox: 0.3744, aux_task3.loss_heatmap: 0.8038, aux_task3.loss_bbox: 0.3042, aux_task4.loss_heatmap: 0.6219, aux_task4.loss_bbox: 0.3203, aux_task5.loss_heatmap: 0.5944, aux_task5.loss_bbox: 0.3068, loss: 15.9596, grad_norm: 42.2676
2025-05-19 16:03:22,185 - mmdet - INFO - Epoch [4][2150/2207]	lr: 6.817e-05, eta: 8:23:05, time: 0.859, data_time: 0.006, memory: 11397, loss_cls: 0.5557, loss_bbox: 0.8946, d0.loss_cls: 0.6116, d0.loss_bbox: 1.0507, d1.loss_cls: 0.5918, d1.loss_bbox: 0.9405, d2.loss_cls: 0.5790, d2.loss_bbox: 0.9114, d3.loss_cls: 0.5637, d3.loss_bbox: 0.9045, d4.loss_cls: 0.5562, d4.loss_bbox: 0.9010, aux_task0.loss_heatmap: 0.7344, aux_task0.loss_bbox: 0.3063, aux_task1.loss_heatmap: 0.9770, aux_task1.loss_bbox: 0.3497, aux_task2.loss_heatmap: 1.0417, aux_task2.loss_bbox: 0.3772, aux_task3.loss_heatmap: 0.7497, aux_task3.loss_bbox: 0.3051, aux_task4.loss_heatmap: 0.5829, aux_task4.loss_bbox: 0.3143, aux_task5.loss_heatmap: 0.5830, aux_task5.loss_bbox: 0.3075, loss: 15.6895, grad_norm: 41.0070
2025-05-19 16:04:04,783 - mmdet - INFO - Epoch [4][2200/2207]	lr: 6.867e-05, eta: 8:22:22, time: 0.852, data_time: 0.006, memory: 11397, loss_cls: 0.5629, loss_bbox: 0.9072, d0.loss_cls: 0.6184, d0.loss_bbox: 1.0587, d1.loss_cls: 0.6028, d1.loss_bbox: 0.9451, d2.loss_cls: 0.5880, d2.loss_bbox: 0.9212, d3.loss_cls: 0.5723, d3.loss_bbox: 0.9141, d4.loss_cls: 0.5631, d4.loss_bbox: 0.9109, aux_task0.loss_heatmap: 0.7361, aux_task0.loss_bbox: 0.3021, aux_task1.loss_heatmap: 0.9616, aux_task1.loss_bbox: 0.3527, aux_task2.loss_heatmap: 1.0086, aux_task2.loss_bbox: 0.3867, aux_task3.loss_heatmap: 0.7420, aux_task3.loss_bbox: 0.2998, aux_task4.loss_heatmap: 0.6251, aux_task4.loss_bbox: 0.3223, aux_task5.loss_heatmap: 0.5773, aux_task5.loss_bbox: 0.3041, loss: 15.7831, grad_norm: 44.0297
2025-05-19 16:04:11,130 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-05-19 16:05:04,373 - mmdet - INFO - Epoch [5][50/2207]	lr: 6.924e-05, eta: 8:21:22, time: 0.918, data_time: 0.072, memory: 11397, loss_cls: 0.5799, loss_bbox: 0.8973, d0.loss_cls: 0.6296, d0.loss_bbox: 1.0468, d1.loss_cls: 0.6150, d1.loss_bbox: 0.9374, d2.loss_cls: 0.6014, d2.loss_bbox: 0.9107, d3.loss_cls: 0.5866, d3.loss_bbox: 0.9054, d4.loss_cls: 0.5788, d4.loss_bbox: 0.9014, aux_task0.loss_heatmap: 0.7192, aux_task0.loss_bbox: 0.3068, aux_task1.loss_heatmap: 0.9658, aux_task1.loss_bbox: 0.3484, aux_task2.loss_heatmap: 1.0752, aux_task2.loss_bbox: 0.3767, aux_task3.loss_heatmap: 0.8141, aux_task3.loss_bbox: 0.3020, aux_task4.loss_heatmap: 0.6088, aux_task4.loss_bbox: 0.3168, aux_task5.loss_heatmap: 0.5512, aux_task5.loss_bbox: 0.3082, loss: 15.8833, grad_norm: 44.2313
2025-05-19 16:05:47,181 - mmdet - INFO - Epoch [5][100/2207]	lr: 6.974e-05, eta: 8:20:40, time: 0.856, data_time: 0.009, memory: 11397, loss_cls: 0.5691, loss_bbox: 0.8986, d0.loss_cls: 0.6298, d0.loss_bbox: 1.0466, d1.loss_cls: 0.6099, d1.loss_bbox: 0.9375, d2.loss_cls: 0.5960, d2.loss_bbox: 0.9117, d3.loss_cls: 0.5774, d3.loss_bbox: 0.9061, d4.loss_cls: 0.5717, d4.loss_bbox: 0.9003, aux_task0.loss_heatmap: 0.7281, aux_task0.loss_bbox: 0.3133, aux_task1.loss_heatmap: 0.9610, aux_task1.loss_bbox: 0.3432, aux_task2.loss_heatmap: 0.9927, aux_task2.loss_bbox: 0.3823, aux_task3.loss_heatmap: 0.7781, aux_task3.loss_bbox: 0.3000, aux_task4.loss_heatmap: 0.5951, aux_task4.loss_bbox: 0.3119, aux_task5.loss_heatmap: 0.5908, aux_task5.loss_bbox: 0.3022, loss: 15.7532, grad_norm: 46.1965
2025-05-19 16:06:29,990 - mmdet - INFO - Epoch [5][150/2207]	lr: 7.024e-05, eta: 8:19:58, time: 0.856, data_time: 0.006, memory: 11397, loss_cls: 0.5554, loss_bbox: 0.8804, d0.loss_cls: 0.6112, d0.loss_bbox: 1.0264, d1.loss_cls: 0.5926, d1.loss_bbox: 0.9233, d2.loss_cls: 0.5800, d2.loss_bbox: 0.8968, d3.loss_cls: 0.5627, d3.loss_bbox: 0.8891, d4.loss_cls: 0.5560, d4.loss_bbox: 0.8860, aux_task0.loss_heatmap: 0.6912, aux_task0.loss_bbox: 0.3040, aux_task1.loss_heatmap: 0.9718, aux_task1.loss_bbox: 0.3484, aux_task2.loss_heatmap: 1.0032, aux_task2.loss_bbox: 0.3601, aux_task3.loss_heatmap: 0.7916, aux_task3.loss_bbox: 0.3068, aux_task4.loss_heatmap: 0.6023, aux_task4.loss_bbox: 0.3170, aux_task5.loss_heatmap: 0.5946, aux_task5.loss_bbox: 0.3095, loss: 15.5604, grad_norm: 43.5954
2025-05-19 16:07:12,203 - mmdet - INFO - Epoch [5][200/2207]	lr: 7.074e-05, eta: 8:19:14, time: 0.844, data_time: 0.006, memory: 11397, loss_cls: 0.5667, loss_bbox: 0.9101, d0.loss_cls: 0.6296, d0.loss_bbox: 1.0601, d1.loss_cls: 0.6035, d1.loss_bbox: 0.9529, d2.loss_cls: 0.5932, d2.loss_bbox: 0.9277, d3.loss_cls: 0.5756, d3.loss_bbox: 0.9207, d4.loss_cls: 0.5672, d4.loss_bbox: 0.9154, aux_task0.loss_heatmap: 0.7359, aux_task0.loss_bbox: 0.3003, aux_task1.loss_heatmap: 0.9880, aux_task1.loss_bbox: 0.3536, aux_task2.loss_heatmap: 1.0242, aux_task2.loss_bbox: 0.3741, aux_task3.loss_heatmap: 0.7894, aux_task3.loss_bbox: 0.3135, aux_task4.loss_heatmap: 0.5871, aux_task4.loss_bbox: 0.3219, aux_task5.loss_heatmap: 0.5804, aux_task5.loss_bbox: 0.3053, loss: 15.8966, grad_norm: 40.7996
2025-05-19 16:07:54,863 - mmdet - INFO - Epoch [5][250/2207]	lr: 7.124e-05, eta: 8:18:31, time: 0.853, data_time: 0.006, memory: 11397, loss_cls: 0.5638, loss_bbox: 0.8972, d0.loss_cls: 0.6220, d0.loss_bbox: 1.0564, d1.loss_cls: 0.5969, d1.loss_bbox: 0.9388, d2.loss_cls: 0.5848, d2.loss_bbox: 0.9113, d3.loss_cls: 0.5718, d3.loss_bbox: 0.9037, d4.loss_cls: 0.5636, d4.loss_bbox: 0.9008, aux_task0.loss_heatmap: 0.7106, aux_task0.loss_bbox: 0.3041, aux_task1.loss_heatmap: 0.9367, aux_task1.loss_bbox: 0.3515, aux_task2.loss_heatmap: 1.0172, aux_task2.loss_bbox: 0.3706, aux_task3.loss_heatmap: 0.7080, aux_task3.loss_bbox: 0.3073, aux_task4.loss_heatmap: 0.6009, aux_task4.loss_bbox: 0.3189, aux_task5.loss_heatmap: 0.5790, aux_task5.loss_bbox: 0.3036, loss: 15.6193, grad_norm: 44.2441
2025-05-19 16:08:37,247 - mmdet - INFO - Epoch [5][300/2207]	lr: 7.174e-05, eta: 8:17:47, time: 0.848, data_time: 0.006, memory: 11397, loss_cls: 0.5563, loss_bbox: 0.8884, d0.loss_cls: 0.6170, d0.loss_bbox: 1.0592, d1.loss_cls: 0.5978, d1.loss_bbox: 0.9372, d2.loss_cls: 0.5813, d2.loss_bbox: 0.9077, d3.loss_cls: 0.5670, d3.loss_bbox: 0.8960, d4.loss_cls: 0.5594, d4.loss_bbox: 0.8921, aux_task0.loss_heatmap: 0.7188, aux_task0.loss_bbox: 0.3089, aux_task1.loss_heatmap: 0.9662, aux_task1.loss_bbox: 0.3542, aux_task2.loss_heatmap: 0.9788, aux_task2.loss_bbox: 0.3852, aux_task3.loss_heatmap: 0.8134, aux_task3.loss_bbox: 0.3133, aux_task4.loss_heatmap: 0.5589, aux_task4.loss_bbox: 0.3093, aux_task5.loss_heatmap: 0.5866, aux_task5.loss_bbox: 0.3144, loss: 15.6674, grad_norm: 44.6571
2025-05-19 16:09:19,753 - mmdet - INFO - Epoch [5][350/2207]	lr: 7.224e-05, eta: 8:17:04, time: 0.850, data_time: 0.007, memory: 11397, loss_cls: 0.5512, loss_bbox: 0.8849, d0.loss_cls: 0.6047, d0.loss_bbox: 1.0356, d1.loss_cls: 0.5862, d1.loss_bbox: 0.9289, d2.loss_cls: 0.5762, d2.loss_bbox: 0.9010, d3.loss_cls: 0.5611, d3.loss_bbox: 0.8930, d4.loss_cls: 0.5522, d4.loss_bbox: 0.8884, aux_task0.loss_heatmap: 0.7336, aux_task0.loss_bbox: 0.3000, aux_task1.loss_heatmap: 0.9232, aux_task1.loss_bbox: 0.3491, aux_task2.loss_heatmap: 0.9995, aux_task2.loss_bbox: 0.3728, aux_task3.loss_heatmap: 0.7944, aux_task3.loss_bbox: 0.3068, aux_task4.loss_heatmap: 0.5765, aux_task4.loss_bbox: 0.3065, aux_task5.loss_heatmap: 0.5864, aux_task5.loss_bbox: 0.3100, loss: 15.5223, grad_norm: 40.1712
2025-05-19 16:10:03,995 - mmdet - INFO - Epoch [5][400/2207]	lr: 7.274e-05, eta: 8:16:28, time: 0.885, data_time: 0.006, memory: 11397, loss_cls: 0.5548, loss_bbox: 0.8887, d0.loss_cls: 0.6067, d0.loss_bbox: 1.0369, d1.loss_cls: 0.5970, d1.loss_bbox: 0.9324, d2.loss_cls: 0.5827, d2.loss_bbox: 0.9072, d3.loss_cls: 0.5638, d3.loss_bbox: 0.8969, d4.loss_cls: 0.5530, d4.loss_bbox: 0.8920, aux_task0.loss_heatmap: 0.6948, aux_task0.loss_bbox: 0.2955, aux_task1.loss_heatmap: 0.9393, aux_task1.loss_bbox: 0.3505, aux_task2.loss_heatmap: 0.9907, aux_task2.loss_bbox: 0.3875, aux_task3.loss_heatmap: 0.8079, aux_task3.loss_bbox: 0.3063, aux_task4.loss_heatmap: 0.5609, aux_task4.loss_bbox: 0.3114, aux_task5.loss_heatmap: 0.5844, aux_task5.loss_bbox: 0.3091, loss: 15.5507, grad_norm: 39.0630
2025-05-19 16:10:46,648 - mmdet - INFO - Epoch [5][450/2207]	lr: 7.324e-05, eta: 8:15:45, time: 0.853, data_time: 0.006, memory: 11397, loss_cls: 0.5582, loss_bbox: 0.8886, d0.loss_cls: 0.6117, d0.loss_bbox: 1.0411, d1.loss_cls: 0.5965, d1.loss_bbox: 0.9283, d2.loss_cls: 0.5806, d2.loss_bbox: 0.9035, d3.loss_cls: 0.5643, d3.loss_bbox: 0.8958, d4.loss_cls: 0.5585, d4.loss_bbox: 0.8920, aux_task0.loss_heatmap: 0.7151, aux_task0.loss_bbox: 0.3017, aux_task1.loss_heatmap: 0.9463, aux_task1.loss_bbox: 0.3517, aux_task2.loss_heatmap: 0.9774, aux_task2.loss_bbox: 0.3583, aux_task3.loss_heatmap: 0.7737, aux_task3.loss_bbox: 0.2945, aux_task4.loss_heatmap: 0.6064, aux_task4.loss_bbox: 0.3153, aux_task5.loss_heatmap: 0.5659, aux_task5.loss_bbox: 0.3023, loss: 15.5276, grad_norm: 40.8385
2025-05-19 16:11:30,818 - mmdet - INFO - Epoch [5][500/2207]	lr: 7.374e-05, eta: 8:15:08, time: 0.883, data_time: 0.006, memory: 11397, loss_cls: 0.5671, loss_bbox: 0.9073, d0.loss_cls: 0.6181, d0.loss_bbox: 1.0598, d1.loss_cls: 0.6009, d1.loss_bbox: 0.9530, d2.loss_cls: 0.5883, d2.loss_bbox: 0.9241, d3.loss_cls: 0.5764, d3.loss_bbox: 0.9143, d4.loss_cls: 0.5676, d4.loss_bbox: 0.9107, aux_task0.loss_heatmap: 0.7338, aux_task0.loss_bbox: 0.3038, aux_task1.loss_heatmap: 0.9631, aux_task1.loss_bbox: 0.3539, aux_task2.loss_heatmap: 1.0440, aux_task2.loss_bbox: 0.3779, aux_task3.loss_heatmap: 0.7812, aux_task3.loss_bbox: 0.2964, aux_task4.loss_heatmap: 0.6057, aux_task4.loss_bbox: 0.3175, aux_task5.loss_heatmap: 0.5880, aux_task5.loss_bbox: 0.3081, loss: 15.8611, grad_norm: 41.0441
2025-05-19 16:12:13,497 - mmdet - INFO - Epoch [5][550/2207]	lr: 7.424e-05, eta: 8:14:25, time: 0.854, data_time: 0.007, memory: 11397, loss_cls: 0.5611, loss_bbox: 0.8923, d0.loss_cls: 0.6197, d0.loss_bbox: 1.0410, d1.loss_cls: 0.5989, d1.loss_bbox: 0.9333, d2.loss_cls: 0.5873, d2.loss_bbox: 0.9061, d3.loss_cls: 0.5686, d3.loss_bbox: 0.9002, d4.loss_cls: 0.5611, d4.loss_bbox: 0.8954, aux_task0.loss_heatmap: 0.6975, aux_task0.loss_bbox: 0.2998, aux_task1.loss_heatmap: 0.9523, aux_task1.loss_bbox: 0.3507, aux_task2.loss_heatmap: 1.0302, aux_task2.loss_bbox: 0.3956, aux_task3.loss_heatmap: 0.7892, aux_task3.loss_bbox: 0.3067, aux_task4.loss_heatmap: 0.5951, aux_task4.loss_bbox: 0.3048, aux_task5.loss_heatmap: 0.5913, aux_task5.loss_bbox: 0.3089, loss: 15.6872, grad_norm: 38.7909
2025-05-19 16:12:56,374 - mmdet - INFO - Epoch [5][600/2207]	lr: 7.473e-05, eta: 8:13:43, time: 0.858, data_time: 0.006, memory: 11397, loss_cls: 0.5471, loss_bbox: 0.8853, d0.loss_cls: 0.6049, d0.loss_bbox: 1.0347, d1.loss_cls: 0.5880, d1.loss_bbox: 0.9244, d2.loss_cls: 0.5718, d2.loss_bbox: 0.9003, d3.loss_cls: 0.5544, d3.loss_bbox: 0.8949, d4.loss_cls: 0.5476, d4.loss_bbox: 0.8894, aux_task0.loss_heatmap: 0.6701, aux_task0.loss_bbox: 0.3030, aux_task1.loss_heatmap: 0.9886, aux_task1.loss_bbox: 0.3502, aux_task2.loss_heatmap: 0.9321, aux_task2.loss_bbox: 0.3730, aux_task3.loss_heatmap: 0.7689, aux_task3.loss_bbox: 0.3137, aux_task4.loss_heatmap: 0.5821, aux_task4.loss_bbox: 0.3082, aux_task5.loss_heatmap: 0.5508, aux_task5.loss_bbox: 0.3032, loss: 15.3869, grad_norm: 46.7457
