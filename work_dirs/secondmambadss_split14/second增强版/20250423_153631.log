2025-04-23 15:36:31,164 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:52:49) [GCC 13.3.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 4090 D
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.6, V11.6.55
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.13.0
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.1-Product Build 20220311 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0
OpenCV: 4.11.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.6
MMDetection: 2.27.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc6+637e2ea
spconv2.0: True
------------------------------------------------------------

2025-04-23 15:36:32,034 - mmdet - INFO - 分布式训练: True
2025-04-23 15:36:32,864 - mmdet - INFO - 配置:
point_cloud_range = [-54, -54, -5.0, 54, 54, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=False,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='ObjectSample',
        db_sampler=dict(
            data_root='data/nuscenes/',
            info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
            rate=1.0,
            prepare=dict(
                filter_by_difficulty=[-1],
                filter_by_min_points=dict(
                    car=5,
                    truck=5,
                    bus=5,
                    trailer=5,
                    construction_vehicle=5,
                    traffic_cone=5,
                    barrier=5,
                    motorcycle=5,
                    bicycle=5,
                    pedestrian=5)),
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            sample_groups=dict(
                car=2,
                truck=3,
                construction_vehicle=7,
                bus=4,
                trailer=6,
                barrier=2,
                motorcycle=6,
                bicycle=6,
                pedestrian=2,
                traffic_cone=2),
            points_loader=dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk')))),
    dict(
        type='GlobalRotScaleTrans',
        rot_range=[-0.785, 0.785],
        scale_ratio_range=[0.9, 1.1],
        translation_std=[0.5, 0.5, 0.5]),
    dict(
        type='RandomFlip3D',
        sync_2d=False,
        flip_ratio_bev_horizontal=0.5,
        flip_ratio_bev_vertical=0.5),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
]
test_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk'),
        pad_empty_sweeps=True,
        remove_close=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='CBGSDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_train.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=10,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[-0.3925, 0.3925],
                scale_ratio_range=[0.95, 1.05],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D', flip_ratio_bev_horizontal=0.5),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ]),
            dict(type='PointShuffle'),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ]),
            dict(
                type='Collect3D',
                keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
        ],
        classes=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        split=14,
        dataset=dict(
            type='NuScenesDataset',
            data_root='data/nuscenes/',
            ann_file='data/nuscenes/nuscenes_infos_train.pkl',
            pipeline=[
                dict(
                    type='LoadPointsFromFile',
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=5,
                    file_client_args=dict(backend='disk')),
                dict(
                    type='LoadPointsFromMultiSweeps',
                    sweeps_num=9,
                    use_dim=[0, 1, 2, 3, 4],
                    file_client_args=dict(backend='disk'),
                    pad_empty_sweeps=True,
                    remove_close=True),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox_3d=True,
                    with_label_3d=True),
                dict(
                    type='ObjectSample',
                    db_sampler=dict(
                        data_root='data/nuscenes/',
                        info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
                        rate=1.0,
                        prepare=dict(
                            filter_by_difficulty=[-1],
                            filter_by_min_points=dict(
                                car=5,
                                truck=5,
                                bus=5,
                                trailer=5,
                                construction_vehicle=5,
                                traffic_cone=5,
                                barrier=5,
                                motorcycle=5,
                                bicycle=5,
                                pedestrian=5)),
                        classes=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        sample_groups=dict(
                            car=2,
                            truck=3,
                            construction_vehicle=7,
                            bus=4,
                            trailer=6,
                            barrier=2,
                            motorcycle=6,
                            bicycle=6,
                            pedestrian=2,
                            traffic_cone=2),
                        points_loader=dict(
                            type='LoadPointsFromFile',
                            coord_type='LIDAR',
                            load_dim=5,
                            use_dim=[0, 1, 2, 3, 4],
                            file_client_args=dict(backend='disk')))),
                dict(
                    type='GlobalRotScaleTrans',
                    rot_range=[-0.785, 0.785],
                    scale_ratio_range=[0.9, 1.1],
                    translation_std=[0.5, 0.5, 0.5]),
                dict(
                    type='RandomFlip3D',
                    sync_2d=False,
                    flip_ratio_bev_horizontal=0.5,
                    flip_ratio_bev_vertical=0.5),
                dict(
                    type='PointsRangeFilter',
                    point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                dict(
                    type='ObjectNameFilter',
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(type='PointShuffle'),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='Collect3D',
                    keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
            ],
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            test_mode=False,
            use_valid_flag=True,
            box_type_3d='LiDAR')),
    val=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='Collect3D',
                        keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                file_client_args=dict(backend='disk')),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                use_dim=[0, 1, 2, 3, 4],
                file_client_args=dict(backend='disk'),
                pad_empty_sweeps=True,
                remove_close=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='PointsRangeFilter',
                        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='Collect3D',
                        keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=False,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            file_client_args=dict(backend='disk')),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=10,
            file_client_args=dict(backend='disk')),
        dict(
            type='DefaultFormatBundle3D',
            class_names=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            with_label=False),
        dict(type='Collect3D', keys=['points'])
    ])
optimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='cyclic',
    target_ratio=(10, 0.0001),
    cyclic_times=1,
    step_ratio_up=0.4)
momentum_config = dict(
    policy='cyclic',
    target_ratio=(0.8947368421052632, 1),
    cyclic_times=1,
    step_ratio_up=0.4)
runner = dict(type='EpochBasedRunner', max_epochs=20)
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/secondmambadss_split14/second增强版'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
plugin = 'plugin/futr3d'
voxel_size = [0.075, 0.075, 0.2]
center_head = dict(
    type='CenterHead',
    in_channels=512,
    tasks=[
        dict(num_class=1, class_names=['car']),
        dict(num_class=2, class_names=['truck', 'construction_vehicle']),
        dict(num_class=2, class_names=['bus', 'trailer']),
        dict(num_class=1, class_names=['barrier']),
        dict(num_class=2, class_names=['motorcycle', 'bicycle']),
        dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
    ],
    common_heads=dict(
        reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
    share_conv_channel=64,
    bbox_coder=dict(
        type='CenterPointBBoxCoder',
        pc_range=[-54, -54],
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        max_num=500,
        score_threshold=0.1,
        out_size_factor=8,
        voxel_size=[0.075, 0.075],
        code_size=9),
    separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3),
    loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
    loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
    norm_bbox=True)
model = dict(
    type='FUTR3D',
    aux_weight=0.5,
    pts_voxel_layer=dict(
        max_num_points=10,
        voxel_size=[0.075, 0.075, 0.2],
        max_voxels=(120000, 160000),
        point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]),
    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),
    pts_middle_encoder=dict(
        type='SparseEncoder',
        in_channels=5,
        sparse_shape=[41, 1440, 1440],
        output_channels=128,
        order=('conv', 'norm', 'act'),
        encoder_channels=((16, 16, 32), (32, 32, 64), (64, 64, 128), (128,
                                                                      128)),
        encoder_paddings=((0, 0, 1), (0, 0, 1), (0, 0, [0, 1, 1]), (0, 0)),
        block_type='basicblock'),
    pts_backbone=dict(type='SECONDMamba'),
    pts_neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN2d', eps=0.001, momentum=0.01),
        act_cfg=dict(type='ReLU', inplace=False),
        in_channels=[128, 256],
        out_channels=256,
        start_level=0,
        add_extra_convs=True,
        num_outs=4,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='FUTR3DHead',
        use_dab=True,
        use_dss=True,
        use_hybrid=False,
        hybrid=None,
        dss_batch_first=False,
        dss_drop_prob=0.1,
        dss_mamba_prenorm=False,
        dss_mamba_cfg=dict(),
        dss_mamba_version='DSSMamba_Tiny',
        dss_num_layers=2,
        dss_rope=False,
        dss_morton_rearrange=True,
        dss_conv_path=False,
        dss_xy=True,
        dss_deepseek_format=False,
        use_mss=False,
        anchor_size=3,
        use_aux=True,
        aux_head=dict(
            type='CenterHead',
            in_channels=512,
            tasks=[
                dict(num_class=1, class_names=['car']),
                dict(
                    num_class=2, class_names=['truck',
                                              'construction_vehicle']),
                dict(num_class=2, class_names=['bus', 'trailer']),
                dict(num_class=1, class_names=['barrier']),
                dict(num_class=2, class_names=['motorcycle', 'bicycle']),
                dict(num_class=2, class_names=['pedestrian', 'traffic_cone'])
            ],
            common_heads=dict(
                reg=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
            share_conv_channel=64,
            bbox_coder=dict(
                type='CenterPointBBoxCoder',
                pc_range=[-54, -54],
                post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
                max_num=500,
                score_threshold=0.1,
                out_size_factor=8,
                voxel_size=[0.075, 0.075],
                code_size=9),
            separate_head=dict(
                type='SeparateHead', init_bias=-2.19, final_kernel=3),
            loss_cls=dict(type='GaussianFocalLoss', reduction='mean'),
            loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
            norm_bbox=True),
        mix_selection=False,
        num_query=900,
        num_classes=10,
        in_channels=256,
        pc_range=[-54, -54, -5.0, 54, 54, 3.0],
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        transformer=dict(
            type='FUTR3DTransformer',
            use_dab=True,
            decoder=dict(
                type='FUTR3DTransformerDecoder',
                num_layers=6,
                use_dab=True,
                anchor_size=3,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(type='FUTR3DAttention', embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0)),
    train_cfg=dict(
        pts=dict(
            point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0],
            pc_range=[-54, -54, -5.0, 54, 54, 3.0],
            grid_size=[1440, 1440, 40],
            voxel_size=[0.075, 0.075, 0.2],
            out_size_factor=8,
            dense_reg=1,
            gaussian_overlap=0.1,
            max_objs=500,
            min_radius=2,
            code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0)))),
    test_cfg=dict(
        pts=dict(
            pc_range=[-54, -54],
            post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            max_per_img=500,
            max_pool_nms=False,
            min_radius=[4, 12, 10, 1, 0.85, 0.175],
            out_size_factor=8,
            voxel_size=[0.075, 0.075],
            nms_type='circle',
            pre_max_size=1000,
            post_max_size=83,
            nms_thr=0.2,
            max_num=300,
            score_threshold=0,
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0])))
db_sampler = dict(
    data_root='data/nuscenes/',
    info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
    rate=1.0,
    prepare=dict(
        filter_by_difficulty=[-1],
        filter_by_min_points=dict(
            car=5,
            truck=5,
            bus=5,
            trailer=5,
            construction_vehicle=5,
            traffic_cone=5,
            barrier=5,
            motorcycle=5,
            bicycle=5,
            pedestrian=5)),
    classes=[
        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
    ],
    sample_groups=dict(
        car=2,
        truck=3,
        construction_vehicle=7,
        bus=4,
        trailer=6,
        barrier=2,
        motorcycle=6,
        bicycle=6,
        pedestrian=2,
        traffic_cone=2),
    points_loader=dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4],
        file_client_args=dict(backend='disk')))
find_unused_parameters = True
custom_hooks = [dict(type='FadeOjectSampleHook', num_last_epochs=5)]
gpu_ids = range(0, 2)

2025-04-23 15:36:32,865 - mmdet - INFO - 设置随机种子为 0, deterministic: False
2025-04-23 15:36:33,029 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

pts_middle_encoder.conv_input.0.weight - torch.Size([16, 3, 3, 3, 5]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_input.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_input.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.0.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.conv1.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.conv2.weight - torch.Size([16, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn2.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.1.bn2.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.0.weight - torch.Size([32, 3, 3, 3, 16]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer1.2.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.0.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.conv1.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.conv2.weight - torch.Size([32, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.1.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.0.weight - torch.Size([64, 3, 3, 3, 32]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer2.2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.conv1.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.conv2.weight - torch.Size([64, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.0.weight - torch.Size([128, 3, 3, 3, 64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer3.2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.conv1.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.conv2.weight - torch.Size([128, 3, 3, 3, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.encoder_layers.encoder_layer4.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.0.weight - torch.Size([128, 3, 1, 1, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_middle_encoder.conv_out.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.dt_bias_H - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.dt_bias_V - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.A_log_H - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.A_log_V - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.D_H - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.D_V - torch.Size([4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.in_proj_H.weight - torch.Size([524, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.in_proj_V.weight - torch.Size([524, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.out_proj.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.out_norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.out_norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.conv1d_H.weight - torch.Size([512, 256, 4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.0.conv1d_V.weight - torch.Size([512, 256, 4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.3.depthwise.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.3.pointwise.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.6.depthwise.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.6.pointwise.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.7.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.7.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.9.depthwise.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.9.pointwise.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.10.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.0.10.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.dt_bias_H - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.dt_bias_V - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.A_log_H - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.A_log_V - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.D_H - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.D_V - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.in_proj_H.weight - torch.Size([266, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.in_proj_V.weight - torch.Size([266, 128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.out_proj.weight - torch.Size([256, 512]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.out_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.out_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.conv1d_H.weight - torch.Size([256, 128, 4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.0.conv1d_V.weight - torch.Size([256, 128, 4]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.3.depthwise.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.3.pointwise.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.6.depthwise.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.6.pointwise.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.9.depthwise.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.9.pointwise.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.10.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_backbone.blocks.1.10.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.conv.weight - torch.Size([256, 128, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.1.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.lateral_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.lateral_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

pts_neck.fpn_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_neck.fpn_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.0.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.A_log_f - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.A_log_b - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.D_f - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.D_b - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.A_log_f_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.A_log_b_xy - torch.Size([256, 4]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.D_f_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.D_b_xy - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.in_proj.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.in_proj_xy.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.x_proj_f.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.x_proj_b.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_f.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_f.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_b.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_b.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.x_proj_f_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.x_proj_b_xy.weight - torch.Size([24, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_f_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_f_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_b_xy.weight - torch.Size([256, 16]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.dt_proj_b_xy.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.out_proj.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.global_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.0.layers.1.mamba.global_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.query_scale.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.query_scale.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.weight - torch.Size([256, 384]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.transformer.decoder.ref_point_head.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.0.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.1.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.1.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.2.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.2.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.3.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.3.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.cls_branches.5.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.cls_branches.5.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in FUTR3DHead  

pts_bbox_head.tgt_embed.weight - torch.Size([900, 256]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.refpoint_embed.weight - torch.Size([900, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.conv.weight - torch.Size([64, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.shared_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.0.heatmap.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.1.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.2.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.3.heatmap.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.4.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.reg.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.1.weight - torch.Size([1, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.height.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.1.weight - torch.Size([3, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.dim.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.rot.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.vel.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.1.weight - torch.Size([2, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FUTR3D  

pts_bbox_head.aux_head.task_heads.5.heatmap.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FUTR3D  
2025-04-23 15:36:33,108 - mmdet - INFO - Model:
FUTR3D(
  (pts_voxel_layer): Voxelization(voxel_size=[0.075, 0.075, 0.2], point_cloud_range=[-54, -54, -5.0, 54, 54, 3.0], max_num_points=10, max_voxels=(120000, 160000), deterministic=True)
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseEncoder(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (encoder_layers): SparseSequential(
      (encoder_layer1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer2): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer3): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer4): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (pts_backbone): SECONDMamba(
    (blocks): ModuleList(
      (0): Sequential(
        (0): SECONDMambaBlock(
          (in_proj_H): Linear(in_features=256, out_features=524, bias=False)
          (in_proj_V): Linear(in_features=256, out_features=524, bias=False)
          (act): SiLU()
          (out_proj): Linear(in_features=512, out_features=128, bias=False)
          (out_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (conv1d_H): Conv1d(256, 512, kernel_size=(4,), stride=(4,), bias=False)
          (conv1d_V): Conv1d(256, 512, kernel_size=(4,), stride=(4,), bias=False)
        )
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): SECONDMambaBlock(
          (in_proj_H): Linear(in_features=128, out_features=266, bias=False)
          (in_proj_V): Linear(in_features=128, out_features=266, bias=False)
          (act): SiLU()
          (out_proj): Linear(in_features=512, out_features=256, bias=False)
          (out_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (conv1d_H): Conv1d(128, 256, kernel_size=(4,), stride=(4,), bias=False)
          (conv1d_V): Conv1d(128, 256, kernel_size=(4,), stride=(4,), bias=False)
        )
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
      )
    )
  )
  (pts_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (pts_bbox_head): FUTR3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): FUTR3DTransformer(
      (decoder): FUTR3DTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): DSS(
                (layers): ModuleList(
                  (0): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): Identity()
                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  )
                  (1): ModuleDict(
                    (mamba): DSSMamba(
                      (in_proj): Linear(in_features=256, out_features=1024, bias=False)
                      (in_proj_xy): Linear(in_features=256, out_features=1024, bias=False)
                      (act_f): SiLU()
                      (act_b): SiLU()
                      (x_proj_f): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b): Linear(in_features=16, out_features=256, bias=True)
                      (act_f_xy): SiLU()
                      (act_b_xy): SiLU()
                      (x_proj_f_xy): Linear(in_features=256, out_features=24, bias=False)
                      (x_proj_b_xy): Linear(in_features=256, out_features=24, bias=False)
                      (dt_proj_f_xy): Linear(in_features=16, out_features=256, bias=True)
                      (dt_proj_b_xy): Linear(in_features=16, out_features=256, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=256, bias=False)
                      (global_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (dropout): DropPath(drop_prob=0.100)
                    (norm): Identity()
                  )
                )
              )
              (1): FUTR3DAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (query_scale): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (ref_point_head): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=384, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
    )
    (cls_branches): ModuleList(
      (0): Linear(in_features=256, out_features=10, bias=True)
      (1): Linear(in_features=256, out_features=10, bias=True)
      (2): Linear(in_features=256, out_features=10, bias=True)
      (3): Linear(in_features=256, out_features=10, bias=True)
      (4): Linear(in_features=256, out_features=10, bias=True)
      (5): Linear(in_features=256, out_features=10, bias=True)
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (tgt_embed): Embedding(900, 256)
    (refpoint_embed): Embedding(900, 3)
    (aux_head): CenterHead(
      (loss_cls): GaussianFocalLoss()
      (loss_bbox): L1Loss()
      (shared_conv): ConvModule(
        (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (task_heads): ModuleList(
        (0): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (1): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (2): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (3): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (4): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
        (5): SeparateHead(
          (reg): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
      )
    )
  )
)
2025-04-23 15:36:47,560 - mmdet - INFO - Start running, host: ubuntu@ubuntu, work_dir: /home/ubuntu/jxcao/hdd/jxc/FUTR3D/work_dirs/secondmambadss_split14/second增强版
2025-04-23 15:36:47,560 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) FadeOjectSampleHook                
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-04-23 15:36:47,584 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs
2025-04-23 15:36:47,643 - mmdet - INFO - Checkpoints will be saved to /home/ubuntu/jxcao/hdd/jxc/FUTR3D/work_dirs/secondmambadss_split14/second增强版 by HardDiskBackend.
2025-04-23 15:37:56,326 - mmdet - INFO - Epoch [1][50/1104]	lr: 2.502e-05, eta: 8:23:38, time: 1.372, data_time: 0.099, memory: 15795, loss_cls: 1.3661, loss_bbox: 2.2146, d0.loss_cls: 1.7570, d0.loss_bbox: 4.3994, d1.loss_cls: 1.5686, d1.loss_bbox: 2.2686, d2.loss_cls: 1.4669, d2.loss_bbox: 2.2477, d3.loss_cls: 1.4044, d3.loss_bbox: 2.2363, d4.loss_cls: 1.3751, d4.loss_bbox: 2.2238, aux_task0.loss_heatmap: 287.2101, aux_task0.loss_bbox: 0.9011, aux_task1.loss_heatmap: 734.9537, aux_task1.loss_bbox: 1.0112, aux_task2.loss_heatmap: 967.0743, aux_task2.loss_bbox: 1.1224, aux_task3.loss_heatmap: 756.8091, aux_task3.loss_bbox: 0.7391, aux_task4.loss_heatmap: 511.0143, aux_task4.loss_bbox: 0.7112, aux_task5.loss_heatmap: 639.5180, aux_task5.loss_bbox: 0.7671, loss: 3926.3602, grad_norm: 24409.8960
2025-04-23 15:38:47,101 - mmdet - INFO - Epoch [1][100/1104]	lr: 2.507e-05, eta: 7:17:15, time: 1.015, data_time: 0.007, memory: 15795, loss_cls: 1.1848, loss_bbox: 1.9655, d0.loss_cls: 1.2719, d0.loss_bbox: 4.1146, d1.loss_cls: 1.1941, d1.loss_bbox: 2.1056, d2.loss_cls: 1.1885, d2.loss_bbox: 2.0627, d3.loss_cls: 1.1919, d3.loss_bbox: 2.0307, d4.loss_cls: 1.1886, d4.loss_bbox: 1.9989, aux_task0.loss_heatmap: 271.3645, aux_task0.loss_bbox: 0.8617, aux_task1.loss_heatmap: 639.2280, aux_task1.loss_bbox: 0.9570, aux_task2.loss_heatmap: 864.5790, aux_task2.loss_bbox: 1.0824, aux_task3.loss_heatmap: 608.7707, aux_task3.loss_bbox: 0.7144, aux_task4.loss_heatmap: 470.2343, aux_task4.loss_bbox: 0.7031, aux_task5.loss_heatmap: 595.5279, aux_task5.loss_bbox: 0.7576, loss: 3476.2785, grad_norm: 34666.3814
2025-04-23 15:39:37,723 - mmdet - INFO - Epoch [1][150/1104]	lr: 2.516e-05, eta: 6:54:11, time: 1.012, data_time: 0.008, memory: 15795, loss_cls: 1.1708, loss_bbox: 1.9278, d0.loss_cls: 1.1873, d0.loss_bbox: 2.7523, d1.loss_cls: 1.1834, d1.loss_bbox: 1.8240, d2.loss_cls: 1.1781, d2.loss_bbox: 1.8242, d3.loss_cls: 1.1802, d3.loss_bbox: 1.8511, d4.loss_cls: 1.1741, d4.loss_bbox: 1.8844, aux_task0.loss_heatmap: 213.6193, aux_task0.loss_bbox: 0.8079, aux_task1.loss_heatmap: 503.3390, aux_task1.loss_bbox: 0.9249, aux_task2.loss_heatmap: 635.9103, aux_task2.loss_bbox: 1.0634, aux_task3.loss_heatmap: 470.7908, aux_task3.loss_bbox: 0.7160, aux_task4.loss_heatmap: 379.6748, aux_task4.loss_bbox: 0.6467, aux_task5.loss_heatmap: 433.3298, aux_task5.loss_bbox: 0.6928, loss: 2660.6534, grad_norm: 22664.6918
2025-04-23 15:40:28,205 - mmdet - INFO - Epoch [1][200/1104]	lr: 2.528e-05, eta: 6:41:58, time: 1.010, data_time: 0.008, memory: 16004, loss_cls: 1.1512, loss_bbox: 1.8610, d0.loss_cls: 1.1720, d0.loss_bbox: 1.7951, d1.loss_cls: 1.1684, d1.loss_bbox: 1.7823, d2.loss_cls: 1.1649, d2.loss_bbox: 1.8167, d3.loss_cls: 1.1583, d3.loss_bbox: 1.8408, d4.loss_cls: 1.1518, d4.loss_bbox: 1.8529, aux_task0.loss_heatmap: 49.4944, aux_task0.loss_bbox: 0.6087, aux_task1.loss_heatmap: 128.2868, aux_task1.loss_bbox: 0.6895, aux_task2.loss_heatmap: 131.8289, aux_task2.loss_bbox: 0.8210, aux_task3.loss_heatmap: 81.5118, aux_task3.loss_bbox: 0.5347, aux_task4.loss_heatmap: 98.8883, aux_task4.loss_bbox: 0.5128, aux_task5.loss_heatmap: 125.0325, aux_task5.loss_bbox: 0.5574, loss: 636.6820, grad_norm: 8886.8519
2025-04-23 15:41:18,723 - mmdet - INFO - Epoch [1][250/1104]	lr: 2.544e-05, eta: 6:34:21, time: 1.010, data_time: 0.008, memory: 16004, loss_cls: 1.1117, loss_bbox: 1.7297, d0.loss_cls: 1.1418, d0.loss_bbox: 1.7372, d1.loss_cls: 1.1321, d1.loss_bbox: 1.7332, d2.loss_cls: 1.1261, d2.loss_bbox: 1.7300, d3.loss_cls: 1.1146, d3.loss_bbox: 1.7301, d4.loss_cls: 1.1132, d4.loss_bbox: 1.7261, aux_task0.loss_heatmap: 7.9141, aux_task0.loss_bbox: 0.4755, aux_task1.loss_heatmap: 16.0443, aux_task1.loss_bbox: 0.5385, aux_task2.loss_heatmap: 15.5712, aux_task2.loss_bbox: 0.5788, aux_task3.loss_heatmap: 10.3845, aux_task3.loss_bbox: 0.4398, aux_task4.loss_heatmap: 12.5050, aux_task4.loss_bbox: 0.4538, aux_task5.loss_heatmap: 15.5659, aux_task5.loss_bbox: 0.4880, loss: 98.0852, grad_norm: 771.3672
2025-04-23 15:42:09,292 - mmdet - INFO - Epoch [1][300/1104]	lr: 2.564e-05, eta: 6:29:04, time: 1.011, data_time: 0.008, memory: 16004, loss_cls: 1.0506, loss_bbox: 1.7033, d0.loss_cls: 1.1214, d0.loss_bbox: 1.7326, d1.loss_cls: 1.1110, d1.loss_bbox: 1.7197, d2.loss_cls: 1.0835, d2.loss_bbox: 1.7152, d3.loss_cls: 1.0557, d3.loss_bbox: 1.7065, d4.loss_cls: 1.0512, d4.loss_bbox: 1.7063, aux_task0.loss_heatmap: 2.5785, aux_task0.loss_bbox: 0.4570, aux_task1.loss_heatmap: 4.2282, aux_task1.loss_bbox: 0.5135, aux_task2.loss_heatmap: 4.2892, aux_task2.loss_bbox: 0.5456, aux_task3.loss_heatmap: 3.3586, aux_task3.loss_bbox: 0.4236, aux_task4.loss_heatmap: 3.3989, aux_task4.loss_bbox: 0.4326, aux_task5.loss_heatmap: 3.9279, aux_task5.loss_bbox: 0.4804, loss: 41.3912, grad_norm: 167.1019
2025-04-23 15:42:59,933 - mmdet - INFO - Epoch [1][350/1104]	lr: 2.587e-05, eta: 6:25:07, time: 1.013, data_time: 0.009, memory: 16004, loss_cls: 1.0219, loss_bbox: 1.6784, d0.loss_cls: 1.1179, d0.loss_bbox: 1.7336, d1.loss_cls: 1.0979, d1.loss_bbox: 1.6982, d2.loss_cls: 1.0418, d2.loss_bbox: 1.6883, d3.loss_cls: 1.0169, d3.loss_bbox: 1.6834, d4.loss_cls: 1.0171, d4.loss_bbox: 1.6793, aux_task0.loss_heatmap: 1.6950, aux_task0.loss_bbox: 0.4547, aux_task1.loss_heatmap: 2.1268, aux_task1.loss_bbox: 0.5149, aux_task2.loss_heatmap: 2.2234, aux_task2.loss_bbox: 0.5174, aux_task3.loss_heatmap: 1.8657, aux_task3.loss_bbox: 0.4214, aux_task4.loss_heatmap: 1.8244, aux_task4.loss_bbox: 0.4356, aux_task5.loss_heatmap: 1.9755, aux_task5.loss_bbox: 0.4786, loss: 31.0083, grad_norm: 70.4257
2025-04-23 15:43:50,846 - mmdet - INFO - Epoch [1][400/1104]	lr: 2.613e-05, eta: 6:22:12, time: 1.018, data_time: 0.008, memory: 16004, loss_cls: 1.0066, loss_bbox: 1.6305, d0.loss_cls: 1.0897, d0.loss_bbox: 1.7153, d1.loss_cls: 1.0402, d1.loss_bbox: 1.6585, d2.loss_cls: 1.0061, d2.loss_bbox: 1.6431, d3.loss_cls: 0.9970, d3.loss_bbox: 1.6286, d4.loss_cls: 1.0043, d4.loss_bbox: 1.6256, aux_task0.loss_heatmap: 1.4811, aux_task0.loss_bbox: 0.4498, aux_task1.loss_heatmap: 1.7551, aux_task1.loss_bbox: 0.4869, aux_task2.loss_heatmap: 1.9228, aux_task2.loss_bbox: 0.4895, aux_task3.loss_heatmap: 1.6118, aux_task3.loss_bbox: 0.4177, aux_task4.loss_heatmap: 1.4806, aux_task4.loss_bbox: 0.4266, aux_task5.loss_heatmap: 1.6060, aux_task5.loss_bbox: 0.4680, loss: 28.6415, grad_norm: 62.7737
2025-04-23 15:44:41,703 - mmdet - INFO - Epoch [1][450/1104]	lr: 2.643e-05, eta: 6:19:41, time: 1.017, data_time: 0.008, memory: 16004, loss_cls: 0.9767, loss_bbox: 1.6294, d0.loss_cls: 1.0624, d0.loss_bbox: 1.7253, d1.loss_cls: 0.9941, d1.loss_bbox: 1.6550, d2.loss_cls: 0.9732, d2.loss_bbox: 1.6357, d3.loss_cls: 0.9700, d3.loss_bbox: 1.6299, d4.loss_cls: 0.9748, d4.loss_bbox: 1.6302, aux_task0.loss_heatmap: 1.4238, aux_task0.loss_bbox: 0.4460, aux_task1.loss_heatmap: 1.6213, aux_task1.loss_bbox: 0.4771, aux_task2.loss_heatmap: 1.8105, aux_task2.loss_bbox: 0.4999, aux_task3.loss_heatmap: 1.4294, aux_task3.loss_bbox: 0.4030, aux_task4.loss_heatmap: 1.3229, aux_task4.loss_bbox: 0.4111, aux_task5.loss_heatmap: 1.4138, aux_task5.loss_bbox: 0.4581, loss: 27.5739, grad_norm: 45.9962
2025-04-23 15:45:32,231 - mmdet - INFO - Epoch [1][500/1104]	lr: 2.677e-05, eta: 6:17:16, time: 1.011, data_time: 0.008, memory: 16004, loss_cls: 0.9651, loss_bbox: 1.5735, d0.loss_cls: 1.0471, d0.loss_bbox: 1.6971, d1.loss_cls: 0.9767, d1.loss_bbox: 1.5923, d2.loss_cls: 0.9625, d2.loss_bbox: 1.5782, d3.loss_cls: 0.9614, d3.loss_bbox: 1.5741, d4.loss_cls: 0.9638, d4.loss_bbox: 1.5729, aux_task0.loss_heatmap: 1.3557, aux_task0.loss_bbox: 0.4167, aux_task1.loss_heatmap: 1.5773, aux_task1.loss_bbox: 0.4535, aux_task2.loss_heatmap: 1.7494, aux_task2.loss_bbox: 0.4808, aux_task3.loss_heatmap: 1.4004, aux_task3.loss_bbox: 0.3807, aux_task4.loss_heatmap: 1.1881, aux_task4.loss_bbox: 0.3856, aux_task5.loss_heatmap: 1.3449, aux_task5.loss_bbox: 0.4261, loss: 26.6238, grad_norm: 38.5915
2025-04-23 15:46:22,548 - mmdet - INFO - Epoch [1][550/1104]	lr: 2.714e-05, eta: 6:15:00, time: 1.006, data_time: 0.008, memory: 16004, loss_cls: 0.9450, loss_bbox: 1.5247, d0.loss_cls: 1.0264, d0.loss_bbox: 1.6689, d1.loss_cls: 0.9556, d1.loss_bbox: 1.5438, d2.loss_cls: 0.9441, d2.loss_bbox: 1.5273, d3.loss_cls: 0.9418, d3.loss_bbox: 1.5187, d4.loss_cls: 0.9451, d4.loss_bbox: 1.5182, aux_task0.loss_heatmap: 1.3076, aux_task0.loss_bbox: 0.4008, aux_task1.loss_heatmap: 1.5088, aux_task1.loss_bbox: 0.4383, aux_task2.loss_heatmap: 1.7447, aux_task2.loss_bbox: 0.4829, aux_task3.loss_heatmap: 1.3296, aux_task3.loss_bbox: 0.3696, aux_task4.loss_heatmap: 1.1053, aux_task4.loss_bbox: 0.3803, aux_task5.loss_heatmap: 1.2776, aux_task5.loss_bbox: 0.4045, loss: 25.8096, grad_norm: 37.2909
2025-04-23 15:47:13,263 - mmdet - INFO - Epoch [1][600/1104]	lr: 2.754e-05, eta: 6:13:13, time: 1.014, data_time: 0.008, memory: 16004, loss_cls: 0.9365, loss_bbox: 1.4958, d0.loss_cls: 1.0170, d0.loss_bbox: 1.6492, d1.loss_cls: 0.9464, d1.loss_bbox: 1.5182, d2.loss_cls: 0.9359, d2.loss_bbox: 1.4995, d3.loss_cls: 0.9337, d3.loss_bbox: 1.4859, d4.loss_cls: 0.9346, d4.loss_bbox: 1.4861, aux_task0.loss_heatmap: 1.3038, aux_task0.loss_bbox: 0.4078, aux_task1.loss_heatmap: 1.5221, aux_task1.loss_bbox: 0.4342, aux_task2.loss_heatmap: 1.7348, aux_task2.loss_bbox: 0.4744, aux_task3.loss_heatmap: 1.2976, aux_task3.loss_bbox: 0.3625, aux_task4.loss_heatmap: 1.0536, aux_task4.loss_bbox: 0.3714, aux_task5.loss_heatmap: 1.2310, aux_task5.loss_bbox: 0.4009, loss: 25.4331, grad_norm: 37.3492
2025-04-23 15:48:04,047 - mmdet - INFO - Epoch [1][650/1104]	lr: 2.798e-05, eta: 6:11:37, time: 1.016, data_time: 0.008, memory: 16102, loss_cls: 0.9250, loss_bbox: 1.4560, d0.loss_cls: 1.0088, d0.loss_bbox: 1.6337, d1.loss_cls: 0.9332, d1.loss_bbox: 1.4938, d2.loss_cls: 0.9252, d2.loss_bbox: 1.4699, d3.loss_cls: 0.9216, d3.loss_bbox: 1.4559, d4.loss_cls: 0.9232, d4.loss_bbox: 1.4527, aux_task0.loss_heatmap: 1.2614, aux_task0.loss_bbox: 0.3904, aux_task1.loss_heatmap: 1.4597, aux_task1.loss_bbox: 0.4291, aux_task2.loss_heatmap: 1.7179, aux_task2.loss_bbox: 0.4782, aux_task3.loss_heatmap: 1.3195, aux_task3.loss_bbox: 0.3653, aux_task4.loss_heatmap: 1.0626, aux_task4.loss_bbox: 0.3728, aux_task5.loss_heatmap: 1.1755, aux_task5.loss_bbox: 0.3862, loss: 25.0175, grad_norm: 34.7327
2025-04-23 15:48:54,777 - mmdet - INFO - Epoch [1][700/1104]	lr: 2.846e-05, eta: 6:10:05, time: 1.015, data_time: 0.008, memory: 16102, loss_cls: 0.9174, loss_bbox: 1.4287, d0.loss_cls: 1.0003, d0.loss_bbox: 1.6168, d1.loss_cls: 0.9287, d1.loss_bbox: 1.4696, d2.loss_cls: 0.9198, d2.loss_bbox: 1.4419, d3.loss_cls: 0.9165, d3.loss_bbox: 1.4260, d4.loss_cls: 0.9167, d4.loss_bbox: 1.4232, aux_task0.loss_heatmap: 1.2477, aux_task0.loss_bbox: 0.3903, aux_task1.loss_heatmap: 1.4582, aux_task1.loss_bbox: 0.4229, aux_task2.loss_heatmap: 1.7132, aux_task2.loss_bbox: 0.4698, aux_task3.loss_heatmap: 1.2261, aux_task3.loss_bbox: 0.3565, aux_task4.loss_heatmap: 0.9915, aux_task4.loss_bbox: 0.3658, aux_task5.loss_heatmap: 1.1711, aux_task5.loss_bbox: 0.3876, loss: 24.6063, grad_norm: 35.7315
2025-04-23 15:49:45,558 - mmdet - INFO - Epoch [1][750/1104]	lr: 2.897e-05, eta: 6:08:40, time: 1.016, data_time: 0.008, memory: 16102, loss_cls: 0.9106, loss_bbox: 1.3908, d0.loss_cls: 0.9900, d0.loss_bbox: 1.6019, d1.loss_cls: 0.9191, d1.loss_bbox: 1.4441, d2.loss_cls: 0.9113, d2.loss_bbox: 1.4126, d3.loss_cls: 0.9070, d3.loss_bbox: 1.3963, d4.loss_cls: 0.9082, d4.loss_bbox: 1.3904, aux_task0.loss_heatmap: 1.2309, aux_task0.loss_bbox: 0.3845, aux_task1.loss_heatmap: 1.4529, aux_task1.loss_bbox: 0.4222, aux_task2.loss_heatmap: 1.7073, aux_task2.loss_bbox: 0.4597, aux_task3.loss_heatmap: 1.2177, aux_task3.loss_bbox: 0.3488, aux_task4.loss_heatmap: 0.9859, aux_task4.loss_bbox: 0.3659, aux_task5.loss_heatmap: 1.1427, aux_task5.loss_bbox: 0.3793, loss: 24.2803, grad_norm: 34.3184
2025-04-23 15:50:35,924 - mmdet - INFO - Epoch [1][800/1104]	lr: 2.951e-05, eta: 6:07:09, time: 1.007, data_time: 0.008, memory: 16102, loss_cls: 0.9075, loss_bbox: 1.3598, d0.loss_cls: 0.9903, d0.loss_bbox: 1.5898, d1.loss_cls: 0.9192, d1.loss_bbox: 1.4277, d2.loss_cls: 0.9082, d2.loss_bbox: 1.3868, d3.loss_cls: 0.9039, d3.loss_bbox: 1.3680, d4.loss_cls: 0.9029, d4.loss_bbox: 1.3620, aux_task0.loss_heatmap: 1.1870, aux_task0.loss_bbox: 0.3777, aux_task1.loss_heatmap: 1.4446, aux_task1.loss_bbox: 0.4191, aux_task2.loss_heatmap: 1.6986, aux_task2.loss_bbox: 0.4597, aux_task3.loss_heatmap: 1.2651, aux_task3.loss_bbox: 0.3538, aux_task4.loss_heatmap: 0.9632, aux_task4.loss_bbox: 0.3558, aux_task5.loss_heatmap: 1.1324, aux_task5.loss_bbox: 0.3742, loss: 24.0572, grad_norm: 32.8815
2025-04-23 15:51:26,524 - mmdet - INFO - Epoch [1][850/1104]	lr: 3.009e-05, eta: 6:05:48, time: 1.012, data_time: 0.008, memory: 16102, loss_cls: 0.9022, loss_bbox: 1.3445, d0.loss_cls: 0.9841, d0.loss_bbox: 1.5910, d1.loss_cls: 0.9144, d1.loss_bbox: 1.4145, d2.loss_cls: 0.9016, d2.loss_bbox: 1.3722, d3.loss_cls: 0.8983, d3.loss_bbox: 1.3524, d4.loss_cls: 0.8967, d4.loss_bbox: 1.3456, aux_task0.loss_heatmap: 1.1890, aux_task0.loss_bbox: 0.3763, aux_task1.loss_heatmap: 1.4142, aux_task1.loss_bbox: 0.4179, aux_task2.loss_heatmap: 1.6841, aux_task2.loss_bbox: 0.4645, aux_task3.loss_heatmap: 1.2377, aux_task3.loss_bbox: 0.3459, aux_task4.loss_heatmap: 0.9486, aux_task4.loss_bbox: 0.3549, aux_task5.loss_heatmap: 1.1176, aux_task5.loss_bbox: 0.3722, loss: 23.8403, grad_norm: 33.2541
2025-04-23 15:52:17,400 - mmdet - INFO - Epoch [1][900/1104]	lr: 3.070e-05, eta: 6:04:37, time: 1.017, data_time: 0.008, memory: 16102, loss_cls: 0.8878, loss_bbox: 1.3229, d0.loss_cls: 0.9714, d0.loss_bbox: 1.5801, d1.loss_cls: 0.9024, d1.loss_bbox: 1.3925, d2.loss_cls: 0.8877, d2.loss_bbox: 1.3504, d3.loss_cls: 0.8840, d3.loss_bbox: 1.3314, d4.loss_cls: 0.8833, d4.loss_bbox: 1.3241, aux_task0.loss_heatmap: 1.1635, aux_task0.loss_bbox: 0.3691, aux_task1.loss_heatmap: 1.4044, aux_task1.loss_bbox: 0.4114, aux_task2.loss_heatmap: 1.6606, aux_task2.loss_bbox: 0.4644, aux_task3.loss_heatmap: 1.1936, aux_task3.loss_bbox: 0.3463, aux_task4.loss_heatmap: 0.9289, aux_task4.loss_bbox: 0.3492, aux_task5.loss_heatmap: 1.0850, aux_task5.loss_bbox: 0.3754, loss: 23.4696, grad_norm: 34.0470
2025-04-23 15:53:08,190 - mmdet - INFO - Epoch [1][950/1104]	lr: 3.135e-05, eta: 6:03:27, time: 1.016, data_time: 0.009, memory: 16102, loss_cls: 0.8775, loss_bbox: 1.3041, d0.loss_cls: 0.9610, d0.loss_bbox: 1.5800, d1.loss_cls: 0.8950, d1.loss_bbox: 1.3792, d2.loss_cls: 0.8809, d2.loss_bbox: 1.3336, d3.loss_cls: 0.8750, d3.loss_bbox: 1.3134, d4.loss_cls: 0.8742, d4.loss_bbox: 1.3050, aux_task0.loss_heatmap: 1.1705, aux_task0.loss_bbox: 0.3806, aux_task1.loss_heatmap: 1.4035, aux_task1.loss_bbox: 0.4105, aux_task2.loss_heatmap: 1.6630, aux_task2.loss_bbox: 0.4504, aux_task3.loss_heatmap: 1.1527, aux_task3.loss_bbox: 0.3430, aux_task4.loss_heatmap: 0.9113, aux_task4.loss_bbox: 0.3546, aux_task5.loss_heatmap: 1.0494, aux_task5.loss_bbox: 0.3634, loss: 23.2317, grad_norm: 30.2360
2025-04-23 15:53:58,993 - mmdet - INFO - Exp name: secondmambadss_split14.py
2025-04-23 15:53:58,994 - mmdet - INFO - Epoch [1][1000/1104]	lr: 3.203e-05, eta: 6:02:18, time: 1.016, data_time: 0.009, memory: 16102, loss_cls: 0.8754, loss_bbox: 1.2699, d0.loss_cls: 0.9600, d0.loss_bbox: 1.5723, d1.loss_cls: 0.8931, d1.loss_bbox: 1.3590, d2.loss_cls: 0.8785, d2.loss_bbox: 1.3070, d3.loss_cls: 0.8728, d3.loss_bbox: 1.2842, d4.loss_cls: 0.8730, d4.loss_bbox: 1.2723, aux_task0.loss_heatmap: 1.1761, aux_task0.loss_bbox: 0.3770, aux_task1.loss_heatmap: 1.3989, aux_task1.loss_bbox: 0.4130, aux_task2.loss_heatmap: 1.6619, aux_task2.loss_bbox: 0.4553, aux_task3.loss_heatmap: 1.1868, aux_task3.loss_bbox: 0.3453, aux_task4.loss_heatmap: 0.8943, aux_task4.loss_bbox: 0.3529, aux_task5.loss_heatmap: 1.0546, aux_task5.loss_bbox: 0.3627, loss: 23.0962, grad_norm: 32.9000
2025-04-23 15:54:49,439 - mmdet - INFO - Epoch [1][1050/1104]	lr: 3.274e-05, eta: 6:01:04, time: 1.009, data_time: 0.008, memory: 16102, loss_cls: 0.8706, loss_bbox: 1.2689, d0.loss_cls: 0.9587, d0.loss_bbox: 1.5631, d1.loss_cls: 0.8888, d1.loss_bbox: 1.3506, d2.loss_cls: 0.8706, d2.loss_bbox: 1.3021, d3.loss_cls: 0.8672, d3.loss_bbox: 1.2811, d4.loss_cls: 0.8696, d4.loss_bbox: 1.2703, aux_task0.loss_heatmap: 1.1486, aux_task0.loss_bbox: 0.3711, aux_task1.loss_heatmap: 1.3944, aux_task1.loss_bbox: 0.4157, aux_task2.loss_heatmap: 1.6390, aux_task2.loss_bbox: 0.4509, aux_task3.loss_heatmap: 1.1670, aux_task3.loss_bbox: 0.3433, aux_task4.loss_heatmap: 0.9126, aux_task4.loss_bbox: 0.3541, aux_task5.loss_heatmap: 1.0388, aux_task5.loss_bbox: 0.3625, loss: 22.9596, grad_norm: 34.0789
2025-04-23 15:55:40,551 - mmdet - INFO - Epoch [1][1100/1104]	lr: 3.349e-05, eta: 6:00:05, time: 1.022, data_time: 0.008, memory: 16102, loss_cls: 0.8553, loss_bbox: 1.2559, d0.loss_cls: 0.9410, d0.loss_bbox: 1.5670, d1.loss_cls: 0.8746, d1.loss_bbox: 1.3397, d2.loss_cls: 0.8569, d2.loss_bbox: 1.2855, d3.loss_cls: 0.8523, d3.loss_bbox: 1.2639, d4.loss_cls: 0.8533, d4.loss_bbox: 1.2559, aux_task0.loss_heatmap: 1.1235, aux_task0.loss_bbox: 0.3705, aux_task1.loss_heatmap: 1.3875, aux_task1.loss_bbox: 0.4124, aux_task2.loss_heatmap: 1.6402, aux_task2.loss_bbox: 0.4604, aux_task3.loss_heatmap: 1.1355, aux_task3.loss_bbox: 0.3359, aux_task4.loss_heatmap: 0.8991, aux_task4.loss_bbox: 0.3598, aux_task5.loss_heatmap: 1.0307, aux_task5.loss_bbox: 0.3597, loss: 22.7166, grad_norm: 34.1662
2025-04-23 15:55:44,901 - mmdet - INFO - Saving checkpoint at 1 epochs
2025-04-23 16:08:20,575 - mmdet - INFO - Exp name: secondmambadss_split14.py
2025-04-23 16:08:20,575 - mmdet - INFO - Epoch(val) [1][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/car_AP_dist_1.0: 0.0116, pts_bbox_NuScenes/car_AP_dist_2.0: 0.0676, pts_bbox_NuScenes/car_AP_dist_4.0: 0.1362, pts_bbox_NuScenes/car_trans_err: 0.9250, pts_bbox_NuScenes/car_scale_err: 0.2334, pts_bbox_NuScenes/car_orient_err: 1.6684, pts_bbox_NuScenes/car_vel_err: 1.8568, pts_bbox_NuScenes/car_attr_err: 0.4943, pts_bbox_NuScenes/mATE: 0.9005, pts_bbox_NuScenes/mASE: 0.7793, pts_bbox_NuScenes/mAOE: 1.1637, pts_bbox_NuScenes/mAVE: 1.1764, pts_bbox_NuScenes/mAAE: 0.8054, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/truck_trans_err: 1.0000, pts_bbox_NuScenes/truck_scale_err: 1.0000, pts_bbox_NuScenes/truck_orient_err: 1.0000, pts_bbox_NuScenes/truck_vel_err: 1.0000, pts_bbox_NuScenes/truck_attr_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_trans_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_scale_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_vel_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_attr_err: 1.0000, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bus_trans_err: 1.0000, pts_bbox_NuScenes/bus_scale_err: 1.0000, pts_bbox_NuScenes/bus_orient_err: 1.0000, pts_bbox_NuScenes/bus_vel_err: 1.0000, pts_bbox_NuScenes/bus_attr_err: 1.0000, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/trailer_trans_err: 1.0000, pts_bbox_NuScenes/trailer_scale_err: 1.0000, pts_bbox_NuScenes/trailer_orient_err: 1.0000, pts_bbox_NuScenes/trailer_vel_err: 1.0000, pts_bbox_NuScenes/trailer_attr_err: 1.0000, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.0013, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.0076, pts_bbox_NuScenes/barrier_trans_err: 0.9379, pts_bbox_NuScenes/barrier_scale_err: 0.7869, pts_bbox_NuScenes/barrier_orient_err: 0.9368, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/motorcycle_trans_err: 0.4977, pts_bbox_NuScenes/motorcycle_scale_err: 0.5440, pts_bbox_NuScenes/motorcycle_orient_err: 1.3695, pts_bbox_NuScenes/motorcycle_vel_err: 1.5102, pts_bbox_NuScenes/motorcycle_attr_err: 0.6582, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 0.8500, pts_bbox_NuScenes/bicycle_scale_err: 0.5849, pts_bbox_NuScenes/bicycle_orient_err: 1.4987, pts_bbox_NuScenes/bicycle_vel_err: 1.0441, pts_bbox_NuScenes/bicycle_attr_err: 0.2911, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/pedestrian_trans_err: 1.0000, pts_bbox_NuScenes/pedestrian_scale_err: 1.0000, pts_bbox_NuScenes/pedestrian_orient_err: 1.0000, pts_bbox_NuScenes/pedestrian_vel_err: 1.0000, pts_bbox_NuScenes/pedestrian_attr_err: 1.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/traffic_cone_trans_err: 0.7948, pts_bbox_NuScenes/traffic_cone_scale_err: 0.6439, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.0543, pts_bbox_NuScenes/mAP: 0.0056
2025-04-23 16:09:16,494 - mmdet - INFO - Epoch [2][50/1104]	lr: 3.433e-05, eta: 5:59:01, time: 1.103, data_time: 0.101, memory: 16102, loss_cls: 0.8462, loss_bbox: 1.2302, d0.loss_cls: 0.9349, d0.loss_bbox: 1.5405, d1.loss_cls: 0.8636, d1.loss_bbox: 1.3151, d2.loss_cls: 0.8500, d2.loss_bbox: 1.2593, d3.loss_cls: 0.8459, d3.loss_bbox: 1.2390, d4.loss_cls: 0.8460, d4.loss_bbox: 1.2305, aux_task0.loss_heatmap: 1.0931, aux_task0.loss_bbox: 0.3632, aux_task1.loss_heatmap: 1.3628, aux_task1.loss_bbox: 0.4075, aux_task2.loss_heatmap: 1.6289, aux_task2.loss_bbox: 0.4573, aux_task3.loss_heatmap: 1.1197, aux_task3.loss_bbox: 0.3381, aux_task4.loss_heatmap: 0.8834, aux_task4.loss_bbox: 0.3517, aux_task5.loss_heatmap: 1.0123, aux_task5.loss_bbox: 0.3571, loss: 22.3764, grad_norm: 32.5769
2025-04-23 16:10:07,011 - mmdet - INFO - Epoch [2][100/1104]	lr: 3.514e-05, eta: 5:57:53, time: 1.010, data_time: 0.008, memory: 16102, loss_cls: 0.8457, loss_bbox: 1.2254, d0.loss_cls: 0.9278, d0.loss_bbox: 1.5258, d1.loss_cls: 0.8636, d1.loss_bbox: 1.3059, d2.loss_cls: 0.8478, d2.loss_bbox: 1.2499, d3.loss_cls: 0.8446, d3.loss_bbox: 1.2281, d4.loss_cls: 0.8460, d4.loss_bbox: 1.2213, aux_task0.loss_heatmap: 1.1108, aux_task0.loss_bbox: 0.3592, aux_task1.loss_heatmap: 1.3795, aux_task1.loss_bbox: 0.4039, aux_task2.loss_heatmap: 1.6316, aux_task2.loss_bbox: 0.4417, aux_task3.loss_heatmap: 1.1506, aux_task3.loss_bbox: 0.3364, aux_task4.loss_heatmap: 0.8641, aux_task4.loss_bbox: 0.3525, aux_task5.loss_heatmap: 0.9939, aux_task5.loss_bbox: 0.3542, loss: 22.3101, grad_norm: 33.5023
2025-04-23 16:10:58,029 - mmdet - INFO - Epoch [2][150/1104]	lr: 3.599e-05, eta: 5:56:54, time: 1.020, data_time: 0.008, memory: 16167, loss_cls: 0.8455, loss_bbox: 1.2221, d0.loss_cls: 0.9259, d0.loss_bbox: 1.5339, d1.loss_cls: 0.8607, d1.loss_bbox: 1.3064, d2.loss_cls: 0.8465, d2.loss_bbox: 1.2510, d3.loss_cls: 0.8428, d3.loss_bbox: 1.2298, d4.loss_cls: 0.8425, d4.loss_bbox: 1.2227, aux_task0.loss_heatmap: 1.1272, aux_task0.loss_bbox: 0.3730, aux_task1.loss_heatmap: 1.3439, aux_task1.loss_bbox: 0.4031, aux_task2.loss_heatmap: 1.6071, aux_task2.loss_bbox: 0.4447, aux_task3.loss_heatmap: 1.1044, aux_task3.loss_bbox: 0.3430, aux_task4.loss_heatmap: 0.8491, aux_task4.loss_bbox: 0.3491, aux_task5.loss_heatmap: 0.9801, aux_task5.loss_bbox: 0.3557, loss: 22.2102, grad_norm: 34.8440
2025-04-23 16:11:48,558 - mmdet - INFO - Epoch [2][200/1104]	lr: 3.687e-05, eta: 5:55:49, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.8378, loss_bbox: 1.2084, d0.loss_cls: 0.9199, d0.loss_bbox: 1.5169, d1.loss_cls: 0.8565, d1.loss_bbox: 1.2937, d2.loss_cls: 0.8409, d2.loss_bbox: 1.2359, d3.loss_cls: 0.8359, d3.loss_bbox: 1.2172, d4.loss_cls: 0.8362, d4.loss_bbox: 1.2086, aux_task0.loss_heatmap: 1.1035, aux_task0.loss_bbox: 0.3612, aux_task1.loss_heatmap: 1.3403, aux_task1.loss_bbox: 0.4063, aux_task2.loss_heatmap: 1.6061, aux_task2.loss_bbox: 0.4415, aux_task3.loss_heatmap: 1.0963, aux_task3.loss_bbox: 0.3350, aux_task4.loss_heatmap: 0.8452, aux_task4.loss_bbox: 0.3498, aux_task5.loss_heatmap: 1.0027, aux_task5.loss_bbox: 0.3599, loss: 22.0558, grad_norm: 35.0436
2025-04-23 16:12:39,094 - mmdet - INFO - Epoch [2][250/1104]	lr: 3.778e-05, eta: 5:54:45, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.8263, loss_bbox: 1.1872, d0.loss_cls: 0.9056, d0.loss_bbox: 1.4956, d1.loss_cls: 0.8431, d1.loss_bbox: 1.2697, d2.loss_cls: 0.8309, d2.loss_bbox: 1.2154, d3.loss_cls: 0.8228, d3.loss_bbox: 1.1968, d4.loss_cls: 0.8241, d4.loss_bbox: 1.1886, aux_task0.loss_heatmap: 1.0824, aux_task0.loss_bbox: 0.3535, aux_task1.loss_heatmap: 1.3222, aux_task1.loss_bbox: 0.4040, aux_task2.loss_heatmap: 1.5895, aux_task2.loss_bbox: 0.4359, aux_task3.loss_heatmap: 1.0731, aux_task3.loss_bbox: 0.3314, aux_task4.loss_heatmap: 0.8490, aux_task4.loss_bbox: 0.3491, aux_task5.loss_heatmap: 0.9645, aux_task5.loss_bbox: 0.3499, loss: 21.7106, grad_norm: 36.4795
2025-04-23 16:13:29,923 - mmdet - INFO - Epoch [2][300/1104]	lr: 3.872e-05, eta: 5:53:46, time: 1.017, data_time: 0.008, memory: 16167, loss_cls: 0.8278, loss_bbox: 1.1975, d0.loss_cls: 0.9057, d0.loss_bbox: 1.4968, d1.loss_cls: 0.8450, d1.loss_bbox: 1.2795, d2.loss_cls: 0.8338, d2.loss_bbox: 1.2243, d3.loss_cls: 0.8265, d3.loss_bbox: 1.2054, d4.loss_cls: 0.8259, d4.loss_bbox: 1.1995, aux_task0.loss_heatmap: 1.0689, aux_task0.loss_bbox: 0.3638, aux_task1.loss_heatmap: 1.3421, aux_task1.loss_bbox: 0.4014, aux_task2.loss_heatmap: 1.5902, aux_task2.loss_bbox: 0.4542, aux_task3.loss_heatmap: 1.1133, aux_task3.loss_bbox: 0.3375, aux_task4.loss_heatmap: 0.8487, aux_task4.loss_bbox: 0.3383, aux_task5.loss_heatmap: 0.9477, aux_task5.loss_bbox: 0.3514, loss: 21.8253, grad_norm: 35.5391
2025-04-23 16:14:20,469 - mmdet - INFO - Epoch [2][350/1104]	lr: 3.969e-05, eta: 5:52:43, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.8241, loss_bbox: 1.1858, d0.loss_cls: 0.9016, d0.loss_bbox: 1.4697, d1.loss_cls: 0.8406, d1.loss_bbox: 1.2607, d2.loss_cls: 0.8292, d2.loss_bbox: 1.2071, d3.loss_cls: 0.8223, d3.loss_bbox: 1.1886, d4.loss_cls: 0.8231, d4.loss_bbox: 1.1831, aux_task0.loss_heatmap: 1.0718, aux_task0.loss_bbox: 0.3548, aux_task1.loss_heatmap: 1.3353, aux_task1.loss_bbox: 0.4040, aux_task2.loss_heatmap: 1.5747, aux_task2.loss_bbox: 0.4396, aux_task3.loss_heatmap: 1.1039, aux_task3.loss_bbox: 0.3406, aux_task4.loss_heatmap: 0.8475, aux_task4.loss_bbox: 0.3485, aux_task5.loss_heatmap: 0.9489, aux_task5.loss_bbox: 0.3480, loss: 21.6532, grad_norm: 33.7888
2025-04-23 16:15:11,179 - mmdet - INFO - Epoch [2][400/1104]	lr: 4.070e-05, eta: 5:51:44, time: 1.014, data_time: 0.008, memory: 16167, loss_cls: 0.8067, loss_bbox: 1.1632, d0.loss_cls: 0.8850, d0.loss_bbox: 1.4547, d1.loss_cls: 0.8257, d1.loss_bbox: 1.2446, d2.loss_cls: 0.8166, d2.loss_bbox: 1.1879, d3.loss_cls: 0.8078, d3.loss_bbox: 1.1705, d4.loss_cls: 0.8058, d4.loss_bbox: 1.1645, aux_task0.loss_heatmap: 1.0480, aux_task0.loss_bbox: 0.3539, aux_task1.loss_heatmap: 1.3097, aux_task1.loss_bbox: 0.3966, aux_task2.loss_heatmap: 1.5853, aux_task2.loss_bbox: 0.4363, aux_task3.loss_heatmap: 1.0652, aux_task3.loss_bbox: 0.3393, aux_task4.loss_heatmap: 0.8222, aux_task4.loss_bbox: 0.3481, aux_task5.loss_heatmap: 0.9275, aux_task5.loss_bbox: 0.3526, loss: 21.3178, grad_norm: 34.9116
2025-04-23 16:16:01,834 - mmdet - INFO - Epoch [2][450/1104]	lr: 4.173e-05, eta: 5:50:44, time: 1.013, data_time: 0.008, memory: 16167, loss_cls: 0.8027, loss_bbox: 1.1583, d0.loss_cls: 0.8791, d0.loss_bbox: 1.4364, d1.loss_cls: 0.8227, d1.loss_bbox: 1.2358, d2.loss_cls: 0.8089, d2.loss_bbox: 1.1846, d3.loss_cls: 0.8023, d3.loss_bbox: 1.1651, d4.loss_cls: 0.8013, d4.loss_bbox: 1.1596, aux_task0.loss_heatmap: 1.0619, aux_task0.loss_bbox: 0.3488, aux_task1.loss_heatmap: 1.3094, aux_task1.loss_bbox: 0.3981, aux_task2.loss_heatmap: 1.5596, aux_task2.loss_bbox: 0.4426, aux_task3.loss_heatmap: 1.0651, aux_task3.loss_bbox: 0.3367, aux_task4.loss_heatmap: 0.8490, aux_task4.loss_bbox: 0.3469, aux_task5.loss_heatmap: 0.9123, aux_task5.loss_bbox: 0.3506, loss: 21.2377, grad_norm: 36.7295
2025-04-23 16:16:52,340 - mmdet - INFO - Epoch [2][500/1104]	lr: 4.280e-05, eta: 5:49:43, time: 1.010, data_time: 0.008, memory: 16167, loss_cls: 0.7899, loss_bbox: 1.1491, d0.loss_cls: 0.8679, d0.loss_bbox: 1.3991, d1.loss_cls: 0.8100, d1.loss_bbox: 1.2256, d2.loss_cls: 0.7953, d2.loss_bbox: 1.1735, d3.loss_cls: 0.7883, d3.loss_bbox: 1.1558, d4.loss_cls: 0.7888, d4.loss_bbox: 1.1499, aux_task0.loss_heatmap: 1.0435, aux_task0.loss_bbox: 0.3534, aux_task1.loss_heatmap: 1.3242, aux_task1.loss_bbox: 0.3936, aux_task2.loss_heatmap: 1.5270, aux_task2.loss_bbox: 0.4354, aux_task3.loss_heatmap: 1.1301, aux_task3.loss_bbox: 0.3372, aux_task4.loss_heatmap: 0.8166, aux_task4.loss_bbox: 0.3399, aux_task5.loss_heatmap: 0.8974, aux_task5.loss_bbox: 0.3460, loss: 21.0375, grad_norm: 38.1585
2025-04-23 16:17:42,898 - mmdet - INFO - Epoch [2][550/1104]	lr: 4.389e-05, eta: 5:48:44, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.7985, loss_bbox: 1.1523, d0.loss_cls: 0.8681, d0.loss_bbox: 1.3915, d1.loss_cls: 0.8187, d1.loss_bbox: 1.2304, d2.loss_cls: 0.8059, d2.loss_bbox: 1.1804, d3.loss_cls: 0.7987, d3.loss_bbox: 1.1619, d4.loss_cls: 0.7969, d4.loss_bbox: 1.1546, aux_task0.loss_heatmap: 1.0468, aux_task0.loss_bbox: 0.3546, aux_task1.loss_heatmap: 1.2750, aux_task1.loss_bbox: 0.3947, aux_task2.loss_heatmap: 1.5544, aux_task2.loss_bbox: 0.4433, aux_task3.loss_heatmap: 1.0437, aux_task3.loss_bbox: 0.3289, aux_task4.loss_heatmap: 0.8085, aux_task4.loss_bbox: 0.3471, aux_task5.loss_heatmap: 0.9144, aux_task5.loss_bbox: 0.3488, loss: 21.0182, grad_norm: 37.2458
2025-04-23 16:18:33,871 - mmdet - INFO - Epoch [2][600/1104]	lr: 4.502e-05, eta: 5:47:49, time: 1.019, data_time: 0.010, memory: 16167, loss_cls: 0.7842, loss_bbox: 1.1381, d0.loss_cls: 0.8543, d0.loss_bbox: 1.3751, d1.loss_cls: 0.8019, d1.loss_bbox: 1.2145, d2.loss_cls: 0.7904, d2.loss_bbox: 1.1628, d3.loss_cls: 0.7818, d3.loss_bbox: 1.1441, d4.loss_cls: 0.7827, d4.loss_bbox: 1.1383, aux_task0.loss_heatmap: 1.0199, aux_task0.loss_bbox: 0.3473, aux_task1.loss_heatmap: 1.3056, aux_task1.loss_bbox: 0.3948, aux_task2.loss_heatmap: 1.5362, aux_task2.loss_bbox: 0.4428, aux_task3.loss_heatmap: 1.0828, aux_task3.loss_bbox: 0.3318, aux_task4.loss_heatmap: 0.7887, aux_task4.loss_bbox: 0.3427, aux_task5.loss_heatmap: 0.8883, aux_task5.loss_bbox: 0.3473, loss: 20.7965, grad_norm: 34.7664
2025-04-23 16:19:24,900 - mmdet - INFO - Epoch [2][650/1104]	lr: 4.617e-05, eta: 5:46:56, time: 1.021, data_time: 0.008, memory: 16167, loss_cls: 0.7784, loss_bbox: 1.1292, d0.loss_cls: 0.8446, d0.loss_bbox: 1.3560, d1.loss_cls: 0.7974, d1.loss_bbox: 1.2030, d2.loss_cls: 0.7862, d2.loss_bbox: 1.1529, d3.loss_cls: 0.7770, d3.loss_bbox: 1.1348, d4.loss_cls: 0.7777, d4.loss_bbox: 1.1289, aux_task0.loss_heatmap: 1.0038, aux_task0.loss_bbox: 0.3413, aux_task1.loss_heatmap: 1.2437, aux_task1.loss_bbox: 0.3909, aux_task2.loss_heatmap: 1.5485, aux_task2.loss_bbox: 0.4393, aux_task3.loss_heatmap: 1.0928, aux_task3.loss_bbox: 0.3343, aux_task4.loss_heatmap: 0.8259, aux_task4.loss_bbox: 0.3408, aux_task5.loss_heatmap: 0.8610, aux_task5.loss_bbox: 0.3401, loss: 20.6286, grad_norm: 34.0226
2025-04-23 16:20:15,794 - mmdet - INFO - Epoch [2][700/1104]	lr: 4.735e-05, eta: 5:46:01, time: 1.018, data_time: 0.009, memory: 16167, loss_cls: 0.7710, loss_bbox: 1.1202, d0.loss_cls: 0.8407, d0.loss_bbox: 1.3490, d1.loss_cls: 0.7924, d1.loss_bbox: 1.1961, d2.loss_cls: 0.7808, d2.loss_bbox: 1.1464, d3.loss_cls: 0.7703, d3.loss_bbox: 1.1291, d4.loss_cls: 0.7705, d4.loss_bbox: 1.1234, aux_task0.loss_heatmap: 1.0350, aux_task0.loss_bbox: 0.3451, aux_task1.loss_heatmap: 1.2601, aux_task1.loss_bbox: 0.3947, aux_task2.loss_heatmap: 1.5289, aux_task2.loss_bbox: 0.4404, aux_task3.loss_heatmap: 1.0339, aux_task3.loss_bbox: 0.3321, aux_task4.loss_heatmap: 0.7886, aux_task4.loss_bbox: 0.3422, aux_task5.loss_heatmap: 0.8476, aux_task5.loss_bbox: 0.3367, loss: 20.4751, grad_norm: 35.2759
2025-04-23 16:21:06,473 - mmdet - INFO - Epoch [2][750/1104]	lr: 4.857e-05, eta: 5:45:04, time: 1.014, data_time: 0.010, memory: 16167, loss_cls: 0.7673, loss_bbox: 1.1120, d0.loss_cls: 0.8374, d0.loss_bbox: 1.3306, d1.loss_cls: 0.7879, d1.loss_bbox: 1.1873, d2.loss_cls: 0.7762, d2.loss_bbox: 1.1411, d3.loss_cls: 0.7678, d3.loss_bbox: 1.1212, d4.loss_cls: 0.7661, d4.loss_bbox: 1.1160, aux_task0.loss_heatmap: 1.0079, aux_task0.loss_bbox: 0.3484, aux_task1.loss_heatmap: 1.2699, aux_task1.loss_bbox: 0.3949, aux_task2.loss_heatmap: 1.5149, aux_task2.loss_bbox: 0.4382, aux_task3.loss_heatmap: 1.0551, aux_task3.loss_bbox: 0.3277, aux_task4.loss_heatmap: 0.7866, aux_task4.loss_bbox: 0.3421, aux_task5.loss_heatmap: 0.8476, aux_task5.loss_bbox: 0.3377, loss: 20.3819, grad_norm: 35.6823
2025-04-23 16:21:57,030 - mmdet - INFO - Epoch [2][800/1104]	lr: 4.980e-05, eta: 5:44:07, time: 1.011, data_time: 0.009, memory: 16167, loss_cls: 0.7588, loss_bbox: 1.1036, d0.loss_cls: 0.8281, d0.loss_bbox: 1.3272, d1.loss_cls: 0.7822, d1.loss_bbox: 1.1812, d2.loss_cls: 0.7710, d2.loss_bbox: 1.1360, d3.loss_cls: 0.7601, d3.loss_bbox: 1.1167, d4.loss_cls: 0.7594, d4.loss_bbox: 1.1110, aux_task0.loss_heatmap: 0.9946, aux_task0.loss_bbox: 0.3427, aux_task1.loss_heatmap: 1.2564, aux_task1.loss_bbox: 0.3900, aux_task2.loss_heatmap: 1.5067, aux_task2.loss_bbox: 0.4289, aux_task3.loss_heatmap: 1.0460, aux_task3.loss_bbox: 0.3301, aux_task4.loss_heatmap: 0.7927, aux_task4.loss_bbox: 0.3341, aux_task5.loss_heatmap: 0.8293, aux_task5.loss_bbox: 0.3377, loss: 20.2244, grad_norm: 34.2295
2025-04-23 16:22:47,567 - mmdet - INFO - Epoch [2][850/1104]	lr: 5.107e-05, eta: 5:43:09, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.7409, loss_bbox: 1.0830, d0.loss_cls: 0.8117, d0.loss_bbox: 1.3075, d1.loss_cls: 0.7660, d1.loss_bbox: 1.1626, d2.loss_cls: 0.7529, d2.loss_bbox: 1.1164, d3.loss_cls: 0.7423, d3.loss_bbox: 1.0989, d4.loss_cls: 0.7404, d4.loss_bbox: 1.0893, aux_task0.loss_heatmap: 0.9642, aux_task0.loss_bbox: 0.3431, aux_task1.loss_heatmap: 1.2659, aux_task1.loss_bbox: 0.3914, aux_task2.loss_heatmap: 1.5024, aux_task2.loss_bbox: 0.4323, aux_task3.loss_heatmap: 1.0227, aux_task3.loss_bbox: 0.3253, aux_task4.loss_heatmap: 0.7822, aux_task4.loss_bbox: 0.3330, aux_task5.loss_heatmap: 0.7900, aux_task5.loss_bbox: 0.3339, loss: 19.8982, grad_norm: 34.2797
2025-04-23 16:23:38,401 - mmdet - INFO - Epoch [2][900/1104]	lr: 5.237e-05, eta: 5:42:15, time: 1.017, data_time: 0.009, memory: 16167, loss_cls: 0.7593, loss_bbox: 1.1034, d0.loss_cls: 0.8258, d0.loss_bbox: 1.3223, d1.loss_cls: 0.7820, d1.loss_bbox: 1.1818, d2.loss_cls: 0.7699, d2.loss_bbox: 1.1380, d3.loss_cls: 0.7598, d3.loss_bbox: 1.1178, d4.loss_cls: 0.7589, d4.loss_bbox: 1.1070, aux_task0.loss_heatmap: 0.9861, aux_task0.loss_bbox: 0.3362, aux_task1.loss_heatmap: 1.2824, aux_task1.loss_bbox: 0.3922, aux_task2.loss_heatmap: 1.4989, aux_task2.loss_bbox: 0.4360, aux_task3.loss_heatmap: 1.0147, aux_task3.loss_bbox: 0.3270, aux_task4.loss_heatmap: 0.8018, aux_task4.loss_bbox: 0.3312, aux_task5.loss_heatmap: 0.8291, aux_task5.loss_bbox: 0.3331, loss: 20.1947, grad_norm: 35.9747
2025-04-23 16:24:29,512 - mmdet - INFO - Epoch [2][950/1104]	lr: 5.369e-05, eta: 5:41:23, time: 1.022, data_time: 0.009, memory: 16167, loss_cls: 0.7453, loss_bbox: 1.1002, d0.loss_cls: 0.8110, d0.loss_bbox: 1.3187, d1.loss_cls: 0.7685, d1.loss_bbox: 1.1749, d2.loss_cls: 0.7566, d2.loss_bbox: 1.1351, d3.loss_cls: 0.7453, d3.loss_bbox: 1.1136, d4.loss_cls: 0.7426, d4.loss_bbox: 1.1030, aux_task0.loss_heatmap: 1.0049, aux_task0.loss_bbox: 0.3493, aux_task1.loss_heatmap: 1.2732, aux_task1.loss_bbox: 0.3896, aux_task2.loss_heatmap: 1.5056, aux_task2.loss_bbox: 0.4302, aux_task3.loss_heatmap: 0.9856, aux_task3.loss_bbox: 0.3243, aux_task4.loss_heatmap: 0.7545, aux_task4.loss_bbox: 0.3354, aux_task5.loss_heatmap: 0.8261, aux_task5.loss_bbox: 0.3373, loss: 20.0307, grad_norm: 37.2138
2025-04-23 16:25:19,747 - mmdet - INFO - Epoch [2][1000/1104]	lr: 5.504e-05, eta: 5:40:23, time: 1.005, data_time: 0.008, memory: 16167, loss_cls: 0.7412, loss_bbox: 1.0877, d0.loss_cls: 0.8095, d0.loss_bbox: 1.3114, d1.loss_cls: 0.7654, d1.loss_bbox: 1.1661, d2.loss_cls: 0.7547, d2.loss_bbox: 1.1204, d3.loss_cls: 0.7418, d3.loss_bbox: 1.0993, d4.loss_cls: 0.7403, d4.loss_bbox: 1.0908, aux_task0.loss_heatmap: 0.9712, aux_task0.loss_bbox: 0.3408, aux_task1.loss_heatmap: 1.2735, aux_task1.loss_bbox: 0.3888, aux_task2.loss_heatmap: 1.4889, aux_task2.loss_bbox: 0.4268, aux_task3.loss_heatmap: 1.0097, aux_task3.loss_bbox: 0.3293, aux_task4.loss_heatmap: 0.7570, aux_task4.loss_bbox: 0.3364, aux_task5.loss_heatmap: 0.8052, aux_task5.loss_bbox: 0.3375, loss: 19.8936, grad_norm: 32.8037
2025-04-23 16:26:10,495 - mmdet - INFO - Epoch [2][1050/1104]	lr: 5.641e-05, eta: 5:39:29, time: 1.015, data_time: 0.008, memory: 16167, loss_cls: 0.7327, loss_bbox: 1.0739, d0.loss_cls: 0.7976, d0.loss_bbox: 1.2982, d1.loss_cls: 0.7555, d1.loss_bbox: 1.1577, d2.loss_cls: 0.7466, d2.loss_bbox: 1.1091, d3.loss_cls: 0.7310, d3.loss_bbox: 1.0870, d4.loss_cls: 0.7306, d4.loss_bbox: 1.0786, aux_task0.loss_heatmap: 0.9633, aux_task0.loss_bbox: 0.3383, aux_task1.loss_heatmap: 1.2503, aux_task1.loss_bbox: 0.3956, aux_task2.loss_heatmap: 1.4769, aux_task2.loss_bbox: 0.4258, aux_task3.loss_heatmap: 0.9616, aux_task3.loss_bbox: 0.3186, aux_task4.loss_heatmap: 0.7750, aux_task4.loss_bbox: 0.3317, aux_task5.loss_heatmap: 0.7746, aux_task5.loss_bbox: 0.3293, loss: 19.6397, grad_norm: 34.5800
2025-04-23 16:27:01,074 - mmdet - INFO - Epoch [2][1100/1104]	lr: 5.781e-05, eta: 5:38:33, time: 1.012, data_time: 0.008, memory: 16167, loss_cls: 0.7156, loss_bbox: 1.0728, d0.loss_cls: 0.7813, d0.loss_bbox: 1.2869, d1.loss_cls: 0.7408, d1.loss_bbox: 1.1486, d2.loss_cls: 0.7301, d2.loss_bbox: 1.1037, d3.loss_cls: 0.7160, d3.loss_bbox: 1.0823, d4.loss_cls: 0.7146, d4.loss_bbox: 1.0752, aux_task0.loss_heatmap: 0.9379, aux_task0.loss_bbox: 0.3331, aux_task1.loss_heatmap: 1.2520, aux_task1.loss_bbox: 0.3920, aux_task2.loss_heatmap: 1.4719, aux_task2.loss_bbox: 0.4412, aux_task3.loss_heatmap: 0.9509, aux_task3.loss_bbox: 0.3236, aux_task4.loss_heatmap: 0.7659, aux_task4.loss_bbox: 0.3393, aux_task5.loss_heatmap: 0.7523, aux_task5.loss_bbox: 0.3282, loss: 19.4563, grad_norm: 39.2302
2025-04-23 16:27:05,498 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-04-23 16:42:06,863 - mmdet - INFO - Exp name: secondmambadss_split14.py
2025-04-23 16:42:06,863 - mmdet - INFO - Epoch(val) [2][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0186, pts_bbox_NuScenes/car_AP_dist_1.0: 0.1402, pts_bbox_NuScenes/car_AP_dist_2.0: 0.2774, pts_bbox_NuScenes/car_AP_dist_4.0: 0.3795, pts_bbox_NuScenes/car_trans_err: 0.7319, pts_bbox_NuScenes/car_scale_err: 0.2832, pts_bbox_NuScenes/car_orient_err: 1.4781, pts_bbox_NuScenes/car_vel_err: 1.4426, pts_bbox_NuScenes/car_attr_err: 0.4425, pts_bbox_NuScenes/mATE: 0.8053, pts_bbox_NuScenes/mASE: 0.3840, pts_bbox_NuScenes/mAOE: 1.4320, pts_bbox_NuScenes/mAVE: 1.2093, pts_bbox_NuScenes/mAAE: 0.4838, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0091, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0297, pts_bbox_NuScenes/truck_trans_err: 0.9611, pts_bbox_NuScenes/truck_scale_err: 0.3492, pts_bbox_NuScenes/truck_orient_err: 1.5731, pts_bbox_NuScenes/truck_vel_err: 1.1657, pts_bbox_NuScenes/truck_attr_err: 0.4261, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.9388, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.5823, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.5405, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1247, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3891, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0006, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.0132, pts_bbox_NuScenes/bus_trans_err: 1.0972, pts_bbox_NuScenes/bus_scale_err: 0.3112, pts_bbox_NuScenes/bus_orient_err: 1.4527, pts_bbox_NuScenes/bus_vel_err: 3.0877, pts_bbox_NuScenes/bus_attr_err: 0.6595, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/trailer_trans_err: 1.2298, pts_bbox_NuScenes/trailer_scale_err: 0.3181, pts_bbox_NuScenes/trailer_orient_err: 1.4309, pts_bbox_NuScenes/trailer_vel_err: 0.8227, pts_bbox_NuScenes/trailer_attr_err: 0.4061, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0002, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0292, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.0866, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.1445, pts_bbox_NuScenes/barrier_trans_err: 0.9428, pts_bbox_NuScenes/barrier_scale_err: 0.4014, pts_bbox_NuScenes/barrier_orient_err: 0.5255, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0003, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0014, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0016, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0018, pts_bbox_NuScenes/motorcycle_trans_err: 0.3996, pts_bbox_NuScenes/motorcycle_scale_err: 0.3132, pts_bbox_NuScenes/motorcycle_orient_err: 1.7756, pts_bbox_NuScenes/motorcycle_vel_err: 1.6236, pts_bbox_NuScenes/motorcycle_attr_err: 0.6104, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 0.6562, pts_bbox_NuScenes/bicycle_scale_err: 0.3787, pts_bbox_NuScenes/bicycle_orient_err: 1.6969, pts_bbox_NuScenes/bicycle_vel_err: 0.4905, pts_bbox_NuScenes/bicycle_attr_err: 0.1541, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.0754, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.2227, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.2785, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.3221, pts_bbox_NuScenes/pedestrian_trans_err: 0.5573, pts_bbox_NuScenes/pedestrian_scale_err: 0.3589, pts_bbox_NuScenes/pedestrian_orient_err: 1.4151, pts_bbox_NuScenes/pedestrian_vel_err: 0.9169, pts_bbox_NuScenes/pedestrian_attr_err: 0.7826, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0099, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0240, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.0388, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.0819, pts_bbox_NuScenes/traffic_cone_trans_err: 0.5388, pts_bbox_NuScenes/traffic_cone_scale_err: 0.5434, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.1600, pts_bbox_NuScenes/mAP: 0.0547
2025-04-23 16:43:07,255 - mmdet - INFO - Epoch [3][50/1104]	lr: 5.935e-05, eta: 5:38:13, time: 1.184, data_time: 0.118, memory: 16167, loss_cls: 0.7290, loss_bbox: 1.0669, d0.loss_cls: 0.7906, d0.loss_bbox: 1.2791, d1.loss_cls: 0.7486, d1.loss_bbox: 1.1377, d2.loss_cls: 0.7402, d2.loss_bbox: 1.0939, d3.loss_cls: 0.7298, d3.loss_bbox: 1.0725, d4.loss_cls: 0.7273, d4.loss_bbox: 1.0683, aux_task0.loss_heatmap: 0.9646, aux_task0.loss_bbox: 0.3339, aux_task1.loss_heatmap: 1.2278, aux_task1.loss_bbox: 0.3831, aux_task2.loss_heatmap: 1.4799, aux_task2.loss_bbox: 0.4303, aux_task3.loss_heatmap: 0.9640, aux_task3.loss_bbox: 0.3277, aux_task4.loss_heatmap: 0.7619, aux_task4.loss_bbox: 0.3335, aux_task5.loss_heatmap: 0.7669, aux_task5.loss_bbox: 0.3327, loss: 19.4903, grad_norm: 34.7786
2025-04-23 16:44:00,381 - mmdet - INFO - Epoch [3][100/1104]	lr: 6.080e-05, eta: 5:37:38, time: 1.063, data_time: 0.010, memory: 16167, loss_cls: 0.7141, loss_bbox: 1.0621, d0.loss_cls: 0.7768, d0.loss_bbox: 1.2735, d1.loss_cls: 0.7383, d1.loss_bbox: 1.1333, d2.loss_cls: 0.7276, d2.loss_bbox: 1.0883, d3.loss_cls: 0.7143, d3.loss_bbox: 1.0700, d4.loss_cls: 0.7125, d4.loss_bbox: 1.0643, aux_task0.loss_heatmap: 0.9437, aux_task0.loss_bbox: 0.3399, aux_task1.loss_heatmap: 1.2476, aux_task1.loss_bbox: 0.3870, aux_task2.loss_heatmap: 1.4621, aux_task2.loss_bbox: 0.4220, aux_task3.loss_heatmap: 0.9464, aux_task3.loss_bbox: 0.3295, aux_task4.loss_heatmap: 0.7370, aux_task4.loss_bbox: 0.3367, aux_task5.loss_heatmap: 0.7361, aux_task5.loss_bbox: 0.3262, loss: 19.2894, grad_norm: 37.0643
2025-04-23 16:44:53,418 - mmdet - INFO - Epoch [3][150/1104]	lr: 6.228e-05, eta: 5:37:02, time: 1.061, data_time: 0.009, memory: 16167, loss_cls: 0.7035, loss_bbox: 1.0461, d0.loss_cls: 0.7665, d0.loss_bbox: 1.2436, d1.loss_cls: 0.7261, d1.loss_bbox: 1.1084, d2.loss_cls: 0.7180, d2.loss_bbox: 1.0617, d3.loss_cls: 0.7034, d3.loss_bbox: 1.0478, d4.loss_cls: 0.7019, d4.loss_bbox: 1.0445, aux_task0.loss_heatmap: 0.9193, aux_task0.loss_bbox: 0.3368, aux_task1.loss_heatmap: 1.1996, aux_task1.loss_bbox: 0.3871, aux_task2.loss_heatmap: 1.4452, aux_task2.loss_bbox: 0.4284, aux_task3.loss_heatmap: 0.9403, aux_task3.loss_bbox: 0.3298, aux_task4.loss_heatmap: 0.7270, aux_task4.loss_bbox: 0.3279, aux_task5.loss_heatmap: 0.7106, aux_task5.loss_bbox: 0.3284, loss: 18.9519, grad_norm: 36.9565
2025-04-23 16:45:46,506 - mmdet - INFO - Epoch [3][200/1104]	lr: 6.378e-05, eta: 5:36:25, time: 1.061, data_time: 0.009, memory: 16167, loss_cls: 0.7197, loss_bbox: 1.0722, d0.loss_cls: 0.7822, d0.loss_bbox: 1.2822, d1.loss_cls: 0.7437, d1.loss_bbox: 1.1420, d2.loss_cls: 0.7321, d2.loss_bbox: 1.0964, d3.loss_cls: 0.7196, d3.loss_bbox: 1.0790, d4.loss_cls: 0.7182, d4.loss_bbox: 1.0740, aux_task0.loss_heatmap: 0.9394, aux_task0.loss_bbox: 0.3464, aux_task1.loss_heatmap: 1.2094, aux_task1.loss_bbox: 0.3881, aux_task2.loss_heatmap: 1.4365, aux_task2.loss_bbox: 0.4270, aux_task3.loss_heatmap: 0.9758, aux_task3.loss_bbox: 0.3238, aux_task4.loss_heatmap: 0.7357, aux_task4.loss_bbox: 0.3319, aux_task5.loss_heatmap: 0.7366, aux_task5.loss_bbox: 0.3335, loss: 19.3453, grad_norm: 37.8447
2025-04-23 16:46:39,216 - mmdet - INFO - Epoch [3][250/1104]	lr: 6.530e-05, eta: 5:35:46, time: 1.055, data_time: 0.010, memory: 16167, loss_cls: 0.7075, loss_bbox: 1.0450, d0.loss_cls: 0.7722, d0.loss_bbox: 1.2618, d1.loss_cls: 0.7338, d1.loss_bbox: 1.1167, d2.loss_cls: 0.7225, d2.loss_bbox: 1.0715, d3.loss_cls: 0.7077, d3.loss_bbox: 1.0545, d4.loss_cls: 0.7075, d4.loss_bbox: 1.0479, aux_task0.loss_heatmap: 0.9375, aux_task0.loss_bbox: 0.3360, aux_task1.loss_heatmap: 1.1945, aux_task1.loss_bbox: 0.3890, aux_task2.loss_heatmap: 1.4433, aux_task2.loss_bbox: 0.4276, aux_task3.loss_heatmap: 0.9256, aux_task3.loss_bbox: 0.3236, aux_task4.loss_heatmap: 0.7508, aux_task4.loss_bbox: 0.3349, aux_task5.loss_heatmap: 0.7265, aux_task5.loss_bbox: 0.3289, loss: 19.0670, grad_norm: 37.2372
2025-04-23 16:47:30,574 - mmdet - INFO - Epoch [3][300/1104]	lr: 6.684e-05, eta: 5:34:55, time: 1.027, data_time: 0.008, memory: 16167, loss_cls: 0.7027, loss_bbox: 1.0426, d0.loss_cls: 0.7667, d0.loss_bbox: 1.2386, d1.loss_cls: 0.7293, d1.loss_bbox: 1.1017, d2.loss_cls: 0.7183, d2.loss_bbox: 1.0605, d3.loss_cls: 0.7045, d3.loss_bbox: 1.0464, d4.loss_cls: 0.7022, d4.loss_bbox: 1.0434, aux_task0.loss_heatmap: 0.8836, aux_task0.loss_bbox: 0.3279, aux_task1.loss_heatmap: 1.2172, aux_task1.loss_bbox: 0.3869, aux_task2.loss_heatmap: 1.4219, aux_task2.loss_bbox: 0.4248, aux_task3.loss_heatmap: 0.9879, aux_task3.loss_bbox: 0.3186, aux_task4.loss_heatmap: 0.7352, aux_task4.loss_bbox: 0.3228, aux_task5.loss_heatmap: 0.7268, aux_task5.loss_bbox: 0.3267, loss: 18.9372, grad_norm: 35.9114
2025-04-23 16:48:21,146 - mmdet - INFO - Epoch [3][350/1104]	lr: 6.841e-05, eta: 5:33:57, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.7097, loss_bbox: 1.0478, d0.loss_cls: 0.7656, d0.loss_bbox: 1.2501, d1.loss_cls: 0.7319, d1.loss_bbox: 1.1138, d2.loss_cls: 0.7229, d2.loss_bbox: 1.0696, d3.loss_cls: 0.7104, d3.loss_bbox: 1.0544, d4.loss_cls: 0.7087, d4.loss_bbox: 1.0511, aux_task0.loss_heatmap: 0.9090, aux_task0.loss_bbox: 0.3291, aux_task1.loss_heatmap: 1.1986, aux_task1.loss_bbox: 0.3861, aux_task2.loss_heatmap: 1.4519, aux_task2.loss_bbox: 0.4284, aux_task3.loss_heatmap: 0.9402, aux_task3.loss_bbox: 0.3182, aux_task4.loss_heatmap: 0.7398, aux_task4.loss_bbox: 0.3327, aux_task5.loss_heatmap: 0.7100, aux_task5.loss_bbox: 0.3199, loss: 19.0000, grad_norm: 39.0722
2025-04-23 16:49:11,975 - mmdet - INFO - Epoch [3][400/1104]	lr: 7.000e-05, eta: 5:33:02, time: 1.017, data_time: 0.009, memory: 16167, loss_cls: 0.6956, loss_bbox: 1.0360, d0.loss_cls: 0.7579, d0.loss_bbox: 1.2330, d1.loss_cls: 0.7209, d1.loss_bbox: 1.0979, d2.loss_cls: 0.7103, d2.loss_bbox: 1.0577, d3.loss_cls: 0.6970, d3.loss_bbox: 1.0432, d4.loss_cls: 0.6945, d4.loss_bbox: 1.0385, aux_task0.loss_heatmap: 0.8984, aux_task0.loss_bbox: 0.3301, aux_task1.loss_heatmap: 1.1763, aux_task1.loss_bbox: 0.3818, aux_task2.loss_heatmap: 1.4355, aux_task2.loss_bbox: 0.4129, aux_task3.loss_heatmap: 0.9190, aux_task3.loss_bbox: 0.3216, aux_task4.loss_heatmap: 0.7087, aux_task4.loss_bbox: 0.3309, aux_task5.loss_heatmap: 0.7235, aux_task5.loss_bbox: 0.3208, loss: 18.7422, grad_norm: 35.6052
2025-04-23 16:50:02,762 - mmdet - INFO - Epoch [3][450/1104]	lr: 7.161e-05, eta: 5:32:07, time: 1.016, data_time: 0.008, memory: 16167, loss_cls: 0.6936, loss_bbox: 1.0266, d0.loss_cls: 0.7519, d0.loss_bbox: 1.2230, d1.loss_cls: 0.7153, d1.loss_bbox: 1.0893, d2.loss_cls: 0.7065, d2.loss_bbox: 1.0487, d3.loss_cls: 0.6923, d3.loss_bbox: 1.0351, d4.loss_cls: 0.6913, d4.loss_bbox: 1.0300, aux_task0.loss_heatmap: 0.8997, aux_task0.loss_bbox: 0.3304, aux_task1.loss_heatmap: 1.1762, aux_task1.loss_bbox: 0.3830, aux_task2.loss_heatmap: 1.4257, aux_task2.loss_bbox: 0.4246, aux_task3.loss_heatmap: 0.9376, aux_task3.loss_bbox: 0.3128, aux_task4.loss_heatmap: 0.7405, aux_task4.loss_bbox: 0.3301, aux_task5.loss_heatmap: 0.7054, aux_task5.loss_bbox: 0.3276, loss: 18.6971, grad_norm: 35.6022
2025-04-23 16:50:53,834 - mmdet - INFO - Epoch [3][500/1104]	lr: 7.325e-05, eta: 5:31:14, time: 1.021, data_time: 0.008, memory: 16167, loss_cls: 0.6877, loss_bbox: 1.0235, d0.loss_cls: 0.7455, d0.loss_bbox: 1.2143, d1.loss_cls: 0.7086, d1.loss_bbox: 1.0830, d2.loss_cls: 0.6995, d2.loss_bbox: 1.0466, d3.loss_cls: 0.6858, d3.loss_bbox: 1.0338, d4.loss_cls: 0.6859, d4.loss_bbox: 1.0292, aux_task0.loss_heatmap: 0.9138, aux_task0.loss_bbox: 0.3268, aux_task1.loss_heatmap: 1.1822, aux_task1.loss_bbox: 0.3784, aux_task2.loss_heatmap: 1.3825, aux_task2.loss_bbox: 0.4130, aux_task3.loss_heatmap: 0.9005, aux_task3.loss_bbox: 0.3163, aux_task4.loss_heatmap: 0.7080, aux_task4.loss_bbox: 0.3274, aux_task5.loss_heatmap: 0.6871, aux_task5.loss_bbox: 0.3280, loss: 18.5074, grad_norm: 38.0765
2025-04-23 16:51:44,842 - mmdet - INFO - Epoch [3][550/1104]	lr: 7.490e-05, eta: 5:30:21, time: 1.020, data_time: 0.009, memory: 16167, loss_cls: 0.6743, loss_bbox: 1.0220, d0.loss_cls: 0.7329, d0.loss_bbox: 1.2166, d1.loss_cls: 0.6983, d1.loss_bbox: 1.0792, d2.loss_cls: 0.6894, d2.loss_bbox: 1.0406, d3.loss_cls: 0.6767, d3.loss_bbox: 1.0282, d4.loss_cls: 0.6744, d4.loss_bbox: 1.0242, aux_task0.loss_heatmap: 0.9069, aux_task0.loss_bbox: 0.3319, aux_task1.loss_heatmap: 1.1490, aux_task1.loss_bbox: 0.3819, aux_task2.loss_heatmap: 1.4271, aux_task2.loss_bbox: 0.4183, aux_task3.loss_heatmap: 0.8714, aux_task3.loss_bbox: 0.3202, aux_task4.loss_heatmap: 0.7066, aux_task4.loss_bbox: 0.3298, aux_task5.loss_heatmap: 0.6698, aux_task5.loss_bbox: 0.3236, loss: 18.3932, grad_norm: 34.2602
2025-04-23 16:52:35,477 - mmdet - INFO - Epoch [3][600/1104]	lr: 7.657e-05, eta: 5:29:25, time: 1.013, data_time: 0.008, memory: 16167, loss_cls: 0.6714, loss_bbox: 1.0155, d0.loss_cls: 0.7347, d0.loss_bbox: 1.2023, d1.loss_cls: 0.6978, d1.loss_bbox: 1.0698, d2.loss_cls: 0.6875, d2.loss_bbox: 1.0358, d3.loss_cls: 0.6731, d3.loss_bbox: 1.0239, d4.loss_cls: 0.6706, d4.loss_bbox: 1.0185, aux_task0.loss_heatmap: 0.8761, aux_task0.loss_bbox: 0.3238, aux_task1.loss_heatmap: 1.1691, aux_task1.loss_bbox: 0.3816, aux_task2.loss_heatmap: 1.3890, aux_task2.loss_bbox: 0.4230, aux_task3.loss_heatmap: 0.9422, aux_task3.loss_bbox: 0.3176, aux_task4.loss_heatmap: 0.6776, aux_task4.loss_bbox: 0.3236, aux_task5.loss_heatmap: 0.6812, aux_task5.loss_bbox: 0.3220, loss: 18.3277, grad_norm: 35.3686
2025-04-23 16:53:25,958 - mmdet - INFO - Epoch [3][650/1104]	lr: 7.826e-05, eta: 5:28:28, time: 1.010, data_time: 0.008, memory: 16167, loss_cls: 0.6846, loss_bbox: 1.0221, d0.loss_cls: 0.7399, d0.loss_bbox: 1.2026, d1.loss_cls: 0.7060, d1.loss_bbox: 1.0744, d2.loss_cls: 0.7006, d2.loss_bbox: 1.0375, d3.loss_cls: 0.6880, d3.loss_bbox: 1.0246, d4.loss_cls: 0.6848, d4.loss_bbox: 1.0213, aux_task0.loss_heatmap: 0.8790, aux_task0.loss_bbox: 0.3322, aux_task1.loss_heatmap: 1.1179, aux_task1.loss_bbox: 0.3751, aux_task2.loss_heatmap: 1.4078, aux_task2.loss_bbox: 0.4216, aux_task3.loss_heatmap: 0.9709, aux_task3.loss_bbox: 0.3171, aux_task4.loss_heatmap: 0.7394, aux_task4.loss_bbox: 0.3305, aux_task5.loss_heatmap: 0.6853, aux_task5.loss_bbox: 0.3214, loss: 18.4847, grad_norm: 33.3647
2025-04-23 16:54:16,733 - mmdet - INFO - Epoch [3][700/1104]	lr: 7.997e-05, eta: 5:27:34, time: 1.015, data_time: 0.007, memory: 16167, loss_cls: 0.6678, loss_bbox: 1.0029, d0.loss_cls: 0.7279, d0.loss_bbox: 1.1870, d1.loss_cls: 0.6917, d1.loss_bbox: 1.0573, d2.loss_cls: 0.6813, d2.loss_bbox: 1.0242, d3.loss_cls: 0.6688, d3.loss_bbox: 1.0097, d4.loss_cls: 0.6684, d4.loss_bbox: 1.0051, aux_task0.loss_heatmap: 0.8787, aux_task0.loss_bbox: 0.3309, aux_task1.loss_heatmap: 1.1331, aux_task1.loss_bbox: 0.3792, aux_task2.loss_heatmap: 1.3658, aux_task2.loss_bbox: 0.4129, aux_task3.loss_heatmap: 0.9023, aux_task3.loss_bbox: 0.3207, aux_task4.loss_heatmap: 0.6848, aux_task4.loss_bbox: 0.3280, aux_task5.loss_heatmap: 0.6902, aux_task5.loss_bbox: 0.3208, loss: 18.1395, grad_norm: 35.6951
2025-04-23 16:55:07,341 - mmdet - INFO - Epoch [3][750/1104]	lr: 8.170e-05, eta: 5:26:38, time: 1.012, data_time: 0.008, memory: 16167, loss_cls: 0.6626, loss_bbox: 1.0091, d0.loss_cls: 0.7239, d0.loss_bbox: 1.1829, d1.loss_cls: 0.6907, d1.loss_bbox: 1.0534, d2.loss_cls: 0.6796, d2.loss_bbox: 1.0208, d3.loss_cls: 0.6660, d3.loss_bbox: 1.0118, d4.loss_cls: 0.6627, d4.loss_bbox: 1.0118, aux_task0.loss_heatmap: 0.8656, aux_task0.loss_bbox: 0.3265, aux_task1.loss_heatmap: 1.1318, aux_task1.loss_bbox: 0.3758, aux_task2.loss_heatmap: 1.3607, aux_task2.loss_bbox: 0.4143, aux_task3.loss_heatmap: 0.8950, aux_task3.loss_bbox: 0.3079, aux_task4.loss_heatmap: 0.6921, aux_task4.loss_bbox: 0.3305, aux_task5.loss_heatmap: 0.6920, aux_task5.loss_bbox: 0.3232, loss: 18.0906, grad_norm: 36.4112
2025-04-23 16:55:57,865 - mmdet - INFO - Epoch [3][800/1104]	lr: 8.345e-05, eta: 5:25:43, time: 1.010, data_time: 0.008, memory: 16167, loss_cls: 0.6655, loss_bbox: 0.9996, d0.loss_cls: 0.7208, d0.loss_bbox: 1.1763, d1.loss_cls: 0.6862, d1.loss_bbox: 1.0503, d2.loss_cls: 0.6774, d2.loss_bbox: 1.0180, d3.loss_cls: 0.6654, d3.loss_bbox: 1.0055, d4.loss_cls: 0.6641, d4.loss_bbox: 1.0020, aux_task0.loss_heatmap: 0.8356, aux_task0.loss_bbox: 0.3203, aux_task1.loss_heatmap: 1.1482, aux_task1.loss_bbox: 0.3763, aux_task2.loss_heatmap: 1.3793, aux_task2.loss_bbox: 0.4068, aux_task3.loss_heatmap: 0.8849, aux_task3.loss_bbox: 0.3182, aux_task4.loss_heatmap: 0.6965, aux_task4.loss_bbox: 0.3221, aux_task5.loss_heatmap: 0.6700, aux_task5.loss_bbox: 0.3191, loss: 18.0083, grad_norm: 34.8329
2025-04-23 16:56:48,182 - mmdet - INFO - Epoch [3][850/1104]	lr: 8.521e-05, eta: 5:24:46, time: 1.006, data_time: 0.008, memory: 16167, loss_cls: 0.6619, loss_bbox: 0.9944, d0.loss_cls: 0.7174, d0.loss_bbox: 1.1756, d1.loss_cls: 0.6868, d1.loss_bbox: 1.0471, d2.loss_cls: 0.6747, d2.loss_bbox: 1.0149, d3.loss_cls: 0.6625, d3.loss_bbox: 1.0024, d4.loss_cls: 0.6636, d4.loss_bbox: 0.9966, aux_task0.loss_heatmap: 0.8438, aux_task0.loss_bbox: 0.3216, aux_task1.loss_heatmap: 1.1302, aux_task1.loss_bbox: 0.3785, aux_task2.loss_heatmap: 1.3550, aux_task2.loss_bbox: 0.4129, aux_task3.loss_heatmap: 0.8877, aux_task3.loss_bbox: 0.3202, aux_task4.loss_heatmap: 0.6845, aux_task4.loss_bbox: 0.3227, aux_task5.loss_heatmap: 0.6641, aux_task5.loss_bbox: 0.3170, loss: 17.9359, grad_norm: 34.1306
2025-04-23 16:57:38,839 - mmdet - INFO - Epoch [3][900/1104]	lr: 8.699e-05, eta: 5:23:51, time: 1.013, data_time: 0.008, memory: 16167, loss_cls: 0.6669, loss_bbox: 0.9997, d0.loss_cls: 0.7257, d0.loss_bbox: 1.1707, d1.loss_cls: 0.6923, d1.loss_bbox: 1.0538, d2.loss_cls: 0.6835, d2.loss_bbox: 1.0203, d3.loss_cls: 0.6690, d3.loss_bbox: 1.0081, d4.loss_cls: 0.6686, d4.loss_bbox: 1.0017, aux_task0.loss_heatmap: 0.8670, aux_task0.loss_bbox: 0.3227, aux_task1.loss_heatmap: 1.1459, aux_task1.loss_bbox: 0.3700, aux_task2.loss_heatmap: 1.3378, aux_task2.loss_bbox: 0.4167, aux_task3.loss_heatmap: 0.9069, aux_task3.loss_bbox: 0.3193, aux_task4.loss_heatmap: 0.7113, aux_task4.loss_bbox: 0.3188, aux_task5.loss_heatmap: 0.6487, aux_task5.loss_bbox: 0.3189, loss: 18.0444, grad_norm: 32.5967
2025-04-23 16:58:29,176 - mmdet - INFO - Epoch [3][950/1104]	lr: 8.879e-05, eta: 5:22:55, time: 1.007, data_time: 0.009, memory: 16167, loss_cls: 0.6503, loss_bbox: 0.9973, d0.loss_cls: 0.7022, d0.loss_bbox: 1.1649, d1.loss_cls: 0.6724, d1.loss_bbox: 1.0477, d2.loss_cls: 0.6635, d2.loss_bbox: 1.0180, d3.loss_cls: 0.6506, d3.loss_bbox: 1.0068, d4.loss_cls: 0.6494, d4.loss_bbox: 1.0016, aux_task0.loss_heatmap: 0.8603, aux_task0.loss_bbox: 0.3206, aux_task1.loss_heatmap: 1.1448, aux_task1.loss_bbox: 0.3761, aux_task2.loss_heatmap: 1.3313, aux_task2.loss_bbox: 0.4052, aux_task3.loss_heatmap: 0.8485, aux_task3.loss_bbox: 0.3181, aux_task4.loss_heatmap: 0.6735, aux_task4.loss_bbox: 0.3225, aux_task5.loss_heatmap: 0.6336, aux_task5.loss_bbox: 0.3217, loss: 17.7811, grad_norm: 32.4107
2025-04-23 16:59:21,670 - mmdet - INFO - Epoch [3][1000/1104]	lr: 9.060e-05, eta: 5:22:11, time: 1.050, data_time: 0.008, memory: 16167, loss_cls: 0.6461, loss_bbox: 0.9872, d0.loss_cls: 0.7026, d0.loss_bbox: 1.1594, d1.loss_cls: 0.6696, d1.loss_bbox: 1.0406, d2.loss_cls: 0.6596, d2.loss_bbox: 1.0073, d3.loss_cls: 0.6473, d3.loss_bbox: 0.9947, d4.loss_cls: 0.6459, d4.loss_bbox: 0.9918, aux_task0.loss_heatmap: 0.8508, aux_task0.loss_bbox: 0.3214, aux_task1.loss_heatmap: 1.1370, aux_task1.loss_bbox: 0.3732, aux_task2.loss_heatmap: 1.3071, aux_task2.loss_bbox: 0.4091, aux_task3.loss_heatmap: 0.8271, aux_task3.loss_bbox: 0.3092, aux_task4.loss_heatmap: 0.6649, aux_task4.loss_bbox: 0.3215, aux_task5.loss_heatmap: 0.6359, aux_task5.loss_bbox: 0.3204, loss: 17.6295, grad_norm: 38.4400
2025-04-23 17:00:12,299 - mmdet - INFO - Epoch [3][1050/1104]	lr: 9.242e-05, eta: 5:21:16, time: 1.013, data_time: 0.008, memory: 16167, loss_cls: 0.6532, loss_bbox: 0.9949, d0.loss_cls: 0.7115, d0.loss_bbox: 1.1632, d1.loss_cls: 0.6801, d1.loss_bbox: 1.0462, d2.loss_cls: 0.6684, d2.loss_bbox: 1.0146, d3.loss_cls: 0.6551, d3.loss_bbox: 1.0033, d4.loss_cls: 0.6541, d4.loss_bbox: 0.9972, aux_task0.loss_heatmap: 0.8563, aux_task0.loss_bbox: 0.3254, aux_task1.loss_heatmap: 1.1286, aux_task1.loss_bbox: 0.3816, aux_task2.loss_heatmap: 1.3043, aux_task2.loss_bbox: 0.3985, aux_task3.loss_heatmap: 0.9066, aux_task3.loss_bbox: 0.3100, aux_task4.loss_heatmap: 0.6834, aux_task4.loss_bbox: 0.3226, aux_task5.loss_heatmap: 0.6517, aux_task5.loss_bbox: 0.3176, loss: 17.8286, grad_norm: 37.9220
2025-04-23 17:01:03,140 - mmdet - INFO - Epoch [3][1100/1104]	lr: 9.426e-05, eta: 5:20:23, time: 1.017, data_time: 0.008, memory: 16167, loss_cls: 0.6321, loss_bbox: 0.9853, d0.loss_cls: 0.6907, d0.loss_bbox: 1.1494, d1.loss_cls: 0.6604, d1.loss_bbox: 1.0355, d2.loss_cls: 0.6511, d2.loss_bbox: 1.0036, d3.loss_cls: 0.6371, d3.loss_bbox: 0.9933, d4.loss_cls: 0.6352, d4.loss_bbox: 0.9874, aux_task0.loss_heatmap: 0.8235, aux_task0.loss_bbox: 0.3183, aux_task1.loss_heatmap: 1.1128, aux_task1.loss_bbox: 0.3717, aux_task2.loss_heatmap: 1.2916, aux_task2.loss_bbox: 0.4082, aux_task3.loss_heatmap: 0.8806, aux_task3.loss_bbox: 0.3161, aux_task4.loss_heatmap: 0.6705, aux_task4.loss_bbox: 0.3266, aux_task5.loss_heatmap: 0.6269, aux_task5.loss_bbox: 0.3115, loss: 17.5190, grad_norm: 36.0096
2025-04-23 17:01:07,533 - mmdet - INFO - Saving checkpoint at 3 epochs
2025-04-23 17:12:48,464 - mmdet - INFO - Exp name: secondmambadss_split14.py
2025-04-23 17:12:48,464 - mmdet - INFO - Epoch(val) [3][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0918, pts_bbox_NuScenes/car_AP_dist_1.0: 0.2746, pts_bbox_NuScenes/car_AP_dist_2.0: 0.4299, pts_bbox_NuScenes/car_AP_dist_4.0: 0.5203, pts_bbox_NuScenes/car_trans_err: 0.5883, pts_bbox_NuScenes/car_scale_err: 0.2123, pts_bbox_NuScenes/car_orient_err: 1.4064, pts_bbox_NuScenes/car_vel_err: 1.1957, pts_bbox_NuScenes/car_attr_err: 0.4281, pts_bbox_NuScenes/mATE: 0.7764, pts_bbox_NuScenes/mASE: 0.3570, pts_bbox_NuScenes/mAOE: 1.4285, pts_bbox_NuScenes/mAVE: 1.2227, pts_bbox_NuScenes/mAAE: 0.4647, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0038, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0411, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0744, pts_bbox_NuScenes/truck_trans_err: 0.9332, pts_bbox_NuScenes/truck_scale_err: 0.3312, pts_bbox_NuScenes/truck_orient_err: 1.5137, pts_bbox_NuScenes/truck_vel_err: 1.0183, pts_bbox_NuScenes/truck_attr_err: 0.3879, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0005, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.8900, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.5162, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.7191, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1315, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3972, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0477, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.1454, pts_bbox_NuScenes/bus_trans_err: 1.2266, pts_bbox_NuScenes/bus_scale_err: 0.3076, pts_bbox_NuScenes/bus_orient_err: 1.6961, pts_bbox_NuScenes/bus_vel_err: 2.6900, pts_bbox_NuScenes/bus_attr_err: 0.6311, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0029, pts_bbox_NuScenes/trailer_trans_err: 1.0838, pts_bbox_NuScenes/trailer_scale_err: 0.3559, pts_bbox_NuScenes/trailer_orient_err: 1.4753, pts_bbox_NuScenes/trailer_vel_err: 0.7537, pts_bbox_NuScenes/trailer_attr_err: 0.2745, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0145, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0871, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.1729, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.2524, pts_bbox_NuScenes/barrier_trans_err: 0.8858, pts_bbox_NuScenes/barrier_scale_err: 0.3776, pts_bbox_NuScenes/barrier_orient_err: 0.6835, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0003, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0027, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0059, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0070, pts_bbox_NuScenes/motorcycle_trans_err: 0.4895, pts_bbox_NuScenes/motorcycle_scale_err: 0.3210, pts_bbox_NuScenes/motorcycle_orient_err: 1.4461, pts_bbox_NuScenes/motorcycle_vel_err: 2.1366, pts_bbox_NuScenes/motorcycle_attr_err: 0.5762, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 0.6329, pts_bbox_NuScenes/bicycle_scale_err: 0.3712, pts_bbox_NuScenes/bicycle_orient_err: 1.5335, pts_bbox_NuScenes/bicycle_vel_err: 0.9026, pts_bbox_NuScenes/bicycle_attr_err: 0.2272, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.1679, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.4202, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.4941, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.5341, pts_bbox_NuScenes/pedestrian_trans_err: 0.5216, pts_bbox_NuScenes/pedestrian_scale_err: 0.2962, pts_bbox_NuScenes/pedestrian_orient_err: 1.3828, pts_bbox_NuScenes/pedestrian_vel_err: 0.9533, pts_bbox_NuScenes/pedestrian_attr_err: 0.7956, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0448, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0844, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.1096, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.1709, pts_bbox_NuScenes/traffic_cone_trans_err: 0.5120, pts_bbox_NuScenes/traffic_cone_scale_err: 0.4809, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.1927, pts_bbox_NuScenes/mAP: 0.1050
2025-04-23 17:13:44,843 - mmdet - INFO - Epoch [4][50/1104]	lr: 9.627e-05, eta: 5:19:29, time: 1.111, data_time: 0.098, memory: 16167, loss_cls: 0.6427, loss_bbox: 0.9742, d0.loss_cls: 0.6964, d0.loss_bbox: 1.1351, d1.loss_cls: 0.6679, d1.loss_bbox: 1.0236, d2.loss_cls: 0.6572, d2.loss_bbox: 0.9939, d3.loss_cls: 0.6453, d3.loss_bbox: 0.9829, d4.loss_cls: 0.6434, d4.loss_bbox: 0.9792, aux_task0.loss_heatmap: 0.8295, aux_task0.loss_bbox: 0.3202, aux_task1.loss_heatmap: 1.1033, aux_task1.loss_bbox: 0.3651, aux_task2.loss_heatmap: 1.3211, aux_task2.loss_bbox: 0.4118, aux_task3.loss_heatmap: 0.8702, aux_task3.loss_bbox: 0.3026, aux_task4.loss_heatmap: 0.6811, aux_task4.loss_bbox: 0.3257, aux_task5.loss_heatmap: 0.6057, aux_task5.loss_bbox: 0.3133, loss: 17.4915, grad_norm: 34.5845
2025-04-23 17:14:35,694 - mmdet - INFO - Epoch [4][100/1104]	lr: 9.813e-05, eta: 5:18:36, time: 1.017, data_time: 0.008, memory: 16167, loss_cls: 0.6269, loss_bbox: 0.9684, d0.loss_cls: 0.6863, d0.loss_bbox: 1.1295, d1.loss_cls: 0.6584, d1.loss_bbox: 1.0180, d2.loss_cls: 0.6453, d2.loss_bbox: 0.9876, d3.loss_cls: 0.6321, d3.loss_bbox: 0.9755, d4.loss_cls: 0.6295, d4.loss_bbox: 0.9717, aux_task0.loss_heatmap: 0.8226, aux_task0.loss_bbox: 0.3197, aux_task1.loss_heatmap: 1.1098, aux_task1.loss_bbox: 0.3698, aux_task2.loss_heatmap: 1.2689, aux_task2.loss_bbox: 0.3970, aux_task3.loss_heatmap: 0.8848, aux_task3.loss_bbox: 0.3169, aux_task4.loss_heatmap: 0.6714, aux_task4.loss_bbox: 0.3268, aux_task5.loss_heatmap: 0.6081, aux_task5.loss_bbox: 0.3140, loss: 17.3391, grad_norm: 32.0463
2025-04-23 17:15:25,953 - mmdet - INFO - Epoch [4][150/1104]	lr: 1.000e-04, eta: 5:17:40, time: 1.005, data_time: 0.007, memory: 16167, loss_cls: 0.6234, loss_bbox: 0.9610, d0.loss_cls: 0.6841, d0.loss_bbox: 1.1214, d1.loss_cls: 0.6520, d1.loss_bbox: 1.0104, d2.loss_cls: 0.6430, d2.loss_bbox: 0.9784, d3.loss_cls: 0.6287, d3.loss_bbox: 0.9696, d4.loss_cls: 0.6248, d4.loss_bbox: 0.9662, aux_task0.loss_heatmap: 0.8029, aux_task0.loss_bbox: 0.3179, aux_task1.loss_heatmap: 1.0910, aux_task1.loss_bbox: 0.3708, aux_task2.loss_heatmap: 1.2474, aux_task2.loss_bbox: 0.4001, aux_task3.loss_heatmap: 0.8438, aux_task3.loss_bbox: 0.3176, aux_task4.loss_heatmap: 0.6492, aux_task4.loss_bbox: 0.3210, aux_task5.loss_heatmap: 0.6019, aux_task5.loss_bbox: 0.3141, loss: 17.1407, grad_norm: 31.3282
2025-04-23 17:16:16,092 - mmdet - INFO - Epoch [4][200/1104]	lr: 1.019e-04, eta: 5:16:43, time: 1.003, data_time: 0.008, memory: 16167, loss_cls: 0.6251, loss_bbox: 0.9682, d0.loss_cls: 0.6807, d0.loss_bbox: 1.1253, d1.loss_cls: 0.6540, d1.loss_bbox: 1.0165, d2.loss_cls: 0.6419, d2.loss_bbox: 0.9867, d3.loss_cls: 0.6278, d3.loss_bbox: 0.9761, d4.loss_cls: 0.6251, d4.loss_bbox: 0.9719, aux_task0.loss_heatmap: 0.8282, aux_task0.loss_bbox: 0.3226, aux_task1.loss_heatmap: 1.0788, aux_task1.loss_bbox: 0.3680, aux_task2.loss_heatmap: 1.2512, aux_task2.loss_bbox: 0.3961, aux_task3.loss_heatmap: 0.8526, aux_task3.loss_bbox: 0.3150, aux_task4.loss_heatmap: 0.6358, aux_task4.loss_bbox: 0.3204, aux_task5.loss_heatmap: 0.6318, aux_task5.loss_bbox: 0.3188, loss: 17.2187, grad_norm: 34.0607
2025-04-23 17:17:06,671 - mmdet - INFO - Epoch [4][250/1104]	lr: 1.038e-04, eta: 5:15:49, time: 1.012, data_time: 0.008, memory: 16167, loss_cls: 0.6247, loss_bbox: 0.9620, d0.loss_cls: 0.6838, d0.loss_bbox: 1.1158, d1.loss_cls: 0.6563, d1.loss_bbox: 1.0058, d2.loss_cls: 0.6458, d2.loss_bbox: 0.9756, d3.loss_cls: 0.6305, d3.loss_bbox: 0.9675, d4.loss_cls: 0.6269, d4.loss_bbox: 0.9638, aux_task0.loss_heatmap: 0.7996, aux_task0.loss_bbox: 0.3136, aux_task1.loss_heatmap: 1.0877, aux_task1.loss_bbox: 0.3696, aux_task2.loss_heatmap: 1.2494, aux_task2.loss_bbox: 0.3952, aux_task3.loss_heatmap: 0.8586, aux_task3.loss_bbox: 0.3121, aux_task4.loss_heatmap: 0.6548, aux_task4.loss_bbox: 0.3233, aux_task5.loss_heatmap: 0.6285, aux_task5.loss_bbox: 0.3120, loss: 17.1629, grad_norm: 36.1005
2025-04-23 17:17:57,240 - mmdet - INFO - Epoch [4][300/1104]	lr: 1.057e-04, eta: 5:14:55, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.6137, loss_bbox: 0.9549, d0.loss_cls: 0.6732, d0.loss_bbox: 1.1145, d1.loss_cls: 0.6464, d1.loss_bbox: 1.0023, d2.loss_cls: 0.6340, d2.loss_bbox: 0.9735, d3.loss_cls: 0.6202, d3.loss_bbox: 0.9627, d4.loss_cls: 0.6155, d4.loss_bbox: 0.9576, aux_task0.loss_heatmap: 0.8104, aux_task0.loss_bbox: 0.3145, aux_task1.loss_heatmap: 1.0804, aux_task1.loss_bbox: 0.3674, aux_task2.loss_heatmap: 1.2340, aux_task2.loss_bbox: 0.4077, aux_task3.loss_heatmap: 0.8154, aux_task3.loss_bbox: 0.3105, aux_task4.loss_heatmap: 0.6571, aux_task4.loss_bbox: 0.3132, aux_task5.loss_heatmap: 0.5951, aux_task5.loss_bbox: 0.3177, loss: 16.9919, grad_norm: 37.8907
2025-04-23 17:18:47,901 - mmdet - INFO - Epoch [4][350/1104]	lr: 1.076e-04, eta: 5:14:01, time: 1.013, data_time: 0.008, memory: 16167, loss_cls: 0.6234, loss_bbox: 0.9565, d0.loss_cls: 0.6758, d0.loss_bbox: 1.1149, d1.loss_cls: 0.6491, d1.loss_bbox: 1.0052, d2.loss_cls: 0.6401, d2.loss_bbox: 0.9741, d3.loss_cls: 0.6275, d3.loss_bbox: 0.9647, d4.loss_cls: 0.6254, d4.loss_bbox: 0.9598, aux_task0.loss_heatmap: 0.8070, aux_task0.loss_bbox: 0.3196, aux_task1.loss_heatmap: 1.1024, aux_task1.loss_bbox: 0.3678, aux_task2.loss_heatmap: 1.2542, aux_task2.loss_bbox: 0.4043, aux_task3.loss_heatmap: 0.8444, aux_task3.loss_bbox: 0.3117, aux_task4.loss_heatmap: 0.6746, aux_task4.loss_bbox: 0.3216, aux_task5.loss_heatmap: 0.5938, aux_task5.loss_bbox: 0.3135, loss: 17.1316, grad_norm: 34.4101
2025-04-23 17:19:38,580 - mmdet - INFO - Epoch [4][400/1104]	lr: 1.096e-04, eta: 5:13:07, time: 1.014, data_time: 0.008, memory: 16167, loss_cls: 0.6169, loss_bbox: 0.9494, d0.loss_cls: 0.6789, d0.loss_bbox: 1.0986, d1.loss_cls: 0.6516, d1.loss_bbox: 0.9927, d2.loss_cls: 0.6397, d2.loss_bbox: 0.9627, d3.loss_cls: 0.6234, d3.loss_bbox: 0.9543, d4.loss_cls: 0.6196, d4.loss_bbox: 0.9515, aux_task0.loss_heatmap: 0.8208, aux_task0.loss_bbox: 0.3154, aux_task1.loss_heatmap: 1.0636, aux_task1.loss_bbox: 0.3649, aux_task2.loss_heatmap: 1.2569, aux_task2.loss_bbox: 0.3895, aux_task3.loss_heatmap: 0.8371, aux_task3.loss_bbox: 0.3125, aux_task4.loss_heatmap: 0.6349, aux_task4.loss_bbox: 0.3205, aux_task5.loss_heatmap: 0.6151, aux_task5.loss_bbox: 0.3123, loss: 16.9830, grad_norm: 33.1443
2025-04-23 17:20:29,270 - mmdet - INFO - Epoch [4][450/1104]	lr: 1.115e-04, eta: 5:12:14, time: 1.014, data_time: 0.009, memory: 16167, loss_cls: 0.6084, loss_bbox: 0.9472, d0.loss_cls: 0.6666, d0.loss_bbox: 1.0919, d1.loss_cls: 0.6366, d1.loss_bbox: 0.9901, d2.loss_cls: 0.6270, d2.loss_bbox: 0.9631, d3.loss_cls: 0.6133, d3.loss_bbox: 0.9542, d4.loss_cls: 0.6100, d4.loss_bbox: 0.9506, aux_task0.loss_heatmap: 0.8071, aux_task0.loss_bbox: 0.3125, aux_task1.loss_heatmap: 1.0619, aux_task1.loss_bbox: 0.3662, aux_task2.loss_heatmap: 1.2403, aux_task2.loss_bbox: 0.3921, aux_task3.loss_heatmap: 0.7792, aux_task3.loss_bbox: 0.3087, aux_task4.loss_heatmap: 0.6791, aux_task4.loss_bbox: 0.3212, aux_task5.loss_heatmap: 0.5966, aux_task5.loss_bbox: 0.3148, loss: 16.8385, grad_norm: 33.8699
2025-04-23 17:21:19,433 - mmdet - INFO - Epoch [4][500/1104]	lr: 1.135e-04, eta: 5:11:18, time: 1.003, data_time: 0.008, memory: 16167, loss_cls: 0.6013, loss_bbox: 0.9462, d0.loss_cls: 0.6622, d0.loss_bbox: 1.0957, d1.loss_cls: 0.6363, d1.loss_bbox: 0.9918, d2.loss_cls: 0.6247, d2.loss_bbox: 0.9647, d3.loss_cls: 0.6089, d3.loss_bbox: 0.9548, d4.loss_cls: 0.6047, d4.loss_bbox: 0.9503, aux_task0.loss_heatmap: 0.7882, aux_task0.loss_bbox: 0.3113, aux_task1.loss_heatmap: 1.0682, aux_task1.loss_bbox: 0.3576, aux_task2.loss_heatmap: 1.1797, aux_task2.loss_bbox: 0.3858, aux_task3.loss_heatmap: 0.8285, aux_task3.loss_bbox: 0.3135, aux_task4.loss_heatmap: 0.6414, aux_task4.loss_bbox: 0.3187, aux_task5.loss_heatmap: 0.5927, aux_task5.loss_bbox: 0.3140, loss: 16.7414, grad_norm: 35.8082
2025-04-23 17:22:10,123 - mmdet - INFO - Epoch [4][550/1104]	lr: 1.154e-04, eta: 5:10:25, time: 1.014, data_time: 0.008, memory: 16167, loss_cls: 0.5992, loss_bbox: 0.9418, d0.loss_cls: 0.6590, d0.loss_bbox: 1.0908, d1.loss_cls: 0.6334, d1.loss_bbox: 0.9850, d2.loss_cls: 0.6217, d2.loss_bbox: 0.9578, d3.loss_cls: 0.6069, d3.loss_bbox: 0.9492, d4.loss_cls: 0.6009, d4.loss_bbox: 0.9465, aux_task0.loss_heatmap: 0.7885, aux_task0.loss_bbox: 0.3139, aux_task1.loss_heatmap: 1.0300, aux_task1.loss_bbox: 0.3572, aux_task2.loss_heatmap: 1.2332, aux_task2.loss_bbox: 0.3961, aux_task3.loss_heatmap: 0.8145, aux_task3.loss_bbox: 0.3109, aux_task4.loss_heatmap: 0.6309, aux_task4.loss_bbox: 0.3190, aux_task5.loss_heatmap: 0.5970, aux_task5.loss_bbox: 0.3112, loss: 16.6945, grad_norm: 38.1493
2025-04-23 17:23:00,921 - mmdet - INFO - Epoch [4][600/1104]	lr: 1.174e-04, eta: 5:09:32, time: 1.016, data_time: 0.008, memory: 16167, loss_cls: 0.5874, loss_bbox: 0.9359, d0.loss_cls: 0.6502, d0.loss_bbox: 1.0769, d1.loss_cls: 0.6235, d1.loss_bbox: 0.9735, d2.loss_cls: 0.6120, d2.loss_bbox: 0.9489, d3.loss_cls: 0.5940, d3.loss_bbox: 0.9428, d4.loss_cls: 0.5912, d4.loss_bbox: 0.9388, aux_task0.loss_heatmap: 0.7889, aux_task0.loss_bbox: 0.3097, aux_task1.loss_heatmap: 1.0681, aux_task1.loss_bbox: 0.3635, aux_task2.loss_heatmap: 1.1951, aux_task2.loss_bbox: 0.4008, aux_task3.loss_heatmap: 0.8476, aux_task3.loss_bbox: 0.3121, aux_task4.loss_heatmap: 0.6048, aux_task4.loss_bbox: 0.3100, aux_task5.loss_heatmap: 0.6124, aux_task5.loss_bbox: 0.3099, loss: 16.5979, grad_norm: 37.5874
2025-04-23 17:23:51,613 - mmdet - INFO - Epoch [4][650/1104]	lr: 1.194e-04, eta: 5:08:39, time: 1.014, data_time: 0.008, memory: 16167, loss_cls: 0.5957, loss_bbox: 0.9418, d0.loss_cls: 0.6559, d0.loss_bbox: 1.0814, d1.loss_cls: 0.6303, d1.loss_bbox: 0.9821, d2.loss_cls: 0.6174, d2.loss_bbox: 0.9566, d3.loss_cls: 0.6019, d3.loss_bbox: 0.9493, d4.loss_cls: 0.5984, d4.loss_bbox: 0.9458, aux_task0.loss_heatmap: 0.7878, aux_task0.loss_bbox: 0.3134, aux_task1.loss_heatmap: 1.0080, aux_task1.loss_bbox: 0.3599, aux_task2.loss_heatmap: 1.2495, aux_task2.loss_bbox: 0.3967, aux_task3.loss_heatmap: 0.8141, aux_task3.loss_bbox: 0.3126, aux_task4.loss_heatmap: 0.6581, aux_task4.loss_bbox: 0.3171, aux_task5.loss_heatmap: 0.5964, aux_task5.loss_bbox: 0.3119, loss: 16.6820, grad_norm: 33.6012
2025-04-23 17:24:41,989 - mmdet - INFO - Epoch [4][700/1104]	lr: 1.213e-04, eta: 5:07:45, time: 1.008, data_time: 0.007, memory: 16167, loss_cls: 0.5976, loss_bbox: 0.9409, d0.loss_cls: 0.6576, d0.loss_bbox: 1.0850, d1.loss_cls: 0.6308, d1.loss_bbox: 0.9821, d2.loss_cls: 0.6189, d2.loss_bbox: 0.9554, d3.loss_cls: 0.6031, d3.loss_bbox: 0.9478, d4.loss_cls: 0.5996, d4.loss_bbox: 0.9441, aux_task0.loss_heatmap: 0.7851, aux_task0.loss_bbox: 0.3112, aux_task1.loss_heatmap: 1.0273, aux_task1.loss_bbox: 0.3611, aux_task2.loss_heatmap: 1.1592, aux_task2.loss_bbox: 0.3883, aux_task3.loss_heatmap: 0.8144, aux_task3.loss_bbox: 0.3089, aux_task4.loss_heatmap: 0.6141, aux_task4.loss_bbox: 0.3156, aux_task5.loss_heatmap: 0.5979, aux_task5.loss_bbox: 0.3140, loss: 16.5599, grad_norm: 36.6839
2025-04-23 17:25:32,119 - mmdet - INFO - Epoch [4][750/1104]	lr: 1.233e-04, eta: 5:06:50, time: 1.003, data_time: 0.008, memory: 16167, loss_cls: 0.5902, loss_bbox: 0.9246, d0.loss_cls: 0.6506, d0.loss_bbox: 1.0672, d1.loss_cls: 0.6260, d1.loss_bbox: 0.9650, d2.loss_cls: 0.6130, d2.loss_bbox: 0.9395, d3.loss_cls: 0.5960, d3.loss_bbox: 0.9322, d4.loss_cls: 0.5913, d4.loss_bbox: 0.9289, aux_task0.loss_heatmap: 0.7809, aux_task0.loss_bbox: 0.3074, aux_task1.loss_heatmap: 1.0474, aux_task1.loss_bbox: 0.3583, aux_task2.loss_heatmap: 1.1659, aux_task2.loss_bbox: 0.3856, aux_task3.loss_heatmap: 0.8438, aux_task3.loss_bbox: 0.3118, aux_task4.loss_heatmap: 0.6340, aux_task4.loss_bbox: 0.3192, aux_task5.loss_heatmap: 0.5883, aux_task5.loss_bbox: 0.3070, loss: 16.4742, grad_norm: 33.1156
2025-04-23 17:26:22,455 - mmdet - INFO - Epoch [4][800/1104]	lr: 1.253e-04, eta: 5:05:55, time: 1.007, data_time: 0.008, memory: 16167, loss_cls: 0.5893, loss_bbox: 0.9257, d0.loss_cls: 0.6477, d0.loss_bbox: 1.0659, d1.loss_cls: 0.6224, d1.loss_bbox: 0.9659, d2.loss_cls: 0.6113, d2.loss_bbox: 0.9401, d3.loss_cls: 0.5949, d3.loss_bbox: 0.9341, d4.loss_cls: 0.5912, d4.loss_bbox: 0.9301, aux_task0.loss_heatmap: 0.7636, aux_task0.loss_bbox: 0.3059, aux_task1.loss_heatmap: 1.0404, aux_task1.loss_bbox: 0.3590, aux_task2.loss_heatmap: 1.1859, aux_task2.loss_bbox: 0.3843, aux_task3.loss_heatmap: 0.7886, aux_task3.loss_bbox: 0.3040, aux_task4.loss_heatmap: 0.6396, aux_task4.loss_bbox: 0.3116, aux_task5.loss_heatmap: 0.5894, aux_task5.loss_bbox: 0.3098, loss: 16.4007, grad_norm: 30.2966
2025-04-23 17:27:12,877 - mmdet - INFO - Epoch [4][850/1104]	lr: 1.273e-04, eta: 5:05:01, time: 1.008, data_time: 0.007, memory: 16167, loss_cls: 0.5673, loss_bbox: 0.9260, d0.loss_cls: 0.6394, d0.loss_bbox: 1.0629, d1.loss_cls: 0.6056, d1.loss_bbox: 0.9688, d2.loss_cls: 0.5930, d2.loss_bbox: 0.9417, d3.loss_cls: 0.5742, d3.loss_bbox: 0.9344, d4.loss_cls: 0.5712, d4.loss_bbox: 0.9283, aux_task0.loss_heatmap: 0.7375, aux_task0.loss_bbox: 0.3049, aux_task1.loss_heatmap: 1.0348, aux_task1.loss_bbox: 0.3630, aux_task2.loss_heatmap: 1.1634, aux_task2.loss_bbox: 0.3905, aux_task3.loss_heatmap: 0.7626, aux_task3.loss_bbox: 0.3050, aux_task4.loss_heatmap: 0.6127, aux_task4.loss_bbox: 0.3117, aux_task5.loss_heatmap: 0.5844, aux_task5.loss_bbox: 0.3099, loss: 16.1932, grad_norm: 33.5170
2025-04-23 17:28:03,772 - mmdet - INFO - Epoch [4][900/1104]	lr: 1.293e-04, eta: 5:04:10, time: 1.018, data_time: 0.007, memory: 16167, loss_cls: 0.5887, loss_bbox: 0.9299, d0.loss_cls: 0.6514, d0.loss_bbox: 1.0617, d1.loss_cls: 0.6252, d1.loss_bbox: 0.9657, d2.loss_cls: 0.6118, d2.loss_bbox: 0.9413, d3.loss_cls: 0.5948, d3.loss_bbox: 0.9345, d4.loss_cls: 0.5892, d4.loss_bbox: 0.9321, aux_task0.loss_heatmap: 0.7636, aux_task0.loss_bbox: 0.3118, aux_task1.loss_heatmap: 1.0341, aux_task1.loss_bbox: 0.3537, aux_task2.loss_heatmap: 1.1588, aux_task2.loss_bbox: 0.3931, aux_task3.loss_heatmap: 0.8065, aux_task3.loss_bbox: 0.3162, aux_task4.loss_heatmap: 0.6499, aux_task4.loss_bbox: 0.3066, aux_task5.loss_heatmap: 0.5769, aux_task5.loss_bbox: 0.3107, loss: 16.4083, grad_norm: 30.8765
2025-04-23 17:28:54,120 - mmdet - INFO - Epoch [4][950/1104]	lr: 1.313e-04, eta: 5:03:15, time: 1.007, data_time: 0.007, memory: 16167, loss_cls: 0.5830, loss_bbox: 0.9249, d0.loss_cls: 0.6450, d0.loss_bbox: 1.0629, d1.loss_cls: 0.6174, d1.loss_bbox: 0.9675, d2.loss_cls: 0.6063, d2.loss_bbox: 0.9416, d3.loss_cls: 0.5896, d3.loss_bbox: 0.9324, d4.loss_cls: 0.5861, d4.loss_bbox: 0.9282, aux_task0.loss_heatmap: 0.7760, aux_task0.loss_bbox: 0.3109, aux_task1.loss_heatmap: 1.0556, aux_task1.loss_bbox: 0.3611, aux_task2.loss_heatmap: 1.1725, aux_task2.loss_bbox: 0.3871, aux_task3.loss_heatmap: 0.7942, aux_task3.loss_bbox: 0.3080, aux_task4.loss_heatmap: 0.6034, aux_task4.loss_bbox: 0.3127, aux_task5.loss_heatmap: 0.5783, aux_task5.loss_bbox: 0.3115, loss: 16.3564, grad_norm: 32.6954
2025-04-23 17:29:44,663 - mmdet - INFO - Epoch [4][1000/1104]	lr: 1.333e-04, eta: 5:02:22, time: 1.011, data_time: 0.008, memory: 16167, loss_cls: 0.5678, loss_bbox: 0.9225, d0.loss_cls: 0.6301, d0.loss_bbox: 1.0681, d1.loss_cls: 0.6088, d1.loss_bbox: 0.9659, d2.loss_cls: 0.5949, d2.loss_bbox: 0.9399, d3.loss_cls: 0.5760, d3.loss_bbox: 0.9319, d4.loss_cls: 0.5711, d4.loss_bbox: 0.9273, aux_task0.loss_heatmap: 0.7669, aux_task0.loss_bbox: 0.3089, aux_task1.loss_heatmap: 1.0492, aux_task1.loss_bbox: 0.3564, aux_task2.loss_heatmap: 1.1619, aux_task2.loss_bbox: 0.3900, aux_task3.loss_heatmap: 0.7707, aux_task3.loss_bbox: 0.3083, aux_task4.loss_heatmap: 0.5919, aux_task4.loss_bbox: 0.3093, aux_task5.loss_heatmap: 0.5559, aux_task5.loss_bbox: 0.3065, loss: 16.1802, grad_norm: 42.5383
2025-04-23 17:30:35,038 - mmdet - INFO - Epoch [4][1050/1104]	lr: 1.353e-04, eta: 5:01:28, time: 1.008, data_time: 0.008, memory: 16167, loss_cls: 0.5761, loss_bbox: 0.9116, d0.loss_cls: 0.6351, d0.loss_bbox: 1.0555, d1.loss_cls: 0.6120, d1.loss_bbox: 0.9561, d2.loss_cls: 0.5983, d2.loss_bbox: 0.9277, d3.loss_cls: 0.5802, d3.loss_bbox: 0.9220, d4.loss_cls: 0.5770, d4.loss_bbox: 0.9186, aux_task0.loss_heatmap: 0.7624, aux_task0.loss_bbox: 0.3060, aux_task1.loss_heatmap: 1.0208, aux_task1.loss_bbox: 0.3573, aux_task2.loss_heatmap: 1.1315, aux_task2.loss_bbox: 0.3788, aux_task3.loss_heatmap: 0.8001, aux_task3.loss_bbox: 0.3042, aux_task4.loss_heatmap: 0.6215, aux_task4.loss_bbox: 0.3105, aux_task5.loss_heatmap: 0.5804, aux_task5.loss_bbox: 0.3067, loss: 16.1504, grad_norm: 35.8846
2025-04-23 17:31:25,905 - mmdet - INFO - Epoch [4][1100/1104]	lr: 1.373e-04, eta: 5:00:37, time: 1.017, data_time: 0.007, memory: 16195, loss_cls: 0.5713, loss_bbox: 0.9312, d0.loss_cls: 0.6310, d0.loss_bbox: 1.0690, d1.loss_cls: 0.6062, d1.loss_bbox: 0.9687, d2.loss_cls: 0.5926, d2.loss_bbox: 0.9456, d3.loss_cls: 0.5794, d3.loss_bbox: 0.9377, d4.loss_cls: 0.5751, d4.loss_bbox: 0.9335, aux_task0.loss_heatmap: 0.7819, aux_task0.loss_bbox: 0.3067, aux_task1.loss_heatmap: 1.0188, aux_task1.loss_bbox: 0.3566, aux_task2.loss_heatmap: 1.1396, aux_task2.loss_bbox: 0.3901, aux_task3.loss_heatmap: 0.7665, aux_task3.loss_bbox: 0.3034, aux_task4.loss_heatmap: 0.6182, aux_task4.loss_bbox: 0.3185, aux_task5.loss_heatmap: 0.5624, aux_task5.loss_bbox: 0.3095, loss: 16.2133, grad_norm: 39.1882
2025-04-23 17:31:30,386 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-04-23 17:43:47,454 - mmdet - INFO - Exp name: secondmambadss_split14.py
2025-04-23 17:43:47,454 - mmdet - INFO - Epoch(val) [4][3010]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.1688, pts_bbox_NuScenes/car_AP_dist_1.0: 0.4011, pts_bbox_NuScenes/car_AP_dist_2.0: 0.5463, pts_bbox_NuScenes/car_AP_dist_4.0: 0.6319, pts_bbox_NuScenes/car_trans_err: 0.5047, pts_bbox_NuScenes/car_scale_err: 0.2210, pts_bbox_NuScenes/car_orient_err: 1.3335, pts_bbox_NuScenes/car_vel_err: 1.2130, pts_bbox_NuScenes/car_attr_err: 0.4122, pts_bbox_NuScenes/mATE: 0.6837, pts_bbox_NuScenes/mASE: 0.3384, pts_bbox_NuScenes/mAOE: 1.4249, pts_bbox_NuScenes/mAVE: 1.1749, pts_bbox_NuScenes/mAAE: 0.4559, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0013, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0326, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.1044, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.1507, pts_bbox_NuScenes/truck_trans_err: 0.7924, pts_bbox_NuScenes/truck_scale_err: 0.2977, pts_bbox_NuScenes/truck_orient_err: 1.5930, pts_bbox_NuScenes/truck_vel_err: 0.9170, pts_bbox_NuScenes/truck_attr_err: 0.3895, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0142, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0265, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.9942, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.5047, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.4142, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1296, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3529, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0008, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0438, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.1617, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.3096, pts_bbox_NuScenes/bus_trans_err: 0.8766, pts_bbox_NuScenes/bus_scale_err: 0.2799, pts_bbox_NuScenes/bus_orient_err: 1.2302, pts_bbox_NuScenes/bus_vel_err: 2.8470, pts_bbox_NuScenes/bus_attr_err: 0.7143, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0108, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0615, pts_bbox_NuScenes/trailer_trans_err: 1.0626, pts_bbox_NuScenes/trailer_scale_err: 0.3145, pts_bbox_NuScenes/trailer_orient_err: 1.4930, pts_bbox_NuScenes/trailer_vel_err: 0.5676, pts_bbox_NuScenes/trailer_attr_err: 0.2687, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0051, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.1303, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.2770, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.3364, pts_bbox_NuScenes/barrier_trans_err: 0.8031, pts_bbox_NuScenes/barrier_scale_err: 0.3696, pts_bbox_NuScenes/barrier_orient_err: 1.2353, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0403, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0803, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0980, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.1039, pts_bbox_NuScenes/motorcycle_trans_err: 0.4317, pts_bbox_NuScenes/motorcycle_scale_err: 0.2877, pts_bbox_NuScenes/motorcycle_orient_err: 1.3915, pts_bbox_NuScenes/motorcycle_vel_err: 2.2439, pts_bbox_NuScenes/motorcycle_attr_err: 0.5688, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 0.4588, pts_bbox_NuScenes/bicycle_scale_err: 0.3388, pts_bbox_NuScenes/bicycle_orient_err: 1.5897, pts_bbox_NuScenes/bicycle_vel_err: 0.5432, pts_bbox_NuScenes/bicycle_attr_err: 0.1482, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.2139, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.5221, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.5929, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.6299, pts_bbox_NuScenes/pedestrian_trans_err: 0.4862, pts_bbox_NuScenes/pedestrian_scale_err: 0.3149, pts_bbox_NuScenes/pedestrian_orient_err: 1.5434, pts_bbox_NuScenes/pedestrian_vel_err: 0.9383, pts_bbox_NuScenes/pedestrian_attr_err: 0.7929, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.1187, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.1793, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.2122, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.2681, pts_bbox_NuScenes/traffic_cone_trans_err: 0.4266, pts_bbox_NuScenes/traffic_cone_scale_err: 0.4554, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.2331, pts_bbox_NuScenes/mAP: 0.1619
2025-04-23 17:44:43,464 - mmdet - INFO - Epoch [5][50/1104]	lr: 1.395e-04, eta: 4:59:41, time: 1.101, data_time: 0.091, memory: 16195, loss_cls: 0.5579, loss_bbox: 0.9131, d0.loss_cls: 0.6205, d0.loss_bbox: 1.0440, d1.loss_cls: 0.5983, d1.loss_bbox: 0.9490, d2.loss_cls: 0.5825, d2.loss_bbox: 0.9258, d3.loss_cls: 0.5635, d3.loss_bbox: 0.9185, d4.loss_cls: 0.5593, d4.loss_bbox: 0.9148, aux_task0.loss_heatmap: 0.7363, aux_task0.loss_bbox: 0.3019, aux_task1.loss_heatmap: 1.0175, aux_task1.loss_bbox: 0.3507, aux_task2.loss_heatmap: 1.1279, aux_task2.loss_bbox: 0.3877, aux_task3.loss_heatmap: 0.7724, aux_task3.loss_bbox: 0.3078, aux_task4.loss_heatmap: 0.6099, aux_task4.loss_bbox: 0.3097, aux_task5.loss_heatmap: 0.5488, aux_task5.loss_bbox: 0.3066, loss: 15.9243, grad_norm: 34.7243
2025-04-23 17:45:34,320 - mmdet - INFO - Epoch [5][100/1104]	lr: 1.415e-04, eta: 4:58:50, time: 1.017, data_time: 0.009, memory: 16195, loss_cls: 0.5688, loss_bbox: 0.9083, d0.loss_cls: 0.6275, d0.loss_bbox: 1.0396, d1.loss_cls: 0.6037, d1.loss_bbox: 0.9505, d2.loss_cls: 0.5926, d2.loss_bbox: 0.9237, d3.loss_cls: 0.5770, d3.loss_bbox: 0.9142, d4.loss_cls: 0.5717, d4.loss_bbox: 0.9118, aux_task0.loss_heatmap: 0.7411, aux_task0.loss_bbox: 0.3033, aux_task1.loss_heatmap: 1.0404, aux_task1.loss_bbox: 0.3544, aux_task2.loss_heatmap: 1.0907, aux_task2.loss_bbox: 0.3758, aux_task3.loss_heatmap: 0.7987, aux_task3.loss_bbox: 0.3062, aux_task4.loss_heatmap: 0.6015, aux_task4.loss_bbox: 0.3164, aux_task5.loss_heatmap: 0.5755, aux_task5.loss_bbox: 0.3065, loss: 15.9999, grad_norm: 32.1558
2025-04-23 17:46:24,739 - mmdet - INFO - Epoch [5][150/1104]	lr: 1.435e-04, eta: 4:57:56, time: 1.008, data_time: 0.008, memory: 16195, loss_cls: 0.5602, loss_bbox: 0.9143, d0.loss_cls: 0.6287, d0.loss_bbox: 1.0435, d1.loss_cls: 0.5990, d1.loss_bbox: 0.9530, d2.loss_cls: 0.5841, d2.loss_bbox: 0.9296, d3.loss_cls: 0.5695, d3.loss_bbox: 0.9212, d4.loss_cls: 0.5637, d4.loss_bbox: 0.9182, aux_task0.loss_heatmap: 0.7432, aux_task0.loss_bbox: 0.3020, aux_task1.loss_heatmap: 1.0092, aux_task1.loss_bbox: 0.3546, aux_task2.loss_heatmap: 1.1170, aux_task2.loss_bbox: 0.3818, aux_task3.loss_heatmap: 0.8109, aux_task3.loss_bbox: 0.3063, aux_task4.loss_heatmap: 0.5963, aux_task4.loss_bbox: 0.3098, aux_task5.loss_heatmap: 0.5654, aux_task5.loss_bbox: 0.3048, loss: 15.9860, grad_norm: 32.4476
2025-04-23 17:47:15,180 - mmdet - INFO - Epoch [5][200/1104]	lr: 1.455e-04, eta: 4:57:03, time: 1.009, data_time: 0.008, memory: 16195, loss_cls: 0.5563, loss_bbox: 0.9222, d0.loss_cls: 0.6221, d0.loss_bbox: 1.0479, d1.loss_cls: 0.5991, d1.loss_bbox: 0.9545, d2.loss_cls: 0.5814, d2.loss_bbox: 0.9340, d3.loss_cls: 0.5637, d3.loss_bbox: 0.9285, d4.loss_cls: 0.5596, d4.loss_bbox: 0.9243, aux_task0.loss_heatmap: 0.7411, aux_task0.loss_bbox: 0.3046, aux_task1.loss_heatmap: 0.9955, aux_task1.loss_bbox: 0.3587, aux_task2.loss_heatmap: 1.0897, aux_task2.loss_bbox: 0.3795, aux_task3.loss_heatmap: 0.7800, aux_task3.loss_bbox: 0.3089, aux_task4.loss_heatmap: 0.5797, aux_task4.loss_bbox: 0.3089, aux_task5.loss_heatmap: 0.5782, aux_task5.loss_bbox: 0.3137, loss: 15.9321, grad_norm: 35.0759
2025-04-23 17:48:05,737 - mmdet - INFO - Epoch [5][250/1104]	lr: 1.475e-04, eta: 4:56:10, time: 1.011, data_time: 0.008, memory: 16195, loss_cls: 0.5642, loss_bbox: 0.9104, d0.loss_cls: 0.6275, d0.loss_bbox: 1.0353, d1.loss_cls: 0.5977, d1.loss_bbox: 0.9431, d2.loss_cls: 0.5836, d2.loss_bbox: 0.9217, d3.loss_cls: 0.5687, d3.loss_bbox: 0.9165, d4.loss_cls: 0.5650, d4.loss_bbox: 0.9136, aux_task0.loss_heatmap: 0.7470, aux_task0.loss_bbox: 0.3021, aux_task1.loss_heatmap: 1.0052, aux_task1.loss_bbox: 0.3570, aux_task2.loss_heatmap: 1.0934, aux_task2.loss_bbox: 0.3740, aux_task3.loss_heatmap: 0.7926, aux_task3.loss_bbox: 0.3028, aux_task4.loss_heatmap: 0.6071, aux_task4.loss_bbox: 0.3094, aux_task5.loss_heatmap: 0.5655, aux_task5.loss_bbox: 0.3084, loss: 15.9119, grad_norm: 35.9707
2025-04-23 17:48:56,546 - mmdet - INFO - Epoch [5][300/1104]	lr: 1.494e-04, eta: 4:55:18, time: 1.016, data_time: 0.008, memory: 16195, loss_cls: 0.5551, loss_bbox: 0.9109, d0.loss_cls: 0.6143, d0.loss_bbox: 1.0434, d1.loss_cls: 0.5901, d1.loss_bbox: 0.9499, d2.loss_cls: 0.5781, d2.loss_bbox: 0.9267, d3.loss_cls: 0.5625, d3.loss_bbox: 0.9179, d4.loss_cls: 0.5578, d4.loss_bbox: 0.9152, aux_task0.loss_heatmap: 0.7486, aux_task0.loss_bbox: 0.3016, aux_task1.loss_heatmap: 1.0075, aux_task1.loss_bbox: 0.3512, aux_task2.loss_heatmap: 1.0722, aux_task2.loss_bbox: 0.3867, aux_task3.loss_heatmap: 0.7856, aux_task3.loss_bbox: 0.3043, aux_task4.loss_heatmap: 0.5939, aux_task4.loss_bbox: 0.3025, aux_task5.loss_heatmap: 0.5611, aux_task5.loss_bbox: 0.3077, loss: 15.8447, grad_norm: 36.4588
2025-04-23 17:49:47,001 - mmdet - INFO - Epoch [5][350/1104]	lr: 1.514e-04, eta: 4:54:25, time: 1.009, data_time: 0.007, memory: 16195, loss_cls: 0.5571, loss_bbox: 0.9131, d0.loss_cls: 0.6229, d0.loss_bbox: 1.0344, d1.loss_cls: 0.5956, d1.loss_bbox: 0.9448, d2.loss_cls: 0.5803, d2.loss_bbox: 0.9239, d3.loss_cls: 0.5648, d3.loss_bbox: 0.9168, d4.loss_cls: 0.5592, d4.loss_bbox: 0.9145, aux_task0.loss_heatmap: 0.7266, aux_task0.loss_bbox: 0.3022, aux_task1.loss_heatmap: 1.0241, aux_task1.loss_bbox: 0.3556, aux_task2.loss_heatmap: 1.1020, aux_task2.loss_bbox: 0.3818, aux_task3.loss_heatmap: 0.7796, aux_task3.loss_bbox: 0.3074, aux_task4.loss_heatmap: 0.6059, aux_task4.loss_bbox: 0.3109, aux_task5.loss_heatmap: 0.5748, aux_task5.loss_bbox: 0.3045, loss: 15.9029, grad_norm: 32.6163
2025-04-23 17:50:37,575 - mmdet - INFO - Epoch [5][400/1104]	lr: 1.534e-04, eta: 4:53:33, time: 1.011, data_time: 0.008, memory: 16195, loss_cls: 0.5467, loss_bbox: 0.8969, d0.loss_cls: 0.6111, d0.loss_bbox: 1.0221, d1.loss_cls: 0.5849, d1.loss_bbox: 0.9324, d2.loss_cls: 0.5702, d2.loss_bbox: 0.9095, d3.loss_cls: 0.5553, d3.loss_bbox: 0.9033, d4.loss_cls: 0.5513, d4.loss_bbox: 0.9009, aux_task0.loss_heatmap: 0.7462, aux_task0.loss_bbox: 0.3045, aux_task1.loss_heatmap: 0.9762, aux_task1.loss_bbox: 0.3511, aux_task2.loss_heatmap: 1.1160, aux_task2.loss_bbox: 0.3757, aux_task3.loss_heatmap: 0.7628, aux_task3.loss_bbox: 0.3000, aux_task4.loss_heatmap: 0.5771, aux_task4.loss_bbox: 0.3086, aux_task5.loss_heatmap: 0.5547, aux_task5.loss_bbox: 0.3028, loss: 15.6602, grad_norm: 34.0115
2025-04-23 17:51:28,468 - mmdet - INFO - Epoch [5][450/1104]	lr: 1.554e-04, eta: 4:52:41, time: 1.018, data_time: 0.007, memory: 16195, loss_cls: 0.5454, loss_bbox: 0.8994, d0.loss_cls: 0.6149, d0.loss_bbox: 1.0228, d1.loss_cls: 0.5858, d1.loss_bbox: 0.9348, d2.loss_cls: 0.5692, d2.loss_bbox: 0.9152, d3.loss_cls: 0.5536, d3.loss_bbox: 0.9059, d4.loss_cls: 0.5483, d4.loss_bbox: 0.9034, aux_task0.loss_heatmap: 0.7368, aux_task0.loss_bbox: 0.3058, aux_task1.loss_heatmap: 0.9914, aux_task1.loss_bbox: 0.3499, aux_task2.loss_heatmap: 1.0921, aux_task2.loss_bbox: 0.3754, aux_task3.loss_heatmap: 0.7506, aux_task3.loss_bbox: 0.2987, aux_task4.loss_heatmap: 0.6096, aux_task4.loss_bbox: 0.3097, aux_task5.loss_heatmap: 0.5792, aux_task5.loss_bbox: 0.3053, loss: 15.7032, grad_norm: 30.9023
2025-04-23 17:52:18,950 - mmdet - INFO - Epoch [5][500/1104]	lr: 1.574e-04, eta: 4:51:48, time: 1.010, data_time: 0.008, memory: 16195, loss_cls: 0.5474, loss_bbox: 0.9026, d0.loss_cls: 0.6162, d0.loss_bbox: 1.0191, d1.loss_cls: 0.5861, d1.loss_bbox: 0.9351, d2.loss_cls: 0.5693, d2.loss_bbox: 0.9141, d3.loss_cls: 0.5542, d3.loss_bbox: 0.9078, d4.loss_cls: 0.5490, d4.loss_bbox: 0.9058, aux_task0.loss_heatmap: 0.7470, aux_task0.loss_bbox: 0.3011, aux_task1.loss_heatmap: 1.0040, aux_task1.loss_bbox: 0.3466, aux_task2.loss_heatmap: 1.0359, aux_task2.loss_bbox: 0.3698, aux_task3.loss_heatmap: 0.7841, aux_task3.loss_bbox: 0.2944, aux_task4.loss_heatmap: 0.5840, aux_task4.loss_bbox: 0.3080, aux_task5.loss_heatmap: 0.5691, aux_task5.loss_bbox: 0.3073, loss: 15.6578, grad_norm: 34.1633
2025-04-23 17:53:09,528 - mmdet - INFO - Epoch [5][550/1104]	lr: 1.593e-04, eta: 4:50:56, time: 1.012, data_time: 0.008, memory: 16195, loss_cls: 0.5428, loss_bbox: 0.9046, d0.loss_cls: 0.6100, d0.loss_bbox: 1.0277, d1.loss_cls: 0.5826, d1.loss_bbox: 0.9408, d2.loss_cls: 0.5699, d2.loss_bbox: 0.9191, d3.loss_cls: 0.5518, d3.loss_bbox: 0.9110, d4.loss_cls: 0.5463, d4.loss_bbox: 0.9071, aux_task0.loss_heatmap: 0.7294, aux_task0.loss_bbox: 0.2997, aux_task1.loss_heatmap: 0.9621, aux_task1.loss_bbox: 0.3468, aux_task2.loss_heatmap: 1.1022, aux_task2.loss_bbox: 0.3839, aux_task3.loss_heatmap: 0.7736, aux_task3.loss_bbox: 0.3131, aux_task4.loss_heatmap: 0.5640, aux_task4.loss_bbox: 0.3063, aux_task5.loss_heatmap: 0.5655, aux_task5.loss_bbox: 0.3089, loss: 15.6691, grad_norm: 30.4520
2025-04-23 17:54:00,141 - mmdet - INFO - Epoch [5][600/1104]	lr: 1.613e-04, eta: 4:50:03, time: 1.012, data_time: 0.008, memory: 16195, loss_cls: 0.5294, loss_bbox: 0.9034, d0.loss_cls: 0.6014, d0.loss_bbox: 1.0284, d1.loss_cls: 0.5708, d1.loss_bbox: 0.9403, d2.loss_cls: 0.5556, d2.loss_bbox: 0.9185, d3.loss_cls: 0.5371, d3.loss_bbox: 0.9116, d4.loss_cls: 0.5332, d4.loss_bbox: 0.9075, aux_task0.loss_heatmap: 0.7260, aux_task0.loss_bbox: 0.3058, aux_task1.loss_heatmap: 0.9879, aux_task1.loss_bbox: 0.3504, aux_task2.loss_heatmap: 1.0679, aux_task2.loss_bbox: 0.3801, aux_task3.loss_heatmap: 0.7411, aux_task3.loss_bbox: 0.3025, aux_task4.loss_heatmap: 0.5593, aux_task4.loss_bbox: 0.3017, aux_task5.loss_heatmap: 0.5543, aux_task5.loss_bbox: 0.3086, loss: 15.5225, grad_norm: 33.1150
2025-04-23 17:54:50,648 - mmdet - INFO - Epoch [5][650/1104]	lr: 1.632e-04, eta: 4:49:11, time: 1.010, data_time: 0.008, memory: 16195, loss_cls: 0.5312, loss_bbox: 0.8977, d0.loss_cls: 0.5991, d0.loss_bbox: 1.0217, d1.loss_cls: 0.5701, d1.loss_bbox: 0.9372, d2.loss_cls: 0.5552, d2.loss_bbox: 0.9132, d3.loss_cls: 0.5382, d3.loss_bbox: 0.9054, d4.loss_cls: 0.5338, d4.loss_bbox: 0.9020, aux_task0.loss_heatmap: 0.7264, aux_task0.loss_bbox: 0.2999, aux_task1.loss_heatmap: 0.9400, aux_task1.loss_bbox: 0.3463, aux_task2.loss_heatmap: 1.0890, aux_task2.loss_bbox: 0.3870, aux_task3.loss_heatmap: 0.7740, aux_task3.loss_bbox: 0.3053, aux_task4.loss_heatmap: 0.6013, aux_task4.loss_bbox: 0.3081, aux_task5.loss_heatmap: 0.5448, aux_task5.loss_bbox: 0.3071, loss: 15.5339, grad_norm: 32.5465
2025-04-23 17:55:41,000 - mmdet - INFO - Epoch [5][700/1104]	lr: 1.652e-04, eta: 4:48:18, time: 1.007, data_time: 0.008, memory: 16195, loss_cls: 0.5250, loss_bbox: 0.8863, d0.loss_cls: 0.5949, d0.loss_bbox: 1.0150, d1.loss_cls: 0.5660, d1.loss_bbox: 0.9253, d2.loss_cls: 0.5491, d2.loss_bbox: 0.9013, d3.loss_cls: 0.5329, d3.loss_bbox: 0.8941, d4.loss_cls: 0.5276, d4.loss_bbox: 0.8915, aux_task0.loss_heatmap: 0.7163, aux_task0.loss_bbox: 0.2949, aux_task1.loss_heatmap: 0.9562, aux_task1.loss_bbox: 0.3502, aux_task2.loss_heatmap: 1.0564, aux_task2.loss_bbox: 0.3763, aux_task3.loss_heatmap: 0.7433, aux_task3.loss_bbox: 0.2996, aux_task4.loss_heatmap: 0.5598, aux_task4.loss_bbox: 0.3076, aux_task5.loss_heatmap: 0.5409, aux_task5.loss_bbox: 0.2992, loss: 15.3097, grad_norm: 30.7810
